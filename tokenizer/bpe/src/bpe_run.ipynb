{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dacb26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6745884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bpe import BPETokenizer\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c6d868",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('../../data/historyOfChina.txt', 'r', encoding='utf-8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cac6fbe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 8/4744 [00:00<01:00, 78.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256/4744 pairs merged. (32, 116) -> b' t' occured 1724 times.\n",
      "257/4744 pairs merged. (104, 101) -> b'he' occured 1605 times.\n",
      "258/4744 pairs merged. (105, 110) -> b'in' occured 1562 times.\n",
      "259/4744 pairs merged. (97, 110) -> b'an' occured 1317 times.\n",
      "260/4744 pairs merged. (256, 257) -> b' the' occured 1151 times.\n",
      "261/4744 pairs merged. (101, 114) -> b'er' occured 957 times.\n",
      "262/4744 pairs merged. (111, 110) -> b'on' occured 830 times.\n",
      "263/4744 pairs merged. (101, 100) -> b'ed' occured 795 times.\n",
      "264/4744 pairs merged. (115, 116) -> b'st' occured 775 times.\n",
      "265/4744 pairs merged. (114, 101) -> b're' occured 692 times.\n",
      "266/4744 pairs merged. (32, 111) -> b' o' occured 680 times.\n",
      "267/4744 pairs merged. (32, 97) -> b' a' occured 677 times.\n",
      "268/4744 pairs merged. (101, 110) -> b'en' occured 646 times.\n",
      "269/4744 pairs merged. (97, 116) -> b'at' occured 603 times.\n",
      "270/4744 pairs merged. (32, 119) -> b' w' occured 598 times.\n",
      "271/4744 pairs merged. (32, 99) -> b' c' occured 544 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 28/4744 [00:00<00:54, 86.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "272/4744 pairs merged. (266, 102) -> b' of' occured 541 times.\n",
      "273/4744 pairs merged. (105, 116) -> b'it' occured 540 times.\n",
      "274/4744 pairs merged. (259, 100) -> b'and' occured 540 times.\n",
      "275/4744 pairs merged. (97, 108) -> b'al' occured 517 times.\n",
      "276/4744 pairs merged. (111, 114) -> b'or' occured 506 times.\n",
      "277/4744 pairs merged. (32, 258) -> b' in' occured 496 times.\n",
      "278/4744 pairs merged. (258, 103) -> b'ing' occured 480 times.\n",
      "279/4744 pairs merged. (32, 274) -> b' and' occured 453 times.\n",
      "280/4744 pairs merged. (32, 115) -> b' s' occured 445 times.\n",
      "281/4744 pairs merged. (101, 115) -> b'es' occured 439 times.\n",
      "282/4744 pairs merged. (32, 100) -> b' d' occured 435 times.\n",
      "283/4744 pairs merged. (32, 112) -> b' p' occured 405 times.\n",
      "284/4744 pairs merged. (32, 102) -> b' f' occured 405 times.\n",
      "285/4744 pairs merged. (97, 114) -> b'ar' occured 382 times.\n",
      "286/4744 pairs merged. (111, 117) -> b'ou' occured 363 times.\n",
      "287/4744 pairs merged. (105, 99) -> b'ic' occured 353 times.\n",
      "288/4744 pairs merged. (32, 98) -> b' b' occured 353 times.\n",
      "289/4744 pairs merged. (32, 67) -> b' C' occured 337 times.\n",
      "290/4744 pairs merged. (105, 262) -> b'ion' occured 322 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 48/4744 [00:00<00:52, 90.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "291/4744 pairs merged. (32, 101) -> b' e' occured 315 times.\n",
      "292/4744 pairs merged. (268, 116) -> b'ent' occured 297 times.\n",
      "293/4744 pairs merged. (32, 109) -> b' m' occured 291 times.\n",
      "294/4744 pairs merged. (105, 115) -> b'is' occured 281 times.\n",
      "295/4744 pairs merged. (97, 115) -> b'as' occured 276 times.\n",
      "296/4744 pairs merged. (256, 111) -> b' to' occured 268 times.\n",
      "297/4744 pairs merged. (289, 104) -> b' Ch' occured 257 times.\n",
      "298/4744 pairs merged. (111, 109) -> b'om' occured 257 times.\n",
      "299/4744 pairs merged. (32, 84) -> b' T' occured 253 times.\n",
      "300/4744 pairs merged. (32, 108) -> b' l' occured 246 times.\n",
      "301/4744 pairs merged. (32, 265) -> b' re' occured 244 times.\n",
      "302/4744 pairs merged. (297, 258) -> b' Chin' occured 230 times.\n",
      "303/4744 pairs merged. (97, 264) -> b'ast' occured 228 times.\n",
      "304/4744 pairs merged. (108, 121) -> b'ly' occured 227 times.\n",
      "305/4744 pairs merged. (111, 108) -> b'ol' occured 213 times.\n",
      "306/4744 pairs merged. (32, 83) -> b' S' occured 208 times.\n",
      "307/4744 pairs merged. (117, 114) -> b'ur' occured 207 times.\n",
      "308/4744 pairs merged. (105, 108) -> b'il' occured 198 times.\n",
      "309/4744 pairs merged. (61, 61) -> b'==' occured 186 times.\n",
      "310/4744 pairs merged. (32, 104) -> b' h' occured 180 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|▏         | 68/4744 [00:00<00:54, 85.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "311/4744 pairs merged. (259, 103) -> b'ang' occured 180 times.\n",
      "312/4744 pairs merged. (109, 112) -> b'mp' occured 180 times.\n",
      "313/4744 pairs merged. (105, 118) -> b'iv' occured 177 times.\n",
      "314/4744 pairs merged. (117, 108) -> b'ul' occured 170 times.\n",
      "315/4744 pairs merged. (32, 77) -> b' M' occured 165 times.\n",
      "316/4744 pairs merged. (121, 110) -> b'yn' occured 163 times.\n",
      "317/4744 pairs merged. (316, 303) -> b'ynast' occured 161 times.\n",
      "318/4744 pairs merged. (282, 317) -> b' dynast' occured 158 times.\n",
      "319/4744 pairs merged. (101, 99) -> b'ec' occured 153 times.\n",
      "320/4744 pairs merged. (32, 110) -> b' n' occured 152 times.\n",
      "321/4744 pairs merged. (97, 100) -> b'ad' occured 151 times.\n",
      "322/4744 pairs merged. (111, 119) -> b'ow' occured 147 times.\n",
      "323/4744 pairs merged. (262, 103) -> b'ong' occured 144 times.\n",
      "324/4744 pairs merged. (318, 121) -> b' dynasty' occured 143 times.\n",
      "325/4744 pairs merged. (32, 103) -> b' g' occured 142 times.\n",
      "326/4744 pairs merged. (270, 295) -> b' was' occured 142 times.\n",
      "327/4744 pairs merged. (267, 115) -> b' as' occured 138 times.\n",
      "328/4744 pairs merged. (302, 97) -> b' China' occured 137 times.\n",
      "329/4744 pairs merged. (118, 261) -> b'ver' occured 135 times.\n",
      "330/4744 pairs merged. (271, 262) -> b' con' occured 134 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 89/4744 [00:01<00:52, 89.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "331/4744 pairs merged. (32, 66) -> b' B' occured 134 times.\n",
      "332/4744 pairs merged. (114, 111) -> b'ro' occured 132 times.\n",
      "333/4744 pairs merged. (269, 290) -> b'ation' occured 132 times.\n",
      "334/4744 pairs merged. (117, 110) -> b'un' occured 129 times.\n",
      "335/4744 pairs merged. (105, 264) -> b'ist' occured 128 times.\n",
      "336/4744 pairs merged. (299, 257) -> b' The' occured 128 times.\n",
      "337/4744 pairs merged. (32, 264) -> b' st' occured 127 times.\n",
      "338/4744 pairs merged. (101, 116) -> b'et' occured 127 times.\n",
      "339/4744 pairs merged. (273, 104) -> b'ith' occured 124 times.\n",
      "340/4744 pairs merged. (10, 10) -> b'\\n\\n' occured 123 times.\n",
      "341/4744 pairs merged. (99, 104) -> b'ch' occured 122 times.\n",
      "342/4744 pairs merged. (256, 104) -> b' th' occured 121 times.\n",
      "343/4744 pairs merged. (99, 101) -> b'ce' occured 121 times.\n",
      "344/4744 pairs merged. (116, 257) -> b'the' occured 121 times.\n",
      "345/4744 pairs merged. (108, 101) -> b'le' occured 117 times.\n",
      "346/4744 pairs merged. (32, 65) -> b' A' occured 115 times.\n",
      "347/4744 pairs merged. (281, 101) -> b'ese' occured 112 times.\n",
      "348/4744 pairs merged. (116, 104) -> b'th' occured 112 times.\n",
      "349/4744 pairs merged. (105, 100) -> b'id' occured 110 times.\n",
      "350/4744 pairs merged. (105, 281) -> b'ies' occured 109 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 110/4744 [00:01<00:53, 87.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351/4744 pairs merged. (32, 40) -> b' (' occured 109 times.\n",
      "352/4744 pairs merged. (288, 121) -> b' by' occured 109 times.\n",
      "353/4744 pairs merged. (105, 109) -> b'im' occured 106 times.\n",
      "354/4744 pairs merged. (32, 87) -> b' W' occured 106 times.\n",
      "355/4744 pairs merged. (284, 276) -> b' for' occured 104 times.\n",
      "356/4744 pairs merged. (32, 72) -> b' H' occured 104 times.\n",
      "357/4744 pairs merged. (109, 292) -> b'ment' occured 103 times.\n",
      "358/4744 pairs merged. (101, 108) -> b'el' occured 102 times.\n",
      "359/4744 pairs merged. (344, 114) -> b'ther' occured 102 times.\n",
      "360/4744 pairs merged. (97, 99) -> b'ac' occured 101 times.\n",
      "361/4744 pairs merged. (117, 116) -> b'ut' occured 101 times.\n",
      "362/4744 pairs merged. (111, 112) -> b'op' occured 101 times.\n",
      "363/4744 pairs merged. (270, 104) -> b' wh' occured 100 times.\n",
      "364/4744 pairs merged. (261, 101) -> b'ere' occured 100 times.\n",
      "365/4744 pairs merged. (270, 339) -> b' with' occured 98 times.\n",
      "366/4744 pairs merged. (270, 364) -> b' were' occured 98 times.\n",
      "367/4744 pairs merged. (32, 114) -> b' r' occured 97 times.\n",
      "368/4744 pairs merged. (105, 103) -> b'ig' occured 97 times.\n",
      "369/4744 pairs merged. (32, 69) -> b' E' occured 94 times.\n",
      "370/4744 pairs merged. (101, 264) -> b'est' occured 94 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 133/4744 [00:01<00:50, 91.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "371/4744 pairs merged. (302, 347) -> b' Chinese' occured 93 times.\n",
      "372/4744 pairs merged. (105, 275) -> b'ial' occured 90 times.\n",
      "373/4744 pairs merged. (280, 117) -> b' su' occured 89 times.\n",
      "374/4744 pairs merged. (97, 112) -> b'ap' occured 88 times.\n",
      "375/4744 pairs merged. (269, 263) -> b'ated' occured 88 times.\n",
      "376/4744 pairs merged. (97, 258) -> b'ain' occured 87 times.\n",
      "377/4744 pairs merged. (115, 101) -> b'se' occured 87 times.\n",
      "378/4744 pairs merged. (111, 100) -> b'od' occured 84 times.\n",
      "379/4744 pairs merged. (105, 259) -> b'ian' occured 84 times.\n",
      "380/4744 pairs merged. (288, 101) -> b' be' occured 81 times.\n",
      "381/4744 pairs merged. (117, 265) -> b'ure' occured 80 times.\n",
      "382/4744 pairs merged. (105, 114) -> b'ir' occured 79 times.\n",
      "383/4744 pairs merged. (312, 261) -> b'mper' occured 79 times.\n",
      "384/4744 pairs merged. (97, 109) -> b'am' occured 79 times.\n",
      "385/4744 pairs merged. (291, 120) -> b' ex' occured 77 times.\n",
      "386/4744 pairs merged. (32, 262) -> b' on' occured 76 times.\n",
      "387/4744 pairs merged. (282, 101) -> b' de' occured 75 times.\n",
      "388/4744 pairs merged. (314, 116) -> b'ult' occured 74 times.\n",
      "389/4744 pairs merged. (105, 97) -> b'ia' occured 73 times.\n",
      "390/4744 pairs merged. (269, 101) -> b'ate' occured 73 times.\n",
      "391/4744 pairs merged. (32, 82) -> b' R' occured 72 times.\n",
      "392/4744 pairs merged. (267, 108) -> b' al' occured 72 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 156/4744 [00:01<00:49, 92.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393/4744 pairs merged. (261, 115) -> b'ers' occured 72 times.\n",
      "394/4744 pairs merged. (46, 10) -> b'.\\n' occured 71 times.\n",
      "395/4744 pairs merged. (32, 89) -> b' Y' occured 70 times.\n",
      "396/4744 pairs merged. (226, 128) -> b'\\xe2\\x80' occured 70 times.\n",
      "397/4744 pairs merged. (32, 76) -> b' L' occured 70 times.\n",
      "398/4744 pairs merged. (267, 116) -> b' at' occured 70 times.\n",
      "399/4744 pairs merged. (32, 80) -> b' P' occured 69 times.\n",
      "400/4744 pairs merged. (283, 332) -> b' pro' occured 68 times.\n",
      "401/4744 pairs merged. (256, 114) -> b' tr' occured 68 times.\n",
      "402/4744 pairs merged. (32, 273) -> b' it' occured 68 times.\n",
      "403/4744 pairs merged. (286, 110) -> b'oun' occured 68 times.\n",
      "404/4744 pairs merged. (261, 110) -> b'ern' occured 68 times.\n",
      "405/4744 pairs merged. (32, 73) -> b' I' occured 68 times.\n",
      "406/4744 pairs merged. (287, 104) -> b'ich' occured 67 times.\n",
      "407/4744 pairs merged. (32, 78) -> b' N' occured 67 times.\n",
      "408/4744 pairs merged. (32, 90) -> b' Z' occured 66 times.\n",
      "409/4744 pairs merged. (113, 117) -> b'qu' occured 66 times.\n",
      "410/4744 pairs merged. (32, 259) -> b' an' occured 65 times.\n",
      "411/4744 pairs merged. (97, 118) -> b'av' occured 65 times.\n",
      "412/4744 pairs merged. (116, 115) -> b'ts' occured 65 times.\n",
      "413/4744 pairs merged. (117, 115) -> b'us' occured 65 times.\n",
      "414/4744 pairs merged. (32, 74) -> b' J' occured 65 times.\n",
      "415/4744 pairs merged. (284, 114) -> b' fr' occured 64 times.\n",
      "416/4744 pairs merged. (116, 263) -> b'ted' occured 64 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 179/4744 [00:01<00:48, 94.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "417/4744 pairs merged. (287, 275) -> b'ical' occured 63 times.\n",
      "418/4744 pairs merged. (286, 115) -> b'ous' occured 63 times.\n",
      "419/4744 pairs merged. (49, 57) -> b'19' occured 61 times.\n",
      "420/4744 pairs merged. (32, 75) -> b' K' occured 61 times.\n",
      "421/4744 pairs merged. (363, 406) -> b' which' occured 60 times.\n",
      "422/4744 pairs merged. (313, 101) -> b'ive' occured 59 times.\n",
      "423/4744 pairs merged. (32, 334) -> b' un' occured 58 times.\n",
      "424/4744 pairs merged. (39, 115) -> b\"'s\" occured 58 times.\n",
      "425/4744 pairs merged. (293, 111) -> b' mo' occured 58 times.\n",
      "426/4744 pairs merged. (111, 329) -> b'over' occured 58 times.\n",
      "427/4744 pairs merged. (261, 105) -> b'eri' occured 57 times.\n",
      "428/4744 pairs merged. (402, 115) -> b' its' occured 57 times.\n",
      "429/4744 pairs merged. (306, 104) -> b' Sh' occured 56 times.\n",
      "430/4744 pairs merged. (415, 298) -> b' from' occured 56 times.\n",
      "431/4744 pairs merged. (97, 98) -> b'ab' occured 56 times.\n",
      "432/4744 pairs merged. (105, 265) -> b'ire' occured 55 times.\n",
      "433/4744 pairs merged. (32, 268) -> b' en' occured 55 times.\n",
      "434/4744 pairs merged. (103, 101) -> b'ge' occured 54 times.\n",
      "435/4744 pairs merged. (103, 104) -> b'gh' occured 54 times.\n",
      "436/4744 pairs merged. (117, 99) -> b'uc' occured 54 times.\n",
      "437/4744 pairs merged. (48, 48) -> b'00' occured 54 times.\n",
      "438/4744 pairs merged. (105, 102) -> b'if' occured 52 times.\n",
      "439/4744 pairs merged. (331, 67) -> b' BC' occured 52 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 202/4744 [00:02<00:47, 95.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "440/4744 pairs merged. (111, 99) -> b'oc' occured 52 times.\n",
      "441/4744 pairs merged. (396, 147) -> b'\\xe2\\x80\\x93' occured 52 times.\n",
      "442/4744 pairs merged. (283, 427) -> b' peri' occured 51 times.\n",
      "443/4744 pairs merged. (442, 378) -> b' period' occured 51 times.\n",
      "444/4744 pairs merged. (277, 116) -> b' int' occured 51 times.\n",
      "445/4744 pairs merged. (330, 116) -> b' cont' occured 51 times.\n",
      "446/4744 pairs merged. (32, 107) -> b' k' occured 51 times.\n",
      "447/4744 pairs merged. (359, 110) -> b'thern' occured 50 times.\n",
      "448/4744 pairs merged. (285, 121) -> b'ary' occured 50 times.\n",
      "449/4744 pairs merged. (293, 308) -> b' mil' occured 49 times.\n",
      "450/4744 pairs merged. (271, 298) -> b' com' occured 49 times.\n",
      "451/4744 pairs merged. (32, 81) -> b' Q' occured 49 times.\n",
      "452/4744 pairs merged. (275, 304) -> b'ally' occured 49 times.\n",
      "453/4744 pairs merged. (105, 122) -> b'iz' occured 48 times.\n",
      "454/4744 pairs merged. (383, 276) -> b'mperor' occured 48 times.\n",
      "455/4744 pairs merged. (32, 68) -> b' D' occured 48 times.\n",
      "456/4744 pairs merged. (277, 99) -> b' inc' occured 47 times.\n",
      "457/4744 pairs merged. (32, 88) -> b' X' occured 47 times.\n",
      "458/4744 pairs merged. (307, 278) -> b'uring' occured 47 times.\n",
      "459/4744 pairs merged. (405, 110) -> b' In' occured 47 times.\n",
      "460/4744 pairs merged. (100, 261) -> b'der' occured 46 times.\n",
      "461/4744 pairs merged. (267, 114) -> b' ar' occured 46 times.\n",
      "462/4744 pairs merged. (32, 118) -> b' v' occured 45 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 224/4744 [00:02<00:47, 95.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "463/4744 pairs merged. (117, 109) -> b'um' occured 45 times.\n",
      "464/4744 pairs merged. (408, 104) -> b' Zh' occured 45 times.\n",
      "465/4744 pairs merged. (368, 110) -> b'ign' occured 45 times.\n",
      "466/4744 pairs merged. (32, 71) -> b' G' occured 45 times.\n",
      "467/4744 pairs merged. (273, 121) -> b'ity' occured 44 times.\n",
      "468/4744 pairs merged. (105, 98) -> b'ib' occured 44 times.\n",
      "469/4744 pairs merged. (271, 292) -> b' cent' occured 44 times.\n",
      "470/4744 pairs merged. (342, 269) -> b' that' occured 44 times.\n",
      "471/4744 pairs merged. (116, 261) -> b'ter' occured 44 times.\n",
      "472/4744 pairs merged. (84, 257) -> b'The' occured 43 times.\n",
      "473/4744 pairs merged. (111, 103) -> b'og' occured 43 times.\n",
      "474/4744 pairs merged. (108, 100) -> b'ld' occured 43 times.\n",
      "475/4744 pairs merged. (271, 388) -> b' cult' occured 43 times.\n",
      "476/4744 pairs merged. (101, 109) -> b'em' occured 43 times.\n",
      "477/4744 pairs merged. (356, 259) -> b' Han' occured 43 times.\n",
      "478/4744 pairs merged. (267, 100) -> b' ad' occured 43 times.\n",
      "479/4744 pairs merged. (32, 105) -> b' i' occured 42 times.\n",
      "480/4744 pairs merged. (403, 100) -> b'ound' occured 42 times.\n",
      "481/4744 pairs merged. (312, 432) -> b'mpire' occured 42 times.\n",
      "482/4744 pairs merged. (257, 110) -> b'hen' occured 42 times.\n",
      "483/4744 pairs merged. (367, 314) -> b' rul' occured 42 times.\n",
      "484/4744 pairs merged. (32, 70) -> b' F' occured 42 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 247/4744 [00:02<00:46, 96.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "485/4744 pairs merged. (358, 108) -> b'ell' occured 41 times.\n",
      "486/4744 pairs merged. (32, 294) -> b' is' occured 41 times.\n",
      "487/4744 pairs merged. (337, 269) -> b' stat' occured 41 times.\n",
      "488/4744 pairs merged. (259, 116) -> b'ant' occured 41 times.\n",
      "489/4744 pairs merged. (286, 435) -> b'ough' occured 41 times.\n",
      "490/4744 pairs merged. (117, 100) -> b'ud' occured 41 times.\n",
      "491/4744 pairs merged. (426, 110) -> b'overn' occured 41 times.\n",
      "492/4744 pairs merged. (46, 340) -> b'.\\n\\n' occured 41 times.\n",
      "493/4744 pairs merged. (32, 309) -> b' ==' occured 41 times.\n",
      "494/4744 pairs merged. (319, 116) -> b'ect' occured 41 times.\n",
      "495/4744 pairs merged. (273, 290) -> b'ition' occured 40 times.\n",
      "496/4744 pairs merged. (101, 285) -> b'ear' occured 40 times.\n",
      "497/4744 pairs merged. (114, 273) -> b'rit' occured 40 times.\n",
      "498/4744 pairs merged. (325, 491) -> b' govern' occured 40 times.\n",
      "499/4744 pairs merged. (306, 323) -> b' Song' occured 40 times.\n",
      "500/4744 pairs merged. (99, 281) -> b'ces' occured 40 times.\n",
      "501/4744 pairs merged. (265, 115) -> b'res' occured 39 times.\n",
      "502/4744 pairs merged. (97, 111) -> b'ao' occured 39 times.\n",
      "503/4744 pairs merged. (257, 100) -> b'hed' occured 39 times.\n",
      "504/4744 pairs merged. (384, 101) -> b'ame' occured 39 times.\n",
      "505/4744 pairs merged. (265, 269) -> b'reat' occured 39 times.\n",
      "506/4744 pairs merged. (267, 103) -> b' ag' occured 39 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 269/4744 [00:02<00:48, 93.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "507/4744 pairs merged. (315, 278) -> b' Ming' occured 38 times.\n",
      "508/4744 pairs merged. (325, 114) -> b' gr' occured 37 times.\n",
      "509/4744 pairs merged. (322, 110) -> b'own' occured 37 times.\n",
      "510/4744 pairs merged. (105, 112) -> b'ip' occured 36 times.\n",
      "511/4744 pairs merged. (286, 114) -> b'our' occured 36 times.\n",
      "512/4744 pairs merged. (268, 343) -> b'ence' occured 36 times.\n",
      "513/4744 pairs merged. (335, 276) -> b'istor' occured 35 times.\n",
      "514/4744 pairs merged. (275, 108) -> b'all' occured 35 times.\n",
      "515/4744 pairs merged. (101, 112) -> b'ep' occured 35 times.\n",
      "516/4744 pairs merged. (282, 458) -> b' during' occured 35 times.\n",
      "517/4744 pairs merged. (401, 321) -> b' trad' occured 34 times.\n",
      "518/4744 pairs merged. (280, 286) -> b' sou' occured 34 times.\n",
      "519/4744 pairs merged. (294, 109) -> b'ism' occured 34 times.\n",
      "520/4744 pairs merged. (498, 357) -> b' government' occured 34 times.\n",
      "521/4744 pairs merged. (32, 257) -> b' he' occured 34 times.\n",
      "522/4744 pairs merged. (266, 329) -> b' over' occured 34 times.\n",
      "523/4744 pairs merged. (310, 513) -> b' histor' occured 33 times.\n",
      "524/4744 pairs merged. (301, 103) -> b' reg' occured 33 times.\n",
      "525/4744 pairs merged. (266, 114) -> b' or' occured 33 times.\n",
      "526/4744 pairs merged. (276, 100) -> b'ord' occured 33 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 280/4744 [00:03<00:47, 93.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "527/4744 pairs merged. (102, 471) -> b'fter' occured 33 times.\n",
      "528/4744 pairs merged. (117, 259) -> b'uan' occured 33 times.\n",
      "529/4744 pairs merged. (97, 105) -> b'ai' occured 33 times.\n",
      "530/4744 pairs merged. (97, 103) -> b'ag' occured 33 times.\n",
      "531/4744 pairs merged. (285, 116) -> b'art' occured 32 times.\n",
      "532/4744 pairs merged. (300, 101) -> b' le' occured 32 times.\n",
      "533/4744 pairs merged. (383, 372) -> b'mperial' occured 31 times.\n",
      "534/4744 pairs merged. (268, 100) -> b'end' occured 31 times.\n",
      "535/4744 pairs merged. (265, 295) -> b'reas' occured 31 times.\n",
      "536/4744 pairs merged. (291, 285) -> b' ear' occured 31 times.\n",
      "537/4744 pairs merged. (342, 294) -> b' this' occured 31 times.\n",
      "538/4744 pairs merged. (283, 322) -> b' pow' occured 31 times.\n",
      "539/4744 pairs merged. (283, 114) -> b' pr' occured 31 times.\n",
      "540/4744 pairs merged. (101, 105) -> b'ei' occured 31 times.\n",
      "541/4744 pairs merged. (330, 115) -> b' cons' occured 30 times.\n",
      "542/4744 pairs merged. (320, 276) -> b' nor' occured 30 times.\n",
      "543/4744 pairs merged. (282, 294) -> b' dis' occured 30 times.\n",
      "544/4744 pairs merged. (99, 262) -> b'con' occured 30 times.\n",
      "545/4744 pairs merged. (111, 116) -> b'ot' occured 30 times.\n",
      "546/4744 pairs merged. (32, 85) -> b' U' occured 30 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▋         | 302/4744 [00:03<00:46, 96.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "547/4744 pairs merged. (109, 261) -> b'mer' occured 29 times.\n",
      "548/4744 pairs merged. (111, 265) -> b'ore' occured 29 times.\n",
      "549/4744 pairs merged. (283, 101) -> b' pe' occured 29 times.\n",
      "550/4744 pairs merged. (299, 104) -> b' Th' occured 29 times.\n",
      "551/4744 pairs merged. (475, 381) -> b' culture' occured 29 times.\n",
      "552/4744 pairs merged. (283, 305) -> b' pol' occured 29 times.\n",
      "553/4744 pairs merged. (290, 115) -> b'ions' occured 29 times.\n",
      "554/4744 pairs merged. (118, 292) -> b'vent' occured 29 times.\n",
      "555/4744 pairs merged. (373, 341) -> b' such' occured 29 times.\n",
      "556/4744 pairs merged. (392, 108) -> b' all' occured 29 times.\n",
      "557/4744 pairs merged. (50, 48) -> b'20' occured 29 times.\n",
      "558/4744 pairs merged. (315, 323) -> b' Mong' occured 29 times.\n",
      "559/4744 pairs merged. (558, 305) -> b' Mongol' occured 29 times.\n",
      "560/4744 pairs merged. (310, 321) -> b' had' occured 29 times.\n",
      "561/4744 pairs merged. (271, 374) -> b' cap' occured 29 times.\n",
      "562/4744 pairs merged. (261, 263) -> b'ered' occured 28 times.\n",
      "563/4744 pairs merged. (444, 111) -> b' into' occured 28 times.\n",
      "564/4744 pairs merged. (284, 480) -> b' found' occured 28 times.\n",
      "565/4744 pairs merged. (295, 115) -> b'ass' occured 28 times.\n",
      "566/4744 pairs merged. (310, 294) -> b' his' occured 28 times.\n",
      "567/4744 pairs merged. (102, 276) -> b'for' occured 28 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 324/4744 [00:03<00:45, 97.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "568/4744 pairs merged. (273, 101) -> b'ite' occured 28 times.\n",
      "569/4744 pairs merged. (97, 107) -> b'ak' occured 27 times.\n",
      "570/4744 pairs merged. (305, 108) -> b'oll' occured 27 times.\n",
      "571/4744 pairs merged. (97, 121) -> b'ay' occured 27 times.\n",
      "572/4744 pairs merged. (105, 263) -> b'ied' occured 27 times.\n",
      "573/4744 pairs merged. (333, 115) -> b'ations' occured 27 times.\n",
      "574/4744 pairs merged. (368, 104) -> b'igh' occured 27 times.\n",
      "575/4744 pairs merged. (538, 261) -> b' power' occured 27 times.\n",
      "576/4744 pairs merged. (101, 268) -> b'een' occured 27 times.\n",
      "577/4744 pairs merged. (380, 268) -> b' been' occured 27 times.\n",
      "578/4744 pairs merged. (282, 319) -> b' dec' occured 27 times.\n",
      "579/4744 pairs merged. (492, 10) -> b'.\\n\\n\\n' occured 27 times.\n",
      "580/4744 pairs merged. (112, 112) -> b'pp' occured 27 times.\n",
      "581/4744 pairs merged. (369, 454) -> b' Emperor' occured 27 times.\n",
      "582/4744 pairs merged. (280, 112) -> b' sp' occured 26 times.\n",
      "583/4744 pairs merged. (360, 116) -> b'act' occured 26 times.\n",
      "584/4744 pairs merged. (487, 281) -> b' states' occured 26 times.\n",
      "585/4744 pairs merged. (411, 101) -> b'ave' occured 26 times.\n",
      "586/4744 pairs merged. (423, 460) -> b' under' occured 26 times.\n",
      "587/4744 pairs merged. (446, 110) -> b' kn' occured 26 times.\n",
      "588/4744 pairs merged. (291, 481) -> b' empire' occured 26 times.\n",
      "589/4744 pairs merged. (288, 319) -> b' bec' occured 26 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 346/4744 [00:03<00:44, 99.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "590/4744 pairs merged. (544, 298) -> b'conom' occured 26 times.\n",
      "591/4744 pairs merged. (98, 108) -> b'bl' occured 26 times.\n",
      "592/4744 pairs merged. (267, 98) -> b' ab' occured 26 times.\n",
      "593/4744 pairs merged. (301, 115) -> b' res' occured 26 times.\n",
      "594/4744 pairs merged. (414, 258) -> b' Jin' occured 26 times.\n",
      "595/4744 pairs merged. (270, 276) -> b' wor' occured 25 times.\n",
      "596/4744 pairs merged. (479, 533) -> b' imperial' occured 25 times.\n",
      "597/4744 pairs merged. (445, 114) -> b' contr' occured 25 times.\n",
      "598/4744 pairs merged. (41, 44) -> b'),' occured 25 times.\n",
      "599/4744 pairs merged. (111, 115) -> b'os' occured 25 times.\n",
      "600/4744 pairs merged. (285, 100) -> b'ard' occured 25 times.\n",
      "601/4744 pairs merged. (276, 116) -> b'ort' occured 25 times.\n",
      "602/4744 pairs merged. (32, 34) -> b' \"' occured 25 times.\n",
      "603/4744 pairs merged. (260, 382) -> b' their' occured 25 times.\n",
      "604/4744 pairs merged. (291, 590) -> b' econom' occured 25 times.\n",
      "605/4744 pairs merged. (266, 359) -> b' other' occured 25 times.\n",
      "606/4744 pairs merged. (300, 263) -> b' led' occured 25 times.\n",
      "607/4744 pairs merged. (291, 264) -> b' est' occured 25 times.\n",
      "608/4744 pairs merged. (353, 101) -> b'ime' occured 25 times.\n",
      "609/4744 pairs merged. (117, 112) -> b'up' occured 25 times.\n",
      "610/4744 pairs merged. (425, 264) -> b' most' occured 25 times.\n",
      "611/4744 pairs merged. (271, 104) -> b' ch' occured 25 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 368/4744 [00:03<00:43, 99.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "612/4744 pairs merged. (320, 101) -> b' ne' occured 25 times.\n",
      "613/4744 pairs merged. (506, 376) -> b' again' occured 25 times.\n",
      "614/4744 pairs merged. (273, 448) -> b'itary' occured 25 times.\n",
      "615/4744 pairs merged. (449, 108) -> b' mill' occured 24 times.\n",
      "616/4744 pairs merged. (298, 258) -> b'omin' occured 24 times.\n",
      "617/4744 pairs merged. (301, 99) -> b' rec' occured 24 times.\n",
      "618/4744 pairs merged. (464, 286) -> b' Zhou' occured 24 times.\n",
      "619/4744 pairs merged. (32, 79) -> b' O' occured 24 times.\n",
      "620/4744 pairs merged. (300, 274) -> b' land' occured 24 times.\n",
      "621/4744 pairs merged. (280, 121) -> b' sy' occured 24 times.\n",
      "622/4744 pairs merged. (431, 108) -> b'abl' occured 24 times.\n",
      "623/4744 pairs merged. (270, 285) -> b' war' occured 24 times.\n",
      "624/4744 pairs merged. (370, 404) -> b'estern' occured 24 times.\n",
      "625/4744 pairs merged. (613, 264) -> b' against' occured 24 times.\n",
      "626/4744 pairs merged. (259, 115) -> b'ans' occured 23 times.\n",
      "627/4744 pairs merged. (382, 264) -> b'irst' occured 23 times.\n",
      "628/4744 pairs merged. (32, 121) -> b' y' occured 23 times.\n",
      "629/4744 pairs merged. (105, 418) -> b'ious' occured 23 times.\n",
      "630/4744 pairs merged. (114, 275) -> b'ral' occured 23 times.\n",
      "631/4744 pairs merged. (49, 50) -> b'12' occured 23 times.\n",
      "632/4744 pairs merged. (108, 490) -> b'lud' occured 23 times.\n",
      "633/4744 pairs merged. (277, 100) -> b' ind' occured 23 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 390/4744 [00:04<00:42, 101.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634/4744 pairs merged. (256, 261) -> b' ter' occured 23 times.\n",
      "635/4744 pairs merged. (587, 509) -> b' known' occured 23 times.\n",
      "636/4744 pairs merged. (450, 109) -> b' comm' occured 23 times.\n",
      "637/4744 pairs merged. (621, 264) -> b' syst' occured 23 times.\n",
      "638/4744 pairs merged. (637, 476) -> b' system' occured 23 times.\n",
      "639/4744 pairs merged. (273, 417) -> b'itical' occured 23 times.\n",
      "640/4744 pairs merged. (354, 285) -> b' War' occured 23 times.\n",
      "641/4744 pairs merged. (108, 97) -> b'la' occured 23 times.\n",
      "642/4744 pairs merged. (567, 109) -> b'form' occured 23 times.\n",
      "643/4744 pairs merged. (561, 273) -> b' capit' occured 23 times.\n",
      "644/4744 pairs merged. (449, 614) -> b' military' occured 23 times.\n",
      "645/4744 pairs merged. (337, 114) -> b' str' occured 22 times.\n",
      "646/4744 pairs merged. (307, 275) -> b'ural' occured 22 times.\n",
      "647/4744 pairs merged. (259, 121) -> b'any' occured 22 times.\n",
      "648/4744 pairs merged. (403, 116) -> b'ount' occured 22 times.\n",
      "649/4744 pairs merged. (117, 275) -> b'ual' occured 22 times.\n",
      "650/4744 pairs merged. (114, 121) -> b'ry' occured 22 times.\n",
      "651/4744 pairs merged. (102, 287) -> b'fic' occured 22 times.\n",
      "652/4744 pairs merged. (299, 311) -> b' Tang' occured 22 times.\n",
      "653/4744 pairs merged. (294, 104) -> b'ish' occured 22 times.\n",
      "654/4744 pairs merged. (307, 121) -> b'ury' occured 22 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▊         | 412/4744 [00:04<00:42, 101.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "655/4744 pairs merged. (117, 452) -> b'ually' occured 22 times.\n",
      "656/4744 pairs merged. (607, 622) -> b' establ' occured 22 times.\n",
      "657/4744 pairs merged. (395, 528) -> b' Yuan' occured 22 times.\n",
      "658/4744 pairs merged. (451, 278) -> b' Qing' occured 22 times.\n",
      "659/4744 pairs merged. (433, 100) -> b' end' occured 22 times.\n",
      "660/4744 pairs merged. (269, 261) -> b'ater' occured 22 times.\n",
      "661/4744 pairs merged. (283, 265) -> b' pre' occured 22 times.\n",
      "662/4744 pairs merged. (643, 275) -> b' capital' occured 22 times.\n",
      "663/4744 pairs merged. (349, 101) -> b'ide' occured 21 times.\n",
      "664/4744 pairs merged. (99, 263) -> b'ced' occured 21 times.\n",
      "665/4744 pairs merged. (112, 261) -> b'per' occured 21 times.\n",
      "666/4744 pairs merged. (313, 308) -> b'ivil' occured 21 times.\n",
      "667/4744 pairs merged. (357, 115) -> b'ments' occured 21 times.\n",
      "668/4744 pairs merged. (115, 111) -> b'so' occured 21 times.\n",
      "669/4744 pairs merged. (301, 112) -> b' rep' occured 21 times.\n",
      "670/4744 pairs merged. (108, 105) -> b'li' occured 21 times.\n",
      "671/4744 pairs merged. (300, 285) -> b' lar' occured 21 times.\n",
      "672/4744 pairs merged. (456, 632) -> b' includ' occured 21 times.\n",
      "673/4744 pairs merged. (385, 116) -> b' ext' occured 21 times.\n",
      "674/4744 pairs merged. (117, 311) -> b'uang' occured 21 times.\n",
      "675/4744 pairs merged. (305, 473) -> b'olog' occured 21 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 434/4744 [00:04<00:42, 100.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "676/4744 pairs merged. (589, 504) -> b' became' occured 21 times.\n",
      "677/4744 pairs merged. (118, 358) -> b'vel' occured 21 times.\n",
      "678/4744 pairs merged. (552, 639) -> b' political' occured 21 times.\n",
      "679/4744 pairs merged. (373, 98) -> b' sub' occured 21 times.\n",
      "680/4744 pairs merged. (49, 54) -> b'16' occured 21 times.\n",
      "681/4744 pairs merged. (338, 119) -> b'etw' occured 21 times.\n",
      "682/4744 pairs merged. (283, 362) -> b' pop' occured 21 times.\n",
      "683/4744 pairs merged. (682, 314) -> b' popul' occured 21 times.\n",
      "684/4744 pairs merged. (116, 345) -> b'tle' occured 21 times.\n",
      "685/4744 pairs merged. (271, 97) -> b' ca' occured 21 times.\n",
      "686/4744 pairs merged. (283, 531) -> b' part' occured 20 times.\n",
      "687/4744 pairs merged. (385, 112) -> b' exp' occured 20 times.\n",
      "688/4744 pairs merged. (118, 101) -> b've' occured 20 times.\n",
      "689/4744 pairs merged. (628, 496) -> b' year' occured 20 times.\n",
      "690/4744 pairs merged. (386, 101) -> b' one' occured 20 times.\n",
      "691/4744 pairs merged. (518, 348) -> b' south' occured 20 times.\n",
      "692/4744 pairs merged. (301, 109) -> b' rem' occured 20 times.\n",
      "693/4744 pairs merged. (294, 503) -> b'ished' occured 20 times.\n",
      "694/4744 pairs merged. (104, 259) -> b'han' occured 20 times.\n",
      "695/4744 pairs merged. (265, 101) -> b'ree' occured 20 times.\n",
      "696/4744 pairs merged. (681, 576) -> b'etween' occured 20 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|▉         | 455/4744 [00:04<00:44, 96.37it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "697/4744 pairs merged. (374, 259) -> b'apan' occured 20 times.\n",
      "698/4744 pairs merged. (97, 106) -> b'aj' occured 20 times.\n",
      "699/4744 pairs merged. (105, 120) -> b'ix' occured 20 times.\n",
      "700/4744 pairs merged. (106, 278) -> b'jing' occured 20 times.\n",
      "701/4744 pairs merged. (286, 116) -> b'out' occured 20 times.\n",
      "702/4744 pairs merged. (117, 111) -> b'uo' occured 20 times.\n",
      "703/4744 pairs merged. (122, 104) -> b'zh' occured 20 times.\n",
      "704/4744 pairs merged. (429, 311) -> b' Shang' occured 20 times.\n",
      "705/4744 pairs merged. (105, 338) -> b'iet' occured 20 times.\n",
      "706/4744 pairs merged. (284, 627) -> b' first' occured 19 times.\n",
      "707/4744 pairs merged. (313, 261) -> b'iver' occured 19 times.\n",
      "708/4744 pairs merged. (122, 101) -> b'ze' occured 19 times.\n",
      "709/4744 pairs merged. (105, 101) -> b'ie' occured 19 times.\n",
      "710/4744 pairs merged. (392, 668) -> b' also' occured 19 times.\n",
      "711/4744 pairs merged. (310, 585) -> b' have' occured 19 times.\n",
      "712/4744 pairs merged. (380, 103) -> b' beg' occured 19 times.\n",
      "713/4744 pairs merged. (313, 263) -> b'ived' occured 19 times.\n",
      "714/4744 pairs merged. (651, 372) -> b'ficial' occured 19 times.\n",
      "715/4744 pairs merged. (453, 263) -> b'ized' occured 19 times.\n",
      "716/4744 pairs merged. (32, 261) -> b' er' occured 19 times.\n",
      "717/4744 pairs merged. (308, 108) -> b'ill' occured 19 times.\n",
      "718/4744 pairs merged. (267, 527) -> b' after' occured 19 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 475/4744 [00:05<00:46, 92.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "719/4744 pairs merged. (102, 108) -> b'fl' occured 19 times.\n",
      "720/4744 pairs merged. (330, 409) -> b' conqu' occured 19 times.\n",
      "721/4744 pairs merged. (117, 591) -> b'ubl' occured 19 times.\n",
      "722/4744 pairs merged. (105, 311) -> b'iang' occured 19 times.\n",
      "723/4744 pairs merged. (387, 102) -> b' def' occured 19 times.\n",
      "724/4744 pairs merged. (280, 104) -> b' sh' occured 19 times.\n",
      "725/4744 pairs merged. (278, 115) -> b'ings' occured 19 times.\n",
      "726/4744 pairs merged. (265, 110) -> b'ren' occured 19 times.\n",
      "727/4744 pairs merged. (363, 111) -> b' who' occured 19 times.\n",
      "728/4744 pairs merged. (117, 101) -> b'ue' occured 19 times.\n",
      "729/4744 pairs merged. (333, 275) -> b'ational' occured 19 times.\n",
      "730/4744 pairs merged. (523, 121) -> b' history' occured 18 times.\n",
      "731/4744 pairs merged. (280, 101) -> b' se' occured 18 times.\n",
      "732/4744 pairs merged. (271, 666) -> b' civil' occured 18 times.\n",
      "733/4744 pairs merged. (391, 707) -> b' River' occured 18 times.\n",
      "734/4744 pairs merged. (362, 345) -> b'ople' occured 18 times.\n",
      "735/4744 pairs merged. (450, 112) -> b' comp' occured 18 times.\n",
      "736/4744 pairs merged. (457, 389) -> b' Xia' occured 18 times.\n",
      "737/4744 pairs merged. (288, 114) -> b' br' occured 18 times.\n",
      "738/4744 pairs merged. (49, 48) -> b'10' occured 18 times.\n",
      "739/4744 pairs merged. (337, 390) -> b' state' occured 18 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 496/4744 [00:05<00:45, 93.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "740/4744 pairs merged. (293, 285) -> b' mar' occured 18 times.\n",
      "741/4744 pairs merged. (284, 384) -> b' fam' occured 18 times.\n",
      "742/4744 pairs merged. (268, 103) -> b'eng' occured 18 times.\n",
      "743/4744 pairs merged. (501, 115) -> b'ress' occured 18 times.\n",
      "744/4744 pairs merged. (291, 454) -> b' emperor' occured 18 times.\n",
      "745/4744 pairs merged. (259, 343) -> b'ance' occured 18 times.\n",
      "746/4744 pairs merged. (721, 287) -> b'ublic' occured 18 times.\n",
      "747/4744 pairs merged. (288, 361) -> b' but' occured 18 times.\n",
      "748/4744 pairs merged. (391, 101) -> b' Re' occured 18 times.\n",
      "749/4744 pairs merged. (264, 114) -> b'str' occured 18 times.\n",
      "750/4744 pairs merged. (301, 108) -> b' rel' occured 18 times.\n",
      "751/4744 pairs merged. (41, 46) -> b').' occured 18 times.\n",
      "752/4744 pairs merged. (335, 114) -> b'istr' occured 18 times.\n",
      "753/4744 pairs merged. (278, 100) -> b'ingd' occured 18 times.\n",
      "754/4744 pairs merged. (121, 311) -> b'yang' occured 18 times.\n",
      "755/4744 pairs merged. (309, 309) -> b'====' occured 18 times.\n",
      "756/4744 pairs merged. (493, 309) -> b' ====' occured 18 times.\n",
      "757/4744 pairs merged. (73, 110) -> b'In' occured 18 times.\n",
      "758/4744 pairs merged. (280, 440) -> b' soc' occured 18 times.\n",
      "759/4744 pairs merged. (517, 101) -> b' trade' occured 18 times.\n",
      "760/4744 pairs merged. (266, 361) -> b' out' occured 18 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 517/4744 [00:05<00:46, 91.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761/4744 pairs merged. (267, 99) -> b' ac' occured 17 times.\n",
      "762/4744 pairs merged. (32, 292) -> b' ent' occured 17 times.\n",
      "763/4744 pairs merged. (479, 312) -> b' imp' occured 17 times.\n",
      "764/4744 pairs merged. (425, 265) -> b' more' occured 17 times.\n",
      "765/4744 pairs merged. (107, 115) -> b'ks' occured 17 times.\n",
      "766/4744 pairs merged. (315, 259) -> b' Man' occured 17 times.\n",
      "767/4744 pairs merged. (288, 696) -> b' between' occured 17 times.\n",
      "768/4744 pairs merged. (414, 697) -> b' Japan' occured 17 times.\n",
      "769/4744 pairs merged. (698, 276) -> b'ajor' occured 17 times.\n",
      "770/4744 pairs merged. (300, 660) -> b' later' occured 17 times.\n",
      "771/4744 pairs merged. (468, 361) -> b'ibut' occured 17 times.\n",
      "772/4744 pairs merged. (376, 263) -> b'ained' occured 17 times.\n",
      "773/4744 pairs merged. (273, 350) -> b'ities' occured 17 times.\n",
      "774/4744 pairs merged. (280, 338) -> b' set' occured 17 times.\n",
      "775/4744 pairs merged. (291, 554) -> b' event' occured 17 times.\n",
      "776/4744 pairs merged. (346, 108) -> b' Al' occured 17 times.\n",
      "777/4744 pairs merged. (306, 286) -> b' Sou' occured 17 times.\n",
      "778/4744 pairs merged. (595, 474) -> b' world' occured 16 times.\n",
      "779/4744 pairs merged. (453, 333) -> b'ization' occured 16 times.\n",
      "780/4744 pairs merged. (353, 281) -> b'imes' occured 16 times.\n",
      "781/4744 pairs merged. (407, 101) -> b' Ne' occured 16 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 538/4744 [00:05<00:44, 94.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/4744 pairs merged. (469, 630) -> b' central' occured 16 times.\n",
      "783/4744 pairs merged. (536, 670) -> b' earli' occured 16 times.\n",
      "784/4744 pairs merged. (272, 714) -> b' official' occured 16 times.\n",
      "785/4744 pairs merged. (118, 263) -> b'ved' occured 16 times.\n",
      "786/4744 pairs merged. (97, 434) -> b'age' occured 16 times.\n",
      "787/4744 pairs merged. (354, 117) -> b' Wu' occured 16 times.\n",
      "788/4744 pairs merged. (271, 108) -> b' cl' occured 16 times.\n",
      "789/4744 pairs merged. (116, 290) -> b'tion' occured 16 times.\n",
      "790/4744 pairs merged. (369, 481) -> b' Empire' occured 16 times.\n",
      "791/4744 pairs merged. (308, 101) -> b'ile' occured 16 times.\n",
      "792/4744 pairs merged. (604, 287) -> b' economic' occured 16 times.\n",
      "793/4744 pairs merged. (118, 305) -> b'vol' occured 16 times.\n",
      "794/4744 pairs merged. (82, 67) -> b'RC' occured 16 times.\n",
      "795/4744 pairs merged. (269, 104) -> b'ath' occured 16 times.\n",
      "796/4744 pairs merged. (61, 340) -> b'=\\n\\n' occured 16 times.\n",
      "797/4744 pairs merged. (378, 404) -> b'odern' occured 16 times.\n",
      "798/4744 pairs merged. (346, 110) -> b' An' occured 16 times.\n",
      "799/4744 pairs merged. (483, 101) -> b' rule' occured 16 times.\n",
      "800/4744 pairs merged. (756, 340) -> b' ====\\n\\n' occured 16 times.\n",
      "801/4744 pairs merged. (259, 412) -> b'ants' occured 16 times.\n",
      "802/4744 pairs merged. (541, 349) -> b' consid' occured 15 times.\n",
      "803/4744 pairs merged. (268, 115) -> b'ens' occured 15 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 559/4744 [00:05<00:43, 95.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "804/4744 pairs merged. (99, 114) -> b'cr' occured 15 times.\n",
      "805/4744 pairs merged. (293, 647) -> b' many' occured 15 times.\n",
      "806/4744 pairs merged. (269, 422) -> b'ative' occured 15 times.\n",
      "807/4744 pairs merged. (284, 285) -> b' far' occured 15 times.\n",
      "808/4744 pairs merged. (456, 535) -> b' increas' occured 15 times.\n",
      "809/4744 pairs merged. (280, 298) -> b' som' occured 15 times.\n",
      "810/4744 pairs merged. (270, 497) -> b' writ' occured 15 times.\n",
      "811/4744 pairs merged. (269, 281) -> b'ates' occured 15 times.\n",
      "812/4744 pairs merged. (276, 115) -> b'ors' occured 15 times.\n",
      "813/4744 pairs merged. (270, 101) -> b' we' occured 15 times.\n",
      "814/4744 pairs merged. (305, 100) -> b'old' occured 15 times.\n",
      "815/4744 pairs merged. (469, 654) -> b' century' occured 15 times.\n",
      "816/4744 pairs merged. (281, 115) -> b'ess' occured 15 times.\n",
      "817/4744 pairs merged. (377, 409) -> b'sequ' occured 15 times.\n",
      "818/4744 pairs merged. (109, 258) -> b'min' occured 15 times.\n",
      "819/4744 pairs merged. (111, 264) -> b'ost' occured 15 times.\n",
      "820/4744 pairs merged. (641, 353) -> b'laim' occured 15 times.\n",
      "821/4744 pairs merged. (399, 794) -> b' PRC' occured 15 times.\n",
      "822/4744 pairs merged. (293, 769) -> b' major' occured 15 times.\n",
      "823/4744 pairs merged. (301, 642) -> b' reform' occured 15 times.\n",
      "824/4744 pairs merged. (309, 61) -> b'===' occured 15 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 581/4744 [00:06<00:42, 99.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "825/4744 pairs merged. (493, 796) -> b' ===\\n\\n' occured 15 times.\n",
      "826/4744 pairs merged. (111, 258) -> b'oin' occured 15 times.\n",
      "827/4744 pairs merged. (397, 389) -> b' Lia' occured 15 times.\n",
      "828/4744 pairs merged. (117, 377) -> b'use' occured 15 times.\n",
      "829/4744 pairs merged. (280, 568) -> b' site' occured 15 times.\n",
      "830/4744 pairs merged. (114, 287) -> b'ric' occured 15 times.\n",
      "831/4744 pairs merged. (570, 322) -> b'ollow' occured 15 times.\n",
      "832/4744 pairs merged. (683, 333) -> b' population' occured 15 times.\n",
      "833/4744 pairs merged. (346, 115) -> b' As' occured 15 times.\n",
      "834/4744 pairs merged. (335, 115) -> b'ists' occured 15 times.\n",
      "835/4744 pairs merged. (32, 413) -> b' us' occured 15 times.\n",
      "836/4744 pairs merged. (597, 305) -> b' control' occured 15 times.\n",
      "837/4744 pairs merged. (753, 298) -> b'ingdom' occured 15 times.\n",
      "838/4744 pairs merged. (49, 56) -> b'18' occured 15 times.\n",
      "839/4744 pairs merged. (407, 276) -> b' Nor' occured 15 times.\n",
      "840/4744 pairs merged. (267, 265) -> b' are' occured 14 times.\n",
      "841/4744 pairs merged. (293, 376) -> b' main' occured 14 times.\n",
      "842/4744 pairs merged. (282, 313) -> b' div' occured 14 times.\n",
      "843/4744 pairs merged. (549, 734) -> b' people' occured 14 times.\n",
      "844/4744 pairs merged. (550, 294) -> b' This' occured 14 times.\n",
      "845/4744 pairs merged. (689, 115) -> b' years' occured 14 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 602/4744 [00:06<00:41, 100.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "846/4744 pairs merged. (280, 307) -> b' sur' occured 14 times.\n",
      "847/4744 pairs merged. (100, 436) -> b'duc' occured 14 times.\n",
      "848/4744 pairs merged. (289, 262) -> b' Con' occured 14 times.\n",
      "849/4744 pairs merged. (451, 258) -> b' Qin' occured 14 times.\n",
      "850/4744 pairs merged. (716, 97) -> b' era' occured 14 times.\n",
      "851/4744 pairs merged. (99, 105) -> b'ci' occured 14 times.\n",
      "852/4744 pairs merged. (114, 360) -> b'rac' occured 14 times.\n",
      "853/4744 pairs merged. (438, 287) -> b'ific' occured 14 times.\n",
      "854/4744 pairs merged. (284, 108) -> b' fl' occured 14 times.\n",
      "855/4744 pairs merged. (117, 105) -> b'ui' occured 14 times.\n",
      "856/4744 pairs merged. (387, 677) -> b' devel' occured 14 times.\n",
      "857/4744 pairs merged. (856, 362) -> b' develop' occured 14 times.\n",
      "858/4744 pairs merged. (256, 608) -> b' time' occured 14 times.\n",
      "859/4744 pairs merged. (817, 292) -> b'sequent' occured 14 times.\n",
      "860/4744 pairs merged. (634, 497) -> b' territ' occured 14 times.\n",
      "861/4744 pairs merged. (860, 276) -> b' territor' occured 14 times.\n",
      "862/4744 pairs merged. (391, 515) -> b' Rep' occured 14 times.\n",
      "863/4744 pairs merged. (862, 746) -> b' Republic' occured 14 times.\n",
      "864/4744 pairs merged. (277, 118) -> b' inv' occured 14 times.\n",
      "865/4744 pairs merged. (271, 648) -> b' count' occured 14 times.\n",
      "866/4744 pairs merged. (723, 101) -> b' defe' occured 14 times.\n",
      "867/4744 pairs merged. (108, 274) -> b'land' occured 14 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 623/4744 [00:06<00:41, 98.12it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868/4744 pairs merged. (487, 413) -> b' status' occured 14 times.\n",
      "869/4744 pairs merged. (387, 795) -> b' death' occured 14 times.\n",
      "870/4744 pairs merged. (437, 48) -> b'000' occured 14 times.\n",
      "871/4744 pairs merged. (574, 116) -> b'ight' occured 14 times.\n",
      "872/4744 pairs merged. (114, 263) -> b'red' occured 14 times.\n",
      "873/4744 pairs merged. (445, 258) -> b' contin' occured 14 times.\n",
      "874/4744 pairs merged. (373, 580) -> b' supp' occured 14 times.\n",
      "875/4744 pairs merged. (354, 624) -> b' Western' occured 14 times.\n",
      "876/4744 pairs merged. (482, 103) -> b'heng' occured 14 times.\n",
      "877/4744 pairs merged. (320, 545) -> b' not' occured 14 times.\n",
      "878/4744 pairs merged. (325, 268) -> b' gen' occured 14 times.\n",
      "879/4744 pairs merged. (260, 121) -> b' they' occured 14 times.\n",
      "880/4744 pairs merged. (114, 278) -> b'ring' occured 14 times.\n",
      "881/4744 pairs merged. (301, 98) -> b' reb' occured 14 times.\n",
      "882/4744 pairs merged. (32, 609) -> b' up' occured 14 times.\n",
      "883/4744 pairs merged. (546, 110) -> b' Un' occured 14 times.\n",
      "884/4744 pairs merged. (268, 263) -> b'ened' occured 14 times.\n",
      "885/4744 pairs merged. (777, 447) -> b' Southern' occured 14 times.\n",
      "886/4744 pairs merged. (395, 311) -> b' Yang' occured 13 times.\n",
      "887/4744 pairs merged. (495, 275) -> b'itional' occured 13 times.\n",
      "888/4744 pairs merged. (318, 350) -> b' dynasties' occured 13 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▎        | 645/4744 [00:06<00:40, 100.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "889/4744 pairs merged. (282, 616) -> b' domin' occured 13 times.\n",
      "890/4744 pairs merged. (542, 348) -> b' north' occured 13 times.\n",
      "891/4744 pairs merged. (438, 572) -> b'ified' occured 13 times.\n",
      "892/4744 pairs merged. (783, 370) -> b' earliest' occured 13 times.\n",
      "893/4744 pairs merged. (116, 268) -> b'ten' occured 13 times.\n",
      "894/4744 pairs merged. (101, 120) -> b'ex' occured 13 times.\n",
      "895/4744 pairs merged. (355, 109) -> b' form' occured 13 times.\n",
      "896/4744 pairs merged. (671, 434) -> b' large' occured 13 times.\n",
      "897/4744 pairs merged. (536, 304) -> b' early' occured 13 times.\n",
      "898/4744 pairs merged. (300, 97) -> b' la' occured 13 times.\n",
      "899/4744 pairs merged. (273, 263) -> b'ited' occured 13 times.\n",
      "900/4744 pairs merged. (712, 259) -> b' began' occured 13 times.\n",
      "901/4744 pairs merged. (293, 565) -> b' mass' occured 13 times.\n",
      "902/4744 pairs merged. (277, 719) -> b' infl' occured 13 times.\n",
      "903/4744 pairs merged. (466, 505) -> b' Great' occured 13 times.\n",
      "904/4744 pairs merged. (373, 99) -> b' suc' occured 13 times.\n",
      "905/4744 pairs merged. (766, 341) -> b' Manch' occured 13 times.\n",
      "906/4744 pairs merged. (289, 298) -> b' Com' occured 13 times.\n",
      "907/4744 pairs merged. (299, 529) -> b' Tai' occured 13 times.\n",
      "908/4744 pairs merged. (119, 259) -> b'wan' occured 13 times.\n",
      "909/4744 pairs merged. (111, 348) -> b'oth' occured 13 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 666/4744 [00:07<00:41, 98.07it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "910/4744 pairs merged. (258, 343) -> b'ince' occured 13 times.\n",
      "911/4744 pairs merged. (320, 463) -> b' num' occured 13 times.\n",
      "912/4744 pairs merged. (303, 404) -> b'astern' occured 13 times.\n",
      "913/4744 pairs merged. (656, 693) -> b' established' occured 13 times.\n",
      "914/4744 pairs merged. (873, 117) -> b' continu' occured 13 times.\n",
      "915/4744 pairs merged. (300, 390) -> b' late' occured 13 times.\n",
      "916/4744 pairs merged. (114, 262) -> b'ron' occured 13 times.\n",
      "917/4744 pairs merged. (321, 101) -> b'ade' occured 13 times.\n",
      "918/4744 pairs merged. (117, 341) -> b'uch' occured 13 times.\n",
      "919/4744 pairs merged. (878, 261) -> b' gener' occured 13 times.\n",
      "920/4744 pairs merged. (286, 474) -> b'ould' occured 13 times.\n",
      "921/4744 pairs merged. (355, 500) -> b' forces' occured 13 times.\n",
      "922/4744 pairs merged. (489, 116) -> b'ought' occured 13 times.\n",
      "923/4744 pairs merged. (685, 312) -> b' camp' occured 13 times.\n",
      "924/4744 pairs merged. (374, 104) -> b'aph' occured 12 times.\n",
      "925/4744 pairs merged. (524, 290) -> b' region' occured 12 times.\n",
      "926/4744 pairs merged. (310, 295) -> b' has' occured 12 times.\n",
      "927/4744 pairs merged. (291, 547) -> b' emer' occured 12 times.\n",
      "928/4744 pairs merged. (275, 345) -> b'alle' occured 12 times.\n",
      "929/4744 pairs merged. (327, 115) -> b' ass' occured 12 times.\n",
      "930/4744 pairs merged. (339, 287) -> b'ithic' occured 12 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 687/4744 [00:07<00:40, 98.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "931/4744 pairs merged. (349, 292) -> b'ident' occured 12 times.\n",
      "932/4744 pairs merged. (617, 526) -> b' record' occured 12 times.\n",
      "933/4744 pairs merged. (102, 436) -> b'fuc' occured 12 times.\n",
      "934/4744 pairs merged. (101, 103) -> b'eg' occured 12 times.\n",
      "935/4744 pairs merged. (429, 105) -> b' Shi' occured 12 times.\n",
      "936/4744 pairs merged. (363, 791) -> b' while' occured 12 times.\n",
      "937/4744 pairs merged. (342, 259) -> b' than' occured 12 times.\n",
      "938/4744 pairs merged. (902, 117) -> b' influ' occured 12 times.\n",
      "939/4744 pairs merged. (49, 51) -> b'13' occured 12 times.\n",
      "940/4744 pairs merged. (269, 278) -> b'ating' occured 12 times.\n",
      "941/4744 pairs merged. (361, 290) -> b'ution' occured 12 times.\n",
      "942/4744 pairs merged. (109, 121) -> b'my' occured 12 times.\n",
      "943/4744 pairs merged. (820, 263) -> b'laimed' occured 12 times.\n",
      "944/4744 pairs merged. (907, 908) -> b' Taiwan' occured 12 times.\n",
      "945/4744 pairs merged. (532, 103) -> b' leg' occured 12 times.\n",
      "946/4744 pairs merged. (615, 290) -> b' million' occured 12 times.\n",
      "947/4744 pairs merged. (331, 540) -> b' Bei' occured 12 times.\n",
      "948/4744 pairs merged. (293, 797) -> b' modern' occured 12 times.\n",
      "949/4744 pairs merged. (284, 831) -> b' follow' occured 12 times.\n",
      "950/4744 pairs merged. (422, 304) -> b'ively' occured 12 times.\n",
      "951/4744 pairs merged. (280, 341) -> b' sch' occured 12 times.\n",
      "952/4744 pairs merged. (564, 263) -> b' founded' occured 12 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▍        | 709/4744 [00:07<00:39, 101.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "953/4744 pairs merged. (578, 108) -> b' decl' occured 12 times.\n",
      "954/4744 pairs merged. (775, 655) -> b' eventually' occured 12 times.\n",
      "955/4744 pairs merged. (307, 359) -> b'urther' occured 12 times.\n",
      "956/4744 pairs merged. (294, 263) -> b'ised' occured 12 times.\n",
      "957/4744 pairs merged. (97, 308) -> b'ail' occured 12 times.\n",
      "958/4744 pairs merged. (542, 447) -> b' northern' occured 12 times.\n",
      "959/4744 pairs merged. (837, 115) -> b'ingdoms' occured 12 times.\n",
      "960/4744 pairs merged. (548, 465) -> b'oreign' occured 12 times.\n",
      "961/4744 pairs merged. (839, 447) -> b' Northern' occured 12 times.\n",
      "962/4744 pairs merged. (464, 117) -> b' Zhu' occured 12 times.\n",
      "963/4744 pairs merged. (827, 111) -> b' Liao' occured 12 times.\n",
      "964/4744 pairs merged. (114, 924) -> b'raph' occured 11 times.\n",
      "965/4744 pairs merged. (802, 562) -> b' considered' occured 11 times.\n",
      "966/4744 pairs merged. (927, 103) -> b' emerg' occured 11 times.\n",
      "967/4744 pairs merged. (928, 121) -> b'alley' occured 11 times.\n",
      "968/4744 pairs merged. (392, 323) -> b' along' occured 11 times.\n",
      "969/4744 pairs merged. (886, 116) -> b' Yangt' occured 11 times.\n",
      "970/4744 pairs merged. (969, 708) -> b' Yangtze' occured 11 times.\n",
      "971/4744 pairs merged. (288, 295) -> b' bas' occured 11 times.\n",
      "972/4744 pairs merged. (286, 112) -> b'oup' occured 11 times.\n",
      "973/4744 pairs merged. (305, 930) -> b'olithic' occured 11 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 731/4744 [00:07<00:38, 103.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "974/4744 pairs merged. (284, 101) -> b' fe' occured 11 times.\n",
      "975/4744 pairs merged. (396, 137) -> b'\\xe2\\x80\\x89' occured 11 times.\n",
      "976/4744 pairs merged. (356, 101) -> b' He' occured 11 times.\n",
      "977/4744 pairs merged. (933, 379) -> b'fucian' occured 11 times.\n",
      "978/4744 pairs merged. (260, 265) -> b' there' occured 11 times.\n",
      "979/4744 pairs merged. (740, 107) -> b' mark' occured 11 times.\n",
      "980/4744 pairs merged. (809, 101) -> b' some' occured 11 times.\n",
      "981/4744 pairs merged. (101, 312) -> b'emp' occured 11 times.\n",
      "982/4744 pairs merged. (119, 600) -> b'ward' occured 11 times.\n",
      "983/4744 pairs merged. (284, 258) -> b' fin' occured 11 times.\n",
      "984/4744 pairs merged. (331, 490) -> b' Bud' occured 11 times.\n",
      "985/4744 pairs merged. (984, 100) -> b' Budd' occured 11 times.\n",
      "986/4744 pairs merged. (985, 104) -> b' Buddh' occured 11 times.\n",
      "987/4744 pairs merged. (116, 278) -> b'ting' occured 11 times.\n",
      "988/4744 pairs merged. (257, 114) -> b'her' occured 11 times.\n",
      "989/4744 pairs merged. (679, 859) -> b' subsequent' occured 11 times.\n",
      "990/4744 pairs merged. (483, 263) -> b' ruled' occured 11 times.\n",
      "991/4744 pairs merged. (419, 49) -> b'191' occured 11 times.\n",
      "992/4744 pairs merged. (419, 52) -> b'194' occured 11 times.\n",
      "993/4744 pairs merged. (906, 109) -> b' Comm' occured 11 times.\n",
      "994/4744 pairs merged. (865, 650) -> b' country' occured 11 times.\n",
      "995/4744 pairs merged. (315, 502) -> b' Mao' occured 11 times.\n",
      "996/4744 pairs merged. (315, 97) -> b' Ma' occured 11 times.\n",
      "997/4744 pairs merged. (306, 116) -> b' St' occured 11 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 764/4744 [00:07<00:38, 104.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "998/4744 pairs merged. (269, 684) -> b'attle' occured 11 times.\n",
      "999/4744 pairs merged. (947, 700) -> b' Beijing' occured 11 times.\n",
      "1000/4744 pairs merged. (672, 278) -> b' including' occured 11 times.\n",
      "1001/4744 pairs merged. (518, 447) -> b' southern' occured 11 times.\n",
      "1002/4744 pairs merged. (283, 501) -> b' pres' occured 11 times.\n",
      "1003/4744 pairs merged. (478, 818) -> b' admin' occured 11 times.\n",
      "1004/4744 pairs merged. (1003, 752) -> b' administr' occured 11 times.\n",
      "1005/4744 pairs merged. (661, 118) -> b' prev' occured 11 times.\n",
      "1006/4744 pairs merged. (305, 285) -> b'olar' occured 11 times.\n",
      "1007/4744 pairs merged. (291, 108) -> b' el' occured 11 times.\n",
      "1008/4744 pairs merged. (703, 286) -> b'zhou' occured 11 times.\n",
      "1009/4744 pairs merged. (101, 329) -> b'ever' occured 11 times.\n",
      "1010/4744 pairs merged. (270, 482) -> b' when' occured 11 times.\n",
      "1011/4744 pairs merged. (39, 259) -> b\"'an\" occured 11 times.\n",
      "1012/4744 pairs merged. (813, 569) -> b' weak' occured 11 times.\n",
      "1013/4744 pairs merged. (380, 278) -> b' being' occured 11 times.\n",
      "1014/4744 pairs merged. (431, 345) -> b'able' occured 11 times.\n",
      "1015/4744 pairs merged. (102, 494) -> b'fect' occured 11 times.\n",
      "1016/4744 pairs merged. (919, 275) -> b' general' occured 11 times.\n",
      "1017/4744 pairs merged. (500, 115) -> b'cess' occured 11 times.\n",
      "1018/4744 pairs merged. (549, 295) -> b' peas' occured 11 times.\n",
      "1019/4744 pairs merged. (284, 960) -> b' foreign' occured 11 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 786/4744 [00:08<00:37, 105.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1020/4744 pairs merged. (776, 108) -> b' All' occured 11 times.\n",
      "1021/4744 pairs merged. (67, 80) -> b'CP' occured 11 times.\n",
      "1022/4744 pairs merged. (407, 729) -> b' National' occured 11 times.\n",
      "1023/4744 pairs merged. (462, 967) -> b' valley' occured 10 times.\n",
      "1024/4744 pairs merged. (264, 273) -> b'stit' occured 10 times.\n",
      "1025/4744 pairs merged. (291, 348) -> b' eth' occured 10 times.\n",
      "1026/4744 pairs merged. (1025, 110) -> b' ethn' occured 10 times.\n",
      "1027/4744 pairs merged. (1026, 287) -> b' ethnic' occured 10 times.\n",
      "1028/4744 pairs merged. (517, 887) -> b' traditional' occured 10 times.\n",
      "1029/4744 pairs merged. (265, 321) -> b'read' occured 10 times.\n",
      "1030/4744 pairs merged. (267, 535) -> b' areas' occured 10 times.\n",
      "1031/4744 pairs merged. (108, 273) -> b'lit' occured 10 times.\n",
      "1032/4744 pairs merged. (313, 278) -> b'iving' occured 10 times.\n",
      "1033/4744 pairs merged. (111, 359) -> b'other' occured 10 times.\n",
      "1034/4744 pairs merged. (515, 534) -> b'epend' occured 10 times.\n",
      "1035/4744 pairs merged. (104, 308) -> b'hil' occured 10 times.\n",
      "1036/4744 pairs merged. (741, 308) -> b' famil' occured 10 times.\n",
      "1037/4744 pairs merged. (1036, 350) -> b' families' occured 10 times.\n",
      "1038/4744 pairs merged. (852, 121) -> b'racy' occured 10 times.\n",
      "1039/4744 pairs merged. (319, 104) -> b'ech' occured 10 times.\n",
      "1040/4744 pairs merged. (675, 121) -> b'ology' occured 10 times.\n",
      "1041/4744 pairs merged. (349, 263) -> b'ided' occured 10 times.\n",
      "1042/4744 pairs merged. (280, 261) -> b' ser' occured 10 times.\n",
      "1043/4744 pairs merged. (388, 381) -> b'ulture' occured 10 times.\n",
      "1044/4744 pairs merged. (938, 512) -> b' influence' occured 10 times.\n",
      "1045/4744 pairs merged. (636, 262) -> b' common' occured 10 times.\n",
      "1046/4744 pairs merged. (631, 55) -> b'127' occured 10 times.\n",
      "1047/4744 pairs merged. (478, 118) -> b' adv' occured 10 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 808/4744 [00:08<00:38, 102.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1048/4744 pairs merged. (354, 514) -> b' Wall' occured 10 times.\n",
      "1049/4744 pairs merged. (45, 115) -> b'-s' occured 10 times.\n",
      "1050/4744 pairs merged. (993, 334) -> b' Commun' occured 10 times.\n",
      "1051/4744 pairs merged. (400, 99) -> b' proc' occured 10 times.\n",
      "1052/4744 pairs merged. (269, 287) -> b'atic' occured 10 times.\n",
      "1053/4744 pairs merged. (114, 489) -> b'rough' occured 10 times.\n",
      "1054/4744 pairs merged. (99, 99) -> b'cc' occured 10 times.\n",
      "1055/4744 pairs merged. (397, 105) -> b' Li' occured 10 times.\n",
      "1056/4744 pairs merged. (385, 335) -> b' exist' occured 10 times.\n",
      "1057/4744 pairs merged. (260, 110) -> b' then' occured 10 times.\n",
      "1058/4744 pairs merged. (293, 918) -> b' much' occured 10 times.\n",
      "1059/4744 pairs merged. (951, 1006) -> b' scholar' occured 10 times.\n",
      "1060/4744 pairs merged. (49, 53) -> b'15' occured 10 times.\n",
      "1061/4744 pairs merged. (270, 920) -> b' would' occured 10 times.\n",
      "1062/4744 pairs merged. (417, 304) -> b'ically' occured 10 times.\n",
      "1063/4744 pairs merged. (260, 109) -> b' them' occured 10 times.\n",
      "1064/4744 pairs merged. (379, 343) -> b'iance' occured 10 times.\n",
      "1065/4744 pairs merged. (355, 547) -> b' former' occured 10 times.\n",
      "1066/4744 pairs merged. (336, 377) -> b' These' occured 10 times.\n",
      "1067/4744 pairs merged. (410, 110) -> b' ann' occured 10 times.\n",
      "1068/4744 pairs merged. (923, 97) -> b' campa' occured 10 times.\n",
      "1069/4744 pairs merged. (1068, 465) -> b' campaign' occured 10 times.\n",
      "1070/4744 pairs merged. (256, 332) -> b' tro' occured 10 times.\n",
      "1071/4744 pairs merged. (1070, 362) -> b' troop' occured 10 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 830/4744 [00:08<00:38, 100.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1072/4744 pairs merged. (300, 303) -> b' last' occured 10 times.\n",
      "1073/4744 pairs merged. (455, 458) -> b' During' occured 10 times.\n",
      "1074/4744 pairs merged. (720, 370) -> b' conquest' occured 10 times.\n",
      "1075/4744 pairs merged. (420, 959) -> b' Kingdoms' occured 10 times.\n",
      "1076/4744 pairs merged. (485, 290) -> b'ellion' occured 10 times.\n",
      "1077/4744 pairs merged. (914, 263) -> b' continued' occured 10 times.\n",
      "1078/4744 pairs merged. (111, 118) -> b'ov' occured 10 times.\n",
      "1079/4744 pairs merged. (117, 103) -> b'ug' occured 10 times.\n",
      "1080/4744 pairs merged. (768, 347) -> b' Japanese' occured 10 times.\n",
      "1081/4744 pairs merged. (473, 964) -> b'ograph' occured 9 times.\n",
      "1082/4744 pairs merged. (97, 341) -> b'ach' occured 9 times.\n",
      "1083/4744 pairs merged. (320, 322) -> b' now' occured 9 times.\n",
      "1084/4744 pairs merged. (376, 115) -> b'ains' occured 9 times.\n",
      "1085/4744 pairs merged. (508, 972) -> b' group' occured 9 times.\n",
      "1086/4744 pairs merged. (284, 514) -> b' fall' occured 9 times.\n",
      "1087/4744 pairs merged. (360, 263) -> b'aced' occured 9 times.\n",
      "1088/4744 pairs merged. (462, 285) -> b' var' occured 9 times.\n",
      "1089/4744 pairs merged. (810, 893) -> b' written' occured 9 times.\n",
      "1090/4744 pairs merged. (804, 510) -> b'crip' occured 9 times.\n",
      "1091/4744 pairs merged. (410, 1033) -> b' another' occured 9 times.\n",
      "1092/4744 pairs merged. (300, 440) -> b' loc' occured 9 times.\n",
      "1093/4744 pairs merged. (633, 1034) -> b' independ' occured 9 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 852/4744 [00:08<00:39, 98.90it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1094/4744 pairs merged. (32, 441) -> b' \\xe2\\x80\\x93' occured 9 times.\n",
      "1095/4744 pairs merged. (346, 434) -> b' Age' occured 9 times.\n",
      "1096/4744 pairs merged. (977, 519) -> b'fucianism' occured 9 times.\n",
      "1097/4744 pairs merged. (337, 274) -> b' stand' occured 9 times.\n",
      "1098/4744 pairs merged. (851, 292) -> b'cient' occured 9 times.\n",
      "1099/4744 pairs merged. (256, 1039) -> b' tech' occured 9 times.\n",
      "1100/4744 pairs merged. (1099, 110) -> b' techn' occured 9 times.\n",
      "1101/4744 pairs merged. (291, 312) -> b' emp' occured 9 times.\n",
      "1102/4744 pairs merged. (102, 314) -> b'ful' occured 9 times.\n",
      "1103/4744 pairs merged. (386, 304) -> b' only' occured 9 times.\n",
      "1104/4744 pairs merged. (478, 362) -> b' adop' occured 9 times.\n",
      "1105/4744 pairs merged. (111, 378) -> b'ood' occured 9 times.\n",
      "1106/4744 pairs merged. (656, 653) -> b' establish' occured 9 times.\n",
      "1107/4744 pairs merged. (319, 412) -> b'ects' occured 9 times.\n",
      "1108/4744 pairs merged. (325, 505) -> b' great' occured 9 times.\n",
      "1109/4744 pairs merged. (32, 332) -> b' ro' occured 9 times.\n",
      "1110/4744 pairs merged. (262, 100) -> b'ond' occured 9 times.\n",
      "1111/4744 pairs merged. (1051, 943) -> b' proclaimed' occured 9 times.\n",
      "1112/4744 pairs merged. (604, 121) -> b' economy' occured 9 times.\n",
      "1113/4744 pairs merged. (363, 269) -> b' what' occured 9 times.\n",
      "1114/4744 pairs merged. (260, 377) -> b' these' occured 9 times.\n",
      "1115/4744 pairs merged. (259, 120) -> b'anx' occured 9 times.\n",
      "1116/4744 pairs merged. (466, 674) -> b' Guang' occured 9 times.\n",
      "1117/4744 pairs merged. (349, 512) -> b'idence' occured 9 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 875/4744 [00:09<00:36, 105.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1118/4744 pairs merged. (275, 115) -> b'als' occured 9 times.\n",
      "1119/4744 pairs merged. (267, 580) -> b' app' occured 9 times.\n",
      "1120/4744 pairs merged. (506, 830) -> b' agric' occured 9 times.\n",
      "1121/4744 pairs merged. (102, 261) -> b'fer' occured 9 times.\n",
      "1122/4744 pairs merged. (107, 101) -> b'ke' occured 9 times.\n",
      "1123/4744 pairs merged. (1005, 629) -> b' previous' occured 9 times.\n",
      "1124/4744 pairs merged. (307, 726) -> b'urren' occured 9 times.\n",
      "1125/4744 pairs merged. (32, 106) -> b' j' occured 9 times.\n",
      "1126/4744 pairs merged. (310, 322) -> b' how' occured 9 times.\n",
      "1127/4744 pairs merged. (258, 101) -> b'ine' occured 9 times.\n",
      "1128/4744 pairs merged. (484, 276) -> b' For' occured 9 times.\n",
      "1129/4744 pairs merged. (532, 321) -> b' lead' occured 9 times.\n",
      "1130/4744 pairs merged. (400, 665) -> b' proper' occured 9 times.\n",
      "1131/4744 pairs merged. (105, 304) -> b'ily' occured 9 times.\n",
      "1132/4744 pairs merged. (354, 540) -> b' Wei' occured 9 times.\n",
      "1133/4744 pairs merged. (612, 119) -> b' new' occured 9 times.\n",
      "1134/4744 pairs merged. (306, 112) -> b' Sp' occured 9 times.\n",
      "1135/4744 pairs merged. (280, 319) -> b' sec' occured 9 times.\n",
      "1136/4744 pairs merged. (758, 705) -> b' societ' occured 9 times.\n",
      "1137/4744 pairs merged. (284, 955) -> b' further' occured 9 times.\n",
      "1138/4744 pairs merged. (291, 102) -> b' ef' occured 9 times.\n",
      "1139/4744 pairs merged. (293, 262) -> b' mon' occured 9 times.\n",
      "1140/4744 pairs merged. (281, 112) -> b'esp' occured 9 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 897/4744 [00:09<00:37, 102.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1141/4744 pairs merged. (758, 372) -> b' social' occured 9 times.\n",
      "1142/4744 pairs merged. (1071, 115) -> b' troops' occured 9 times.\n",
      "1143/4744 pairs merged. (282, 338) -> b' det' occured 9 times.\n",
      "1144/4744 pairs merged. (267, 109) -> b' am' occured 9 times.\n",
      "1145/4744 pairs merged. (266, 112) -> b' op' occured 9 times.\n",
      "1146/4744 pairs merged. (32, 86) -> b' V' occured 9 times.\n",
      "1147/4744 pairs merged. (864, 295) -> b' invas' occured 9 times.\n",
      "1148/4744 pairs merged. (105, 261) -> b'ier' occured 9 times.\n",
      "1149/4744 pairs merged. (546, 121) -> b' Uy' occured 9 times.\n",
      "1150/4744 pairs merged. (1149, 435) -> b' Uygh' occured 9 times.\n",
      "1151/4744 pairs merged. (1150, 307) -> b' Uyghur' occured 9 times.\n",
      "1152/4744 pairs merged. (420, 694) -> b' Khan' occured 9 times.\n",
      "1153/4744 pairs merged. (32, 409) -> b' qu' occured 9 times.\n",
      "1154/4744 pairs merged. (356, 323) -> b' Hong' occured 9 times.\n",
      "1155/4744 pairs merged. (289, 1021) -> b' CCP' occured 9 times.\n",
      "1156/4744 pairs merged. (332, 115) -> b'ros' occured 8 times.\n",
      "1157/4744 pairs merged. (270, 663) -> b' wide' occured 8 times.\n",
      "1158/4744 pairs merged. (732, 779) -> b' civilization' occured 8 times.\n",
      "1159/4744 pairs merged. (485, 322) -> b'ellow' occured 8 times.\n",
      "1160/4744 pairs merged. (475, 646) -> b' cultural' occured 8 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 919/4744 [00:09<00:38, 100.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161/4744 pairs merged. (257, 265) -> b'here' occured 8 times.\n",
      "1162/4744 pairs merged. (99, 116) -> b'ct' occured 8 times.\n",
      "1163/4744 pairs merged. (781, 973) -> b' Neolithic' occured 8 times.\n",
      "1164/4744 pairs merged. (97, 119) -> b'aw' occured 8 times.\n",
      "1165/4744 pairs merged. (369, 114) -> b' Er' occured 8 times.\n",
      "1166/4744 pairs merged. (105, 463) -> b'ium' occured 8 times.\n",
      "1167/4744 pairs merged. (287, 375) -> b'icated' occured 8 times.\n",
      "1168/4744 pairs merged. (974, 119) -> b' few' occured 8 times.\n",
      "1169/4744 pairs merged. (476, 98) -> b'emb' occured 8 times.\n",
      "1170/4744 pairs merged. (411, 268) -> b'aven' occured 8 times.\n",
      "1171/4744 pairs merged. (362, 104) -> b'oph' occured 8 times.\n",
      "1172/4744 pairs merged. (104, 258) -> b'hin' occured 8 times.\n",
      "1173/4744 pairs merged. (356, 674) -> b' Huang' occured 8 times.\n",
      "1174/4744 pairs merged. (381, 115) -> b'ures' occured 8 times.\n",
      "1175/4744 pairs merged. (301, 360) -> b' reac' occured 8 times.\n",
      "1176/4744 pairs merged. (1175, 503) -> b' reached' occured 8 times.\n",
      "1177/4744 pairs merged. (280, 465) -> b' sign' occured 8 times.\n",
      "1178/4744 pairs merged. (445, 981) -> b' contemp' occured 8 times.\n",
      "1179/4744 pairs merged. (1178, 276) -> b' contempor' occured 8 times.\n",
      "1180/4744 pairs merged. (259, 101) -> b'ane' occured 8 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|█▉        | 940/4744 [00:09<00:38, 98.91it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1181/4744 pairs merged. (400, 847) -> b' produc' occured 8 times.\n",
      "1182/4744 pairs merged. (374, 261) -> b'aper' occured 8 times.\n",
      "1183/4744 pairs merged. (111, 121) -> b'oy' occured 8 times.\n",
      "1184/4744 pairs merged. (300, 323) -> b' long' occured 8 times.\n",
      "1185/4744 pairs merged. (45, 108) -> b'-l' occured 8 times.\n",
      "1186/4744 pairs merged. (54, 48) -> b'60' occured 8 times.\n",
      "1187/4744 pairs merged. (301, 465) -> b' reign' occured 8 times.\n",
      "1188/4744 pairs merged. (1104, 416) -> b' adopted' occured 8 times.\n",
      "1189/4744 pairs merged. (387, 109) -> b' dem' occured 8 times.\n",
      "1190/4744 pairs merged. (346, 527) -> b' After' occured 8 times.\n",
      "1191/4744 pairs merged. (97, 120) -> b'ax' occured 8 times.\n",
      "1192/4744 pairs merged. (675, 417) -> b'ological' occured 8 times.\n",
      "1193/4744 pairs merged. (116, 381) -> b'ture' occured 8 times.\n",
      "1194/4744 pairs merged. (288, 381) -> b' bure' occured 8 times.\n",
      "1195/4744 pairs merged. (1194, 97) -> b' burea' occured 8 times.\n",
      "1196/4744 pairs merged. (1195, 436) -> b' bureauc' occured 8 times.\n",
      "1197/4744 pairs merged. (263, 263) -> b'eded' occured 8 times.\n",
      "1198/4744 pairs merged. (287, 116) -> b'ict' occured 8 times.\n",
      "1199/4744 pairs merged. (793, 941) -> b'volution' occured 8 times.\n",
      "1200/4744 pairs merged. (271, 265) -> b' cre' occured 8 times.\n",
      "1201/4744 pairs merged. (419, 50) -> b'192' occured 8 times.\n",
      "1202/4744 pairs merged. (116, 308) -> b'til' occured 8 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 962/4744 [00:09<00:36, 102.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1203/4744 pairs merged. (841, 867) -> b' mainland' occured 8 times.\n",
      "1204/4744 pairs merged. (112, 263) -> b'ped' occured 8 times.\n",
      "1205/4744 pairs merged. (823, 115) -> b' reforms' occured 8 times.\n",
      "1206/4744 pairs merged. (493, 340) -> b' ==\\n\\n' occured 8 times.\n",
      "1207/4744 pairs merged. (261, 418) -> b'erous' occured 8 times.\n",
      "1208/4744 pairs merged. (107, 278) -> b'king' occured 8 times.\n",
      "1209/4744 pairs merged. (99, 426) -> b'cover' occured 8 times.\n",
      "1210/4744 pairs merged. (599, 115) -> b'oss' occured 8 times.\n",
      "1211/4744 pairs merged. (341, 311) -> b'chang' occured 8 times.\n",
      "1212/4744 pairs merged. (457, 379) -> b' Xian' occured 8 times.\n",
      "1213/4744 pairs merged. (118, 1117) -> b'vidence' occured 8 times.\n",
      "1214/4744 pairs merged. (32, 828) -> b' use' occured 8 times.\n",
      "1215/4744 pairs merged. (266, 1054) -> b' occ' occured 8 times.\n",
      "1216/4744 pairs merged. (457, 105) -> b' Xi' occured 8 times.\n",
      "1217/4744 pairs merged. (671, 103) -> b' larg' occured 8 times.\n",
      "1218/4744 pairs merged. (592, 701) -> b' about' occured 8 times.\n",
      "1219/4744 pairs merged. (508, 321) -> b' grad' occured 8 times.\n",
      "1220/4744 pairs merged. (277, 273) -> b' init' occured 8 times.\n",
      "1221/4744 pairs merged. (298, 370) -> b'omest' occured 8 times.\n",
      "1222/4744 pairs merged. (97, 349) -> b'aid' occured 8 times.\n",
      "1223/4744 pairs merged. (461, 480) -> b' around' occured 8 times.\n",
      "1224/4744 pairs merged. (354, 339) -> b' With' occured 8 times.\n",
      "1225/4744 pairs merged. (308, 467) -> b'ility' occured 8 times.\n",
      "1226/4744 pairs merged. (109, 268) -> b'men' occured 8 times.\n",
      "1227/4744 pairs merged. (593, 112) -> b' resp' occured 8 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 984/4744 [00:10<00:35, 105.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1228/4744 pairs merged. (833, 389) -> b' Asia' occured 8 times.\n",
      "1229/4744 pairs merged. (379, 115) -> b'ians' occured 8 times.\n",
      "1230/4744 pairs merged. (256, 119) -> b' tw' occured 8 times.\n",
      "1231/4744 pairs merged. (348, 489) -> b'though' occured 8 times.\n",
      "1232/4744 pairs merged. (774, 684) -> b' settle' occured 8 times.\n",
      "1233/4744 pairs merged. (534, 263) -> b'ended' occured 8 times.\n",
      "1234/4744 pairs merged. (271, 111) -> b' co' occured 8 times.\n",
      "1235/4744 pairs merged. (331, 998) -> b' Battle' occured 8 times.\n",
      "1236/4744 pairs merged. (121, 101) -> b'ye' occured 8 times.\n",
      "1237/4744 pairs merged. (111, 107) -> b'ok' occured 8 times.\n",
      "1238/4744 pairs merged. (405, 116) -> b' It' occured 8 times.\n",
      "1239/4744 pairs merged. (300, 819) -> b' lost' occured 8 times.\n",
      "1240/4744 pairs merged. (271, 511) -> b' cour' occured 8 times.\n",
      "1241/4744 pairs merged. (1240, 116) -> b' court' occured 8 times.\n",
      "1242/4744 pairs merged. (274, 263) -> b'anded' occured 8 times.\n",
      "1243/4744 pairs merged. (110, 278) -> b'ning' occured 8 times.\n",
      "1244/4744 pairs merged. (331, 121) -> b' By' occured 8 times.\n",
      "1245/4744 pairs merged. (98, 259) -> b'ban' occured 8 times.\n",
      "1246/4744 pairs merged. (365, 258) -> b' within' occured 8 times.\n",
      "1247/4744 pairs merged. (355, 664) -> b' forced' occured 8 times.\n",
      "1248/4744 pairs merged. (108, 263) -> b'led' occured 8 times.\n",
      "1249/4744 pairs merged. (282, 114) -> b' dr' occured 8 times.\n",
      "1250/4744 pairs merged. (431, 304) -> b'ably' occured 8 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██▏       | 1018/4744 [00:10<00:36, 103.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1251/4744 pairs merged. (483, 393) -> b' rulers' occured 8 times.\n",
      "1252/4744 pairs merged. (285, 341) -> b'arch' occured 8 times.\n",
      "1253/4744 pairs merged. (904, 1017) -> b' success' occured 8 times.\n",
      "1254/4744 pairs merged. (276, 416) -> b'orted' occured 8 times.\n",
      "1255/4744 pairs merged. (111, 120) -> b'ox' occured 8 times.\n",
      "1256/4744 pairs merged. (737, 922) -> b' brought' occured 8 times.\n",
      "1257/4744 pairs merged. (99, 503) -> b'ched' occured 8 times.\n",
      "1258/4744 pairs merged. (298, 321) -> b'omad' occured 8 times.\n",
      "1259/4744 pairs merged. (495, 115) -> b'itions' occured 8 times.\n",
      "1260/4744 pairs merged. (114, 294) -> b'ris' occured 8 times.\n",
      "1261/4744 pairs merged. (108, 526) -> b'lord' occured 8 times.\n",
      "1262/4744 pairs merged. (407, 259) -> b' Nan' occured 8 times.\n",
      "1263/4744 pairs merged. (284, 583) -> b' fact' occured 8 times.\n",
      "1264/4744 pairs merged. (524, 780) -> b' regimes' occured 8 times.\n",
      "1265/4744 pairs merged. (508, 322) -> b' grow' occured 8 times.\n",
      "1266/4744 pairs merged. (401, 771) -> b' tribut' occured 8 times.\n",
      "1267/4744 pairs merged. (420, 104) -> b' Kh' occured 8 times.\n",
      "1268/4744 pairs merged. (659, 263) -> b' ended' occured 8 times.\n",
      "1269/4744 pairs merged. (419, 57) -> b'199' occured 8 times.\n",
      "1270/4744 pairs merged. (615, 268) -> b' millen' occured 7 times.\n",
      "1271/4744 pairs merged. (1270, 110) -> b' millenn' occured 7 times.\n",
      "1272/4744 pairs merged. (1156, 115) -> b'ross' occured 7 times.\n",
      "1273/4744 pairs merged. (840, 97) -> b' area' occured 7 times.\n",
      "1274/4744 pairs merged. (400, 115) -> b' pros' occured 7 times.\n",
      "1275/4744 pairs merged. (966, 263) -> b' emerged' occured 7 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1040/4744 [00:10<00:35, 103.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1276/4744 pairs merged. (395, 1159) -> b' Yellow' occured 7 times.\n",
      "1277/4744 pairs merged. (270, 370) -> b' west' occured 7 times.\n",
      "1278/4744 pairs merged. (808, 278) -> b' increasing' occured 7 times.\n",
      "1279/4744 pairs merged. (283, 108) -> b' pl' occured 7 times.\n",
      "1280/4744 pairs merged. (277, 115) -> b' ins' occured 7 times.\n",
      "1281/4744 pairs merged. (256, 894) -> b' tex' occured 7 times.\n",
      "1282/4744 pairs merged. (300, 273) -> b' lit' occured 7 times.\n",
      "1283/4744 pairs merged. (283, 111) -> b' po' occured 7 times.\n",
      "1284/4744 pairs merged. (543, 112) -> b' disp' occured 7 times.\n",
      "1285/4744 pairs merged. (976, 1170) -> b' Heaven' occured 7 times.\n",
      "1286/4744 pairs merged. (848, 1096) -> b' Confucianism' occured 7 times.\n",
      "1287/4744 pairs merged. (397, 934) -> b' Leg' occured 7 times.\n",
      "1288/4744 pairs merged. (346, 68) -> b' AD' occured 7 times.\n",
      "1289/4744 pairs merged. (634, 109) -> b' term' occured 7 times.\n",
      "1290/4744 pairs merged. (104, 814) -> b'hold' occured 7 times.\n",
      "1291/4744 pairs merged. (1177, 853) -> b' signific' occured 7 times.\n",
      "1292/4744 pairs merged. (1291, 488) -> b' significant' occured 7 times.\n",
      "1293/4744 pairs merged. (1100, 1040) -> b' technology' occured 7 times.\n",
      "1294/4744 pairs merged. (283, 1182) -> b' paper' occured 7 times.\n",
      "1295/4744 pairs merged. (986, 519) -> b' Buddhism' occured 7 times.\n",
      "1296/4744 pairs merged. (854, 511) -> b' flour' occured 7 times.\n",
      "1297/4744 pairs merged. (575, 1102) -> b' powerful' occured 7 times.\n",
      "1298/4744 pairs merged. (53, 56) -> b'58' occured 7 times.\n",
      "1299/4744 pairs merged. (857, 357) -> b' development' occured 7 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 1063/4744 [00:10<00:35, 102.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1300/4744 pairs merged. (550, 695) -> b' Three' occured 7 times.\n",
      "1301/4744 pairs merged. (433, 99) -> b' enc' occured 7 times.\n",
      "1302/4744 pairs merged. (271, 504) -> b' came' occured 7 times.\n",
      "1303/4744 pairs merged. (297, 722) -> b' Chiang' occured 7 times.\n",
      "1304/4744 pairs merged. (346, 114) -> b' Ar' occured 7 times.\n",
      "1305/4744 pairs merged. (114, 609) -> b'rup' occured 7 times.\n",
      "1306/4744 pairs merged. (633, 117) -> b' indu' occured 7 times.\n",
      "1307/4744 pairs merged. (866, 269) -> b' defeat' occured 7 times.\n",
      "1308/4744 pairs merged. (761, 99) -> b' acc' occured 7 times.\n",
      "1309/4744 pairs merged. (510, 108) -> b'ipl' occured 7 times.\n",
      "1310/4744 pairs merged. (388, 646) -> b'ultural' occured 7 times.\n",
      "1311/4744 pairs merged. (911, 1207) -> b' numerous' occured 7 times.\n",
      "1312/4744 pairs merged. (282, 375) -> b' dated' occured 7 times.\n",
      "1313/4744 pairs merged. (342, 1053) -> b' through' occured 7 times.\n",
      "1314/4744 pairs merged. (342, 695) -> b' three' occured 7 times.\n",
      "1315/4744 pairs merged. (258, 100) -> b'ind' occured 7 times.\n",
      "1316/4744 pairs merged. (353, 390) -> b'imate' occured 7 times.\n",
      "1317/4744 pairs merged. (45, 100) -> b'-d' occured 7 times.\n",
      "1318/4744 pairs merged. (115, 104) -> b'sh' occured 7 times.\n",
      "1319/4744 pairs merged. (400, 116) -> b' prot' occured 7 times.\n",
      "1320/4744 pairs merged. (332, 112) -> b'rop' occured 7 times.\n",
      "1321/4744 pairs merged. (692, 772) -> b' remained' occured 7 times.\n",
      "1322/4744 pairs merged. (271, 467) -> b' city' occured 7 times.\n",
      "1323/4744 pairs merged. (98, 540) -> b'bei' occured 7 times.\n",
      "1324/4744 pairs merged. (105, 375) -> b'iated' occured 7 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1085/4744 [00:11<00:35, 103.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1325/4744 pairs merged. (288, 909) -> b' both' occured 7 times.\n",
      "1326/4744 pairs merged. (649, 115) -> b'uals' occured 7 times.\n",
      "1327/4744 pairs merged. (401, 626) -> b' trans' occured 7 times.\n",
      "1328/4744 pairs merged. (398, 116) -> b' att' occured 7 times.\n",
      "1329/4744 pairs merged. (798, 754) -> b' Anyang' occured 7 times.\n",
      "1330/4744 pairs merged. (396, 148) -> b'\\xe2\\x80\\x94' occured 7 times.\n",
      "1331/4744 pairs merged. (400, 118) -> b' prov' occured 7 times.\n",
      "1332/4744 pairs merged. (866, 375) -> b' defeated' occured 7 times.\n",
      "1333/4744 pairs merged. (313, 281) -> b'ives' occured 7 times.\n",
      "1334/4744 pairs merged. (1230, 111) -> b' two' occured 7 times.\n",
      "1335/4744 pairs merged. (356, 117) -> b' Hu' occured 7 times.\n",
      "1336/4744 pairs merged. (369, 912) -> b' Eastern' occured 7 times.\n",
      "1337/4744 pairs merged. (997, 811) -> b' States' occured 7 times.\n",
      "1338/4744 pairs merged. (334, 100) -> b'und' occured 7 times.\n",
      "1339/4744 pairs merged. (1136, 121) -> b' society' occured 7 times.\n",
      "1340/4744 pairs merged. (97, 265) -> b'are' occured 7 times.\n",
      "1341/4744 pairs merged. (485, 494) -> b'ellect' occured 7 times.\n",
      "1342/4744 pairs merged. (293, 917) -> b' made' occured 7 times.\n",
      "1343/4744 pairs merged. (115, 358) -> b'sel' occured 7 times.\n",
      "1344/4744 pairs merged. (825, 10) -> b' ===\\n\\n\\n' occured 7 times.\n",
      "1345/4744 pairs merged. (271, 1124) -> b' curren' occured 7 times.\n",
      "1346/4744 pairs merged. (749, 436) -> b'struc' occured 7 times.\n",
      "1347/4744 pairs merged. (116, 307) -> b'tur' occured 7 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1107/4744 [00:11<00:36, 98.75it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1348/4744 pairs merged. (423, 891) -> b' unified' occured 7 times.\n",
      "1349/4744 pairs merged. (120, 116) -> b'xt' occured 7 times.\n",
      "1350/4744 pairs merged. (552, 287) -> b' polic' occured 7 times.\n",
      "1351/4744 pairs merged. (320, 1258) -> b' nomad' occured 7 times.\n",
      "1352/4744 pairs merged. (1351, 287) -> b' nomadic' occured 7 times.\n",
      "1353/4744 pairs merged. (319, 416) -> b'ected' occured 7 times.\n",
      "1354/4744 pairs merged. (401, 468) -> b' trib' occured 7 times.\n",
      "1355/4744 pairs merged. (1354, 281) -> b' tribes' occured 7 times.\n",
      "1356/4744 pairs merged. (49, 49) -> b'11' occured 7 times.\n",
      "1357/4744 pairs merged. (685, 413) -> b' caus' occured 7 times.\n",
      "1358/4744 pairs merged. (530, 263) -> b'aged' occured 7 times.\n",
      "1359/4744 pairs merged. (306, 101) -> b' Se' occured 7 times.\n",
      "1360/4744 pairs merged. (306, 699) -> b' Six' occured 7 times.\n",
      "1361/4744 pairs merged. (1012, 884) -> b' weakened' occured 7 times.\n",
      "1362/4744 pairs merged. (784, 115) -> b' officials' occured 7 times.\n",
      "1363/4744 pairs merged. (461, 942) -> b' army' occured 7 times.\n",
      "1364/4744 pairs merged. (530, 259) -> b'agan' occured 7 times.\n",
      "1365/4744 pairs merged. (116, 121) -> b'ty' occured 7 times.\n",
      "1366/4744 pairs merged. (979, 338) -> b' market' occured 7 times.\n",
      "1367/4744 pairs merged. (883, 899) -> b' United' occured 7 times.\n",
      "1368/4744 pairs merged. (731, 329) -> b' sever' occured 6 times.\n",
      "1369/4744 pairs merged. (1274, 665) -> b' prosper' occured 6 times.\n",
      "1370/4744 pairs merged. (1024, 361) -> b'stitut' occured 6 times.\n",
      "1371/4744 pairs merged. (1085, 115) -> b' groups' occured 6 times.\n",
      "1372/4744 pairs merged. (294, 101) -> b'ise' occured 6 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1130/4744 [00:11<00:34, 105.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1373/4744 pairs merged. (116, 376) -> b'tain' occured 6 times.\n",
      "1374/4744 pairs merged. (271, 259) -> b' can' occured 6 times.\n",
      "1375/4744 pairs merged. (271, 114) -> b' cr' occured 6 times.\n",
      "1376/4744 pairs merged. (108, 281) -> b'les' occured 6 times.\n",
      "1377/4744 pairs merged. (1088, 629) -> b' various' occured 6 times.\n",
      "1378/4744 pairs merged. (889, 488) -> b' dominant' occured 6 times.\n",
      "1379/4744 pairs merged. (597, 570) -> b' controll' occured 6 times.\n",
      "1380/4744 pairs merged. (1379, 263) -> b' controlled' occured 6 times.\n",
      "1381/4744 pairs merged. (265, 116) -> b'ret' occured 6 times.\n",
      "1382/4744 pairs merged. (1165, 1031) -> b' Erlit' occured 6 times.\n",
      "1383/4744 pairs merged. (1382, 286) -> b' Erlitou' occured 6 times.\n",
      "1384/4744 pairs merged. (846, 118) -> b' surv' occured 6 times.\n",
      "1385/4744 pairs merged. (1281, 412) -> b' texts' occured 6 times.\n",
      "1386/4744 pairs merged. (1282, 261) -> b' liter' occured 6 times.\n",
      "1387/4744 pairs merged. (932, 115) -> b' records' occured 6 times.\n",
      "1388/4744 pairs merged. (1093, 292) -> b' independent' occured 6 times.\n",
      "1389/4744 pairs merged. (300, 311) -> b' lang' occured 6 times.\n",
      "1390/4744 pairs merged. (1389, 117) -> b' langu' occured 6 times.\n",
      "1391/4744 pairs merged. (738, 52) -> b'104' occured 6 times.\n",
      "1392/4744 pairs merged. (50, 53) -> b'25' occured 6 times.\n",
      "1393/4744 pairs merged. (1287, 275) -> b' Legal' occured 6 times.\n",
      "1394/4744 pairs merged. (67, 1172) -> b'Chin' occured 6 times.\n",
      "1395/4744 pairs merged. (50, 49) -> b'21' occured 6 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 1152/4744 [00:11<00:34, 105.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1396/4744 pairs merged. (762, 562) -> b' entered' occured 6 times.\n",
      "1397/4744 pairs merged. (788, 565) -> b' class' occured 6 times.\n",
      "1398/4744 pairs merged. (50, 557) -> b'220' occured 6 times.\n",
      "1399/4744 pairs merged. (410, 1098) -> b' ancient' occured 6 times.\n",
      "1400/4744 pairs merged. (525, 460) -> b' order' occured 6 times.\n",
      "1401/4744 pairs merged. (271, 570) -> b' coll' occured 6 times.\n",
      "1402/4744 pairs merged. (469, 307) -> b' centur' occured 6 times.\n",
      "1403/4744 pairs merged. (1402, 350) -> b' centuries' occured 6 times.\n",
      "1404/4744 pairs merged. (461, 116) -> b' art' occured 6 times.\n",
      "1405/4744 pairs merged. (306, 855) -> b' Sui' occured 6 times.\n",
      "1406/4744 pairs merged. (57, 48) -> b'90' occured 6 times.\n",
      "1407/4744 pairs merged. (617, 473) -> b' recog' occured 6 times.\n",
      "1408/4744 pairs merged. (1407, 110) -> b' recogn' occured 6 times.\n",
      "1409/4744 pairs merged. (57, 1186) -> b'960' occured 6 times.\n",
      "1410/4744 pairs merged. (539, 258) -> b' prin' occured 6 times.\n",
      "1411/4744 pairs merged. (436, 1193) -> b'ucture' occured 6 times.\n",
      "1412/4744 pairs merged. (1196, 1038) -> b' bureaucracy' occured 6 times.\n",
      "1413/4744 pairs merged. (369, 307) -> b' Eur' occured 6 times.\n",
      "1414/4744 pairs merged. (111, 98) -> b'ob' occured 6 times.\n",
      "1415/4744 pairs merged. (111, 377) -> b'ose' occured 6 times.\n",
      "1416/4744 pairs merged. (114, 274) -> b'rand' occured 6 times.\n",
      "1417/4744 pairs merged. (905, 117) -> b' Manchu' occured 6 times.\n",
      "1418/4744 pairs merged. (49, 55) -> b'17' occured 6 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 1174/4744 [00:11<00:34, 104.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1419/4744 pairs merged. (101, 259) -> b'ean' occured 6 times.\n",
      "1420/4744 pairs merged. (306, 334) -> b' Sun' occured 6 times.\n",
      "1421/4744 pairs merged. (321, 278) -> b'ading' occured 6 times.\n",
      "1422/4744 pairs merged. (423, 1202) -> b' until' occured 6 times.\n",
      "1423/4744 pairs merged. (391, 79) -> b' RO' occured 6 times.\n",
      "1424/4744 pairs merged. (1423, 67) -> b' ROC' occured 6 times.\n",
      "1425/4744 pairs merged. (762, 432) -> b' entire' occured 6 times.\n",
      "1426/4744 pairs merged. (282, 1309) -> b' dipl' occured 6 times.\n",
      "1427/4744 pairs merged. (1426, 298) -> b' diplom' occured 6 times.\n",
      "1428/4744 pairs merged. (419, 55) -> b'197' occured 6 times.\n",
      "1429/4744 pairs merged. (578, 321) -> b' decad' occured 6 times.\n",
      "1430/4744 pairs merged. (1429, 281) -> b' decades' occured 6 times.\n",
      "1431/4744 pairs merged. (459, 100) -> b' Ind' occured 6 times.\n",
      "1432/4744 pairs merged. (1206, 10) -> b' ==\\n\\n\\n' occured 6 times.\n",
      "1433/4744 pairs merged. (461, 341) -> b' arch' occured 6 times.\n",
      "1434/4744 pairs merged. (1433, 97) -> b' archa' occured 6 times.\n",
      "1435/4744 pairs merged. (582, 319) -> b' spec' occured 6 times.\n",
      "1436/4744 pairs merged. (45, 102) -> b'-f' occured 6 times.\n",
      "1437/4744 pairs merged. (310, 121) -> b' hy' occured 6 times.\n",
      "1438/4744 pairs merged. (1209, 263) -> b'covered' occured 6 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1196/4744 [00:12<00:34, 103.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1439/4744 pairs merged. (429, 97) -> b' Sha' occured 6 times.\n",
      "1440/4744 pairs merged. (1115, 105) -> b'anxi' occured 6 times.\n",
      "1441/4744 pairs merged. (276, 350) -> b'ories' occured 6 times.\n",
      "1442/4744 pairs merged. (258, 263) -> b'ined' occured 6 times.\n",
      "1443/4744 pairs merged. (1120, 1043) -> b' agriculture' occured 6 times.\n",
      "1444/4744 pairs merged. (1219, 655) -> b' gradually' occured 6 times.\n",
      "1445/4744 pairs merged. (478, 100) -> b' add' occured 6 times.\n",
      "1446/4744 pairs merged. (291, 1213) -> b' evidence' occured 6 times.\n",
      "1447/4744 pairs merged. (414, 389) -> b' Jia' occured 6 times.\n",
      "1448/4744 pairs merged. (611, 285) -> b' char' occured 6 times.\n",
      "1449/4744 pairs merged. (526, 278) -> b'ording' occured 6 times.\n",
      "1450/4744 pairs merged. (808, 263) -> b' increased' occured 6 times.\n",
      "1451/4744 pairs merged. (50, 437) -> b'200' occured 6 times.\n",
      "1452/4744 pairs merged. (288, 108) -> b' bl' occured 6 times.\n",
      "1453/4744 pairs merged. (299, 468) -> b' Tib' occured 6 times.\n",
      "1454/4744 pairs merged. (1453, 338) -> b' Tibet' occured 6 times.\n",
      "1455/4744 pairs merged. (464, 311) -> b' Zhang' occured 6 times.\n",
      "1456/4744 pairs merged. (282, 281) -> b' des' occured 6 times.\n",
      "1457/4744 pairs merged. (418, 304) -> b'ously' occured 6 times.\n",
      "1458/4744 pairs merged. (295, 101) -> b'ase' occured 6 times.\n",
      "1459/4744 pairs merged. (103, 259) -> b'gan' occured 6 times.\n",
      "1460/4744 pairs merged. (298, 112) -> b'omp' occured 6 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1218/4744 [00:12<00:34, 103.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1461/4744 pairs merged. (358, 115) -> b'els' occured 6 times.\n",
      "1462/4744 pairs merged. (408, 876) -> b' Zheng' occured 6 times.\n",
      "1463/4744 pairs merged. (1042, 350) -> b' series' occured 6 times.\n",
      "1464/4744 pairs merged. (109, 418) -> b'mous' occured 6 times.\n",
      "1465/4744 pairs merged. (310, 275) -> b' hal' occured 6 times.\n",
      "1466/4744 pairs merged. (673, 1233) -> b' extended' occured 6 times.\n",
      "1467/4744 pairs merged. (270, 624) -> b' western' occured 6 times.\n",
      "1468/4744 pairs merged. (320, 269) -> b' nat' occured 6 times.\n",
      "1469/4744 pairs merged. (911, 98) -> b' numb' occured 6 times.\n",
      "1470/4744 pairs merged. (508, 259) -> b' gran' occured 6 times.\n",
      "1471/4744 pairs merged. (702, 754) -> b'uoyang' occured 6 times.\n",
      "1472/4744 pairs merged. (687, 1242) -> b' expanded' occured 6 times.\n",
      "1473/4744 pairs merged. (1134, 880) -> b' Spring' occured 6 times.\n",
      "1474/4744 pairs merged. (346, 361) -> b' Aut' occured 6 times.\n",
      "1475/4744 pairs merged. (1474, 463) -> b' Autum' occured 6 times.\n",
      "1476/4744 pairs merged. (1475, 110) -> b' Autumn' occured 6 times.\n",
      "1477/4744 pairs merged. (276, 467) -> b'ority' occured 6 times.\n",
      "1478/4744 pairs merged. (119, 110) -> b'wn' occured 6 times.\n",
      "1479/4744 pairs merged. (280, 109) -> b' sm' occured 6 times.\n",
      "1480/4744 pairs merged. (1479, 514) -> b' small' occured 6 times.\n",
      "1481/4744 pairs merged. (307, 1245) -> b'urban' occured 6 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 1240/4744 [00:12<00:36, 96.29it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1482/4744 pairs merged. (511, 500) -> b'ources' occured 6 times.\n",
      "1483/4744 pairs merged. (291, 1082) -> b' each' occured 6 times.\n",
      "1484/4744 pairs merged. (521, 474) -> b' held' occured 6 times.\n",
      "1485/4744 pairs merged. (861, 350) -> b' territories' occured 6 times.\n",
      "1486/4744 pairs merged. (310, 353) -> b' him' occured 6 times.\n",
      "1487/4744 pairs merged. (1343, 102) -> b'self' occured 6 times.\n",
      "1488/4744 pairs merged. (1138, 1015) -> b' effect' occured 6 times.\n",
      "1489/4744 pairs merged. (283, 261) -> b' per' occured 6 times.\n",
      "1490/4744 pairs merged. (284, 957) -> b' fail' occured 6 times.\n",
      "1491/4744 pairs merged. (842, 294) -> b' divis' occured 6 times.\n",
      "1492/4744 pairs merged. (457, 290) -> b' Xion' occured 6 times.\n",
      "1493/4744 pairs merged. (1492, 103) -> b' Xiong' occured 6 times.\n",
      "1494/4744 pairs merged. (117, 308) -> b'uil' occured 6 times.\n",
      "1495/4744 pairs merged. (360, 107) -> b'ack' occured 6 times.\n",
      "1496/4744 pairs merged. (949, 263) -> b' followed' occured 6 times.\n",
      "1497/4744 pairs merged. (861, 121) -> b' territory' occured 6 times.\n",
      "1498/4744 pairs merged. (1350, 350) -> b' policies' occured 6 times.\n",
      "1499/4744 pairs merged. (898, 334) -> b' laun' occured 6 times.\n",
      "1500/4744 pairs merged. (330, 110) -> b' conn' occured 6 times.\n",
      "1501/4744 pairs merged. (882, 1260) -> b' upris' occured 6 times.\n",
      "1502/4744 pairs merged. (446, 717) -> b' kill' occured 6 times.\n",
      "1503/4744 pairs merged. (1018, 488) -> b' peasant' occured 6 times.\n",
      "1504/4744 pairs merged. (261, 341) -> b'erch' occured 6 times.\n",
      "1505/4744 pairs merged. (748, 98) -> b' Reb' occured 6 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1262/4744 [00:12<00:34, 101.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1506/4744 pairs merged. (1505, 1076) -> b' Rebellion' occured 6 times.\n",
      "1507/4744 pairs merged. (623, 1261) -> b' warlord' occured 6 times.\n",
      "1508/4744 pairs merged. (301, 334) -> b' reun' occured 6 times.\n",
      "1509/4744 pairs merged. (292, 630) -> b'entral' occured 6 times.\n",
      "1510/4744 pairs merged. (297, 311) -> b' Chang' occured 6 times.\n",
      "1511/4744 pairs merged. (1262, 700) -> b' Nanjing' occured 6 times.\n",
      "1512/4744 pairs merged. (1265, 348) -> b' growth' occured 6 times.\n",
      "1513/4744 pairs merged. (750, 368) -> b' relig' occured 6 times.\n",
      "1514/4744 pairs merged. (1217, 370) -> b' largest' occured 6 times.\n",
      "1515/4744 pairs merged. (740, 273) -> b' marit' occured 6 times.\n",
      "1516/4744 pairs merged. (1515, 608) -> b' maritime' occured 6 times.\n",
      "1517/4744 pairs merged. (293, 1169) -> b' memb' occured 6 times.\n",
      "1518/4744 pairs merged. (874, 743) -> b' suppress' occured 6 times.\n",
      "1519/4744 pairs merged. (962, 1236) -> b' Zhuye' occured 6 times.\n",
      "1520/4744 pairs merged. (1364, 390) -> b'aganate' occured 6 times.\n",
      "1521/4744 pairs merged. (505, 121) -> b'reaty' occured 6 times.\n",
      "1522/4744 pairs merged. (121, 345) -> b'yle' occured 6 times.\n",
      "1523/4744 pairs merged. (285, 263) -> b'ared' occured 6 times.\n",
      "1524/4744 pairs merged. (382, 263) -> b'ired' occured 6 times.\n",
      "1525/4744 pairs merged. (569, 101) -> b'ake' occured 6 times.\n",
      "1526/4744 pairs merged. (593, 388) -> b' result' occured 6 times.\n",
      "1527/4744 pairs merged. (688, 357) -> b'vement' occured 6 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1284/4744 [00:13<00:33, 103.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1528/4744 pairs merged. (1078, 705) -> b'oviet' occured 6 times.\n",
      "1529/4744 pairs merged. (1022, 335) -> b' Nationalist' occured 6 times.\n",
      "1530/4744 pairs merged. (761, 1272) -> b' across' occured 5 times.\n",
      "1531/4744 pairs merged. (335, 287) -> b'istic' occured 5 times.\n",
      "1532/4744 pairs merged. (804, 468) -> b'crib' occured 5 times.\n",
      "1533/4744 pairs merged. (1532, 263) -> b'cribed' occured 5 times.\n",
      "1534/4744 pairs merged. (688, 667) -> b'vements' occured 5 times.\n",
      "1535/4744 pairs merged. (274, 115) -> b'ands' occured 5 times.\n",
      "1536/4744 pairs merged. (331, 295) -> b' Bas' occured 5 times.\n",
      "1537/4744 pairs merged. (1278, 304) -> b' increasingly' occured 5 times.\n",
      "1538/4744 pairs merged. (712, 258) -> b' begin' occured 5 times.\n",
      "1539/4744 pairs merged. (367, 489) -> b' rough' occured 5 times.\n",
      "1540/4744 pairs merged. (1539, 304) -> b' roughly' occured 5 times.\n",
      "1541/4744 pairs merged. (271, 276) -> b' cor' occured 5 times.\n",
      "1542/4744 pairs merged. (810, 278) -> b' writing' occured 5 times.\n",
      "1543/4744 pairs merged. (672, 101) -> b' include' occured 5 times.\n",
      "1544/4744 pairs merged. (1283, 338) -> b' poet' occured 5 times.\n",
      "1545/4744 pairs merged. (258, 333) -> b'ination' occured 5 times.\n",
      "1546/4744 pairs merged. (288, 358) -> b' bel' occured 5 times.\n",
      "1547/4744 pairs merged. (1546, 709) -> b' belie' occured 5 times.\n",
      "1548/4744 pairs merged. (329, 121) -> b'very' occured 5 times.\n",
      "1549/4744 pairs merged. (277, 554) -> b' invent' occured 5 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1306/4744 [00:13<00:33, 101.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1550/4744 pairs merged. (1390, 786) -> b' language' occured 5 times.\n",
      "1551/4744 pairs merged. (315, 274) -> b' Mand' occured 5 times.\n",
      "1552/4744 pairs merged. (1551, 390) -> b' Mandate' occured 5 times.\n",
      "1553/4744 pairs merged. (332, 847) -> b'roduc' occured 5 times.\n",
      "1554/4744 pairs merged. (283, 1035) -> b' phil' occured 5 times.\n",
      "1555/4744 pairs merged. (1554, 599) -> b' philos' occured 5 times.\n",
      "1556/4744 pairs merged. (1555, 1171) -> b' philosoph' occured 5 times.\n",
      "1557/4744 pairs merged. (299, 502) -> b' Tao' occured 5 times.\n",
      "1558/4744 pairs merged. (1393, 519) -> b' Legalism' occured 5 times.\n",
      "1559/4744 pairs merged. (1394, 97) -> b'China' occured 5 times.\n",
      "1560/4744 pairs merged. (1097, 600) -> b' standard' occured 5 times.\n",
      "1561/4744 pairs merged. (557, 50) -> b'202' occured 5 times.\n",
      "1562/4744 pairs merged. (337, 717) -> b' still' occured 5 times.\n",
      "1563/4744 pairs merged. (72, 259) -> b'Han' occured 5 times.\n",
      "1564/4744 pairs merged. (673, 292) -> b' extent' occured 5 times.\n",
      "1565/4744 pairs merged. (784, 304) -> b' officially' occured 5 times.\n",
      "1566/4744 pairs merged. (348, 121) -> b'thy' occured 5 times.\n",
      "1567/4744 pairs merged. (620, 1290) -> b' landhold' occured 5 times.\n",
      "1568/4744 pairs merged. (105, 358) -> b'iel' occured 5 times.\n",
      "1569/4744 pairs merged. (1568, 100) -> b'ield' occured 5 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1328/4744 [00:13<00:33, 103.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1570/4744 pairs merged. (283, 285) -> b' par' occured 5 times.\n",
      "1571/4744 pairs merged. (1179, 1180) -> b' contemporane' occured 5 times.\n",
      "1572/4744 pairs merged. (539, 305) -> b' prol' occured 5 times.\n",
      "1573/4744 pairs merged. (444, 404) -> b' intern' occured 5 times.\n",
      "1574/4744 pairs merged. (291, 409) -> b' equ' occured 5 times.\n",
      "1575/4744 pairs merged. (276, 121) -> b'ory' occured 5 times.\n",
      "1576/4744 pairs merged. (280, 111) -> b' so' occured 5 times.\n",
      "1577/4744 pairs merged. (1185, 713) -> b'-lived' occured 5 times.\n",
      "1578/4744 pairs merged. (1406, 55) -> b'907' occured 5 times.\n",
      "1579/4744 pairs merged. (814, 268) -> b'olden' occured 5 times.\n",
      "1580/4744 pairs merged. (267, 434) -> b' age' occured 5 times.\n",
      "1581/4744 pairs merged. (280, 851) -> b' sci' occured 5 times.\n",
      "1582/4744 pairs merged. (1581, 512) -> b' science' occured 5 times.\n",
      "1583/4744 pairs merged. (744, 115) -> b' emperors' occured 5 times.\n",
      "1584/4744 pairs merged. (720, 562) -> b' conquered' occured 5 times.\n",
      "1585/4744 pairs merged. (1413, 362) -> b' Europ' occured 5 times.\n",
      "1586/4744 pairs merged. (939, 54) -> b'136' occured 5 times.\n",
      "1587/4744 pairs merged. (680, 52) -> b'164' occured 5 times.\n",
      "1588/4744 pairs merged. (283, 276) -> b' por' occured 5 times.\n",
      "1589/4744 pairs merged. (108, 376) -> b'lain' occured 5 times.\n",
      "1590/4744 pairs merged. (400, 106) -> b' proj' occured 5 times.\n",
      "1591/4744 pairs merged. (1590, 1107) -> b' projects' occured 5 times.\n",
      "1592/4744 pairs merged. (466, 1416) -> b' Grand' occured 5 times.\n",
      "1593/4744 pairs merged. (289, 259) -> b' Can' occured 5 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1351/4744 [00:13<00:31, 107.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1594/4744 pairs merged. (1593, 275) -> b' Canal' occured 5 times.\n",
      "1595/4744 pairs merged. (904, 343) -> b' succe' occured 5 times.\n",
      "1596/4744 pairs merged. (735, 108) -> b' compl' occured 5 times.\n",
      "1597/4744 pairs merged. (320, 496) -> b' near' occured 5 times.\n",
      "1598/4744 pairs merged. (405, 533) -> b' Imperial' occured 5 times.\n",
      "1599/4744 pairs merged. (748, 1199) -> b' Revolution' occured 5 times.\n",
      "1600/4744 pairs merged. (1200, 375) -> b' created' occured 5 times.\n",
      "1601/4744 pairs merged. (1050, 335) -> b' Communist' occured 5 times.\n",
      "1602/4744 pairs merged. (1304, 942) -> b' Army' occured 5 times.\n",
      "1603/4744 pairs merged. (444, 261) -> b' inter' occured 5 times.\n",
      "1604/4744 pairs merged. (1306, 749) -> b' industr' occured 5 times.\n",
      "1605/4744 pairs merged. (354, 276) -> b' Wor' occured 5 times.\n",
      "1606/4744 pairs merged. (1605, 474) -> b' World' occured 5 times.\n",
      "1607/4744 pairs merged. (65, 527) -> b'After' occured 5 times.\n",
      "1608/4744 pairs merged. (462, 1198) -> b' vict' occured 5 times.\n",
      "1609/4744 pairs merged. (399, 101) -> b' Pe' occured 5 times.\n",
      "1610/4744 pairs merged. (305, 101) -> b'ole' occured 5 times.\n",
      "1611/4744 pairs merged. (280, 108) -> b' sl' occured 5 times.\n",
      "1612/4744 pairs merged. (314, 375) -> b'ulated' occured 5 times.\n",
      "1613/4744 pairs merged. (822, 467) -> b' majority' occured 5 times.\n",
      "1614/4744 pairs merged. (541, 305) -> b' consol' occured 5 times.\n",
      "1615/4744 pairs merged. (1614, 349) -> b' consolid' occured 5 times.\n",
      "1616/4744 pairs merged. (280, 910) -> b' since' occured 5 times.\n",
      "1617/4744 pairs merged. (310, 463) -> b' hum' occured 5 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 1375/4744 [00:13<00:31, 105.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1618/4744 pairs merged. (298, 111) -> b'omo' occured 5 times.\n",
      "1619/4744 pairs merged. (382, 262) -> b'iron' occured 5 times.\n",
      "1620/4744 pairs merged. (115, 663) -> b'side' occured 5 times.\n",
      "1621/4744 pairs merged. (291, 345) -> b' ele' occured 5 times.\n",
      "1622/4744 pairs merged. (379, 116) -> b'iant' occured 5 times.\n",
      "1623/4744 pairs merged. (724, 601) -> b' short' occured 5 times.\n",
      "1624/4744 pairs merged. (543, 1438) -> b' discovered' occured 5 times.\n",
      "1625/4744 pairs merged. (1313, 701) -> b' throughout' occured 5 times.\n",
      "1626/4744 pairs merged. (1439, 1440) -> b' Shaanxi' occured 5 times.\n",
      "1627/4744 pairs merged. (270, 485) -> b' well' occured 5 times.\n",
      "1628/4744 pairs merged. (293, 258) -> b' min' occured 5 times.\n",
      "1629/4744 pairs merged. (1215, 307) -> b' occur' occured 5 times.\n",
      "1630/4744 pairs merged. (1629, 872) -> b' occurred' occured 5 times.\n",
      "1631/4744 pairs merged. (1434, 101) -> b' archae' occured 5 times.\n",
      "1632/4744 pairs merged. (925, 275) -> b' regional' occured 5 times.\n",
      "1633/4744 pairs merged. (108, 816) -> b'less' occured 5 times.\n",
      "1634/4744 pairs merged. (56, 48) -> b'80' occured 5 times.\n",
      "1635/4744 pairs merged. (1316, 304) -> b'imately' occured 5 times.\n",
      "1636/4744 pairs merged. (524, 553) -> b' regions' occured 5 times.\n",
      "1637/4744 pairs merged. (282, 1221) -> b' domest' occured 5 times.\n",
      "1638/4744 pairs merged. (285, 304) -> b'arly' occured 5 times.\n",
      "1639/4744 pairs merged. (104, 117) -> b'hu' occured 5 times.\n",
      "1640/4744 pairs merged. (1002, 261) -> b' preser' occured 5 times.\n",
      "1641/4744 pairs merged. (367, 263) -> b' red' occured 5 times.\n",
      "1642/4744 pairs merged. (752, 771) -> b'istribut' occured 5 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1400/4744 [00:14<00:31, 104.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1643/4744 pairs merged. (1056, 263) -> b' existed' occured 5 times.\n",
      "1644/4744 pairs merged. (397, 722) -> b' Liang' occured 5 times.\n",
      "1645/4744 pairs merged. (51, 437) -> b'300' occured 5 times.\n",
      "1646/4744 pairs merged. (287, 107) -> b'ick' occured 5 times.\n",
      "1647/4744 pairs merged. (916, 708) -> b'ronze' occured 5 times.\n",
      "1648/4744 pairs merged. (106, 105) -> b'ji' occured 5 times.\n",
      "1649/4744 pairs merged. (680, 48) -> b'160' occured 5 times.\n",
      "1650/4744 pairs merged. (344, 303) -> b'theast' occured 5 times.\n",
      "1651/4744 pairs merged. (446, 725) -> b' kings' occured 5 times.\n",
      "1652/4744 pairs merged. (310, 574) -> b' high' occured 5 times.\n",
      "1653/4744 pairs merged. (293, 338) -> b' met' occured 5 times.\n",
      "1654/4744 pairs merged. (97, 117) -> b'au' occured 5 times.\n",
      "1655/4744 pairs merged. (1059, 115) -> b' scholars' occured 5 times.\n",
      "1656/4744 pairs merged. (301, 1121) -> b' refer' occured 5 times.\n",
      "1657/4744 pairs merged. (330, 99) -> b' conc' occured 5 times.\n",
      "1658/4744 pairs merged. (116, 304) -> b'tly' occured 5 times.\n",
      "1659/4744 pairs merged. (280, 504) -> b' same' occured 5 times.\n",
      "1660/4744 pairs merged. (523, 417) -> b' historical' occured 5 times.\n",
      "1661/4744 pairs merged. (320, 111) -> b' no' occured 5 times.\n",
      "1662/4744 pairs merged. (1007, 568) -> b' elite' occured 5 times.\n",
      "1663/4744 pairs merged. (273, 416) -> b'itted' occured 5 times.\n",
      "1664/4744 pairs merged. (108, 108) -> b'll' occured 5 times.\n",
      "1665/4744 pairs merged. (835, 263) -> b' used' occured 5 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|██▉       | 1422/4744 [00:14<00:31, 106.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1666/4744 pairs merged. (97, 312) -> b'amp' occured 5 times.\n",
      "1667/4744 pairs merged. (1047, 259) -> b' advan' occured 5 times.\n",
      "1668/4744 pairs merged. (336, 121) -> b' They' occured 5 times.\n",
      "1669/4744 pairs merged. (1468, 646) -> b' natural' occured 5 times.\n",
      "1670/4744 pairs merged. (1109, 121) -> b' roy' occured 5 times.\n",
      "1671/4744 pairs merged. (1670, 275) -> b' royal' occured 5 times.\n",
      "1672/4744 pairs merged. (286, 377) -> b'ouse' occured 5 times.\n",
      "1673/4744 pairs merged. (1470, 416) -> b' granted' occured 5 times.\n",
      "1674/4744 pairs merged. (440, 114) -> b'ocr' occured 5 times.\n",
      "1675/4744 pairs merged. (397, 1471) -> b' Luoyang' occured 5 times.\n",
      "1676/4744 pairs merged. (1135, 1110) -> b' second' occured 5 times.\n",
      "1677/4744 pairs merged. (640, 880) -> b' Warring' occured 5 times.\n",
      "1678/4744 pairs merged. (1092, 275) -> b' local' occured 5 times.\n",
      "1679/4744 pairs merged. (1338, 872) -> b'undred' occured 5 times.\n",
      "1680/4744 pairs merged. (265, 119) -> b'rew' occured 5 times.\n",
      "1681/4744 pairs merged. (741, 1131) -> b' family' occured 5 times.\n",
      "1682/4744 pairs merged. (444, 1341) -> b' intellect' occured 5 times.\n",
      "1683/4744 pairs merged. (315, 111) -> b' Mo' occured 5 times.\n",
      "1684/4744 pairs merged. (611, 311) -> b' chang' occured 5 times.\n",
      "1685/4744 pairs merged. (276, 1464) -> b'ormous' occured 5 times.\n",
      "1686/4744 pairs merged. (118, 268) -> b'ven' occured 5 times.\n",
      "1687/4744 pairs merged. (269, 116) -> b'att' occured 5 times.\n",
      "1688/4744 pairs merged. (494, 290) -> b'ection' occured 5 times.\n",
      "1689/4744 pairs merged. (971, 101) -> b' base' occured 5 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1446/4744 [00:14<00:29, 111.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1690/4744 pairs merged. (1004, 806) -> b' administrative' occured 5 times.\n",
      "1691/4744 pairs merged. (1486, 1487) -> b' himself' occured 5 times.\n",
      "1692/4744 pairs merged. (1101, 104) -> b' emph' occured 5 times.\n",
      "1693/4744 pairs merged. (1692, 295) -> b' emphas' occured 5 times.\n",
      "1694/4744 pairs merged. (763, 332) -> b' impro' occured 5 times.\n",
      "1695/4744 pairs merged. (262, 115) -> b'ons' occured 5 times.\n",
      "1696/4744 pairs merged. (99, 121) -> b'cy' occured 5 times.\n",
      "1697/4744 pairs merged. (1140, 568) -> b'espite' occured 5 times.\n",
      "1698/4744 pairs merged. (345, 357) -> b'lement' occured 5 times.\n",
      "1699/4744 pairs merged. (320, 262) -> b' non' occured 5 times.\n",
      "1700/4744 pairs merged. (115, 117) -> b'su' occured 5 times.\n",
      "1701/4744 pairs merged. (541, 1090) -> b' conscrip' occured 5 times.\n",
      "1702/4744 pairs merged. (300, 431) -> b' lab' occured 5 times.\n",
      "1703/4744 pairs merged. (1702, 276) -> b' labor' occured 5 times.\n",
      "1704/4744 pairs merged. (901, 422) -> b' massive' occured 5 times.\n",
      "1705/4744 pairs merged. (1493, 110) -> b' Xiongn' occured 5 times.\n",
      "1706/4744 pairs merged. (1705, 117) -> b' Xiongnu' occured 5 times.\n",
      "1707/4744 pairs merged. (288, 1494) -> b' buil' occured 5 times.\n",
      "1708/4744 pairs merged. (1347, 263) -> b'tured' occured 5 times.\n",
      "1709/4744 pairs merged. (431, 1225) -> b'ability' occured 5 times.\n",
      "1710/4744 pairs merged. (612, 1349) -> b' next' occured 5 times.\n",
      "1711/4744 pairs merged. (320, 504) -> b' name' occured 5 times.\n",
      "1712/4744 pairs merged. (32, 122) -> b' z' occured 5 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 1471/4744 [00:14<00:29, 110.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1713/4744 pairs merged. (1126, 1009) -> b' however' occured 5 times.\n",
      "1714/4744 pairs merged. (110, 263) -> b'ned' occured 5 times.\n",
      "1715/4744 pairs merged. (1069, 115) -> b' campaigns' occured 5 times.\n",
      "1716/4744 pairs merged. (1499, 1257) -> b' launched' occured 5 times.\n",
      "1717/4744 pairs merged. (308, 107) -> b'ilk' occured 5 times.\n",
      "1718/4744 pairs merged. (953, 1127) -> b' decline' occured 5 times.\n",
      "1719/4744 pairs merged. (256, 535) -> b' treas' occured 5 times.\n",
      "1720/4744 pairs merged. (354, 311) -> b' Wang' occured 5 times.\n",
      "1721/4744 pairs merged. (320, 729) -> b' national' occured 5 times.\n",
      "1722/4744 pairs merged. (1018, 801) -> b' peasants' occured 5 times.\n",
      "1723/4744 pairs merged. (300, 1210) -> b' loss' occured 5 times.\n",
      "1724/4744 pairs merged. (293, 1504) -> b' merch' occured 5 times.\n",
      "1725/4744 pairs merged. (256, 307) -> b' tur' occured 5 times.\n",
      "1726/4744 pairs merged. (116, 576) -> b'teen' occured 5 times.\n",
      "1727/4744 pairs merged. (1212, 1323) -> b' Xianbei' occured 5 times.\n",
      "1728/4744 pairs merged. (299, 307) -> b' Tur' occured 5 times.\n",
      "1729/4744 pairs merged. (258, 287) -> b'inic' occured 5 times.\n",
      "1730/4744 pairs merged. (556, 322) -> b' allow' occured 5 times.\n",
      "1731/4744 pairs merged. (1730, 263) -> b' allowed' occured 5 times.\n",
      "1732/4744 pairs merged. (1491, 290) -> b' division' occured 5 times.\n",
      "1733/4744 pairs merged. (284, 1148) -> b' fier' occured 5 times.\n",
      "1734/4744 pairs merged. (1733, 343) -> b' fierce' occured 5 times.\n",
      "1735/4744 pairs merged. (459, 116) -> b' Int' occured 5 times.\n",
      "1736/4744 pairs merged. (686, 287) -> b' partic' occured 5 times.\n",
      "1737/4744 pairs merged. (299, 97) -> b' Ta' occured 5 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1495/4744 [00:14<00:28, 112.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1738/4744 pairs merged. (289, 1509) -> b' Central' occured 5 times.\n",
      "1739/4744 pairs merged. (469, 393) -> b' centers' occured 5 times.\n",
      "1740/4744 pairs merged. (401, 411) -> b' trav' occured 5 times.\n",
      "1741/4744 pairs merged. (1517, 393) -> b' members' occured 5 times.\n",
      "1742/4744 pairs merged. (313, 390) -> b'ivate' occured 5 times.\n",
      "1743/4744 pairs merged. (115, 422) -> b'sive' occured 5 times.\n",
      "1744/4744 pairs merged. (284, 485) -> b' fell' occured 5 times.\n",
      "1745/4744 pairs merged. (949, 278) -> b' following' occured 5 times.\n",
      "1746/4744 pairs merged. (429, 269) -> b' Shat' occured 5 times.\n",
      "1747/4744 pairs merged. (1746, 702) -> b' Shatuo' occured 5 times.\n",
      "1748/4744 pairs merged. (599, 263) -> b'osed' occured 5 times.\n",
      "1749/4744 pairs merged. (299, 1521) -> b' Treaty' occured 5 times.\n",
      "1750/4744 pairs merged. (411, 121) -> b'avy' occured 5 times.\n",
      "1751/4744 pairs merged. (1147, 290) -> b' invasion' occured 5 times.\n",
      "1752/4744 pairs merged. (284, 360) -> b' fac' occured 5 times.\n",
      "1753/4744 pairs merged. (1752, 308) -> b' facil' occured 5 times.\n",
      "1754/4744 pairs merged. (645, 323) -> b' strong' occured 5 times.\n",
      "1755/4744 pairs merged. (306, 258) -> b' Sin' occured 5 times.\n",
      "1756/4744 pairs merged. (1755, 111) -> b' Sino' occured 5 times.\n",
      "1757/4744 pairs merged. (905, 413) -> b' Manchus' occured 5 times.\n",
      "1758/4744 pairs merged. (382, 100) -> b'ird' occured 5 times.\n",
      "1759/4744 pairs merged. (331, 497) -> b' Brit' occured 5 times.\n",
      "1760/4744 pairs merged. (636, 334) -> b' commun' occured 5 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1518/4744 [00:15<00:30, 107.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1761/4744 pairs merged. (331, 1255) -> b' Box' occured 5 times.\n",
      "1762/4744 pairs merged. (419, 51) -> b'193' occured 5 times.\n",
      "1763/4744 pairs merged. (1079, 103) -> b'ugg' occured 5 times.\n",
      "1764/4744 pairs merged. (77, 84) -> b'MT' occured 5 times.\n",
      "1765/4744 pairs merged. (1050, 834) -> b' Communists' occured 5 times.\n",
      "1766/4744 pairs merged. (557, 49) -> b'201' occured 5 times.\n",
      "1767/4744 pairs merged. (1368, 275) -> b' several' occured 4 times.\n",
      "1768/4744 pairs merged. (1271, 389) -> b' millennia' occured 4 times.\n",
      "1769/4744 pairs merged. (325, 101) -> b' ge' occured 4 times.\n",
      "1770/4744 pairs merged. (1769, 1081) -> b' geograph' occured 4 times.\n",
      "1771/4744 pairs merged. (443, 115) -> b' periods' occured 4 times.\n",
      "1772/4744 pairs merged. (1369, 467) -> b' prosperity' occured 4 times.\n",
      "1773/4744 pairs merged. (438, 101) -> b'ife' occured 4 times.\n",
      "1774/4744 pairs merged. (582, 1161) -> b' sphere' occured 4 times.\n",
      "1775/4744 pairs merged. (261, 1373) -> b'ertain' occured 4 times.\n",
      "1776/4744 pairs merged. (256, 780) -> b' times' occured 4 times.\n",
      "1777/4744 pairs merged. (299, 379) -> b' Tian' occured 4 times.\n",
      "1778/4744 pairs merged. (1536, 258) -> b' Basin' occured 4 times.\n",
      "1779/4744 pairs merged. (116, 97) -> b'ta' occured 4 times.\n",
      "1780/4744 pairs merged. (280, 1164) -> b' saw' occured 4 times.\n",
      "1781/4744 pairs merged. (345, 120) -> b'lex' occured 4 times.\n",
      "1782/4744 pairs merged. (287, 115) -> b'ics' occured 4 times.\n",
      "1783/4744 pairs merged. (809, 338) -> b' somet' occured 4 times.\n",
      "1784/4744 pairs merged. (1081, 121) -> b'ography' occured 4 times.\n",
      "1785/4744 pairs merged. (1384, 1032) -> b' surviving' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1542/4744 [00:15<00:28, 110.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1786/4744 pairs merged. (631, 53) -> b'125' occured 4 times.\n",
      "1787/4744 pairs merged. (288, 262) -> b' bon' occured 4 times.\n",
      "1788/4744 pairs merged. (1787, 281) -> b' bones' occured 4 times.\n",
      "1789/4744 pairs merged. (737, 262) -> b' bron' occured 4 times.\n",
      "1790/4744 pairs merged. (269, 381) -> b'ature' occured 4 times.\n",
      "1791/4744 pairs merged. (1544, 650) -> b' poetry' occured 4 times.\n",
      "1792/4744 pairs merged. (1284, 108) -> b' displ' occured 4 times.\n",
      "1793/4744 pairs merged. (1392, 54) -> b'256' occured 4 times.\n",
      "1794/4744 pairs merged. (444, 1553) -> b' introduc' occured 4 times.\n",
      "1795/4744 pairs merged. (50, 1395) -> b'221' occured 4 times.\n",
      "1796/4744 pairs merged. (574, 412) -> b'ights' occured 4 times.\n",
      "1797/4744 pairs merged. (898, 119) -> b' law' occured 4 times.\n",
      "1798/4744 pairs merged. (461, 335) -> b' arist' occured 4 times.\n",
      "1799/4744 pairs merged. (440, 1038) -> b'ocracy' occured 4 times.\n",
      "1800/4744 pairs merged. (1571, 418) -> b' contemporaneous' occured 4 times.\n",
      "1801/4744 pairs merged. (983, 452) -> b' finally' occured 4 times.\n",
      "1802/4744 pairs merged. (284, 511) -> b' four' occured 4 times.\n",
      "1803/4744 pairs merged. (271, 514) -> b' call' occured 4 times.\n",
      "1804/4744 pairs merged. (1296, 693) -> b' flourished' occured 4 times.\n",
      "1805/4744 pairs merged. (270, 571) -> b' way' occured 4 times.\n",
      "1806/4744 pairs merged. (325, 1579) -> b' golden' occured 4 times.\n",
      "1807/4744 pairs merged. (262, 121) -> b'ony' occured 4 times.\n",
      "1808/4744 pairs merged. (273, 259) -> b'itan' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1566/4744 [00:15<00:29, 108.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1809/4744 pairs merged. (440, 107) -> b'ock' occured 4 times.\n",
      "1810/4744 pairs merged. (385, 384) -> b' exam' occured 4 times.\n",
      "1811/4744 pairs merged. (338, 988) -> b'ether' occured 4 times.\n",
      "1812/4744 pairs merged. (45, 67) -> b'-C' occured 4 times.\n",
      "1813/4744 pairs merged. (595, 765) -> b' works' occured 4 times.\n",
      "1814/4744 pairs merged. (301, 264) -> b' rest' occured 4 times.\n",
      "1815/4744 pairs merged. (276, 278) -> b'oring' occured 4 times.\n",
      "1816/4744 pairs merged. (451, 379) -> b' Qian' occured 4 times.\n",
      "1817/4744 pairs merged. (1596, 338) -> b' complet' occured 4 times.\n",
      "1818/4744 pairs merged. (99, 108) -> b'cl' occured 4 times.\n",
      "1819/4744 pairs merged. (263, 389) -> b'edia' occured 4 times.\n",
      "1820/4744 pairs merged. (538, 393) -> b' powers' occured 4 times.\n",
      "1821/4744 pairs merged. (256, 505) -> b' treat' occured 4 times.\n",
      "1822/4744 pairs merged. (457, 258) -> b' Xin' occured 4 times.\n",
      "1823/4744 pairs merged. (104, 529) -> b'hai' occured 4 times.\n",
      "1824/4744 pairs merged. (395, 269) -> b' Yat' occured 4 times.\n",
      "1825/4744 pairs merged. (1049, 268) -> b'-sen' occured 4 times.\n",
      "1826/4744 pairs merged. (605, 115) -> b' others' occured 4 times.\n",
      "1827/4744 pairs merged. (864, 1421) -> b' invading' occured 4 times.\n",
      "1828/4744 pairs merged. (842, 1041) -> b' divided' occured 4 times.\n",
      "1829/4744 pairs merged. (306, 319) -> b' Sec' occured 4 times.\n",
      "1830/4744 pairs merged. (1106, 357) -> b' establishment' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1588/4744 [00:15<00:29, 106.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1831/4744 pairs merged. (1609, 734) -> b' People' occured 4 times.\n",
      "1832/4744 pairs merged. (945, 273) -> b' legit' occured 4 times.\n",
      "1833/4744 pairs merged. (1427, 1052) -> b' diplomatic' occured 4 times.\n",
      "1834/4744 pairs merged. (692, 1084) -> b' remains' occured 4 times.\n",
      "1835/4744 pairs merged. (289, 1310) -> b' Cultural' occured 4 times.\n",
      "1836/4744 pairs merged. (103, 114) -> b'gr' occured 4 times.\n",
      "1837/4744 pairs merged. (320, 333) -> b' nation' occured 4 times.\n",
      "1838/4744 pairs merged. (565, 263) -> b'assed' occured 4 times.\n",
      "1839/4744 pairs merged. (399, 275) -> b' Pal' occured 4 times.\n",
      "1840/4744 pairs merged. (356, 1618) -> b' Homo' occured 4 times.\n",
      "1841/4744 pairs merged. (716, 494) -> b' erect' occured 4 times.\n",
      "1842/4744 pairs merged. (1841, 413) -> b' erectus' occured 4 times.\n",
      "1843/4744 pairs merged. (461, 114) -> b' arr' occured 4 times.\n",
      "1844/4744 pairs merged. (506, 111) -> b' ago' occured 4 times.\n",
      "1845/4744 pairs merged. (228, 186) -> b'\\xe4\\xba' occured 4 times.\n",
      "1846/4744 pairs merged. (433, 118) -> b' env' occured 4 times.\n",
      "1847/4744 pairs merged. (55, 437) -> b'700' occured 4 times.\n",
      "1848/4744 pairs merged. (288, 307) -> b' bur' occured 4 times.\n",
      "1849/4744 pairs merged. (258, 115) -> b'ins' occured 4 times.\n",
      "1850/4744 pairs merged. (1157, 304) -> b' widely' occured 4 times.\n",
      "1851/4744 pairs merged. (280, 273) -> b' sit' occured 4 times.\n",
      "1852/4744 pairs merged. (387, 98) -> b' deb' occured 4 times.\n",
      "1853/4744 pairs merged. (112, 111) -> b'po' occured 4 times.\n",
      "1854/4744 pairs merged. (100, 117) -> b'du' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1622/4744 [00:16<00:28, 110.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1855/4744 pairs merged. (399, 332) -> b' Pro' occured 4 times.\n",
      "1856/4744 pairs merged. (410, 353) -> b' anim' occured 4 times.\n",
      "1857/4744 pairs merged. (1856, 1118) -> b' animals' occured 4 times.\n",
      "1858/4744 pairs merged. (332, 99) -> b'roc' occured 4 times.\n",
      "1859/4744 pairs merged. (32, 388) -> b' ult' occured 4 times.\n",
      "1860/4744 pairs merged. (353, 97) -> b'ima' occured 4 times.\n",
      "1861/4744 pairs merged. (349, 100) -> b'idd' occured 4 times.\n",
      "1862/4744 pairs merged. (397, 101) -> b' Le' occured 4 times.\n",
      "1863/4744 pairs merged. (377, 109) -> b'sem' occured 4 times.\n",
      "1864/4744 pairs merged. (97, 828) -> b'ause' occured 4 times.\n",
      "1865/4744 pairs merged. (1220, 372) -> b' initial' occured 4 times.\n",
      "1866/4744 pairs merged. (287, 333) -> b'ication' occured 4 times.\n",
      "1867/4744 pairs merged. (313, 375) -> b'ivated' occured 4 times.\n",
      "1868/4744 pairs merged. (271, 285) -> b' car' occured 4 times.\n",
      "1869/4744 pairs merged. (530, 281) -> b'ages' occured 4 times.\n",
      "1870/4744 pairs merged. (53, 437) -> b'500' occured 4 times.\n",
      "1871/4744 pairs merged. (1448, 583) -> b' charact' occured 4 times.\n",
      "1872/4744 pairs merged. (1308, 1449) -> b' according' occured 4 times.\n",
      "1873/4744 pairs merged. (331, 259) -> b' Ban' occured 4 times.\n",
      "1874/4744 pairs merged. (292, 372) -> b'ential' occured 4 times.\n",
      "1875/4744 pairs merged. (874, 601) -> b' support' occured 4 times.\n",
      "1876/4744 pairs merged. (300, 105) -> b' li' occured 4 times.\n",
      "1877/4744 pairs merged. (1876, 1122) -> b' like' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▍      | 1647/4744 [00:16<00:28, 110.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1878/4744 pairs merged. (114, 350) -> b'ries' occured 4 times.\n",
      "1879/4744 pairs merged. (331, 1647) -> b' Bronze' occured 4 times.\n",
      "1880/4744 pairs merged. (360, 412) -> b'acts' occured 4 times.\n",
      "1881/4744 pairs merged. (419, 56) -> b'198' occured 4 times.\n",
      "1882/4744 pairs merged. (300, 258) -> b' lin' occured 4 times.\n",
      "1883/4744 pairs merged. (945, 534) -> b' legend' occured 4 times.\n",
      "1884/4744 pairs merged. (1119, 496) -> b' appear' occured 4 times.\n",
      "1885/4744 pairs merged. (385, 99) -> b' exc' occured 4 times.\n",
      "1886/4744 pairs merged. (1885, 411) -> b' excav' occured 4 times.\n",
      "1887/4744 pairs merged. (49, 52) -> b'14' occured 4 times.\n",
      "1888/4744 pairs merged. (117, 264) -> b'ust' occured 4 times.\n",
      "1889/4744 pairs merged. (353, 308) -> b'imil' occured 4 times.\n",
      "1890/4744 pairs merged. (299, 114) -> b' Tr' occured 4 times.\n",
      "1891/4744 pairs merged. (592, 100) -> b' abd' occured 4 times.\n",
      "1892/4744 pairs merged. (111, 111) -> b'oo' occured 4 times.\n",
      "1893/4744 pairs merged. (298, 101) -> b'ome' occured 4 times.\n",
      "1894/4744 pairs merged. (763, 601) -> b' import' occured 4 times.\n",
      "1895/4744 pairs merged. (983, 275) -> b' final' occured 4 times.\n",
      "1896/4744 pairs merged. (280, 699) -> b' six' occured 4 times.\n",
      "1897/4744 pairs merged. (392, 1231) -> b' although' occured 4 times.\n",
      "1898/4744 pairs merged. (385, 1666) -> b' examp' occured 4 times.\n",
      "1899/4744 pairs merged. (1898, 345) -> b' example' occured 4 times.\n",
      "1900/4744 pairs merged. (420, 278) -> b' King' occured 4 times.\n",
      "1901/4744 pairs merged. (343, 112) -> b'cep' occured 4 times.\n",
      "1902/4744 pairs merged. (453, 101) -> b'ize' occured 4 times.\n",
      "1903/4744 pairs merged. (543, 303) -> b' disast' occured 4 times.\n",
      "1904/4744 pairs merged. (310, 1672) -> b' house' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 1671/4744 [00:16<00:29, 105.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1905/4744 pairs merged. (522, 348) -> b' overth' occured 4 times.\n",
      "1906/4744 pairs merged. (289, 876) -> b' Cheng' occured 4 times.\n",
      "1907/4744 pairs merged. (556, 1064) -> b' alliance' occured 4 times.\n",
      "1908/4744 pairs merged. (881, 358) -> b' rebel' occured 4 times.\n",
      "1909/4744 pairs merged. (267, 117) -> b' au' occured 4 times.\n",
      "1910/4744 pairs merged. (1909, 348) -> b' auth' occured 4 times.\n",
      "1911/4744 pairs merged. (102, 116) -> b'ft' occured 4 times.\n",
      "1912/4744 pairs merged. (720, 261) -> b' conquer' occured 4 times.\n",
      "1913/4744 pairs merged. (623, 115) -> b' wars' occured 4 times.\n",
      "1914/4744 pairs merged. (315, 647) -> b' Many' occured 4 times.\n",
      "1915/4744 pairs merged. (271, 773) -> b' cities' occured 4 times.\n",
      "1916/4744 pairs merged. (32, 1481) -> b' urban' occured 4 times.\n",
      "1917/4744 pairs merged. (99, 372) -> b'cial' occured 4 times.\n",
      "1918/4744 pairs merged. (102, 1340) -> b'fare' occured 4 times.\n",
      "1919/4744 pairs merged. (593, 1482) -> b' resources' occured 4 times.\n",
      "1920/4744 pairs merged. (264, 488) -> b'stant' occured 4 times.\n",
      "1921/4744 pairs merged. (483, 278) -> b' ruling' occured 4 times.\n",
      "1922/4744 pairs merged. (433, 1685) -> b' enormous' occured 4 times.\n",
      "1923/4744 pairs merged. (320, 616) -> b' nomin' occured 4 times.\n",
      "1924/4744 pairs merged. (51, 48) -> b'30' occured 4 times.\n",
      "1925/4744 pairs merged. (612, 574) -> b' neigh' occured 4 times.\n",
      "1926/4744 pairs merged. (1925, 98) -> b' neighb' occured 4 times.\n",
      "1927/4744 pairs merged. (258, 500) -> b'inces' occured 4 times.\n",
      "1928/4744 pairs merged. (32, 353) -> b' im' occured 4 times.\n",
      "1929/4744 pairs merged. (273, 375) -> b'itated' occured 4 times.\n",
      "1930/4744 pairs merged. (438, 121) -> b'ify' occured 4 times.\n",
      "1931/4744 pairs merged. (299, 111) -> b' To' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1693/4744 [00:16<00:28, 107.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1932/4744 pairs merged. (1252, 121) -> b'archy' occured 4 times.\n",
      "1933/4744 pairs merged. (1345, 1696) -> b' currency' occured 4 times.\n",
      "1934/4744 pairs merged. (325, 117) -> b' gu' occured 4 times.\n",
      "1935/4744 pairs merged. (802, 261) -> b' consider' occured 4 times.\n",
      "1936/4744 pairs merged. (515, 116) -> b'ept' occured 4 times.\n",
      "1937/4744 pairs merged. (330, 1346) -> b' construc' occured 4 times.\n",
      "1938/4744 pairs merged. (56, 52) -> b'84' occured 4 times.\n",
      "1939/4744 pairs merged. (669, 1254) -> b' reported' occured 4 times.\n",
      "1940/4744 pairs merged. (561, 1708) -> b' captured' occured 4 times.\n",
      "1941/4744 pairs merged. (354, 268) -> b' Wen' occured 4 times.\n",
      "1942/4744 pairs merged. (1712, 268) -> b' zen' occured 4 times.\n",
      "1943/4744 pairs merged. (1942, 339) -> b' zenith' occured 4 times.\n",
      "1944/4744 pairs merged. (102, 114) -> b'fr' occured 4 times.\n",
      "1945/4744 pairs merged. (306, 1717) -> b' Silk' occured 4 times.\n",
      "1946/4744 pairs merged. (391, 111) -> b' Ro' occured 4 times.\n",
      "1947/4744 pairs merged. (1946, 321) -> b' Road' occured 4 times.\n",
      "1948/4744 pairs merged. (337, 353) -> b' stim' occured 4 times.\n",
      "1949/4744 pairs merged. (385, 1211) -> b' exchang' occured 4 times.\n",
      "1950/4744 pairs merged. (1949, 101) -> b' exchange' occured 4 times.\n",
      "1951/4744 pairs merged. (368, 114) -> b'igr' occured 4 times.\n",
      "1952/4744 pairs merged. (1719, 654) -> b' treasury' occured 4 times.\n",
      "1953/4744 pairs merged. (256, 1191) -> b' tax' occured 4 times.\n",
      "1954/4744 pairs merged. (315, 311) -> b' Mang' occured 4 times.\n",
      "1955/4744 pairs merged. (266, 1478) -> b' own' occured 4 times.\n",
      "1956/4744 pairs merged. (673, 803) -> b' extens' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1718/4744 [00:17<00:26, 114.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1957/4744 pairs merged. (612, 329) -> b' never' occured 4 times.\n",
      "1958/4744 pairs merged. (582, 1031) -> b' split' occured 4 times.\n",
      "1959/4744 pairs merged. (1502, 263) -> b' killed' occured 4 times.\n",
      "1960/4744 pairs merged. (97, 343) -> b'ace' occured 4 times.\n",
      "1961/4744 pairs merged. (119, 117) -> b'wu' occured 4 times.\n",
      "1962/4744 pairs merged. (313, 275) -> b'ival' occured 4 times.\n",
      "1963/4744 pairs merged. (1500, 494) -> b' connect' occured 4 times.\n",
      "1964/4744 pairs merged. (367, 701) -> b' rout' occured 4 times.\n",
      "1965/4744 pairs merged. (877, 1250) -> b' notably' occured 4 times.\n",
      "1966/4744 pairs merged. (65, 68) -> b'AD' occured 4 times.\n",
      "1967/4744 pairs merged. (349, 264) -> b'idst' occured 4 times.\n",
      "1968/4744 pairs merged. (1147, 553) -> b' invasions' occured 4 times.\n",
      "1969/4744 pairs merged. (1507, 115) -> b' warlords' occured 4 times.\n",
      "1970/4744 pairs merged. (539, 263) -> b' pred' occured 4 times.\n",
      "1971/4744 pairs merged. (1970, 616) -> b' predomin' occured 4 times.\n",
      "1972/4744 pairs merged. (659, 278) -> b' ending' occured 4 times.\n",
      "1973/4744 pairs merged. (356, 322) -> b' How' occured 4 times.\n",
      "1974/4744 pairs merged. (1973, 1009) -> b' However' occured 4 times.\n",
      "1975/4744 pairs merged. (369, 871) -> b' Eight' occured 4 times.\n",
      "1976/4744 pairs merged. (1360, 1726) -> b' Sixteen' occured 4 times.\n",
      "1977/4744 pairs merged. (559, 115) -> b' Mongols' occured 4 times.\n",
      "1978/4744 pairs merged. (1454, 626) -> b' Tibetans' occured 4 times.\n",
      "1979/4744 pairs merged. (102, 548) -> b'fore' occured 4 times.\n",
      "1980/4744 pairs merged. (110, 384) -> b'nam' occured 4 times.\n",
      "1981/4744 pairs merged. (284, 265) -> b' fre' occured 4 times.\n",
      "1982/4744 pairs merged. (277, 1370) -> b' institut' occured 4 times.\n",
      "1983/4744 pairs merged. (117, 98) -> b'ub' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1743/4744 [00:17<00:26, 113.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1984/4744 pairs merged. (271, 826) -> b' coin' occured 4 times.\n",
      "1985/4744 pairs merged. (276, 460) -> b'order' occured 4 times.\n",
      "1986/4744 pairs merged. (329, 115) -> b'vers' occured 4 times.\n",
      "1987/4744 pairs merged. (420, 548) -> b' Kore' occured 4 times.\n",
      "1988/4744 pairs merged. (301, 793) -> b' revol' occured 4 times.\n",
      "1989/4744 pairs merged. (414, 334) -> b' Jun' occured 4 times.\n",
      "1990/4744 pairs merged. (1989, 101) -> b' June' occured 4 times.\n",
      "1991/4744 pairs merged. (833, 379) -> b' Asian' occured 4 times.\n",
      "1992/4744 pairs merged. (1266, 448) -> b' tributary' occured 4 times.\n",
      "1993/4744 pairs merged. (1145, 268) -> b' open' occured 4 times.\n",
      "1994/4744 pairs merged. (404, 452) -> b'ernally' occured 4 times.\n",
      "1995/4744 pairs merged. (669, 108) -> b' repl' occured 4 times.\n",
      "1996/4744 pairs merged. (367, 374) -> b' rap' occured 4 times.\n",
      "1997/4744 pairs merged. (1996, 349) -> b' rapid' occured 4 times.\n",
      "1998/4744 pairs merged. (1097, 278) -> b' standing' occured 4 times.\n",
      "1999/4744 pairs merged. (461, 109) -> b' arm' occured 4 times.\n",
      "2000/4744 pairs merged. (1999, 350) -> b' armies' occured 4 times.\n",
      "2001/4744 pairs merged. (539, 1742) -> b' private' occured 4 times.\n",
      "2002/4744 pairs merged. (387, 118) -> b' dev' occured 4 times.\n",
      "2003/4744 pairs merged. (2002, 303) -> b' devast' occured 4 times.\n",
      "2004/4744 pairs merged. (881, 1076) -> b' rebellion' occured 4 times.\n",
      "2005/4744 pairs merged. (325, 772) -> b' gained' occured 4 times.\n",
      "2006/4744 pairs merged. (267, 361) -> b' aut' occured 4 times.\n",
      "2007/4744 pairs merged. (262, 298) -> b'onom' occured 4 times.\n",
      "2008/4744 pairs merged. (433, 103) -> b' eng' occured 4 times.\n",
      "2009/4744 pairs merged. (578, 917) -> b' decade' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 1767/4744 [00:17<00:28, 105.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2010/4744 pairs merged. (466, 702) -> b' Guo' occured 4 times.\n",
      "2011/4744 pairs merged. (1267, 1520) -> b' Khaganate' occured 4 times.\n",
      "2012/4744 pairs merged. (692, 110) -> b' remn' occured 4 times.\n",
      "2013/4744 pairs merged. (2012, 801) -> b' remnants' occured 4 times.\n",
      "2014/4744 pairs merged. (367, 1222) -> b' raid' occured 4 times.\n",
      "2015/4744 pairs merged. (280, 1729) -> b' sinic' occured 4 times.\n",
      "2016/4744 pairs merged. (966, 278) -> b' emerging' occured 4 times.\n",
      "2017/4744 pairs merged. (268, 377) -> b'ense' occured 4 times.\n",
      "2018/4744 pairs merged. (588, 115) -> b' empires' occured 4 times.\n",
      "2019/4744 pairs merged. (420, 97) -> b' Ka' occured 4 times.\n",
      "2020/4744 pairs merged. (2019, 438) -> b' Kaif' occured 4 times.\n",
      "2021/4744 pairs merged. (2020, 742) -> b' Kaifeng' occured 4 times.\n",
      "2022/4744 pairs merged. (280, 119) -> b' sw' occured 4 times.\n",
      "2023/4744 pairs merged. (104, 791) -> b'hile' occured 4 times.\n",
      "2024/4744 pairs merged. (411, 275) -> b'aval' occured 4 times.\n",
      "2025/4744 pairs merged. (1067, 649) -> b' annual' occured 4 times.\n",
      "2026/4744 pairs merged. (889, 745) -> b' dominance' occured 4 times.\n",
      "2027/4744 pairs merged. (307, 99) -> b'urc' occured 4 times.\n",
      "2028/4744 pairs merged. (2027, 482) -> b'urchen' occured 4 times.\n",
      "2029/4744 pairs merged. (854, 263) -> b' fled' occured 4 times.\n",
      "2030/4744 pairs merged. (356, 311) -> b' Hang' occured 4 times.\n",
      "2031/4744 pairs merged. (2030, 1008) -> b' Hangzhou' occured 4 times.\n",
      "2032/4744 pairs merged. (1431, 379) -> b' Indian' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1790/4744 [00:17<00:27, 108.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2033/4744 pairs merged. (619, 343) -> b' Oce' occured 4 times.\n",
      "2034/4744 pairs merged. (2033, 259) -> b' Ocean' occured 4 times.\n",
      "2035/4744 pairs merged. (277, 110) -> b' inn' occured 4 times.\n",
      "2036/4744 pairs merged. (265, 482) -> b'rehen' occured 4 times.\n",
      "2037/4744 pairs merged. (2036, 1743) -> b'rehensive' occured 4 times.\n",
      "2038/4744 pairs merged. (320, 1750) -> b' navy' occured 4 times.\n",
      "2039/4744 pairs merged. (369, 303) -> b' East' occured 4 times.\n",
      "2040/4744 pairs merged. (282, 509) -> b' down' occured 4 times.\n",
      "2041/4744 pairs merged. (395, 323) -> b' Yong' occured 4 times.\n",
      "2042/4744 pairs merged. (2041, 345) -> b' Yongle' occured 4 times.\n",
      "2043/4744 pairs merged. (781, 119) -> b' New' occured 4 times.\n",
      "2044/4744 pairs merged. (301, 409) -> b' requ' occured 4 times.\n",
      "2045/4744 pairs merged. (370, 115) -> b'ests' occured 4 times.\n",
      "2046/4744 pairs merged. (399, 601) -> b' Port' occured 4 times.\n",
      "2047/4744 pairs merged. (2046, 1079) -> b' Portug' occured 4 times.\n",
      "2048/4744 pairs merged. (2047, 117) -> b' Portugu' occured 4 times.\n",
      "2049/4744 pairs merged. (2048, 347) -> b' Portuguese' occured 4 times.\n",
      "2050/4744 pairs merged. (361, 341) -> b'utch' occured 4 times.\n",
      "2051/4744 pairs merged. (110, 261) -> b'ner' occured 4 times.\n",
      "2052/4744 pairs merged. (420, 311) -> b' Kang' occured 4 times.\n",
      "2053/4744 pairs merged. (1759, 653) -> b' British' occured 4 times.\n",
      "2054/4744 pairs merged. (615, 553) -> b' millions' occured 4 times.\n",
      "2055/4744 pairs merged. (266, 580) -> b' opp' occured 4 times.\n",
      "2056/4744 pairs merged. (1020, 1064) -> b' Alliance' occured 4 times.\n",
      "2057/4744 pairs merged. (369, 120) -> b' Ex' occured 4 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 1826/4744 [00:18<00:27, 104.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2058/4744 pairs merged. (109, 259) -> b'man' occured 4 times.\n",
      "2059/4744 pairs merged. (895, 263) -> b' formed' occured 4 times.\n",
      "2060/4744 pairs merged. (315, 1252) -> b' March' occured 4 times.\n",
      "2061/4744 pairs merged. (645, 1763) -> b' strugg' occured 4 times.\n",
      "2062/4744 pairs merged. (306, 1528) -> b' Soviet' occured 4 times.\n",
      "2063/4744 pairs merged. (399, 531) -> b' Part' occured 4 times.\n",
      "2064/4744 pairs merged. (2063, 121) -> b' Party' occured 4 times.\n",
      "2065/4744 pairs merged. (407, 573) -> b' Nations' occured 4 times.\n",
      "2066/4744 pairs merged. (869, 115) -> b' deaths' occured 4 times.\n",
      "2067/4744 pairs merged. (420, 1764) -> b' KMT' occured 4 times.\n",
      "2068/4744 pairs merged. (1002, 931) -> b' president' occured 4 times.\n",
      "2069/4744 pairs merged. (1770, 417) -> b' geographical' occured 3 times.\n",
      "2070/4744 pairs merged. (271, 1775) -> b' certain' occured 3 times.\n",
      "2071/4744 pairs merged. (341, 709) -> b'chie' occured 3 times.\n",
      "2072/4744 pairs merged. (2071, 1534) -> b'chievements' occured 3 times.\n",
      "2073/4744 pairs merged. (569, 278) -> b'aking' occured 3 times.\n",
      "2074/4744 pairs merged. (346, 116) -> b' At' occured 3 times.\n",
      "2075/4744 pairs merged. (669, 501) -> b' repres' occured 3 times.\n",
      "2076/4744 pairs merged. (2075, 292) -> b' represent' occured 3 times.\n",
      "2077/4744 pairs merged. (282, 432) -> b' dire' occured 3 times.\n",
      "2078/4744 pairs merged. (2077, 1162) -> b' direct' occured 3 times.\n",
      "2079/4744 pairs merged. (299, 285) -> b' Tar' occured 3 times.\n",
      "2080/4744 pairs merged. (2079, 353) -> b' Tarim' occured 3 times.\n",
      "2081/4744 pairs merged. (571, 259) -> b'ayan' occured 3 times.\n",
      "2082/4744 pairs merged. (358, 1779) -> b'elta' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 1851/4744 [00:18<00:25, 113.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2083/4744 pairs merged. (391, 263) -> b' Red' occured 3 times.\n",
      "2084/4744 pairs merged. (735, 1781) -> b' complex' occured 3 times.\n",
      "2085/4744 pairs merged. (1783, 780) -> b' sometimes' occured 3 times.\n",
      "2086/4744 pairs merged. (32, 931) -> b' ident' occured 3 times.\n",
      "2087/4744 pairs merged. (1271, 1166) -> b' millennium' occured 3 times.\n",
      "2088/4744 pairs merged. (523, 105) -> b' histori' occured 3 times.\n",
      "2089/4744 pairs merged. (2088, 1784) -> b' historiography' occured 3 times.\n",
      "2090/4744 pairs merged. (258, 573) -> b'inations' occured 3 times.\n",
      "2091/4744 pairs merged. (525, 360) -> b' orac' occured 3 times.\n",
      "2092/4744 pairs merged. (2091, 345) -> b' oracle' occured 3 times.\n",
      "2093/4744 pairs merged. (1789, 708) -> b' bronze' occured 3 times.\n",
      "2094/4744 pairs merged. (1090, 116) -> b'cript' occured 3 times.\n",
      "2095/4744 pairs merged. (301, 343) -> b' rece' occured 3 times.\n",
      "2096/4744 pairs merged. (1386, 1790) -> b' literature' occured 3 times.\n",
      "2097/4744 pairs merged. (582, 101) -> b' spe' occured 3 times.\n",
      "2098/4744 pairs merged. (1547, 785) -> b' believed' occured 3 times.\n",
      "2099/4744 pairs merged. (1549, 290) -> b' invention' occured 3 times.\n",
      "2100/4744 pairs merged. (392, 1029) -> b' alread' occured 3 times.\n",
      "2101/4744 pairs merged. (2100, 121) -> b' already' occured 3 times.\n",
      "2102/4744 pairs merged. (45, 109) -> b'-m' occured 3 times.\n",
      "2103/4744 pairs merged. (1794, 263) -> b' introduced' occured 3 times.\n",
      "2104/4744 pairs merged. (1557, 519) -> b' Taoism' occured 3 times.\n",
      "2105/4744 pairs merged. (1397, 417) -> b' classical' occured 3 times.\n",
      "2106/4744 pairs merged. (34, 44) -> b'\",' occured 3 times.\n",
      "2107/4744 pairs merged. (275, 1566) -> b'althy' occured 3 times.\n",
      "2108/4744 pairs merged. (1567, 278) -> b' landholding' occured 3 times.\n",
      "2109/4744 pairs merged. (391, 298) -> b' Rom' occured 3 times.\n",
      "2110/4744 pairs merged. (1181, 789) -> b' production' occured 3 times.\n",
      "2111/4744 pairs merged. (982, 115) -> b'wards' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 1876/4744 [00:18<00:25, 112.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2112/4744 pairs merged. (354, 482) -> b' When' occured 3 times.\n",
      "2113/4744 pairs merged. (300, 742) -> b' leng' occured 3 times.\n",
      "2114/4744 pairs merged. (456, 276) -> b' incor' occured 3 times.\n",
      "2115/4744 pairs merged. (2114, 112) -> b' incorp' occured 3 times.\n",
      "2116/4744 pairs merged. (2115, 276) -> b' incorpor' occured 3 times.\n",
      "2117/4744 pairs merged. (1298, 49) -> b'581' occured 3 times.\n",
      "2118/4744 pairs merged. (325, 585) -> b' gave' occured 3 times.\n",
      "2119/4744 pairs merged. (524, 600) -> b' regard' occured 3 times.\n",
      "2120/4744 pairs merged. (1296, 653) -> b' flourish' occured 3 times.\n",
      "2121/4744 pairs merged. (857, 667) -> b' developments' occured 3 times.\n",
      "2122/4744 pairs merged. (338, 379) -> b'etian' occured 3 times.\n",
      "2123/4744 pairs merged. (271, 599) -> b' cos' occured 3 times.\n",
      "2124/4744 pairs merged. (2123, 109) -> b' cosm' occured 3 times.\n",
      "2125/4744 pairs merged. (362, 305) -> b'opol' occured 3 times.\n",
      "2126/4744 pairs merged. (1410, 987) -> b' printing' occured 3 times.\n",
      "2127/4744 pairs merged. (110, 816) -> b'ness' occured 3 times.\n",
      "2128/4744 pairs merged. (270, 1105) -> b' wood' occured 3 times.\n",
      "2129/4744 pairs merged. (1047, 745) -> b' advance' occured 3 times.\n",
      "2130/4744 pairs merged. (32, 663) -> b' ide' occured 3 times.\n",
      "2131/4744 pairs merged. (645, 1411) -> b' structure' occured 3 times.\n",
      "2132/4744 pairs merged. (781, 111) -> b' Neo' occured 3 times.\n",
      "2133/4744 pairs merged. (1812, 262) -> b'-Con' occured 3 times.\n",
      "2134/4744 pairs merged. (325, 108) -> b' gl' occured 3 times.\n",
      "2135/4744 pairs merged. (1414, 275) -> b'obal' occured 3 times.\n",
      "2136/4744 pairs merged. (687, 108) -> b' expl' occured 3 times.\n",
      "2137/4744 pairs merged. (276, 333) -> b'oration' occured 3 times.\n",
      "2138/4744 pairs merged. (1588, 343) -> b' porce' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 1902/4744 [00:18<00:25, 113.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2139/4744 pairs merged. (2138, 1589) -> b' porcelain' occured 3 times.\n",
      "2140/4744 pairs merged. (342, 1415) -> b' those' occured 3 times.\n",
      "2141/4744 pairs merged. (1595, 1197) -> b' succeeded' occured 3 times.\n",
      "2142/4744 pairs merged. (294, 115) -> b'iss' occured 3 times.\n",
      "2143/4744 pairs merged. (2142, 290) -> b'ission' occured 3 times.\n",
      "2144/4744 pairs merged. (1817, 101) -> b' complete' occured 3 times.\n",
      "2145/4744 pairs merged. (1818, 362) -> b'clop' occured 3 times.\n",
      "2146/4744 pairs merged. (468, 114) -> b'ibr' occured 3 times.\n",
      "2147/4744 pairs merged. (1108, 370) -> b' greatest' occured 3 times.\n",
      "2148/4744 pairs merged. (1585, 1419) -> b' European' occured 3 times.\n",
      "2149/4744 pairs merged. (619, 112) -> b' Op' occured 3 times.\n",
      "2150/4744 pairs merged. (2149, 1166) -> b' Opium' occured 3 times.\n",
      "2151/4744 pairs merged. (101, 409) -> b'equ' occured 3 times.\n",
      "2152/4744 pairs merged. (2151, 275) -> b'equal' occured 3 times.\n",
      "2153/4744 pairs merged. (1821, 350) -> b' treaties' occured 3 times.\n",
      "2154/4744 pairs merged. (484, 114) -> b' Fr' occured 3 times.\n",
      "2155/4744 pairs merged. (308, 263) -> b'iled' occured 3 times.\n",
      "2156/4744 pairs merged. (465, 263) -> b'igned' occured 3 times.\n",
      "2157/4744 pairs merged. (1305, 416) -> b'rupted' occured 3 times.\n",
      "2158/4744 pairs merged. (408, 263) -> b' Zed' occured 3 times.\n",
      "2159/4744 pairs merged. (2158, 323) -> b' Zedong' occured 3 times.\n",
      "2160/4744 pairs merged. (301, 116) -> b' ret' occured 3 times.\n",
      "2161/4744 pairs merged. (280, 1610) -> b' sole' occured 3 times.\n",
      "2162/4744 pairs merged. (360, 121) -> b'acy' occured 3 times.\n",
      "2163/4744 pairs merged. (521, 108) -> b' hel' occured 3 times.\n",
      "2164/4744 pairs merged. (736, 362) -> b' Xiaop' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1926/4744 [00:18<00:24, 114.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2165/4744 pairs merged. (2164, 278) -> b' Xiaoping' occured 3 times.\n",
      "2166/4744 pairs merged. (399, 265) -> b' Pre' occured 3 times.\n",
      "2167/4744 pairs merged. (101, 973) -> b'eolithic' occured 3 times.\n",
      "2168/4744 pairs merged. (1617, 259) -> b' human' occured 3 times.\n",
      "2169/4744 pairs merged. (1843, 713) -> b' arrived' occured 3 times.\n",
      "2170/4744 pairs merged. (119, 624) -> b'western' occured 3 times.\n",
      "2171/4744 pairs merged. (300, 713) -> b' lived' occured 3 times.\n",
      "2172/4744 pairs merged. (699, 263) -> b'ixed' occured 3 times.\n",
      "2173/4744 pairs merged. (1846, 1619) -> b' environ' occured 3 times.\n",
      "2174/4744 pairs merged. (2173, 357) -> b' environment' occured 3 times.\n",
      "2175/4744 pairs merged. (968, 1620) -> b' alongside' occured 3 times.\n",
      "2176/4744 pairs merged. (107, 110) -> b'kn' occured 3 times.\n",
      "2177/4744 pairs merged. (2176, 509) -> b'known' occured 3 times.\n",
      "2178/4744 pairs merged. (331, 80) -> b' BP' occured 3 times.\n",
      "2179/4744 pairs merged. (619, 359) -> b' Other' occured 3 times.\n",
      "2180/4744 pairs merged. (1628, 276) -> b' minor' occured 3 times.\n",
      "2181/4744 pairs merged. (344, 912) -> b'theastern' occured 3 times.\n",
      "2182/4744 pairs merged. (1116, 100) -> b' Guangd' occured 3 times.\n",
      "2183/4744 pairs merged. (2182, 323) -> b' Guangdong' occured 3 times.\n",
      "2184/4744 pairs merged. (1851, 281) -> b' sites' occured 3 times.\n",
      "2185/4744 pairs merged. (1852, 375) -> b' debated' occured 3 times.\n",
      "2186/4744 pairs merged. (98, 304) -> b'bly' occured 3 times.\n",
      "2187/4744 pairs merged. (971, 263) -> b' based' occured 3 times.\n",
      "2188/4744 pairs merged. (54, 54) -> b'66' occured 3 times.\n",
      "2189/4744 pairs merged. (51, 54) -> b'36' occured 3 times.\n",
      "2190/4744 pairs merged. (1631, 1192) -> b' archaeological' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 1951/4744 [00:19<00:24, 113.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2191/4744 pairs merged. (1179, 448) -> b' contemporary' occured 3 times.\n",
      "2192/4744 pairs merged. (346, 102) -> b' Af' occured 3 times.\n",
      "2193/4744 pairs merged. (2192, 830) -> b' Afric' occured 3 times.\n",
      "2194/4744 pairs merged. (2193, 97) -> b' Africa' occured 3 times.\n",
      "2195/4744 pairs merged. (478, 109) -> b' adm' occured 3 times.\n",
      "2196/4744 pairs merged. (49, 557) -> b'120' occured 3 times.\n",
      "2197/4744 pairs merged. (484, 117) -> b' Fu' occured 3 times.\n",
      "2198/4744 pairs merged. (327, 1863) -> b' assem' occured 3 times.\n",
      "2199/4744 pairs merged. (2198, 591) -> b' assembl' occured 3 times.\n",
      "2200/4744 pairs merged. (1445, 495) -> b' addition' occured 3 times.\n",
      "2201/4744 pairs merged. (287, 101) -> b'ice' occured 3 times.\n",
      "2202/4744 pairs merged. (285, 98) -> b'arb' occured 3 times.\n",
      "2203/4744 pairs merged. (1640, 785) -> b' preserved' occured 3 times.\n",
      "2204/4744 pairs merged. (1120, 1310) -> b' agricultural' occured 3 times.\n",
      "2205/4744 pairs merged. (282, 940) -> b' dating' occured 3 times.\n",
      "2206/4744 pairs merged. (633, 313) -> b' indiv' occured 3 times.\n",
      "2207/4744 pairs merged. (2206, 349) -> b' individ' occured 3 times.\n",
      "2208/4744 pairs merged. (1871, 393) -> b' characters' occured 3 times.\n",
      "2209/4744 pairs merged. (109, 98) -> b'mb' occured 3 times.\n",
      "2210/4744 pairs merged. (305, 115) -> b'ols' occured 3 times.\n",
      "2211/4744 pairs merged. (1803, 263) -> b' called' occured 3 times.\n",
      "2212/4744 pairs merged. (271, 1320) -> b' crop' occured 3 times.\n",
      "2213/4744 pairs merged. (1435, 372) -> b' special' occured 3 times.\n",
      "2214/4744 pairs merged. (551, 115) -> b' cultures' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1975/4744 [00:19<00:24, 115.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2215/4744 pairs merged. (1227, 494) -> b' respect' occured 3 times.\n",
      "2216/4744 pairs merged. (2215, 950) -> b' respectively' occured 3 times.\n",
      "2217/4744 pairs merged. (397, 323) -> b' Long' occured 3 times.\n",
      "2218/4744 pairs merged. (322, 261) -> b'ower' occured 3 times.\n",
      "2219/4744 pairs merged. (306, 1115) -> b' Sanx' occured 3 times.\n",
      "2220/4744 pairs merged. (2219, 753) -> b' Sanxingd' occured 3 times.\n",
      "2221/4744 pairs merged. (2220, 855) -> b' Sanxingdui' occured 3 times.\n",
      "2222/4744 pairs merged. (429, 117) -> b' Shu' occured 3 times.\n",
      "2223/4744 pairs merged. (532, 677) -> b' level' occured 3 times.\n",
      "2224/4744 pairs merged. (462, 105) -> b' vi' occured 3 times.\n",
      "2225/4744 pairs merged. (2224, 305) -> b' viol' occured 3 times.\n",
      "2226/4744 pairs merged. (451, 105) -> b' Qi' occured 3 times.\n",
      "2227/4744 pairs merged. (307, 103) -> b'urg' occured 3 times.\n",
      "2228/4744 pairs merged. (1886, 375) -> b' excavated' occured 3 times.\n",
      "2229/4744 pairs merged. (806, 304) -> b'atively' occured 3 times.\n",
      "2230/4744 pairs merged. (929, 440) -> b' assoc' occured 3 times.\n",
      "2231/4744 pairs merged. (334, 103) -> b'ung' occured 3 times.\n",
      "2232/4744 pairs merged. (1456, 1533) -> b' described' occured 3 times.\n",
      "2233/4744 pairs merged. (523, 1229) -> b' historians' occured 3 times.\n",
      "2234/4744 pairs merged. (475, 307) -> b' cultur' occured 3 times.\n",
      "2235/4744 pairs merged. (2234, 452) -> b' culturally' occured 3 times.\n",
      "2236/4744 pairs merged. (45, 101) -> b'-e' occured 3 times.\n",
      "2237/4744 pairs merged. (395, 502) -> b' Yao' occured 3 times.\n",
      "2238/4744 pairs merged. (429, 334) -> b' Shun' occured 3 times.\n",
      "2239/4744 pairs merged. (395, 117) -> b' Yu' occured 3 times.\n",
      "2240/4744 pairs merged. (1890, 321) -> b' Trad' occured 3 times.\n",
      "2241/4744 pairs merged. (539, 616) -> b' promin' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 1999/4744 [00:19<00:24, 110.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2242/4744 pairs merged. (2241, 292) -> b' prominent' occured 3 times.\n",
      "2243/4744 pairs merged. (342, 916) -> b' thron' occured 3 times.\n",
      "2244/4744 pairs merged. (2243, 101) -> b' throne' occured 3 times.\n",
      "2245/4744 pairs merged. (557, 55) -> b'207' occured 3 times.\n",
      "2246/4744 pairs merged. (798, 110) -> b' Ann' occured 3 times.\n",
      "2247/4744 pairs merged. (2246, 1118) -> b' Annals' occured 3 times.\n",
      "2248/4744 pairs merged. (306, 1860) -> b' Sima' occured 3 times.\n",
      "2249/4744 pairs merged. (1060, 48) -> b'150' occured 3 times.\n",
      "2250/4744 pairs merged. (410, 121) -> b' any' occured 3 times.\n",
      "2251/4744 pairs merged. (456, 1460) -> b' incomp' occured 3 times.\n",
      "2252/4744 pairs merged. (932, 263) -> b' recorded' occured 3 times.\n",
      "2253/4744 pairs merged. (315, 548) -> b' More' occured 3 times.\n",
      "2254/4744 pairs merged. (1056, 512) -> b' existence' occured 3 times.\n",
      "2255/4744 pairs merged. (783, 261) -> b' earlier' occured 3 times.\n",
      "2256/4744 pairs merged. (109, 797) -> b'modern' occured 3 times.\n",
      "2257/4744 pairs merged. (395, 258) -> b' Yin' occured 3 times.\n",
      "2258/4744 pairs merged. (532, 303) -> b' least' occured 3 times.\n",
      "2259/4744 pairs merged. (425, 785) -> b' moved' occured 3 times.\n",
      "2260/4744 pairs merged. (1465, 102) -> b' half' occured 3 times.\n",
      "2261/4744 pairs merged. (272, 893) -> b' often' occured 3 times.\n",
      "2262/4744 pairs merged. (1232, 357) -> b' settlement' occured 3 times.\n",
      "2263/4744 pairs merged. (1667, 664) -> b' advanced' occured 3 times.\n",
      "2264/4744 pairs merged. (301, 275) -> b' real' occured 3 times.\n",
      "2265/4744 pairs merged. (335, 263) -> b'isted' occured 3 times.\n",
      "2266/4744 pairs merged. (342, 489) -> b' though' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2036/4744 [00:19<00:22, 117.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2267/4744 pairs merged. (953, 1442) -> b' declined' occured 3 times.\n",
      "2268/4744 pairs merged. (270, 1161) -> b' where' occured 3 times.\n",
      "2269/4744 pairs merged. (826, 416) -> b'ointed' occured 3 times.\n",
      "2270/4744 pairs merged. (1234, 275) -> b' coal' occured 3 times.\n",
      "2271/4744 pairs merged. (483, 261) -> b' ruler' occured 3 times.\n",
      "2272/4744 pairs merged. (296, 1237) -> b' took' occured 3 times.\n",
      "2273/4744 pairs merged. (111, 102) -> b'of' occured 3 times.\n",
      "2274/4744 pairs merged. (269, 1333) -> b'atives' occured 3 times.\n",
      "2275/4744 pairs merged. (330, 1901) -> b' concep' occured 3 times.\n",
      "2276/4744 pairs merged. (2275, 116) -> b' concept' occured 3 times.\n",
      "2277/4744 pairs merged. (100, 105) -> b'di' occured 3 times.\n",
      "2278/4744 pairs merged. (1903, 393) -> b' disasters' occured 3 times.\n",
      "2279/4744 pairs merged. (1469, 261) -> b' number' occured 3 times.\n",
      "2280/4744 pairs merged. (1657, 404) -> b' concern' occured 3 times.\n",
      "2281/4744 pairs merged. (1227, 262) -> b' respon' occured 3 times.\n",
      "2282/4744 pairs merged. (2281, 377) -> b' response' occured 3 times.\n",
      "2283/4744 pairs merged. (662, 115) -> b' capitals' occured 3 times.\n",
      "2284/4744 pairs merged. (425, 118) -> b' mov' occured 3 times.\n",
      "2285/4744 pairs merged. (314, 1638) -> b'ularly' occured 3 times.\n",
      "2286/4744 pairs merged. (291, 303) -> b' east' occured 3 times.\n",
      "2287/4744 pairs merged. (1335, 529) -> b' Huai' occured 3 times.\n",
      "2288/4744 pairs merged. (691, 982) -> b' southward' occured 3 times.\n",
      "2289/4744 pairs merged. (55, 54) -> b'76' occured 3 times.\n",
      "2290/4744 pairs merged. (1538, 1243) -> b' beginning' occured 3 times.\n",
      "2291/4744 pairs merged. (741, 418) -> b' famous' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 2060/4744 [00:20<00:24, 110.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2292/4744 pairs merged. (436, 263) -> b'uced' occured 3 times.\n",
      "2293/4744 pairs merged. (1910, 1477) -> b' authority' occured 3 times.\n",
      "2294/4744 pairs merged. (532, 1911) -> b' left' occured 3 times.\n",
      "2295/4744 pairs merged. (360, 117) -> b'acu' occured 3 times.\n",
      "2296/4744 pairs merged. (345, 103) -> b'leg' occured 3 times.\n",
      "2297/4744 pairs merged. (310, 1679) -> b' hundred' occured 3 times.\n",
      "2298/4744 pairs merged. (284, 871) -> b' fight' occured 3 times.\n",
      "2299/4744 pairs merged. (543, 374) -> b' disap' occured 3 times.\n",
      "2300/4744 pairs merged. (2299, 112) -> b' disapp' occured 3 times.\n",
      "2301/4744 pairs merged. (1067, 894) -> b' annex' occured 3 times.\n",
      "2302/4744 pairs merged. (2301, 263) -> b' annexed' occured 3 times.\n",
      "2303/4744 pairs merged. (99, 510) -> b'cip' occured 3 times.\n",
      "2304/4744 pairs merged. (297, 117) -> b' Chu' occured 3 times.\n",
      "2305/4744 pairs merged. (1093, 512) -> b' independence' occured 3 times.\n",
      "2306/4744 pairs merged. (450, 547) -> b' commer' occured 3 times.\n",
      "2307/4744 pairs merged. (611, 502) -> b' chao' occured 3 times.\n",
      "2308/4744 pairs merged. (1556, 121) -> b' philosophy' occured 3 times.\n",
      "2309/4744 pairs merged. (1682, 649) -> b' intellectual' occured 3 times.\n",
      "2310/4744 pairs merged. (731, 1686) -> b' seven' occured 3 times.\n",
      "2311/4744 pairs merged. (257, 109) -> b'hem' occured 3 times.\n",
      "2312/4744 pairs merged. (1386, 448) -> b' literary' occured 3 times.\n",
      "2313/4744 pairs merged. (661, 664) -> b' preced' occured 3 times.\n",
      "2314/4744 pairs merged. (510, 115) -> b'ips' occured 3 times.\n",
      "2315/4744 pairs merged. (293, 388) -> b' mult' occured 3 times.\n",
      "2316/4744 pairs merged. (1926, 1815) -> b' neighboring' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2085/4744 [00:20<00:22, 116.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2317/4744 pairs merged. (636, 274) -> b' command' occured 3 times.\n",
      "2318/4744 pairs merged. (661, 1015) -> b' prefect' occured 3 times.\n",
      "2319/4744 pairs merged. (1004, 333) -> b' administration' occured 3 times.\n",
      "2320/4744 pairs merged. (32, 120) -> b' x' occured 3 times.\n",
      "2321/4744 pairs merged. (283, 641) -> b' pla' occured 3 times.\n",
      "2322/4744 pairs merged. (2321, 343) -> b' place' occured 3 times.\n",
      "2323/4744 pairs merged. (395, 278) -> b' Ying' occured 3 times.\n",
      "2324/4744 pairs merged. (1859, 1635) -> b' ultimately' occured 3 times.\n",
      "2325/4744 pairs merged. (1488, 950) -> b' effectively' occured 3 times.\n",
      "2326/4744 pairs merged. (367, 269) -> b' rat' occured 3 times.\n",
      "2327/4744 pairs merged. (2326, 988) -> b' rather' occured 3 times.\n",
      "2328/4744 pairs merged. (400, 98) -> b' prob' occured 3 times.\n",
      "2329/4744 pairs merged. (2328, 1250) -> b' probably' occured 3 times.\n",
      "2330/4744 pairs merged. (782, 715) -> b' centralized' occured 3 times.\n",
      "2331/4744 pairs merged. (1139, 1932) -> b' monarchy' occured 3 times.\n",
      "2332/4744 pairs merged. (1138, 567) -> b' effor' occured 3 times.\n",
      "2333/4744 pairs merged. (1129, 261) -> b' leader' occured 3 times.\n",
      "2334/4744 pairs merged. (642, 263) -> b'formed' occured 3 times.\n",
      "2335/4744 pairs merged. (539, 583) -> b' pract' occured 3 times.\n",
      "2336/4744 pairs merged. (672, 263) -> b' included' occured 3 times.\n",
      "2337/4744 pairs merged. (1301, 511) -> b' encour' occured 3 times.\n",
      "2338/4744 pairs merged. (310, 285) -> b' har' occured 3 times.\n",
      "2339/4744 pairs merged. (1937, 789) -> b' construction' occured 3 times.\n",
      "2340/4744 pairs merged. (119, 571) -> b'way' occured 3 times.\n",
      "2341/4744 pairs merged. (450, 98) -> b' comb' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 2109/4744 [00:20<00:23, 110.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2342/4744 pairs merged. (522, 115) -> b' overs' occured 3 times.\n",
      "2343/4744 pairs merged. (2342, 1164) -> b' oversaw' occured 3 times.\n",
      "2344/4744 pairs merged. (1249, 303) -> b' drast' occured 3 times.\n",
      "2345/4744 pairs merged. (2344, 1062) -> b' drastically' occured 3 times.\n",
      "2346/4744 pairs merged. (280, 1495) -> b' sack' occured 3 times.\n",
      "2347/4744 pairs merged. (292, 290) -> b'ention' occured 3 times.\n",
      "2348/4744 pairs merged. (337, 1709) -> b' stability' occured 3 times.\n",
      "2349/4744 pairs merged. (564, 333) -> b' foundation' occured 3 times.\n",
      "2350/4744 pairs merged. (292, 304) -> b'ently' occured 3 times.\n",
      "2351/4744 pairs merged. (1144, 98) -> b' amb' occured 3 times.\n",
      "2352/4744 pairs merged. (498, 812) -> b' governors' occured 3 times.\n",
      "2353/4744 pairs merged. (283, 269) -> b' pat' occured 3 times.\n",
      "2354/4744 pairs merged. (337, 490) -> b' stud' occured 3 times.\n",
      "2355/4744 pairs merged. (337, 726) -> b' stren' occured 3 times.\n",
      "2356/4744 pairs merged. (103, 344) -> b'gthe' occured 3 times.\n",
      "2357/4744 pairs merged. (99, 275) -> b'cal' occured 3 times.\n",
      "2358/4744 pairs merged. (1145, 884) -> b' opened' occured 3 times.\n",
      "2359/4744 pairs merged. (895, 452) -> b' formally' occured 3 times.\n",
      "2360/4744 pairs merged. (315, 258) -> b' Min' occured 3 times.\n",
      "2361/4744 pairs merged. (1356, 49) -> b'111' occured 3 times.\n",
      "2362/4744 pairs merged. (510, 1204) -> b'ipped' occured 3 times.\n",
      "2363/4744 pairs merged. (385, 1017) -> b' excess' occured 3 times.\n",
      "2364/4744 pairs merged. (709, 102) -> b'ief' occured 3 times.\n",
      "2365/4744 pairs merged. (835, 307) -> b' usur' occured 3 times.\n",
      "2366/4744 pairs merged. (1956, 422) -> b' extensive' occured 3 times.\n",
      "2367/4744 pairs merged. (280, 641) -> b' sla' occured 3 times.\n",
      "2368/4744 pairs merged. (1642, 290) -> b'istribution' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 2135/4744 [00:20<00:22, 117.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2369/4744 pairs merged. (589, 1864) -> b' because' occured 3 times.\n",
      "2370/4744 pairs merged. (284, 411) -> b' fav' occured 3 times.\n",
      "2371/4744 pairs merged. (276, 263) -> b'ored' occured 3 times.\n",
      "2372/4744 pairs merged. (1501, 725) -> b' uprisings' occured 3 times.\n",
      "2373/4744 pairs merged. (480, 263) -> b'ounded' occured 3 times.\n",
      "2374/4744 pairs merged. (280, 308) -> b' sil' occured 3 times.\n",
      "2375/4744 pairs merged. (1357, 263) -> b' caused' occured 3 times.\n",
      "2376/4744 pairs merged. (1469, 393) -> b' numbers' occured 3 times.\n",
      "2377/4744 pairs merged. (1074, 115) -> b' conquests' occured 3 times.\n",
      "2378/4744 pairs merged. (1359, 97) -> b' Sea' occured 3 times.\n",
      "2379/4744 pairs merged. (737, 278) -> b' bring' occured 3 times.\n",
      "2380/4744 pairs merged. (2379, 278) -> b' bringing' occured 3 times.\n",
      "2381/4744 pairs merged. (680, 54) -> b'166' occured 3 times.\n",
      "2382/4744 pairs merged. (1572, 853) -> b' prolific' occured 3 times.\n",
      "2383/4744 pairs merged. (597, 771) -> b' contribut' occured 3 times.\n",
      "2384/4744 pairs merged. (455, 317) -> b' Dynast' occured 3 times.\n",
      "2385/4744 pairs merged. (2384, 350) -> b' Dynasties' occured 3 times.\n",
      "2386/4744 pairs merged. (288, 332) -> b' bro' occured 3 times.\n",
      "2387/4744 pairs merged. (838, 52) -> b'184' occured 3 times.\n",
      "2388/4744 pairs merged. (1508, 891) -> b' reunified' occured 3 times.\n",
      "2389/4744 pairs merged. (280, 262) -> b' son' occured 3 times.\n",
      "2390/4744 pairs merged. (399, 114) -> b' Pr' occured 3 times.\n",
      "2391/4744 pairs merged. (774, 116) -> b' sett' occured 3 times.\n",
      "2392/4744 pairs merged. (51, 57) -> b'39' occured 3 times.\n",
      "2393/4744 pairs merged. (415, 530) -> b' frag' occured 3 times.\n",
      "2394/4744 pairs merged. (2393, 357) -> b' fragment' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2159/4744 [00:20<00:23, 109.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2395/4744 pairs merged. (2394, 263) -> b' fragmented' occured 3 times.\n",
      "2396/4744 pairs merged. (1728, 765) -> b' Turks' occured 3 times.\n",
      "2397/4744 pairs merged. (99, 292) -> b'cent' occured 3 times.\n",
      "2398/4744 pairs merged. (623, 1918) -> b' warfare' occured 3 times.\n",
      "2399/4744 pairs merged. (293, 1951) -> b' migr' occured 3 times.\n",
      "2400/4744 pairs merged. (114, 572) -> b'ried' occured 3 times.\n",
      "2401/4744 pairs merged. (68, 1697) -> b'Despite' occured 3 times.\n",
      "2402/4744 pairs merged. (582, 1029) -> b' spread' occured 3 times.\n",
      "2403/4744 pairs merged. (54, 838) -> b'618' occured 3 times.\n",
      "2404/4744 pairs merged. (531, 667) -> b'artments' occured 3 times.\n",
      "2405/4744 pairs merged. (1694, 785) -> b' improved' occured 3 times.\n",
      "2406/4744 pairs merged. (1701, 789) -> b' conscription' occured 3 times.\n",
      "2407/4744 pairs merged. (1513, 290) -> b' religion' occured 3 times.\n",
      "2408/4744 pairs merged. (288, 1985) -> b' border' occured 3 times.\n",
      "2409/4744 pairs merged. (1180, 117) -> b'aneu' occured 3 times.\n",
      "2410/4744 pairs merged. (288, 526) -> b' bord' occured 3 times.\n",
      "2411/4744 pairs merged. (2410, 393) -> b' borders' occured 3 times.\n",
      "2412/4744 pairs merged. (270, 349) -> b' wid' occured 3 times.\n",
      "2413/4744 pairs merged. (2412, 1140) -> b' widesp' occured 3 times.\n",
      "2414/4744 pairs merged. (2413, 1029) -> b' widespread' occured 3 times.\n",
      "2415/4744 pairs merged. (342, 505) -> b' threat' occured 3 times.\n",
      "2416/4744 pairs merged. (114, 806) -> b'rative' occured 3 times.\n",
      "2417/4744 pairs merged. (283, 601) -> b' port' occured 3 times.\n",
      "2418/4744 pairs merged. (1116, 1008) -> b' Guangzhou' occured 3 times.\n",
      "2419/4744 pairs merged. (282, 335) -> b' dist' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2184/4744 [00:21<00:22, 115.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2420/4744 pairs merged. (1724, 801) -> b' merchants' occured 3 times.\n",
      "2421/4744 pairs merged. (98, 115) -> b'bs' occured 3 times.\n",
      "2422/4744 pairs merged. (107, 263) -> b'ked' occured 3 times.\n",
      "2423/4744 pairs merged. (521, 531) -> b' heart' occured 3 times.\n",
      "2424/4744 pairs merged. (2423, 867) -> b' heartland' occured 3 times.\n",
      "2425/4744 pairs merged. (291, 912) -> b' eastern' occured 3 times.\n",
      "2426/4744 pairs merged. (1570, 412) -> b' parts' occured 3 times.\n",
      "2427/4744 pairs merged. (1125, 826) -> b' join' occured 3 times.\n",
      "2428/4744 pairs merged. (1513, 629) -> b' religious' occured 3 times.\n",
      "2429/4744 pairs merged. (369, 312) -> b' Emp' occured 3 times.\n",
      "2430/4744 pairs merged. (2429, 743) -> b' Empress' occured 3 times.\n",
      "2431/4744 pairs merged. (336, 265) -> b' There' occured 3 times.\n",
      "2432/4744 pairs merged. (546, 112) -> b' Up' occured 3 times.\n",
      "2433/4744 pairs merged. (1518, 290) -> b' suppression' occured 3 times.\n",
      "2434/4744 pairs merged. (104, 105) -> b'hi' occured 3 times.\n",
      "2435/4744 pairs merged. (462, 303) -> b' vast' occured 3 times.\n",
      "2436/4744 pairs merged. (617, 426) -> b' recover' occured 3 times.\n",
      "2437/4744 pairs merged. (714, 115) -> b'ficials' occured 3 times.\n",
      "2438/4744 pairs merged. (1928, 1226) -> b' immen' occured 3 times.\n",
      "2439/4744 pairs merged. (2438, 377) -> b' immense' occured 3 times.\n",
      "2440/4744 pairs merged. (56, 55) -> b'87' occured 3 times.\n",
      "2441/4744 pairs merged. (372, 304) -> b'ially' occured 3 times.\n",
      "2442/4744 pairs merged. (284, 922) -> b' fought' occured 3 times.\n",
      "2443/4744 pairs merged. (98, 275) -> b'bal' occured 3 times.\n",
      "2444/4744 pairs merged. (2443, 105) -> b'bali' occured 3 times.\n",
      "2445/4744 pairs merged. (297, 699) -> b' Chix' occured 3 times.\n",
      "2446/4744 pairs merged. (2445, 258) -> b' Chixin' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2208/4744 [00:21<00:21, 117.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2447/4744 pairs merged. (636, 1663) -> b' committed' occured 3 times.\n",
      "2448/4744 pairs merged. (300, 1183) -> b' loy' occured 3 times.\n",
      "2449/4744 pairs merged. (2448, 275) -> b' loyal' occured 3 times.\n",
      "2450/4744 pairs merged. (484, 422) -> b' Five' occured 3 times.\n",
      "2451/4744 pairs merged. (296, 100) -> b' tod' occured 3 times.\n",
      "2452/4744 pairs merged. (2451, 571) -> b' today' occured 3 times.\n",
      "2453/4744 pairs merged. (1146, 705) -> b' Viet' occured 3 times.\n",
      "2454/4744 pairs merged. (2453, 1980) -> b' Vietnam' occured 3 times.\n",
      "2455/4744 pairs merged. (1067, 105) -> b' anni' occured 3 times.\n",
      "2456/4744 pairs merged. (2455, 1035) -> b' annihil' occured 3 times.\n",
      "2457/4744 pairs merged. (1215, 609) -> b' occup' occured 3 times.\n",
      "2458/4744 pairs merged. (49, 631) -> b'112' occured 3 times.\n",
      "2459/4744 pairs merged. (559, 389) -> b' Mongolia' occured 3 times.\n",
      "2460/4744 pairs merged. (315, 1419) -> b' Mean' occured 3 times.\n",
      "2461/4744 pairs merged. (2460, 119) -> b' Meanw' occured 3 times.\n",
      "2462/4744 pairs merged. (2461, 2023) -> b' Meanwhile' occured 3 times.\n",
      "2463/4744 pairs merged. (1490, 381) -> b' failure' occured 3 times.\n",
      "2464/4744 pairs merged. (49, 437) -> b'100' occured 3 times.\n",
      "2465/4744 pairs merged. (839, 348) -> b' North' occured 3 times.\n",
      "2466/4744 pairs merged. (355, 99) -> b' forc' occured 3 times.\n",
      "2467/4744 pairs merged. (325, 1105) -> b' good' occured 3 times.\n",
      "2468/4744 pairs merged. (414, 2028) -> b' Jurchen' occured 3 times.\n",
      "2469/4744 pairs merged. (1220, 1324) -> b' initiated' occured 3 times.\n",
      "2470/4744 pairs merged. (1753, 1929) -> b' facilitated' occured 3 times.\n",
      "2471/4744 pairs merged. (256, 265) -> b' tre' occured 3 times.\n",
      "2472/4744 pairs merged. (109, 534) -> b'mend' occured 3 times.\n",
      "2473/4744 pairs merged. (989, 304) -> b' subsequently' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2232/4744 [00:21<00:22, 111.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2474/4744 pairs merged. (1263, 111) -> b' facto' occured 3 times.\n",
      "2475/4744 pairs merged. (1740, 358) -> b' travel' occured 3 times.\n",
      "2476/4744 pairs merged. (2035, 1078) -> b' innov' occured 3 times.\n",
      "2477/4744 pairs merged. (45, 116) -> b'-t' occured 3 times.\n",
      "2478/4744 pairs merged. (369, 110) -> b' En' occured 3 times.\n",
      "2479/4744 pairs merged. (112, 101) -> b'pe' occured 3 times.\n",
      "2480/4744 pairs merged. (119, 276) -> b'wor' occured 3 times.\n",
      "2481/4744 pairs merged. (283, 361) -> b' put' occured 3 times.\n",
      "2482/4744 pairs merged. (1280, 112) -> b' insp' occured 3 times.\n",
      "2483/4744 pairs merged. (258, 281) -> b'ines' occured 3 times.\n",
      "2484/4744 pairs merged. (484, 955) -> b' Further' occured 3 times.\n",
      "2485/4744 pairs merged. (1307, 115) -> b' defeats' occured 3 times.\n",
      "2486/4744 pairs merged. (831, 278) -> b'ollowing' occured 3 times.\n",
      "2487/4744 pairs merged. (679, 1920) -> b' substant' occured 3 times.\n",
      "2488/4744 pairs merged. (337, 1522) -> b' style' occured 3 times.\n",
      "2489/4744 pairs merged. (320, 319) -> b' nec' occured 3 times.\n",
      "2490/4744 pairs merged. (2489, 816) -> b' necess' occured 3 times.\n",
      "2491/4744 pairs merged. (530, 728) -> b'ague' occured 3 times.\n",
      "2492/4744 pairs merged. (1153, 285) -> b' quar' occured 3 times.\n",
      "2493/4744 pairs merged. (280, 292) -> b' sent' occured 3 times.\n",
      "2494/4744 pairs merged. (703, 311) -> b'zhang' occured 3 times.\n",
      "2495/4744 pairs merged. (957, 263) -> b'ailed' occured 3 times.\n",
      "2496/4744 pairs merged. (1154, 1961) -> b' Hongwu' occured 3 times.\n",
      "2497/4744 pairs merged. (325, 1680) -> b' grew' occured 3 times.\n",
      "2498/4744 pairs merged. (1604, 350) -> b' industries' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2256/4744 [00:21<00:22, 111.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2499/4744 pairs merged. (1674, 1052) -> b'ocratic' occured 3 times.\n",
      "2500/4744 pairs merged. (592, 345) -> b' able' occured 3 times.\n",
      "2501/4744 pairs merged. (1266, 101) -> b' tribute' occured 3 times.\n",
      "2502/4744 pairs merged. (1707, 116) -> b' built' occured 3 times.\n",
      "2503/4744 pairs merged. (1234, 303) -> b' coast' occured 3 times.\n",
      "2504/4744 pairs merged. (320, 573) -> b' nations' occured 3 times.\n",
      "2505/4744 pairs merged. (315, 360) -> b' Mac' occured 3 times.\n",
      "2506/4744 pairs merged. (2505, 1654) -> b' Macau' occured 3 times.\n",
      "2507/4744 pairs merged. (1134, 259) -> b' Span' occured 3 times.\n",
      "2508/4744 pairs merged. (2507, 653) -> b' Spanish' occured 3 times.\n",
      "2509/4744 pairs merged. (455, 2050) -> b' Dutch' occured 3 times.\n",
      "2510/4744 pairs merged. (335, 745) -> b'istance' occured 3 times.\n",
      "2511/4744 pairs merged. (846, 726) -> b' surren' occured 3 times.\n",
      "2512/4744 pairs merged. (2511, 460) -> b' surrender' occured 3 times.\n",
      "2513/4744 pairs merged. (1987, 97) -> b' Korea' occured 3 times.\n",
      "2514/4744 pairs merged. (953, 1523) -> b' declared' occured 3 times.\n",
      "2515/4744 pairs merged. (300, 1333) -> b' lives' occured 3 times.\n",
      "2516/4744 pairs merged. (2044, 1524) -> b' required' occured 3 times.\n",
      "2517/4744 pairs merged. (788, 909) -> b' cloth' occured 3 times.\n",
      "2518/4744 pairs merged. (313, 268) -> b'iven' occured 3 times.\n",
      "2519/4744 pairs merged. (2052, 120) -> b' Kangx' occured 3 times.\n",
      "2520/4744 pairs merged. (2519, 105) -> b' Kangxi' occured 3 times.\n",
      "2521/4744 pairs merged. (1501, 278) -> b' uprising' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 2281/4744 [00:22<00:23, 106.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2522/4744 pairs merged. (1526, 278) -> b' resulting' occured 3 times.\n",
      "2523/4744 pairs merged. (420, 323) -> b' Kong' occured 3 times.\n",
      "2524/4744 pairs merged. (1737, 510) -> b' Taip' occured 3 times.\n",
      "2525/4744 pairs merged. (838, 54) -> b'186' occured 3 times.\n",
      "2526/4744 pairs merged. (297, 114) -> b' Chr' occured 3 times.\n",
      "2527/4744 pairs merged. (2526, 335) -> b' Christ' occured 3 times.\n",
      "2528/4744 pairs merged. (408, 742) -> b' Zeng' occured 3 times.\n",
      "2529/4744 pairs merged. (2010, 102) -> b' Guof' occured 3 times.\n",
      "2530/4744 pairs merged. (550, 1758) -> b' Third' occured 3 times.\n",
      "2531/4744 pairs merged. (45, 83) -> b'-S' occured 3 times.\n",
      "2532/4744 pairs merged. (1683, 1527) -> b' Movement' occured 3 times.\n",
      "2533/4744 pairs merged. (1024, 941) -> b'stitution' occured 3 times.\n",
      "2534/4744 pairs merged. (45, 74) -> b'-J' occured 3 times.\n",
      "2535/4744 pairs merged. (2534, 697) -> b'-Japan' occured 3 times.\n",
      "2536/4744 pairs merged. (2535, 347) -> b'-Japanese' occured 3 times.\n",
      "2537/4744 pairs merged. (838, 57) -> b'189' occured 3 times.\n",
      "2538/4744 pairs merged. (735, 2037) -> b' comprehensive' occured 3 times.\n",
      "2539/4744 pairs merged. (1761, 261) -> b' Boxer' occured 3 times.\n",
      "2540/4744 pairs merged. (2057, 1204) -> b' Exped' occured 3 times.\n",
      "2541/4744 pairs merged. (2540, 495) -> b' Expedition' occured 3 times.\n",
      "2542/4744 pairs merged. (484, 511) -> b' Four' occured 3 times.\n",
      "2543/4744 pairs merged. (1146, 393) -> b' Vers' occured 3 times.\n",
      "2544/4744 pairs merged. (2543, 97) -> b' Versa' occured 3 times.\n",
      "2545/4744 pairs merged. (2544, 717) -> b' Versaill' occured 3 times.\n",
      "2546/4744 pairs merged. (2545, 281) -> b' Versailles' occured 3 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 2307/4744 [00:22<00:20, 116.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2547/4744 pairs merged. (1981, 263) -> b' freed' occured 3 times.\n",
      "2548/4744 pairs merged. (2547, 298) -> b' freedom' occured 3 times.\n",
      "2549/4744 pairs merged. (883, 290) -> b' Union' occured 3 times.\n",
      "2550/4744 pairs merged. (289, 666) -> b' Civil' occured 3 times.\n",
      "2551/4744 pairs merged. (1022, 834) -> b' Nationalists' occured 3 times.\n",
      "2552/4744 pairs merged. (484, 916) -> b' Fron' occured 3 times.\n",
      "2553/4744 pairs merged. (2552, 116) -> b' Front' occured 3 times.\n",
      "2554/4744 pairs merged. (398, 1858) -> b' atroc' occured 3 times.\n",
      "2555/4744 pairs merged. (2554, 773) -> b' atrocities' occured 3 times.\n",
      "2556/4744 pairs merged. (686, 121) -> b' party' occured 3 times.\n",
      "2557/4744 pairs merged. (107, 100) -> b'kd' occured 3 times.\n",
      "2558/4744 pairs merged. (2557, 509) -> b'kdown' occured 3 times.\n",
      "2559/4744 pairs merged. (277, 1944) -> b' infr' occured 3 times.\n",
      "2560/4744 pairs merged. (2559, 303) -> b' infrast' occured 3 times.\n",
      "2561/4744 pairs merged. (2560, 114) -> b' infrastr' occured 3 times.\n",
      "2562/4744 pairs merged. (2561, 1411) -> b' infrastructure' occured 3 times.\n",
      "2563/4744 pairs merged. (284, 695) -> b' free' occured 3 times.\n",
      "2564/4744 pairs merged. (1135, 1381) -> b' secret' occured 3 times.\n",
      "2565/4744 pairs merged. (2564, 448) -> b' secretary' occured 3 times.\n",
      "2566/4744 pairs merged. (369, 1082) -> b' Each' occured 2 times.\n",
      "2567/4744 pairs merged. (423, 467) -> b' unity' occured 2 times.\n",
      "2568/4744 pairs merged. (415, 583) -> b' fract' occured 2 times.\n",
      "2569/4744 pairs merged. (645, 1773) -> b' strife' occured 2 times.\n",
      "2570/4744 pairs merged. (330, 1370) -> b' constitut' occured 2 times.\n",
      "2571/4744 pairs merged. (271, 548) -> b' core' occured 2 times.\n",
      "2572/4744 pairs merged. (278, 117) -> b'ingu' occured 2 times.\n",
      "2573/4744 pairs merged. (300, 803) -> b' lens' occured 2 times.\n",
      "2574/4744 pairs merged. (462, 709) -> b' vie' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2333/4744 [00:22<00:20, 117.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2575/4744 pairs merged. (119, 278) -> b'wing' occured 2 times.\n",
      "2576/4744 pairs merged. (318, 287) -> b' dynastic' occured 2 times.\n",
      "2577/4744 pairs merged. (367, 1372) -> b' rise' occured 2 times.\n",
      "2578/4744 pairs merged. (267, 2072) -> b' achievements' occured 2 times.\n",
      "2579/4744 pairs merged. (929, 463) -> b' assum' occured 2 times.\n",
      "2580/4744 pairs merged. (2078, 304) -> b' directly' occured 2 times.\n",
      "2581/4744 pairs merged. (337, 1381) -> b' stret' occured 2 times.\n",
      "2582/4744 pairs merged. (429, 259) -> b' Shan' occured 2 times.\n",
      "2583/4744 pairs merged. (353, 275) -> b'imal' occured 2 times.\n",
      "2584/4744 pairs merged. (315, 648) -> b' Mount' occured 2 times.\n",
      "2585/4744 pairs merged. (282, 2082) -> b' delta' occured 2 times.\n",
      "2586/4744 pairs merged. (367, 313) -> b' riv' occured 2 times.\n",
      "2587/4744 pairs merged. (2086, 891) -> b' identified' occured 2 times.\n",
      "2588/4744 pairs merged. (282, 811) -> b' dates' occured 2 times.\n",
      "2589/4744 pairs merged. (1280, 2094) -> b' inscript' occured 2 times.\n",
      "2590/4744 pairs merged. (2589, 553) -> b' inscriptions' occured 2 times.\n",
      "2591/4744 pairs merged. (367, 273) -> b' rit' occured 2 times.\n",
      "2592/4744 pairs merged. (410, 343) -> b' ance' occured 2 times.\n",
      "2593/4744 pairs merged. (2592, 264) -> b' ancest' occured 2 times.\n",
      "2594/4744 pairs merged. (2593, 812) -> b' ancestors' occured 2 times.\n",
      "2595/4744 pairs merged. (2095, 713) -> b' received' occured 2 times.\n",
      "2596/4744 pairs merged. (842, 1545) -> b' divination' occured 2 times.\n",
      "2597/4744 pairs merged. (257, 115) -> b'hes' occured 2 times.\n",
      "2598/4744 pairs merged. (32, 1548) -> b' very' occured 2 times.\n",
      "2599/4744 pairs merged. (673, 488) -> b' extant' occured 2 times.\n",
      "2600/4744 pairs merged. (898, 349) -> b' laid' occured 2 times.\n",
      "2601/4744 pairs merged. (787, 120) -> b' Wux' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2372/4744 [00:22<00:20, 117.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2602/4744 pairs merged. (2601, 278) -> b' Wuxing' occured 2 times.\n",
      "2603/4744 pairs merged. (423, 899) -> b' united' occured 2 times.\n",
      "2604/4744 pairs merged. (280, 278) -> b' sing' occured 2 times.\n",
      "2605/4744 pairs merged. (2604, 345) -> b' single' occured 2 times.\n",
      "2606/4744 pairs merged. (619, 114) -> b' Or' occured 2 times.\n",
      "2607/4744 pairs merged. (813, 1796) -> b' weights' occured 2 times.\n",
      "2608/4744 pairs merged. (293, 101) -> b' me' occured 2 times.\n",
      "2609/4744 pairs merged. (2608, 295) -> b' meas' occured 2 times.\n",
      "2610/4744 pairs merged. (2609, 1174) -> b' measures' occured 2 times.\n",
      "2611/4744 pairs merged. (1560, 715) -> b' standardized' occured 2 times.\n",
      "2612/4744 pairs merged. (979, 278) -> b' marking' occured 2 times.\n",
      "2613/4744 pairs merged. (280, 259) -> b' san' occured 2 times.\n",
      "2614/4744 pairs merged. (32, 263) -> b' ed' occured 2 times.\n",
      "2615/4744 pairs merged. (354, 101) -> b' We' occured 2 times.\n",
      "2616/4744 pairs merged. (2615, 2107) -> b' Wealthy' occured 2 times.\n",
      "2617/4744 pairs merged. (1798, 1799) -> b' aristocracy' occured 2 times.\n",
      "2618/4744 pairs merged. (2109, 259) -> b' Roman' occured 2 times.\n",
      "2619/4744 pairs merged. (1572, 438) -> b' prolif' occured 2 times.\n",
      "2620/4744 pairs merged. (2619, 261) -> b' prolifer' occured 2 times.\n",
      "2621/4744 pairs merged. (1183, 263) -> b'oyed' occured 2 times.\n",
      "2622/4744 pairs merged. (1401, 374) -> b' collap' occured 2 times.\n",
      "2623/4744 pairs merged. (115, 263) -> b'sed' occured 2 times.\n",
      "2624/4744 pairs merged. (2113, 1566) -> b' lengthy' occured 2 times.\n",
      "2625/4744 pairs merged. (543, 334) -> b' disun' occured 2 times.\n",
      "2626/4744 pairs merged. (2625, 467) -> b' disunity' occured 2 times.\n",
      "2627/4744 pairs merged. (368, 964) -> b'igraph' occured 2 times.\n",
      "2628/4744 pairs merged. (2627, 121) -> b'igraphy' occured 2 times.\n",
      "2629/4744 pairs merged. (295, 281) -> b'ases' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2396/4744 [00:23<00:20, 117.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2630/4744 pairs merged. (2116, 375) -> b' incorporated' occured 2 times.\n",
      "2631/4744 pairs merged. (1576, 262) -> b' soon' occured 2 times.\n",
      "2632/4744 pairs merged. (2119, 263) -> b' regarded' occured 2 times.\n",
      "2633/4744 pairs merged. (1408, 715) -> b' recognized' occured 2 times.\n",
      "2634/4744 pairs merged. (1101, 743) -> b' empress' occured 2 times.\n",
      "2635/4744 pairs merged. (408, 2122) -> b' Zetian' occured 2 times.\n",
      "2636/4744 pairs merged. (1187, 263) -> b' reigned' occured 2 times.\n",
      "2637/4744 pairs merged. (2124, 2125) -> b' cosmopol' occured 2 times.\n",
      "2638/4744 pairs merged. (2637, 1808) -> b' cosmopolitan' occured 2 times.\n",
      "2639/4744 pairs merged. (319, 694) -> b'echan' occured 2 times.\n",
      "2640/4744 pairs merged. (2639, 417) -> b'echanical' occured 2 times.\n",
      "2641/4744 pairs merged. (273, 2127) -> b'itness' occured 2 times.\n",
      "2642/4744 pairs merged. (591, 1809) -> b'block' occured 2 times.\n",
      "2643/4744 pairs merged. (280, 1098) -> b' scient' occured 2 times.\n",
      "2644/4744 pairs merged. (2643, 853) -> b' scientific' occured 2 times.\n",
      "2645/4744 pairs merged. (2129, 357) -> b' advancement' occured 2 times.\n",
      "2646/4744 pairs merged. (1810, 1545) -> b' examination' occured 2 times.\n",
      "2647/4744 pairs merged. (284, 314) -> b' ful' occured 2 times.\n",
      "2648/4744 pairs merged. (2647, 304) -> b' fully' occured 2 times.\n",
      "2649/4744 pairs merged. (296, 103) -> b' tog' occured 2 times.\n",
      "2650/4744 pairs merged. (2649, 1811) -> b' together' occured 2 times.\n",
      "2651/4744 pairs merged. (2133, 1096) -> b'-Confucianism' occured 2 times.\n",
      "2652/4744 pairs merged. (554, 655) -> b'ventually' occured 2 times.\n",
      "2653/4744 pairs merged. (848, 116) -> b' Cont' occured 2 times.\n",
      "2654/4744 pairs merged. (1585, 101) -> b' Europe' occured 2 times.\n",
      "2655/4744 pairs merged. (808, 101) -> b' increase' occured 2 times.\n",
      "2656/4744 pairs merged. (2134, 2135) -> b' global' occured 2 times.\n",
      "2657/4744 pairs merged. (283, 746) -> b' public' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2421/4744 [00:23<00:20, 114.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2658/4744 pairs merged. (289, 108) -> b' Cl' occured 2 times.\n",
      "2659/4744 pairs merged. (407, 111) -> b' No' occured 2 times.\n",
      "2660/4744 pairs merged. (2659, 677) -> b' Novel' occured 2 times.\n",
      "2661/4744 pairs merged. (2660, 115) -> b' Novels' occured 2 times.\n",
      "2662/4744 pairs merged. (1816, 108) -> b' Qianl' occured 2 times.\n",
      "2663/4744 pairs merged. (2662, 323) -> b' Qianlong' occured 2 times.\n",
      "2664/4744 pairs merged. (1418, 57) -> b'179' occured 2 times.\n",
      "2665/4744 pairs merged. (1301, 121) -> b' ency' occured 2 times.\n",
      "2666/4744 pairs merged. (2665, 2145) -> b' encyclop' occured 2 times.\n",
      "2667/4744 pairs merged. (285, 350) -> b'aries' occured 2 times.\n",
      "2668/4744 pairs merged. (296, 116) -> b' tot' occured 2 times.\n",
      "2669/4744 pairs merged. (2668, 275) -> b' total' occured 2 times.\n",
      "2670/4744 pairs merged. (1597, 304) -> b' nearly' occured 2 times.\n",
      "2671/4744 pairs merged. (861, 372) -> b' territorial' occured 2 times.\n",
      "2672/4744 pairs merged. (330, 719) -> b' confl' occured 2 times.\n",
      "2673/4744 pairs merged. (271, 314) -> b' cul' occured 2 times.\n",
      "2674/4744 pairs merged. (2673, 818) -> b' culmin' occured 2 times.\n",
      "2675/4744 pairs merged. (640, 115) -> b' Wars' occured 2 times.\n",
      "2676/4744 pairs merged. (423, 2152) -> b' unequal' occured 2 times.\n",
      "2677/4744 pairs merged. (2154, 298) -> b' From' occured 2 times.\n",
      "2678/4744 pairs merged. (271, 819) -> b' cost' occured 2 times.\n",
      "2679/4744 pairs merged. (420, 529) -> b' Kai' occured 2 times.\n",
      "2680/4744 pairs merged. (1049, 257) -> b'-she' occured 2 times.\n",
      "2681/4744 pairs merged. (2680, 107) -> b'-shek' occured 2 times.\n",
      "2682/4744 pairs merged. (1603, 2157) -> b' interrupted' occured 2 times.\n",
      "2683/4744 pairs merged. (1604, 372) -> b' industrial' occured 2 times.\n",
      "2684/4744 pairs merged. (1829, 1110) -> b' Second' occured 2 times.\n",
      "2685/4744 pairs merged. (1608, 1575) -> b' victory' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2448/4744 [00:23<00:20, 114.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2686/4744 pairs merged. (2160, 505) -> b' retreat' occured 2 times.\n",
      "2687/4744 pairs merged. (271, 820) -> b' claim' occured 2 times.\n",
      "2688/4744 pairs merged. (1832, 353) -> b' legitim' occured 2 times.\n",
      "2689/4744 pairs merged. (1611, 322) -> b' slow' occured 2 times.\n",
      "2690/4744 pairs merged. (2689, 304) -> b' slowly' occured 2 times.\n",
      "2691/4744 pairs merged. (1284, 361) -> b' disput' occured 2 times.\n",
      "2692/4744 pairs merged. (419, 54) -> b'196' occured 2 times.\n",
      "2693/4744 pairs merged. (2163, 1204) -> b' helped' occured 2 times.\n",
      "2694/4744 pairs merged. (1615, 390) -> b' consolidate' occured 2 times.\n",
      "2695/4744 pairs merged. (296, 2111) -> b' towards' occured 2 times.\n",
      "2696/4744 pairs merged. (300, 1773) -> b' life' occured 2 times.\n",
      "2697/4744 pairs merged. (455, 742) -> b' Deng' occured 2 times.\n",
      "2698/4744 pairs merged. (683, 418) -> b' populous' occured 2 times.\n",
      "2699/4744 pairs merged. (1431, 389) -> b' India' occured 2 times.\n",
      "2700/4744 pairs merged. (513, 121) -> b'istory' occured 2 times.\n",
      "2701/4744 pairs merged. (1839, 2167) -> b' Paleolithic' occured 2 times.\n",
      "2702/4744 pairs merged. (679, 115) -> b' subs' occured 2 times.\n",
      "2703/4744 pairs merged. (1845, 186) -> b'\\xe4\\xba\\xba' occured 2 times.\n",
      "2704/4744 pairs merged. (293, 2172) -> b' mixed' occured 2 times.\n",
      "2705/4744 pairs merged. (997, 934) -> b' Steg' occured 2 times.\n",
      "2706/4744 pairs merged. (2705, 378) -> b' Stegod' occured 2 times.\n",
      "2707/4744 pairs merged. (2706, 262) -> b' Stegodon' occured 2 times.\n",
      "2708/4744 pairs merged. (271, 998) -> b' cattle' occured 2 times.\n",
      "2709/4744 pairs merged. (368, 115) -> b'igs' occured 2 times.\n",
      "2710/4744 pairs merged. (325, 1622) -> b' giant' occured 2 times.\n",
      "2711/4744 pairs merged. (1437, 268) -> b' hyen' occured 2 times.\n",
      "2712/4744 pairs merged. (2711, 97) -> b' hyena' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 2475/4744 [00:23<00:19, 114.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2713/4744 pairs merged. (288, 338) -> b' bet' occured 2 times.\n",
      "2714/4744 pairs merged. (2713, 471) -> b' better' occured 2 times.\n",
      "2715/4744 pairs merged. (283, 826) -> b' poin' occured 2 times.\n",
      "2716/4744 pairs merged. (108, 115) -> b'ls' occured 2 times.\n",
      "2717/4744 pairs merged. (284, 1210) -> b' foss' occured 2 times.\n",
      "2718/4744 pairs merged. (2717, 308) -> b' fossil' occured 2 times.\n",
      "2719/4744 pairs merged. (542, 2181) -> b' northeastern' occured 2 times.\n",
      "2720/4744 pairs merged. (827, 262) -> b' Liaon' occured 2 times.\n",
      "2721/4744 pairs merged. (2720, 278) -> b' Liaoning' occured 2 times.\n",
      "2722/4744 pairs merged. (750, 389) -> b' relia' occured 2 times.\n",
      "2723/4744 pairs merged. (2722, 2186) -> b' reliably' occured 2 times.\n",
      "2724/4744 pairs merged. (530, 110) -> b'agn' occured 2 times.\n",
      "2725/4744 pairs merged. (315, 698) -> b' Maj' occured 2 times.\n",
      "2726/4744 pairs merged. (53, 53) -> b'55' occured 2 times.\n",
      "2727/4744 pairs merged. (484, 101) -> b' Fe' occured 2 times.\n",
      "2728/4744 pairs merged. (369, 1213) -> b' Evidence' occured 2 times.\n",
      "2729/4744 pairs merged. (284, 432) -> b' fire' occured 2 times.\n",
      "2730/4744 pairs merged. (1855, 118) -> b' Prov' occured 2 times.\n",
      "2731/4744 pairs merged. (2730, 910) -> b' Province' occured 2 times.\n",
      "2732/4744 pairs merged. (846, 114) -> b' surr' occured 2 times.\n",
      "2733/4744 pairs merged. (2732, 480) -> b' surround' occured 2 times.\n",
      "2734/4744 pairs merged. (2733, 278) -> b' surrounding' occured 2 times.\n",
      "2735/4744 pairs merged. (260, 1441) -> b' theories' occured 2 times.\n",
      "2736/4744 pairs merged. (79, 65) -> b'OA' occured 2 times.\n",
      "2737/4744 pairs merged. (1437, 1853) -> b' hypo' occured 2 times.\n",
      "2738/4744 pairs merged. (2737, 344) -> b' hypothe' occured 2 times.\n",
      "2739/4744 pairs merged. (2738, 115) -> b' hypothes' occured 2 times.\n",
      "2740/4744 pairs merged. (2739, 294) -> b' hypothesis' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2499/4744 [00:23<00:20, 112.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2741/4744 pairs merged. (1617, 626) -> b' humans' occured 2 times.\n",
      "2742/4744 pairs merged. (289, 585) -> b' Cave' occured 2 times.\n",
      "2743/4744 pairs merged. (1217, 261) -> b' larger' occured 2 times.\n",
      "2744/4744 pairs merged. (258, 1162) -> b'inct' occured 2 times.\n",
      "2745/4744 pairs merged. (283, 274) -> b' pand' occured 2 times.\n",
      "2746/4744 pairs merged. (1861, 345) -> b'iddle' occured 2 times.\n",
      "2747/4744 pairs merged. (119, 370) -> b'west' occured 2 times.\n",
      "2748/4744 pairs merged. (1119, 332) -> b' appro' occured 2 times.\n",
      "2749/4744 pairs merged. (2748, 120) -> b' approx' occured 2 times.\n",
      "2750/4744 pairs merged. (2749, 1635) -> b' approximately' occured 2 times.\n",
      "2751/4744 pairs merged. (554, 290) -> b'vention' occured 2 times.\n",
      "2752/4744 pairs merged. (282, 438) -> b' dif' occured 2 times.\n",
      "2753/4744 pairs merged. (2752, 1121) -> b' differ' occured 2 times.\n",
      "2754/4744 pairs merged. (2753, 292) -> b' different' occured 2 times.\n",
      "2755/4744 pairs merged. (857, 263) -> b' developed' occured 2 times.\n",
      "2756/4744 pairs merged. (508, 1084) -> b' grains' occured 2 times.\n",
      "2757/4744 pairs merged. (274, 278) -> b'anding' occured 2 times.\n",
      "2758/4744 pairs merged. (475, 1867) -> b' cultivated' occured 2 times.\n",
      "2759/4744 pairs merged. (367, 2201) -> b' rice' occured 2 times.\n",
      "2760/4744 pairs merged. (1317, 375) -> b'-dated' occured 2 times.\n",
      "2761/4744 pairs merged. (369, 1638) -> b' Early' occured 2 times.\n",
      "2762/4744 pairs merged. (367, 321) -> b' rad' occured 2 times.\n",
      "2763/4744 pairs merged. (1447, 1639) -> b' Jiahu' occured 2 times.\n",
      "2764/4744 pairs merged. (288, 370) -> b' best' occured 2 times.\n",
      "2765/4744 pairs merged. (1298, 48) -> b'580' occured 2 times.\n",
      "2766/4744 pairs merged. (455, 384) -> b' Dam' occured 2 times.\n",
      "2767/4744 pairs merged. (2766, 1222) -> b' Damaid' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2526/4744 [00:24<00:19, 112.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2768/4744 pairs merged. (2767, 105) -> b' Damaidi' occured 2 times.\n",
      "2769/4744 pairs merged. (407, 278) -> b' Ning' occured 2 times.\n",
      "2770/4744 pairs merged. (2769, 120) -> b' Ningx' occured 2 times.\n",
      "2771/4744 pairs merged. (2770, 389) -> b' Ningxia' occured 2 times.\n",
      "2772/4744 pairs merged. (54, 437) -> b'600' occured 2 times.\n",
      "2773/4744 pairs merged. (102, 101) -> b'fe' occured 2 times.\n",
      "2774/4744 pairs merged. (337, 285) -> b' star' occured 2 times.\n",
      "2775/4744 pairs merged. (325, 378) -> b' god' occured 2 times.\n",
      "2776/4744 pairs merged. (2775, 115) -> b' gods' occured 2 times.\n",
      "2777/4744 pairs merged. (280, 99) -> b' sc' occured 2 times.\n",
      "2778/4744 pairs merged. (97, 122) -> b'az' occured 2 times.\n",
      "2779/4744 pairs merged. (285, 99) -> b'arc' occured 2 times.\n",
      "2780/4744 pairs merged. (1318, 105) -> b'shi' occured 2 times.\n",
      "2781/4744 pairs merged. (45, 119) -> b'-w' occured 2 times.\n",
      "2782/4744 pairs merged. (497, 278) -> b'riting' occured 2 times.\n",
      "2783/4744 pairs merged. (455, 321) -> b' Dad' occured 2 times.\n",
      "2784/4744 pairs merged. (52, 48) -> b'40' occured 2 times.\n",
      "2785/4744 pairs merged. (592, 1225) -> b' ability' occured 2 times.\n",
      "2786/4744 pairs merged. (2212, 115) -> b' crops' occured 2 times.\n",
      "2787/4744 pairs merged. (283, 545) -> b' pot' occured 2 times.\n",
      "2788/4744 pairs merged. (2787, 1874) -> b' potential' occured 2 times.\n",
      "2789/4744 pairs merged. (293, 571) -> b' may' occured 2 times.\n",
      "2790/4744 pairs merged. (115, 694) -> b'shan' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2551/4744 [00:24<00:18, 117.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2791/4744 pairs merged. (282, 473) -> b' dog' occured 2 times.\n",
      "2792/4744 pairs merged. (1637, 1167) -> b' domesticated' occured 2 times.\n",
      "2793/4744 pairs merged. (280, 257) -> b' she' occured 2 times.\n",
      "2794/4744 pairs merged. (1404, 438) -> b' artif' occured 2 times.\n",
      "2795/4744 pairs merged. (2794, 1880) -> b' artifacts' occured 2 times.\n",
      "2796/4744 pairs merged. (98, 696) -> b'between' occured 2 times.\n",
      "2797/4744 pairs merged. (542, 1650) -> b' northeast' occured 2 times.\n",
      "2798/4744 pairs merged. (1092, 375) -> b' located' occured 2 times.\n",
      "2799/4744 pairs merged. (306, 406) -> b' Sich' occured 2 times.\n",
      "2800/4744 pairs merged. (2799, 528) -> b' Sichuan' occured 2 times.\n",
      "2801/4744 pairs merged. (1123, 304) -> b' previously' occured 2 times.\n",
      "2802/4744 pairs merged. (1631, 675) -> b' archaeolog' occured 2 times.\n",
      "2803/4744 pairs merged. (2802, 834) -> b' archaeologists' occured 2 times.\n",
      "2804/4744 pairs merged. (1882, 1208) -> b' linking' occured 2 times.\n",
      "2805/4744 pairs merged. (1883, 448) -> b' legendary' occured 2 times.\n",
      "2806/4744 pairs merged. (411, 281) -> b'aves' occured 2 times.\n",
      "2807/4744 pairs merged. (106, 389) -> b'jia' occured 2 times.\n",
      "2808/4744 pairs merged. (261, 114) -> b'err' occured 2 times.\n",
      "2809/4744 pairs merged. (32, 1619) -> b' iron' occured 2 times.\n",
      "2810/4744 pairs merged. (703, 674) -> b'zhuang' occured 2 times.\n",
      "2811/4744 pairs merged. (110, 322) -> b'now' occured 2 times.\n",
      "2812/4744 pairs merged. (1454, 259) -> b' Tibetan' occured 2 times.\n",
      "2813/4744 pairs merged. (399, 108) -> b' Pl' occured 2 times.\n",
      "2814/4744 pairs merged. (2230, 1324) -> b' associated' occured 2 times.\n",
      "2815/4744 pairs merged. (1888, 298) -> b'ustom' occured 2 times.\n",
      "2816/4744 pairs merged. (1595, 263) -> b' succeed' occured 2 times.\n",
      "2817/4744 pairs merged. (2816, 278) -> b' succeeding' occured 2 times.\n",
      "2818/4744 pairs merged. (373, 103) -> b' sug' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 2577/4744 [00:24<00:18, 117.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2819/4744 pairs merged. (2818, 103) -> b' sugg' occured 2 times.\n",
      "2820/4744 pairs merged. (2819, 370) -> b' suggest' occured 2 times.\n",
      "2821/4744 pairs merged. (1657, 1124) -> b' concurren' occured 2 times.\n",
      "2822/4744 pairs merged. (2821, 1658) -> b' concurrently' occured 2 times.\n",
      "2823/4744 pairs merged. (1125, 1888) -> b' just' occured 2 times.\n",
      "2824/4744 pairs merged. (380, 285) -> b' bear' occured 2 times.\n",
      "2825/4744 pairs merged. (1889, 285) -> b'imilar' occured 2 times.\n",
      "2826/4744 pairs merged. (2240, 495) -> b' Tradition' occured 2 times.\n",
      "2827/4744 pairs merged. (2826, 452) -> b' Traditionally' occured 2 times.\n",
      "2828/4744 pairs merged. (1891, 1866) -> b' abdication' occured 2 times.\n",
      "2829/4744 pairs merged. (1891, 1167) -> b' abdicated' occured 2 times.\n",
      "2830/4744 pairs merged. (672, 281) -> b' includes' occured 2 times.\n",
      "2831/4744 pairs merged. (384, 98) -> b'amb' occured 2 times.\n",
      "2832/4744 pairs merged. (2831, 1892) -> b'amboo' occured 2 times.\n",
      "2833/4744 pairs merged. (935, 1648) -> b' Shiji' occured 2 times.\n",
      "2834/4744 pairs merged. (293, 121) -> b' my' occured 2 times.\n",
      "2835/4744 pairs merged. (2834, 348) -> b' myth' occured 2 times.\n",
      "2836/4744 pairs merged. (835, 655) -> b' usually' occured 2 times.\n",
      "2837/4744 pairs merged. (419, 48) -> b'190' occured 2 times.\n",
      "2838/4744 pairs merged. (356, 268) -> b' Hen' occured 2 times.\n",
      "2839/4744 pairs merged. (2838, 259) -> b' Henan' occured 2 times.\n",
      "2840/4744 pairs merged. (306, 910) -> b' Since' occured 2 times.\n",
      "2841/4744 pairs merged. (400, 688) -> b' prove' occured 2 times.\n",
      "2842/4744 pairs merged. (270, 257) -> b' whe' occured 2 times.\n",
      "2843/4744 pairs merged. (2842, 359) -> b' whether' occured 2 times.\n",
      "2844/4744 pairs merged. (291, 329) -> b' ever' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▍    | 2603/4744 [00:24<00:19, 112.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2845/4744 pairs merged. (306, 1893) -> b' Some' occured 2 times.\n",
      "2846/4744 pairs merged. (525, 1459) -> b' organ' occured 2 times.\n",
      "2847/4744 pairs merged. (1894, 488) -> b' important' occured 2 times.\n",
      "2848/4744 pairs merged. (835, 278) -> b' using' occured 2 times.\n",
      "2849/4744 pairs merged. (462, 816) -> b' vess' occured 2 times.\n",
      "2850/4744 pairs merged. (2849, 1461) -> b' vessels' occured 2 times.\n",
      "2851/4744 pairs merged. (484, 1315) -> b' Find' occured 2 times.\n",
      "2852/4744 pairs merged. (2851, 725) -> b' Findings' occured 2 times.\n",
      "2853/4744 pairs merged. (120, 117) -> b'xu' occured 2 times.\n",
      "2854/4744 pairs merged. (110, 496) -> b'near' occured 2 times.\n",
      "2855/4744 pairs merged. (397, 390) -> b' Late' occured 2 times.\n",
      "2856/4744 pairs merged. (983, 100) -> b' find' occured 2 times.\n",
      "2857/4744 pairs merged. (2856, 725) -> b' findings' occured 2 times.\n",
      "2858/4744 pairs merged. (550, 1053) -> b' Through' occured 2 times.\n",
      "2859/4744 pairs merged. (425, 688) -> b' move' occured 2 times.\n",
      "2860/4744 pairs merged. (455, 278) -> b' Ding' occured 2 times.\n",
      "2861/4744 pairs merged. (269, 471) -> b'atter' occured 2 times.\n",
      "2862/4744 pairs merged. (65, 108) -> b'Al' occured 2 times.\n",
      "2863/4744 pairs merged. (2862, 1231) -> b'Although' occured 2 times.\n",
      "2864/4744 pairs merged. (330, 102) -> b' conf' occured 2 times.\n",
      "2865/4744 pairs merged. (1232, 667) -> b' settlements' occured 2 times.\n",
      "2866/4744 pairs merged. (1129, 278) -> b' leading' occured 2 times.\n",
      "2867/4744 pairs merged. (1234, 894) -> b' coex' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2628/4744 [00:25<00:18, 115.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2868/4744 pairs merged. (2867, 2265) -> b' coexisted' occured 2 times.\n",
      "2869/4744 pairs merged. (517, 263) -> b' traded' occured 2 times.\n",
      "2870/4744 pairs merged. (101, 321) -> b'ead' occured 2 times.\n",
      "2871/4744 pairs merged. (392, 109) -> b' alm' occured 2 times.\n",
      "2872/4744 pairs merged. (2871, 819) -> b' almost' occured 2 times.\n",
      "2873/4744 pairs merged. (291, 871) -> b' eight' occured 2 times.\n",
      "2874/4744 pairs merged. (110, 100) -> b'nd' occured 2 times.\n",
      "2875/4744 pairs merged. (1855, 116) -> b' Prot' occured 2 times.\n",
      "2876/4744 pairs merged. (494, 812) -> b'ectors' occured 2 times.\n",
      "2877/4744 pairs merged. (750, 2274) -> b' relatives' occured 2 times.\n",
      "2878/4744 pairs merged. (556, 350) -> b' allies' occured 2 times.\n",
      "2879/4744 pairs merged. (306, 1009) -> b' Sever' occured 2 times.\n",
      "2880/4744 pairs merged. (2879, 275) -> b' Several' occured 2 times.\n",
      "2881/4744 pairs merged. (938, 1874) -> b' influential' occured 2 times.\n",
      "2882/4744 pairs merged. (1905, 114) -> b' overthr' occured 2 times.\n",
      "2883/4744 pairs merged. (411, 278) -> b'aving' occured 2 times.\n",
      "2884/4744 pairs merged. (408, 323) -> b' Zong' occured 2 times.\n",
      "2885/4744 pairs merged. (446, 278) -> b' king' occured 2 times.\n",
      "2886/4744 pairs merged. (429, 274) -> b' Shand' occured 2 times.\n",
      "2887/4744 pairs merged. (2886, 323) -> b' Shandong' occured 2 times.\n",
      "2888/4744 pairs merged. (518, 1650) -> b' southeast' occured 2 times.\n",
      "2889/4744 pairs merged. (52, 2289) -> b'476' occured 2 times.\n",
      "2890/4744 pairs merged. (395, 286) -> b' You' occured 2 times.\n",
      "2891/4744 pairs merged. (451, 528) -> b' Quan' occured 2 times.\n",
      "2892/4744 pairs merged. (288, 2202) -> b' barb' occured 2 times.\n",
      "2893/4744 pairs merged. (2892, 285) -> b' barbar' occured 2 times.\n",
      "2894/4744 pairs merged. (1798, 1674) -> b' aristocr' occured 2 times.\n",
      "2895/4744 pairs merged. (2894, 269) -> b' aristocrat' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 2654/4744 [00:25<00:18, 116.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2896/4744 pairs merged. (2895, 115) -> b' aristocrats' occured 2 times.\n",
      "2897/4744 pairs merged. (283, 104) -> b' ph' occured 2 times.\n",
      "2898/4744 pairs merged. (320, 384) -> b' nam' occured 2 times.\n",
      "2899/4744 pairs merged. (724, 285) -> b' shar' occured 2 times.\n",
      "2900/4744 pairs merged. (2899, 112) -> b' sharp' occured 2 times.\n",
      "2901/4744 pairs merged. (2900, 304) -> b' sharply' occured 2 times.\n",
      "2902/4744 pairs merged. (1641, 2292) -> b' reduced' occured 2 times.\n",
      "2903/4744 pairs merged. (462, 2295) -> b' vacu' occured 2 times.\n",
      "2904/4744 pairs merged. (2903, 463) -> b' vacuum' occured 2 times.\n",
      "2905/4744 pairs merged. (270, 514) -> b' wall' occured 2 times.\n",
      "2906/4744 pairs merged. (521, 434) -> b' hege' occured 2 times.\n",
      "2907/4744 pairs merged. (2906, 109) -> b' hegem' occured 2 times.\n",
      "2908/4744 pairs merged. (2907, 1807) -> b' hegemony' occured 2 times.\n",
      "2909/4744 pairs merged. (2300, 496) -> b' disappear' occured 2 times.\n",
      "2910/4744 pairs merged. (275, 773) -> b'alities' occured 2 times.\n",
      "2911/4744 pairs merged. (271, 943) -> b' claimed' occured 2 times.\n",
      "2912/4744 pairs merged. (586, 116) -> b' undert' occured 2 times.\n",
      "2913/4744 pairs merged. (2306, 1917) -> b' commercial' occured 2 times.\n",
      "2914/4744 pairs merged. (2207, 1326) -> b' individuals' occured 2 times.\n",
      "2915/4744 pairs merged. (502, 122) -> b'aoz' occured 2 times.\n",
      "2916/4744 pairs merged. (1004, 573) -> b' administrations' occured 2 times.\n",
      "2917/4744 pairs merged. (425, 98) -> b' mob' occured 2 times.\n",
      "2918/4744 pairs merged. (121, 278) -> b'ying' occured 2 times.\n",
      "2919/4744 pairs merged. (1905, 1680) -> b' overthrew' occured 2 times.\n",
      "2920/4744 pairs merged. (356, 1679) -> b' Hundred' occured 2 times.\n",
      "2921/4744 pairs merged. (306, 341) -> b' Sch' occured 2 times.\n",
      "2922/4744 pairs merged. (111, 2210) -> b'ools' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2693/4744 [00:25<00:17, 117.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2923/4744 pairs merged. (298, 278) -> b'oming' occured 2 times.\n",
      "2924/4744 pairs merged. (1684, 278) -> b' changing' occured 2 times.\n",
      "2925/4744 pairs merged. (1923, 452) -> b' nominally' occured 2 times.\n",
      "2926/4744 pairs merged. (896, 304) -> b' largely' occured 2 times.\n",
      "2927/4744 pairs merged. (293, 269) -> b' mat' occured 2 times.\n",
      "2928/4744 pairs merged. (2927, 2311) -> b' mathem' occured 2 times.\n",
      "2929/4744 pairs merged. (258, 99) -> b'inc' occured 2 times.\n",
      "2930/4744 pairs merged. (2929, 632) -> b'includ' occured 2 times.\n",
      "2931/4744 pairs merged. (2930, 278) -> b'including' occured 2 times.\n",
      "2932/4744 pairs merged. (408, 702) -> b' Zuo' occured 2 times.\n",
      "2933/4744 pairs merged. (595, 107) -> b' work' occured 2 times.\n",
      "2934/4744 pairs merged. (373, 109) -> b' sum' occured 2 times.\n",
      "2935/4744 pairs merged. (453, 278) -> b'izing' occured 2 times.\n",
      "2936/4744 pairs merged. (2313, 278) -> b' preceding' occured 2 times.\n",
      "2937/4744 pairs merged. (299, 115) -> b' Ts' occured 2 times.\n",
      "2938/4744 pairs merged. (2937, 278) -> b' Tsing' occured 2 times.\n",
      "2939/4744 pairs merged. (2938, 1639) -> b' Tsinghu' occured 2 times.\n",
      "2940/4744 pairs merged. (2939, 97) -> b' Tsinghua' occured 2 times.\n",
      "2941/4744 pairs merged. (1401, 1688) -> b' collection' occured 2 times.\n",
      "2942/4744 pairs merged. (280, 1171) -> b' soph' occured 2 times.\n",
      "2943/4744 pairs merged. (2317, 261) -> b' commander' occured 2 times.\n",
      "2944/4744 pairs merged. (2943, 350) -> b' commanderies' occured 2 times.\n",
      "2945/4744 pairs merged. (2318, 1174) -> b' prefectures' occured 2 times.\n",
      "2946/4744 pairs merged. (308, 105) -> b'ili' occured 2 times.\n",
      "2947/4744 pairs merged. (2320, 379) -> b' xian' occured 2 times.\n",
      "2948/4744 pairs merged. (351, 34) -> b' (\"' occured 2 times.\n",
      "2949/4744 pairs merged. (34, 41) -> b'\")' occured 2 times.\n",
      "2950/4744 pairs merged. (270, 259) -> b' wan' occured 2 times.\n",
      "2951/4744 pairs merged. (1906, 1854) -> b' Chengdu' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2720/4744 [00:25<00:17, 114.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2952/4744 pairs merged. (399, 1589) -> b' Plain' occured 2 times.\n",
      "2953/4744 pairs merged. (98, 121) -> b'by' occured 2 times.\n",
      "2954/4744 pairs merged. (405, 412) -> b' Its' occured 2 times.\n",
      "2955/4744 pairs merged. (687, 626) -> b' expans' occured 2 times.\n",
      "2956/4744 pairs merged. (2955, 290) -> b' expansion' occured 2 times.\n",
      "2957/4744 pairs merged. (557, 54) -> b'206' occured 2 times.\n",
      "2958/4744 pairs merged. (231, 167) -> b'\\xe7\\xa7' occured 2 times.\n",
      "2959/4744 pairs merged. (2958, 166) -> b'\\xe7\\xa7\\xa6' occured 2 times.\n",
      "2960/4744 pairs merged. (895, 275) -> b' formal' occured 2 times.\n",
      "2961/4744 pairs merged. (283, 313) -> b' piv' occured 2 times.\n",
      "2962/4744 pairs merged. (2961, 545) -> b' pivot' occured 2 times.\n",
      "2963/4744 pairs merged. (2962, 275) -> b' pivotal' occured 2 times.\n",
      "2964/4744 pairs merged. (118, 278) -> b'ving' occured 2 times.\n",
      "2965/4744 pairs merged. (34, 46) -> b'\".' occured 2 times.\n",
      "2966/4744 pairs merged. (1173, 2277) -> b' Huangdi' occured 2 times.\n",
      "2967/4744 pairs merged. (256, 273) -> b' tit' occured 2 times.\n",
      "2968/4744 pairs merged. (2967, 345) -> b' title' occured 2 times.\n",
      "2969/4744 pairs merged. (282, 261) -> b' der' occured 2 times.\n",
      "2970/4744 pairs merged. (2969, 713) -> b' derived' occured 2 times.\n",
      "2971/4744 pairs merged. (1196, 114) -> b' bureaucr' occured 2 times.\n",
      "2972/4744 pairs merged. (2971, 1052) -> b' bureaucratic' occured 2 times.\n",
      "2973/4744 pairs merged. (889, 375) -> b' dominated' occured 2 times.\n",
      "2974/4744 pairs merged. (2332, 116) -> b' effort' occured 2 times.\n",
      "2975/4744 pairs merged. (400, 103) -> b' prog' occured 2 times.\n",
      "2976/4744 pairs merged. (2975, 743) -> b' progress' occured 2 times.\n",
      "2977/4744 pairs merged. (1480, 261) -> b' smaller' occured 2 times.\n",
      "2978/4744 pairs merged. (327, 112) -> b' asp' occured 2 times.\n",
      "2979/4744 pairs merged. (2978, 1107) -> b' aspects' occured 2 times.\n",
      "2980/4744 pairs merged. (611, 745) -> b' chance' occured 2 times.\n",
      "2981/4744 pairs merged. (2980, 1664) -> b' chancell' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2747/4744 [00:26<00:18, 110.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2982/4744 pairs merged. (945, 275) -> b' legal' occured 2 times.\n",
      "2983/4744 pairs merged. (293, 1687) -> b' matt' occured 2 times.\n",
      "2984/4744 pairs merged. (2983, 393) -> b' matters' occured 2 times.\n",
      "2985/4744 pairs merged. (1368, 101) -> b' severe' occured 2 times.\n",
      "2986/4744 pairs merged. (283, 334) -> b' pun' occured 2 times.\n",
      "2987/4744 pairs merged. (786, 357) -> b'agement' occured 2 times.\n",
      "2988/4744 pairs merged. (748, 642) -> b' Reform' occured 2 times.\n",
      "2989/4744 pairs merged. (288, 1892) -> b' boo' occured 2 times.\n",
      "2990/4744 pairs merged. (2989, 765) -> b' books' occured 2 times.\n",
      "2991/4744 pairs merged. (300, 422) -> b' live' occured 2 times.\n",
      "2992/4744 pairs merged. (1935, 1014) -> b' considerable' occured 2 times.\n",
      "2993/4744 pairs merged. (282, 286) -> b' dou' occured 2 times.\n",
      "2994/4744 pairs merged. (523, 287) -> b' historic' occured 2 times.\n",
      "2995/4744 pairs merged. (455, 1697) -> b' Despite' occured 2 times.\n",
      "2996/4744 pairs merged. (874, 1698) -> b' supplement' occured 2 times.\n",
      "2997/4744 pairs merged. (305, 639) -> b'olitical' occured 2 times.\n",
      "2998/4744 pairs merged. (293, 276) -> b' mor' occured 2 times.\n",
      "2999/4744 pairs merged. (2998, 275) -> b' moral' occured 2 times.\n",
      "3000/4744 pairs merged. (1547, 102) -> b' belief' occured 2 times.\n",
      "3001/4744 pairs merged. (3000, 115) -> b' beliefs' occured 2 times.\n",
      "3002/4744 pairs merged. (284, 422) -> b' five' occured 2 times.\n",
      "3003/4744 pairs merged. (446, 1936) -> b' kept' occured 2 times.\n",
      "3004/4744 pairs merged. (1401, 494) -> b' collect' occured 2 times.\n",
      "3005/4744 pairs merged. (731, 120) -> b' sex' occured 2 times.\n",
      "3006/4744 pairs merged. (102, 102) -> b'ff' occured 2 times.\n",
      "3007/4744 pairs merged. (3006, 562) -> b'ffered' occured 2 times.\n",
      "3008/4744 pairs merged. (2338, 1318) -> b' harsh' occured 2 times.\n",
      "3009/4744 pairs merged. (399, 269) -> b' Pat' occured 2 times.\n",
      "3010/4744 pairs merged. (3009, 830) -> b' Patric' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 2773/4744 [00:26<00:16, 119.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3011/4744 pairs merged. (3010, 389) -> b' Patricia' occured 2 times.\n",
      "3012/4744 pairs merged. (369, 98) -> b' Eb' occured 2 times.\n",
      "3013/4744 pairs merged. (3012, 265) -> b' Ebre' occured 2 times.\n",
      "3014/4744 pairs merged. (3013, 121) -> b' Ebrey' occured 2 times.\n",
      "3015/4744 pairs merged. (1701, 416) -> b' conscripted' occured 2 times.\n",
      "3016/4744 pairs merged. (1652, 2340) -> b' highway' occured 2 times.\n",
      "3017/4744 pairs merged. (449, 281) -> b' miles' occured 2 times.\n",
      "3018/4744 pairs merged. (446, 109) -> b' km' occured 2 times.\n",
      "3019/4744 pairs merged. (392, 116) -> b' alt' occured 2 times.\n",
      "3020/4744 pairs merged. (3019, 473) -> b' altog' occured 2 times.\n",
      "3021/4744 pairs merged. (3020, 1811) -> b' altogether' occured 2 times.\n",
      "3022/4744 pairs merged. (315, 742) -> b' Meng' occured 2 times.\n",
      "3023/4744 pairs merged. (1253, 1102) -> b' successful' occured 2 times.\n",
      "3024/4744 pairs merged. (549, 362) -> b' peop' occured 2 times.\n",
      "3025/4744 pairs merged. (3024, 1376) -> b' peoples' occured 2 times.\n",
      "3026/4744 pairs merged. (883, 460) -> b' Under' occured 2 times.\n",
      "3027/4744 pairs merged. (525, 100) -> b' ord' occured 2 times.\n",
      "3028/4744 pairs merged. (258, 278) -> b'ining' occured 2 times.\n",
      "3029/4744 pairs merged. (1707, 100) -> b' build' occured 2 times.\n",
      "3030/4744 pairs merged. (427, 276) -> b'erior' occured 2 times.\n",
      "3031/4744 pairs merged. (2346, 263) -> b' sacked' occured 2 times.\n",
      "3032/4744 pairs merged. (881, 1461) -> b' rebels' occured 2 times.\n",
      "3033/4744 pairs merged. (1055, 117) -> b' Liu' occured 2 times.\n",
      "3034/4744 pairs merged. (1615, 375) -> b' consolidated' occured 2 times.\n",
      "3035/4744 pairs merged. (109, 273) -> b'mit' occured 2 times.\n",
      "3036/4744 pairs merged. (1621, 118) -> b' elev' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 2799/4744 [00:26<00:17, 113.97it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3037/4744 pairs merged. (3036, 375) -> b' elevated' occured 2 times.\n",
      "3038/4744 pairs merged. (724, 374) -> b' shap' occured 2 times.\n",
      "3039/4744 pairs merged. (423, 112) -> b' unp' occured 2 times.\n",
      "3040/4744 pairs merged. (3039, 265) -> b' unpre' occured 2 times.\n",
      "3041/4744 pairs merged. (3040, 664) -> b' unpreced' occured 2 times.\n",
      "3042/4744 pairs merged. (3041, 292) -> b' unprecedent' occured 2 times.\n",
      "3043/4744 pairs merged. (3042, 263) -> b' unprecedented' occured 2 times.\n",
      "3044/4744 pairs merged. (1072, 278) -> b' lasting' occured 2 times.\n",
      "3045/4744 pairs merged. (256, 569) -> b' tak' occured 2 times.\n",
      "3046/4744 pairs merged. (3045, 268) -> b' taken' occured 2 times.\n",
      "3047/4744 pairs merged. (581, 115) -> b' Emperors' occured 2 times.\n",
      "3048/4744 pairs merged. (414, 278) -> b' Jing' occured 2 times.\n",
      "3049/4744 pairs merged. (453, 281) -> b'izes' occured 2 times.\n",
      "3050/4744 pairs merged. (2355, 2356) -> b' strengthe' occured 2 times.\n",
      "3051/4744 pairs merged. (77, 769) -> b'Major' occured 2 times.\n",
      "3052/4744 pairs merged. (1012, 268) -> b' weaken' occured 2 times.\n",
      "3053/4744 pairs merged. (273, 278) -> b'iting' occured 2 times.\n",
      "3054/4744 pairs merged. (776, 323) -> b' Along' occured 2 times.\n",
      "3055/4744 pairs merged. (1500, 1353) -> b' connected' occured 2 times.\n",
      "3056/4744 pairs merged. (1948, 314) -> b' stimul' occured 2 times.\n",
      "3057/4744 pairs merged. (446, 959) -> b' kingdoms' occured 2 times.\n",
      "3058/4744 pairs merged. (380, 121) -> b' bey' occured 2 times.\n",
      "3059/4744 pairs merged. (3058, 1110) -> b' beyond' occured 2 times.\n",
      "3060/4744 pairs merged. (69, 454) -> b'Emperor' occured 2 times.\n",
      "3061/4744 pairs merged. (269, 1257) -> b'atched' occured 2 times.\n",
      "3062/4744 pairs merged. (331, 529) -> b' Bai' occured 2 times.\n",
      "3063/4744 pairs merged. (121, 728) -> b'yue' occured 2 times.\n",
      "3064/4744 pairs merged. (738, 57) -> b'109' occured 2 times.\n",
      "3065/4744 pairs merged. (687, 263) -> b' exped' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|█████▉    | 2825/4744 [00:26<00:16, 119.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3066/4744 pairs merged. (929, 1889) -> b' assimil' occured 2 times.\n",
      "3067/4744 pairs merged. (3066, 333) -> b' assimilation' occured 2 times.\n",
      "3068/4744 pairs merged. (445, 583) -> b' contact' occured 2 times.\n",
      "3069/4744 pairs merged. (1219, 649) -> b' gradual' occured 2 times.\n",
      "3070/4744 pairs merged. (2363, 422) -> b' excessive' occured 2 times.\n",
      "3071/4744 pairs merged. (761, 409) -> b' acqu' occured 2 times.\n",
      "3072/4744 pairs merged. (3071, 294) -> b' acquis' occured 2 times.\n",
      "3073/4744 pairs merged. (3072, 1259) -> b' acquisitions' occured 2 times.\n",
      "3074/4744 pairs merged. (541, 601) -> b' consort' occured 2 times.\n",
      "3075/4744 pairs merged. (788, 626) -> b' clans' occured 2 times.\n",
      "3076/4744 pairs merged. (645, 725) -> b' strings' occured 2 times.\n",
      "3077/4744 pairs merged. (2251, 338) -> b' incompet' occured 2 times.\n",
      "3078/4744 pairs merged. (3077, 292) -> b' incompetent' occured 2 times.\n",
      "3079/4744 pairs merged. (2365, 112) -> b' usurp' occured 2 times.\n",
      "3080/4744 pairs merged. (3079, 333) -> b' usurpation' occured 2 times.\n",
      "3081/4744 pairs merged. (400, 1836) -> b' progr' occured 2 times.\n",
      "3082/4744 pairs merged. (3081, 384) -> b' program' occured 2 times.\n",
      "3083/4744 pairs merged. (2367, 1548) -> b' slavery' occured 2 times.\n",
      "3084/4744 pairs merged. (874, 1254) -> b' supported' occured 2 times.\n",
      "3085/4744 pairs merged. (277, 264) -> b' inst' occured 2 times.\n",
      "3086/4744 pairs merged. (2307, 115) -> b' chaos' occured 2 times.\n",
      "3087/4744 pairs merged. (1792, 1087) -> b' displaced' occured 2 times.\n",
      "3088/4744 pairs merged. (807, 109) -> b' farm' occured 2 times.\n",
      "3089/4744 pairs merged. (3088, 393) -> b' farmers' occured 2 times.\n",
      "3090/4744 pairs merged. (433, 114) -> b' enr' occured 2 times.\n",
      "3091/4744 pairs merged. (1724, 488) -> b' merchant' occured 2 times.\n",
      "3092/4744 pairs merged. (1289, 263) -> b' termed' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 2851/4744 [00:26<00:16, 114.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3093/4744 pairs merged. (578, 294) -> b' decis' occured 2 times.\n",
      "3094/4744 pairs merged. (3093, 950) -> b' decisively' occured 2 times.\n",
      "3095/4744 pairs merged. (297, 502) -> b' Chao' occured 2 times.\n",
      "3096/4744 pairs merged. (342, 413) -> b' thus' occured 2 times.\n",
      "3097/4744 pairs merged. (291, 2209) -> b' emb' occured 2 times.\n",
      "3098/4744 pairs merged. (731, 97) -> b' sea' occured 2 times.\n",
      "3099/4744 pairs merged. (1964, 101) -> b' route' occured 2 times.\n",
      "3100/4744 pairs merged. (50, 1634) -> b'280' occured 2 times.\n",
      "3101/4744 pairs merged. (66, 121) -> b'By' occured 2 times.\n",
      "3102/4744 pairs merged. (1144, 1967) -> b' amidst' occured 2 times.\n",
      "3103/4744 pairs merged. (974, 490) -> b' feud' occured 2 times.\n",
      "3104/4744 pairs merged. (291, 334) -> b' eun' occured 2 times.\n",
      "3105/4744 pairs merged. (3104, 918) -> b' eunuch' occured 2 times.\n",
      "3106/4744 pairs merged. (3105, 115) -> b' eunuchs' occured 2 times.\n",
      "3107/4744 pairs merged. (2386, 1122) -> b' broke' occured 2 times.\n",
      "3108/4744 pairs merged. (835, 257) -> b' ushe' occured 2 times.\n",
      "3109/4744 pairs merged. (3108, 880) -> b' ushering' occured 2 times.\n",
      "3110/4744 pairs merged. (433, 1700) -> b' ensu' occured 2 times.\n",
      "3111/4744 pairs merged. (3110, 278) -> b' ensuing' occured 2 times.\n",
      "3112/4744 pairs merged. (1508, 1930) -> b' reunify' occured 2 times.\n",
      "3113/4744 pairs merged. (325, 1032) -> b' giving' occured 2 times.\n",
      "3114/4744 pairs merged. (1661, 677) -> b' novel' occured 2 times.\n",
      "3115/4744 pairs merged. (775, 115) -> b' events' occured 2 times.\n",
      "3116/4744 pairs merged. (289, 502) -> b' Cao' occured 2 times.\n",
      "3117/4744 pairs merged. (50, 2188) -> b'266' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 2877/4744 [00:27<00:15, 121.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3118/4744 pairs merged. (52, 557) -> b'420' occured 2 times.\n",
      "3119/4744 pairs merged. (45, 1563) -> b'-Han' occured 2 times.\n",
      "3120/4744 pairs merged. (881, 485) -> b' rebell' occured 2 times.\n",
      "3121/4744 pairs merged. (1317, 571) -> b'-day' occured 2 times.\n",
      "3122/4744 pairs merged. (52, 2392) -> b'439' occured 2 times.\n",
      "3123/4744 pairs merged. (451, 722) -> b' Qiang' occured 2 times.\n",
      "3124/4744 pairs merged. (380, 1979) -> b' before' occured 2 times.\n",
      "3125/4744 pairs merged. (415, 262) -> b' fron' occured 2 times.\n",
      "3126/4744 pairs merged. (3125, 116) -> b' front' occured 2 times.\n",
      "3127/4744 pairs merged. (3126, 1148) -> b' frontier' occured 2 times.\n",
      "3128/4744 pairs merged. (367, 411) -> b' rav' occured 2 times.\n",
      "3129/4744 pairs merged. (3128, 1358) -> b' ravaged' occured 2 times.\n",
      "3130/4744 pairs merged. (1049, 2357) -> b'-scal' occured 2 times.\n",
      "3131/4744 pairs merged. (3130, 101) -> b'-scale' occured 2 times.\n",
      "3132/4744 pairs merged. (1298, 57) -> b'589' occured 2 times.\n",
      "3133/4744 pairs merged. (118, 281) -> b'ves' occured 2 times.\n",
      "3134/4744 pairs merged. (289, 482) -> b' Chen' occured 2 times.\n",
      "3135/4744 pairs merged. (107, 311) -> b'kang' occured 2 times.\n",
      "3136/4744 pairs merged. (272, 102) -> b' off' occured 2 times.\n",
      "3137/4744 pairs merged. (1328, 360) -> b' attac' occured 2 times.\n",
      "3138/4744 pairs merged. (296, 108) -> b' tol' occured 2 times.\n",
      "3139/4744 pairs merged. (3138, 261) -> b' toler' occured 2 times.\n",
      "3140/4744 pairs merged. (484, 2373) -> b' Founded' occured 2 times.\n",
      "3141/4744 pairs merged. (1253, 290) -> b' succession' occured 2 times.\n",
      "3142/4744 pairs merged. (270, 292) -> b' went' occured 2 times.\n",
      "3143/4744 pairs merged. (1982, 553) -> b' institutions' occured 2 times.\n",
      "3144/4744 pairs merged. (455, 515) -> b' Dep' occured 2 times.\n",
      "3145/4744 pairs merged. (3144, 2404) -> b' Departments' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 2916/4744 [00:27<00:15, 117.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3146/4744 pairs merged. (2360, 752) -> b' Ministr' occured 2 times.\n",
      "3147/4744 pairs merged. (3146, 350) -> b' Ministries' occured 2 times.\n",
      "3148/4744 pairs merged. (1810, 2090) -> b' examinations' occured 2 times.\n",
      "3149/4744 pairs merged. (280, 358) -> b' sel' occured 2 times.\n",
      "3150/4744 pairs merged. (638, 115) -> b' systems' occured 2 times.\n",
      "3151/4744 pairs merged. (284, 1983) -> b' fub' occured 2 times.\n",
      "3152/4744 pairs merged. (3151, 278) -> b' fubing' occured 2 times.\n",
      "3153/4744 pairs merged. (1436, 1569) -> b'-field' occured 2 times.\n",
      "3154/4744 pairs merged. (1144, 1838) -> b' amassed' occured 2 times.\n",
      "3155/4744 pairs merged. (1984, 786) -> b' coinage' occured 2 times.\n",
      "3156/4744 pairs merged. (433, 567) -> b' enfor' occured 2 times.\n",
      "3157/4744 pairs merged. (3156, 664) -> b' enforced' occured 2 times.\n",
      "3158/4744 pairs merged. (544, 1346) -> b'construc' occured 2 times.\n",
      "3159/4744 pairs merged. (724, 510) -> b' ship' occured 2 times.\n",
      "3160/4744 pairs merged. (293, 2409) -> b' maneu' occured 2 times.\n",
      "3161/4744 pairs merged. (3160, 1986) -> b' maneuvers' occured 2 times.\n",
      "3162/4744 pairs merged. (399, 268) -> b' Pen' occured 2 times.\n",
      "3163/4744 pairs merged. (1490, 263) -> b' failed' occured 2 times.\n",
      "3164/4744 pairs merged. (401, 368) -> b' trig' occured 2 times.\n",
      "3165/4744 pairs merged. (3164, 103) -> b' trigg' occured 2 times.\n",
      "3166/4744 pairs merged. (1988, 412) -> b' revolts' occured 2 times.\n",
      "3167/4744 pairs merged. (1369, 418) -> b' prosperous' occured 2 times.\n",
      "3168/4744 pairs merged. (337, 1014) -> b' stable' occured 2 times.\n",
      "3169/4744 pairs merged. (1736, 2285) -> b' particularly' occured 2 times.\n",
      "3170/4744 pairs merged. (1971, 488) -> b' predominant' occured 2 times.\n",
      "3171/4744 pairs merged. (1279, 1087) -> b' placed' occured 2 times.\n",
      "3172/4744 pairs merged. (1737, 453) -> b' Taiz' occured 2 times.\n",
      "3173/4744 pairs merged. (436, 2416) -> b'ucrative' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 2943/4744 [00:27<00:14, 124.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3174/4744 pairs merged. (1964, 281) -> b' routes' occured 2 times.\n",
      "3175/4744 pairs merged. (865, 1878) -> b' countries' occured 2 times.\n",
      "3176/4744 pairs merged. (2391, 1248) -> b' settled' occured 2 times.\n",
      "3177/4744 pairs merged. (478, 374) -> b' adap' occured 2 times.\n",
      "3178/4744 pairs merged. (457, 528) -> b' Xuan' occured 2 times.\n",
      "3179/4744 pairs merged. (3178, 122) -> b' Xuanz' occured 2 times.\n",
      "3180/4744 pairs merged. (986, 335) -> b' Buddhist' occured 2 times.\n",
      "3181/4744 pairs merged. (1740, 485) -> b' travell' occured 2 times.\n",
      "3182/4744 pairs merged. (301, 1347) -> b' retur' occured 2 times.\n",
      "3183/4744 pairs merged. (2081, 97) -> b'ayana' occured 2 times.\n",
      "3184/4744 pairs merged. (84, 104) -> b'Th' occured 2 times.\n",
      "3185/4744 pairs merged. (301, 118) -> b' rev' occured 2 times.\n",
      "3186/4744 pairs merged. (763, 1698) -> b' implement' occured 2 times.\n",
      "3187/4744 pairs merged. (387, 112) -> b' dep' occured 2 times.\n",
      "3188/4744 pairs merged. (2427, 263) -> b' joined' occured 2 times.\n",
      "3189/4744 pairs merged. (1995, 1087) -> b' replaced' occured 2 times.\n",
      "3190/4744 pairs merged. (774, 987) -> b' setting' occured 2 times.\n",
      "3191/4744 pairs merged. (85, 110) -> b'Un' occured 2 times.\n",
      "3192/4744 pairs merged. (1948, 1612) -> b' stimulated' occured 2 times.\n",
      "3193/4744 pairs merged. (1181, 116) -> b' product' occured 2 times.\n",
      "3194/4744 pairs merged. (293, 349) -> b' mid' occured 2 times.\n",
      "3195/4744 pairs merged. (310, 1535) -> b' hands' occured 2 times.\n",
      "3196/4744 pairs merged. (462, 2146) -> b' vibr' occured 2 times.\n",
      "3197/4744 pairs merged. (3196, 488) -> b' vibrant' occured 2 times.\n",
      "3198/4744 pairs merged. (65, 116) -> b'At' occured 2 times.\n",
      "3199/4744 pairs merged. (270, 269) -> b' wat' occured 2 times.\n",
      "3200/4744 pairs merged. (543, 101) -> b' dise' occured 2 times.\n",
      "3201/4744 pairs merged. (3200, 1458) -> b' disease' occured 2 times.\n",
      "3202/4744 pairs merged. (1305, 789) -> b'ruption' occured 2 times.\n",
      "3203/4744 pairs merged. (2003, 375) -> b' devastated' occured 2 times.\n",
      "3204/4744 pairs merged. (2432, 262) -> b' Upon' occured 2 times.\n",
      "3205/4744 pairs merged. (2006, 2007) -> b' autonom' occured 2 times.\n",
      "3206/4744 pairs merged. (3205, 418) -> b' autonomous' occured 2 times.\n",
      "3207/4744 pairs merged. (111, 304) -> b'oly' occured 2 times.\n",
      "3208/4744 pairs merged. (369, 1349) -> b' Ext' occured 2 times.\n",
      "3209/4744 pairs merged. (679, 109) -> b' subm' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2968/4744 [00:27<00:15, 112.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3210/4744 pairs merged. (367, 97) -> b' ra' occured 2 times.\n",
      "3211/4744 pairs merged. (45, 2273) -> b'-of' occured 2 times.\n",
      "3212/4744 pairs merged. (3211, 2437) -> b'-officials' occured 2 times.\n",
      "3213/4744 pairs merged. (2008, 1358) -> b' engaged' occured 2 times.\n",
      "3214/4744 pairs merged. (290, 275) -> b'ional' occured 2 times.\n",
      "3215/4744 pairs merged. (269, 303) -> b'atast' occured 2 times.\n",
      "3216/4744 pairs merged. (3215, 1320) -> b'atastrop' occured 2 times.\n",
      "3217/4744 pairs merged. (901, 360) -> b' massac' occured 2 times.\n",
      "3218/4744 pairs merged. (277, 104) -> b' inh' occured 2 times.\n",
      "3219/4744 pairs merged. (3218, 431) -> b' inhab' occured 2 times.\n",
      "3220/4744 pairs merged. (3219, 273) -> b' inhabit' occured 2 times.\n",
      "3221/4744 pairs merged. (3220, 801) -> b' inhabitants' occured 2 times.\n",
      "3222/4744 pairs merged. (1728, 107) -> b' Turk' occured 2 times.\n",
      "3223/4744 pairs merged. (3222, 287) -> b' Turkic' occured 2 times.\n",
      "3224/4744 pairs merged. (848, 859) -> b' Consequent' occured 2 times.\n",
      "3225/4744 pairs merged. (3224, 304) -> b' Consequently' occured 2 times.\n",
      "3226/4744 pairs merged. (594, 703) -> b' Jinzh' occured 2 times.\n",
      "3227/4744 pairs merged. (3226, 323) -> b' Jinzhong' occured 2 times.\n",
      "3228/4744 pairs merged. (611, 295) -> b' chas' occured 2 times.\n",
      "3229/4744 pairs merged. (1151, 115) -> b' Uyghurs' occured 2 times.\n",
      "3230/4744 pairs merged. (1042, 785) -> b' served' occured 2 times.\n",
      "3231/4744 pairs merged. (2298, 278) -> b' fighting' occured 2 times.\n",
      "3232/4744 pairs merged. (446, 104) -> b' kh' occured 2 times.\n",
      "3233/4744 pairs merged. (3232, 1520) -> b' khaganate' occured 2 times.\n",
      "3234/4744 pairs merged. (1455, 120) -> b' Zhangx' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 2995/4744 [00:28<00:14, 119.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3235/4744 pairs merged. (3234, 258) -> b' Zhangxin' occured 2 times.\n",
      "3236/4744 pairs merged. (373, 287) -> b' suic' occured 2 times.\n",
      "3237/4744 pairs merged. (3236, 663) -> b' suicide' occured 2 times.\n",
      "3238/4744 pairs merged. (661, 2303) -> b' precip' occured 2 times.\n",
      "3239/4744 pairs merged. (3238, 273) -> b' precipit' occured 2 times.\n",
      "3240/4744 pairs merged. (401, 572) -> b' tried' occured 2 times.\n",
      "3241/4744 pairs merged. (1736, 510) -> b' particip' occured 2 times.\n",
      "3242/4744 pairs merged. (3241, 375) -> b' participated' occured 2 times.\n",
      "3243/4744 pairs merged. (272, 651) -> b' offic' occured 2 times.\n",
      "3244/4744 pairs merged. (299, 117) -> b' Tu' occured 2 times.\n",
      "3245/4744 pairs merged. (652, 361) -> b' Tangut' occured 2 times.\n",
      "3246/4744 pairs merged. (293, 648) -> b' mount' occured 2 times.\n",
      "3247/4744 pairs merged. (3246, 376) -> b' mountain' occured 2 times.\n",
      "3248/4744 pairs merged. (299, 268) -> b' Ten' occured 2 times.\n",
      "3249/4744 pairs merged. (1072, 263) -> b' lasted' occured 2 times.\n",
      "3250/4744 pairs merged. (45, 2397) -> b'-cent' occured 2 times.\n",
      "3251/4744 pairs merged. (3250, 654) -> b'-century' occured 2 times.\n",
      "3252/4744 pairs merged. (45, 264) -> b'-st' occured 2 times.\n",
      "3253/4744 pairs merged. (1711, 304) -> b' namely' occured 2 times.\n",
      "3254/4744 pairs merged. (76, 660) -> b'Later' occured 2 times.\n",
      "3255/4744 pairs merged. (1997, 304) -> b' rapidly' occured 2 times.\n",
      "3256/4744 pairs merged. (346, 109) -> b' Am' occured 2 times.\n",
      "3257/4744 pairs merged. (2015, 715) -> b' sinicized' occured 2 times.\n",
      "3258/4744 pairs merged. (84, 268) -> b'Ten' occured 2 times.\n",
      "3259/4744 pairs merged. (645, 390) -> b' strate' occured 2 times.\n",
      "3260/4744 pairs merged. (3259, 103) -> b' strateg' occured 2 times.\n",
      "3261/4744 pairs merged. (3260, 287) -> b' strategic' occured 2 times.\n",
      "3262/4744 pairs merged. (271, 1197) -> b' ceded' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 3021/4744 [00:28<00:14, 119.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3263/4744 pairs merged. (1267, 1808) -> b' Khitan' occured 2 times.\n",
      "3264/4744 pairs merged. (723, 2017) -> b' defense' occured 2 times.\n",
      "3265/4744 pairs merged. (724, 438) -> b' shif' occured 2 times.\n",
      "3266/4744 pairs merged. (397, 660) -> b' Later' occured 2 times.\n",
      "3267/4744 pairs merged. (2456, 375) -> b' annihilated' occured 2 times.\n",
      "3268/4744 pairs merged. (2457, 572) -> b' occupied' occured 2 times.\n",
      "3269/4744 pairs merged. (905, 307) -> b' Manchur' occured 2 times.\n",
      "3270/4744 pairs merged. (3269, 389) -> b' Manchuria' occured 2 times.\n",
      "3271/4744 pairs merged. (1331, 1927) -> b' provinces' occured 2 times.\n",
      "3272/4744 pairs merged. (738, 51) -> b'103' occured 2 times.\n",
      "3273/4744 pairs merged. (631, 50) -> b'122' occured 2 times.\n",
      "3274/4744 pairs merged. (271, 2024) -> b' caval' occured 2 times.\n",
      "3275/4744 pairs merged. (3274, 650) -> b' cavalry' occured 2 times.\n",
      "3276/4744 pairs merged. (2022, 1936) -> b' swept' occured 2 times.\n",
      "3277/4744 pairs merged. (760, 115) -> b' outs' occured 2 times.\n",
      "3278/4744 pairs merged. (3277, 107) -> b' outsk' occured 2 times.\n",
      "3279/4744 pairs merged. (3278, 382) -> b' outskir' occured 2 times.\n",
      "3280/4744 pairs merged. (2466, 278) -> b' forcing' occured 2 times.\n",
      "3281/4744 pairs merged. (763, 1748) -> b' imposed' occured 2 times.\n",
      "3282/4744 pairs merged. (395, 338) -> b' Yet' occured 2 times.\n",
      "3283/4744 pairs merged. (2374, 329) -> b' silver' occured 2 times.\n",
      "3284/4744 pairs merged. (288, 1495) -> b' back' occured 2 times.\n",
      "3285/4744 pairs merged. (2467, 115) -> b' goods' occured 2 times.\n",
      "3286/4744 pairs merged. (456, 292) -> b' incent' occured 2 times.\n",
      "3287/4744 pairs merged. (2015, 779) -> b' sinicization' occured 2 times.\n",
      "3288/4744 pairs merged. (687, 2017) -> b' expense' occured 2 times.\n",
      "3289/4744 pairs merged. (293, 871) -> b' might' occured 2 times.\n",
      "3290/4744 pairs merged. (300, 438) -> b' lif' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 3060/4744 [00:28<00:14, 116.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3291/4744 pairs merged. (2007, 417) -> b'onomical' occured 2 times.\n",
      "3292/4744 pairs merged. (268, 500) -> b'ences' occured 2 times.\n",
      "3293/4744 pairs merged. (750, 573) -> b' relations' occured 2 times.\n",
      "3294/4744 pairs merged. (2003, 940) -> b' devastating' occured 2 times.\n",
      "3295/4744 pairs merged. (99, 931) -> b'cident' occured 2 times.\n",
      "3296/4744 pairs merged. (300, 1032) -> b' living' occured 2 times.\n",
      "3297/4744 pairs merged. (1560, 115) -> b' standards' occured 2 times.\n",
      "3298/4744 pairs merged. (2471, 2472) -> b' tremend' occured 2 times.\n",
      "3299/4744 pairs merged. (282, 728) -> b' due' occured 2 times.\n",
      "3300/4744 pairs merged. (776, 1231) -> b' Although' occured 2 times.\n",
      "3301/4744 pairs merged. (777, 348) -> b' South' occured 2 times.\n",
      "3302/4744 pairs merged. (1574, 2362) -> b' equipped' occured 2 times.\n",
      "3303/4744 pairs merged. (45, 104) -> b'-h' occured 2 times.\n",
      "3304/4744 pairs merged. (761, 116) -> b' act' occured 2 times.\n",
      "3305/4744 pairs merged. (271, 257) -> b' che' occured 2 times.\n",
      "3306/4744 pairs merged. (2476, 806) -> b' innovative' occured 2 times.\n",
      "3307/4744 pairs merged. (306, 482) -> b' Shen' occured 2 times.\n",
      "3308/4744 pairs merged. (1549, 263) -> b' invented' occured 2 times.\n",
      "3309/4744 pairs merged. (823, 393) -> b' reformers' occured 2 times.\n",
      "3310/4744 pairs merged. (735, 2155) -> b' compiled' occured 2 times.\n",
      "3311/4744 pairs merged. (299, 323) -> b' Tong' occured 2 times.\n",
      "3312/4744 pairs merged. (106, 379) -> b'jian' occured 2 times.\n",
      "3313/4744 pairs merged. (2284, 1014) -> b' movable' occured 2 times.\n",
      "3314/4744 pairs merged. (1248, 434) -> b'ledge' occured 2 times.\n",
      "3315/4744 pairs merged. (289, 1043) -> b' Culture' occured 2 times.\n",
      "3316/4744 pairs merged. (461, 412) -> b' arts' occured 2 times.\n",
      "3317/4744 pairs merged. (361, 101) -> b'ute' occured 2 times.\n",
      "3318/4744 pairs merged. (334, 112) -> b'unp' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 3084/4744 [00:28<00:14, 115.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3319/4744 pairs merged. (3318, 322) -> b'unpow' occured 2 times.\n",
      "3320/4744 pairs merged. (3319, 460) -> b'unpowder' occured 2 times.\n",
      "3321/4744 pairs merged. (109, 115) -> b'ms' occured 2 times.\n",
      "3322/4744 pairs merged. (280, 709) -> b' sie' occured 2 times.\n",
      "3323/4744 pairs merged. (3322, 434) -> b' siege' occured 2 times.\n",
      "3324/4744 pairs merged. (1934, 600) -> b' guard' occured 2 times.\n",
      "3325/4744 pairs merged. (521, 321) -> b' head' occured 2 times.\n",
      "3326/4744 pairs merged. (271, 920) -> b' could' occured 2 times.\n",
      "3327/4744 pairs merged. (1667, 500) -> b' advances' occured 2 times.\n",
      "3328/4744 pairs merged. (294, 333) -> b'isation' occured 2 times.\n",
      "3329/4744 pairs merged. (1305, 116) -> b'rupt' occured 2 times.\n",
      "3330/4744 pairs merged. (979, 263) -> b' marked' occured 2 times.\n",
      "3331/4744 pairs merged. (1445, 887) -> b' additional' occured 2 times.\n",
      "3332/4744 pairs merged. (277, 257) -> b' inhe' occured 2 times.\n",
      "3333/4744 pairs merged. (1425, 1365) -> b' entirety' occured 2 times.\n",
      "3334/4744 pairs merged. (1628, 1477) -> b' minority' occured 2 times.\n",
      "3335/4744 pairs merged. (1152, 2444) -> b' Khanbali' occured 2 times.\n",
      "3336/4744 pairs merged. (3335, 113) -> b' Khanbaliq' occured 2 times.\n",
      "3337/4744 pairs merged. (545, 101) -> b'ote' occured 2 times.\n",
      "3338/4744 pairs merged. (939, 48) -> b'130' occured 2 times.\n",
      "3339/4744 pairs merged. (882, 257) -> b' uphe' occured 2 times.\n",
      "3340/4744 pairs merged. (1923, 275) -> b' nominal' occured 2 times.\n",
      "3341/4744 pairs merged. (283, 819) -> b' post' occured 2 times.\n",
      "3342/4744 pairs merged. (1588, 412) -> b' ports' occured 2 times.\n",
      "3343/4744 pairs merged. (399, 305) -> b' Pol' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 3109/4744 [00:29<00:13, 118.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3344/4744 pairs merged. (2482, 1524) -> b' inspired' occured 2 times.\n",
      "3345/4744 pairs merged. (293, 263) -> b' med' occured 2 times.\n",
      "3346/4744 pairs merged. (582, 108) -> b' spl' occured 2 times.\n",
      "3347/4744 pairs merged. (3346, 534) -> b' splend' occured 2 times.\n",
      "3348/4744 pairs merged. (287, 416) -> b'icted' occured 2 times.\n",
      "3349/4744 pairs merged. (2487, 2441) -> b' substantially' occured 2 times.\n",
      "3350/4744 pairs merged. (300, 816) -> b' less' occured 2 times.\n",
      "3351/4744 pairs merged. (619, 110) -> b' On' occured 2 times.\n",
      "3352/4744 pairs merged. (468, 304) -> b'ibly' occured 2 times.\n",
      "3353/4744 pairs merged. (1088, 705) -> b' variet' occured 2 times.\n",
      "3354/4744 pairs merged. (3353, 121) -> b' variety' occured 2 times.\n",
      "3355/4744 pairs merged. (586, 119) -> b' underw' occured 2 times.\n",
      "3356/4744 pairs merged. (3355, 292) -> b' underwent' occured 2 times.\n",
      "3357/4744 pairs merged. (397, 285) -> b' Lar' occured 2 times.\n",
      "3358/4744 pairs merged. (3357, 434) -> b' Large' occured 2 times.\n",
      "3359/4744 pairs merged. (1621, 667) -> b' elements' occured 2 times.\n",
      "3360/4744 pairs merged. (1682, 1326) -> b' intellectuals' occured 2 times.\n",
      "3361/4744 pairs merged. (314, 285) -> b'ular' occured 2 times.\n",
      "3362/4744 pairs merged. (683, 285) -> b' popular' occured 2 times.\n",
      "3363/4744 pairs merged. (271, 803) -> b' cens' occured 2 times.\n",
      "3364/4744 pairs merged. (3363, 413) -> b' census' occured 2 times.\n",
      "3365/4744 pairs merged. (2490, 285) -> b' necessar' occured 2 times.\n",
      "3366/4744 pairs merged. (3365, 1131) -> b' necessarily' occured 2 times.\n",
      "3367/4744 pairs merged. (461, 103) -> b' arg' occured 2 times.\n",
      "3368/4744 pairs merged. (3367, 728) -> b' argue' occured 2 times.\n",
      "3369/4744 pairs merged. (1144, 323) -> b' among' occured 2 times.\n",
      "3370/4744 pairs merged. (683, 1960) -> b' populace' occured 2 times.\n",
      "3371/4744 pairs merged. (1357, 278) -> b' causing' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 3134/4744 [00:29<00:13, 121.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3372/4744 pairs merged. (276, 1459) -> b'organ' occured 2 times.\n",
      "3373/4744 pairs merged. (1279, 2491) -> b' plague' occured 2 times.\n",
      "3374/4744 pairs merged. (291, 112) -> b' ep' occured 2 times.\n",
      "3375/4744 pairs merged. (3374, 349) -> b' epid' occured 2 times.\n",
      "3376/4744 pairs merged. (3375, 476) -> b' epidem' occured 2 times.\n",
      "3377/4744 pairs merged. (3376, 1782) -> b' epidemics' occured 2 times.\n",
      "3378/4744 pairs merged. (607, 353) -> b' estim' occured 2 times.\n",
      "3379/4744 pairs merged. (3378, 375) -> b' estimated' occured 2 times.\n",
      "3380/4744 pairs merged. (2492, 471) -> b' quarter' occured 2 times.\n",
      "3381/4744 pairs merged. (841, 304) -> b' mainly' occured 2 times.\n",
      "3382/4744 pairs merged. (657, 2494) -> b' Yuanzhang' occured 2 times.\n",
      "3383/4744 pairs merged. (373, 264) -> b' sust' occured 2 times.\n",
      "3384/4744 pairs merged. (3383, 772) -> b' sustained' occured 2 times.\n",
      "3385/4744 pairs merged. (1306, 264) -> b' indust' occured 2 times.\n",
      "3386/4744 pairs merged. (3385, 650) -> b' industry' occured 2 times.\n",
      "3387/4744 pairs merged. (1366, 115) -> b' markets' occured 2 times.\n",
      "3388/4744 pairs merged. (293, 259) -> b' man' occured 2 times.\n",
      "3389/4744 pairs merged. (1448, 360) -> b' charac' occured 2 times.\n",
      "3390/4744 pairs merged. (3389, 471) -> b' character' occured 2 times.\n",
      "3391/4744 pairs merged. (3390, 1531) -> b' characteristic' occured 2 times.\n",
      "3392/4744 pairs merged. (486, 305) -> b' isol' occured 2 times.\n",
      "3393/4744 pairs merged. (760, 1620) -> b' outside' occured 2 times.\n",
      "3394/4744 pairs merged. (462, 1183) -> b' voy' occured 2 times.\n",
      "3395/4744 pairs merged. (3394, 1869) -> b' voyages' occured 2 times.\n",
      "3396/4744 pairs merged. (525, 368) -> b' orig' occured 2 times.\n",
      "3397/4744 pairs merged. (3396, 258) -> b' origin' occured 2 times.\n",
      "3398/4744 pairs merged. (98, 1861) -> b'bidd' occured 2 times.\n",
      "3399/4744 pairs merged. (3398, 268) -> b'bidden' occured 2 times.\n",
      "3400/4744 pairs merged. (1797, 115) -> b' laws' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 3161/4744 [00:29<00:12, 121.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3401/4744 pairs merged. (283, 426) -> b' pover' occured 2 times.\n",
      "3402/4744 pairs merged. (3401, 1365) -> b' poverty' occured 2 times.\n",
      "3403/4744 pairs merged. (2480, 107) -> b'work' occured 2 times.\n",
      "3404/4744 pairs merged. (287, 412) -> b'icts' occured 2 times.\n",
      "3405/4744 pairs merged. (669, 276) -> b' repor' occured 2 times.\n",
      "3406/4744 pairs merged. (3405, 412) -> b' reports' occured 2 times.\n",
      "3407/4744 pairs merged. (360, 278) -> b'acing' occured 2 times.\n",
      "3408/4744 pairs merged. (256, 1695) -> b' tons' occured 2 times.\n",
      "3409/4744 pairs merged. (345, 338) -> b'leet' occured 2 times.\n",
      "3410/4744 pairs merged. (280, 2495) -> b' sailed' occured 2 times.\n",
      "3411/4744 pairs merged. (731, 295) -> b' seas' occured 2 times.\n",
      "3412/4744 pairs merged. (455, 1221) -> b' Domest' occured 2 times.\n",
      "3413/4744 pairs merged. (1637, 287) -> b' domestic' occured 2 times.\n",
      "3414/4744 pairs merged. (619, 329) -> b' Over' occured 2 times.\n",
      "3415/4744 pairs merged. (1345, 116) -> b' current' occured 2 times.\n",
      "3416/4744 pairs merged. (291, 273) -> b' eit' occured 2 times.\n",
      "3417/4744 pairs merged. (3416, 988) -> b' either' occured 2 times.\n",
      "3418/4744 pairs merged. (108, 285) -> b'lar' occured 2 times.\n",
      "3419/4744 pairs merged. (103, 263) -> b'ged' occured 2 times.\n",
      "3420/4744 pairs merged. (104, 468) -> b'hib' occured 2 times.\n",
      "3421/4744 pairs merged. (288, 259) -> b' ban' occured 2 times.\n",
      "3422/4744 pairs merged. (294, 1209) -> b'iscover' occured 2 times.\n",
      "3423/4744 pairs merged. (669, 101) -> b' repe' occured 2 times.\n",
      "3424/4744 pairs merged. (3423, 375) -> b' repeated' occured 2 times.\n",
      "3425/4744 pairs merged. (3424, 304) -> b' repeatedly' occured 2 times.\n",
      "3426/4744 pairs merged. (1060, 50) -> b'152' occured 2 times.\n",
      "3427/4744 pairs merged. (270, 1237) -> b' wok' occured 2 times.\n",
      "3428/4744 pairs merged. (3427, 286) -> b' wokou' occured 2 times.\n",
      "3429/4744 pairs merged. (108, 1127) -> b'line' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 3187/4744 [00:29<00:13, 115.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3430/4744 pairs merged. (1447, 700) -> b' Jiajing' occured 2 times.\n",
      "3431/4744 pairs merged. (2014, 115) -> b' raids' occured 2 times.\n",
      "3432/4744 pairs merged. (399, 1035) -> b' Phil' occured 2 times.\n",
      "3433/4744 pairs merged. (3432, 510) -> b' Philip' occured 2 times.\n",
      "3434/4744 pairs merged. (3433, 112) -> b' Philipp' occured 2 times.\n",
      "3435/4744 pairs merged. (3434, 2483) -> b' Philippines' occured 2 times.\n",
      "3436/4744 pairs merged. (1060, 53) -> b'155' occured 2 times.\n",
      "3437/4744 pairs merged. (763, 1254) -> b' imported' occured 2 times.\n",
      "3438/4744 pairs merged. (287, 259) -> b'ican' occured 2 times.\n",
      "3439/4744 pairs merged. (346, 547) -> b' Amer' occured 2 times.\n",
      "3440/4744 pairs merged. (593, 2510) -> b' resistance' occured 2 times.\n",
      "3441/4744 pairs merged. (486, 867) -> b' island' occured 2 times.\n",
      "3442/4744 pairs merged. (3441, 115) -> b' islands' occured 2 times.\n",
      "3443/4744 pairs merged. (680, 50) -> b'162' occured 2 times.\n",
      "3444/4744 pairs merged. (680, 51) -> b'163' occured 2 times.\n",
      "3445/4744 pairs merged. (2512, 263) -> b' surrendered' occured 2 times.\n",
      "3446/4744 pairs merged. (2449, 335) -> b' loyalist' occured 2 times.\n",
      "3447/4744 pairs merged. (420, 1255) -> b' Kox' occured 2 times.\n",
      "3448/4744 pairs merged. (3447, 278) -> b' Koxing' occured 2 times.\n",
      "3449/4744 pairs merged. (3448, 97) -> b' Koxinga' occured 2 times.\n",
      "3450/4744 pairs merged. (536, 348) -> b' earth' occured 2 times.\n",
      "3451/4744 pairs merged. (3450, 409) -> b' earthqu' occured 2 times.\n",
      "3452/4744 pairs merged. (3451, 1525) -> b' earthquake' occured 2 times.\n",
      "3453/4744 pairs merged. (387, 321) -> b' dead' occured 2 times.\n",
      "3454/4744 pairs merged. (1060, 57) -> b'159' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3214/4744 [00:30<00:12, 122.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3455/4744 pairs merged. (296, 1664) -> b' toll' occured 2 times.\n",
      "3456/4744 pairs merged. (407, 307) -> b' Nur' occured 2 times.\n",
      "3457/4744 pairs merged. (3456, 104) -> b' Nurh' occured 2 times.\n",
      "3458/4744 pairs merged. (3457, 360) -> b' Nurhac' occured 2 times.\n",
      "3459/4744 pairs merged. (3458, 105) -> b' Nurhaci' occured 2 times.\n",
      "3460/4744 pairs merged. (679, 100) -> b' subd' occured 2 times.\n",
      "3461/4744 pairs merged. (3460, 728) -> b' subdue' occured 2 times.\n",
      "3462/4744 pairs merged. (122, 482) -> b'zhen' occured 2 times.\n",
      "3463/4744 pairs merged. (400, 343) -> b' proce' occured 2 times.\n",
      "3464/4744 pairs merged. (3463, 1197) -> b' proceeded' occured 2 times.\n",
      "3465/4744 pairs merged. (1327, 495) -> b' transition' occured 2 times.\n",
      "3466/4744 pairs merged. (1129, 393) -> b' leaders' occured 2 times.\n",
      "3467/4744 pairs merged. (1884, 263) -> b' appeared' occured 2 times.\n",
      "3468/4744 pairs merged. (1153, 101) -> b' que' occured 2 times.\n",
      "3469/4744 pairs merged. (3468, 728) -> b' queue' occured 2 times.\n",
      "3470/4744 pairs merged. (270, 496) -> b' wear' occured 2 times.\n",
      "3471/4744 pairs merged. (2517, 278) -> b' clothing' occured 2 times.\n",
      "3472/4744 pairs merged. (2051, 1226) -> b'nermen' occured 2 times.\n",
      "3473/4744 pairs merged. (325, 2518) -> b' given' occured 2 times.\n",
      "3474/4744 pairs merged. (1400, 263) -> b' ordered' occured 2 times.\n",
      "3475/4744 pairs merged. (1200, 333) -> b' creation' occured 2 times.\n",
      "3476/4744 pairs merged. (287, 789) -> b'iction' occured 2 times.\n",
      "3477/4744 pairs merged. (3476, 448) -> b'ictionary' occured 2 times.\n",
      "3478/4744 pairs merged. (680, 56) -> b'168' occured 2 times.\n",
      "3479/4744 pairs merged. (1518, 263) -> b' suppressed' occured 2 times.\n",
      "3480/4744 pairs merged. (748, 793) -> b' Revol' occured 2 times.\n",
      "3481/4744 pairs merged. (3480, 116) -> b' Revolt' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3240/4744 [00:30<00:12, 119.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3482/4744 pairs merged. (282, 268) -> b' den' occured 2 times.\n",
      "3483/4744 pairs merged. (3482, 572) -> b' denied' occured 2 times.\n",
      "3484/4744 pairs merged. (420, 837) -> b' Kingdom' occured 2 times.\n",
      "3485/4744 pairs merged. (391, 413) -> b' Rus' occured 2 times.\n",
      "3486/4744 pairs merged. (3485, 115) -> b' Russ' occured 2 times.\n",
      "3487/4744 pairs merged. (484, 627) -> b' First' occured 2 times.\n",
      "3488/4744 pairs merged. (1262, 1208) -> b' Nanking' occured 2 times.\n",
      "3489/4744 pairs merged. (2524, 278) -> b' Taiping' occured 2 times.\n",
      "3490/4744 pairs merged. (425, 1527) -> b' movement' occured 2 times.\n",
      "3491/4744 pairs merged. (2529, 259) -> b' Guofan' occured 2 times.\n",
      "3492/4744 pairs merged. (1488, 422) -> b' effective' occured 2 times.\n",
      "3493/4744 pairs merged. (2533, 275) -> b'stitutional' occured 2 times.\n",
      "3494/4744 pairs merged. (935, 107) -> b' Shik' occured 2 times.\n",
      "3495/4744 pairs merged. (3494, 529) -> b' Shikai' occured 2 times.\n",
      "3496/4744 pairs merged. (571, 115) -> b'ays' occured 2 times.\n",
      "3497/4744 pairs merged. (455, 322) -> b' Dow' occured 2 times.\n",
      "3498/4744 pairs merged. (3497, 530) -> b' Dowag' occured 2 times.\n",
      "3499/4744 pairs merged. (3498, 261) -> b' Dowager' occured 2 times.\n",
      "3500/4744 pairs merged. (284, 496) -> b' fear' occured 2 times.\n",
      "3501/4744 pairs merged. (1153, 1646) -> b' quick' occured 2 times.\n",
      "3502/4744 pairs merged. (3501, 304) -> b' quickly' occured 2 times.\n",
      "3503/4744 pairs merged. (2055, 1748) -> b' opposed' occured 2 times.\n",
      "3504/4744 pairs merged. (2527, 1229) -> b' Christians' occured 2 times.\n",
      "3505/4744 pairs merged. (1761, 393) -> b' Boxers' occured 2 times.\n",
      "3506/4744 pairs merged. (466, 261) -> b' Ger' occured 2 times.\n",
      "3507/4744 pairs merged. (3506, 2058) -> b' German' occured 2 times.\n",
      "3508/4744 pairs merged. (367, 286) -> b' rou' occured 2 times.\n",
      "3509/4744 pairs merged. (3508, 416) -> b' routed' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 3280/4744 [00:30<00:12, 118.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3510/4744 pairs merged. (385, 583) -> b' exact' occured 2 times.\n",
      "3511/4744 pairs merged. (476, 110) -> b'emn' occured 2 times.\n",
      "3512/4744 pairs merged. (1982, 263) -> b' instituted' occured 2 times.\n",
      "3513/4744 pairs merged. (592, 305) -> b' abol' occured 2 times.\n",
      "3514/4744 pairs merged. (2354, 292) -> b' student' occured 2 times.\n",
      "3515/4744 pairs merged. (3514, 115) -> b' students' occured 2 times.\n",
      "3516/4744 pairs merged. (669, 746) -> b' republic' occured 2 times.\n",
      "3517/4744 pairs merged. (301, 1199) -> b' revolution' occured 2 times.\n",
      "3518/4744 pairs merged. (3517, 448) -> b' revolutionary' occured 2 times.\n",
      "3519/4744 pairs merged. (787, 1211) -> b' Wuchang' occured 2 times.\n",
      "3520/4744 pairs merged. (619, 1162) -> b' Oct' occured 2 times.\n",
      "3521/4744 pairs merged. (3520, 1414) -> b' Octob' occured 2 times.\n",
      "3522/4744 pairs merged. (3521, 261) -> b' October' occured 2 times.\n",
      "3523/4744 pairs merged. (787, 694) -> b' Wuhan' occured 2 times.\n",
      "3524/4744 pairs merged. (115, 910) -> b'since' occured 2 times.\n",
      "3525/4744 pairs merged. (399, 501) -> b' Pres' occured 2 times.\n",
      "3526/4744 pairs merged. (3525, 931) -> b' President' occured 2 times.\n",
      "3527/4744 pairs merged. (1725, 1714) -> b' turned' occured 2 times.\n",
      "3528/4744 pairs merged. (1331, 258) -> b' provin' occured 2 times.\n",
      "3529/4744 pairs merged. (3528, 1917) -> b' provincial' occured 2 times.\n",
      "3530/4744 pairs merged. (2225, 292) -> b' violent' occured 2 times.\n",
      "3531/4744 pairs merged. (1357, 281) -> b' causes' occured 2 times.\n",
      "3532/4744 pairs merged. (101, 281) -> b'ees' occured 2 times.\n",
      "3533/4744 pairs merged. (735, 338) -> b' compet' occured 2 times.\n",
      "3534/4744 pairs merged. (3533, 278) -> b' competing' occured 2 times.\n",
      "3535/4744 pairs merged. (1735, 1341) -> b' Intellect' occured 2 times.\n",
      "3536/4744 pairs merged. (3535, 1326) -> b' Intellectuals' occured 2 times.\n",
      "3537/4744 pairs merged. (1289, 115) -> b' terms' occured 2 times.\n",
      "3538/4744 pairs merged. (119, 663) -> b'wide' occured 2 times.\n",
      "3539/4744 pairs merged. (1319, 2045) -> b' protests' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|██████▉   | 3308/4744 [00:30<00:11, 119.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3540/4744 pairs merged. (301, 102) -> b' ref' occured 2 times.\n",
      "3541/4744 pairs merged. (3540, 413) -> b' refus' occured 2 times.\n",
      "3542/4744 pairs merged. (293, 335) -> b' mist' occured 2 times.\n",
      "3543/4744 pairs merged. (346, 1054) -> b' Acc' occured 2 times.\n",
      "3544/4744 pairs merged. (3543, 1449) -> b' According' occured 2 times.\n",
      "3545/4744 pairs merged. (2353, 114) -> b' patr' occured 2 times.\n",
      "3546/4744 pairs merged. (3545, 105) -> b' patri' occured 2 times.\n",
      "3547/4744 pairs merged. (325, 111) -> b' go' occured 2 times.\n",
      "3548/4744 pairs merged. (99, 298) -> b'com' occured 2 times.\n",
      "3549/4744 pairs merged. (108, 278) -> b'ling' occured 2 times.\n",
      "3550/4744 pairs merged. (67, 1021) -> b'CCP' occured 2 times.\n",
      "3551/4744 pairs merged. (195, 169) -> b'\\xc3\\xa9' occured 2 times.\n",
      "3552/4744 pairs merged. (45, 121) -> b'-y' occured 2 times.\n",
      "3553/4744 pairs merged. (3552, 496) -> b'-year' occured 2 times.\n",
      "3554/4744 pairs merged. (405, 73) -> b' II' occured 2 times.\n",
      "3555/4744 pairs merged. (256, 268) -> b' ten' occured 2 times.\n",
      "3556/4744 pairs merged. (111, 545) -> b'oot' occured 2 times.\n",
      "3557/4744 pairs merged. (455, 319) -> b' Dec' occured 2 times.\n",
      "3558/4744 pairs merged. (2061, 345) -> b' struggle' occured 2 times.\n",
      "3559/4744 pairs merged. (70, 2486) -> b'Following' occured 2 times.\n",
      "3560/4744 pairs merged. (1328, 981) -> b' attemp' occured 2 times.\n",
      "3561/4744 pairs merged. (354, 370) -> b' West' occured 2 times.\n",
      "3562/4744 pairs merged. (1868, 2400) -> b' carried' occured 2 times.\n",
      "3563/4744 pairs merged. (1408, 956) -> b' recognised' occured 2 times.\n",
      "3564/4744 pairs merged. (1832, 1316) -> b' legitimate' occured 2 times.\n",
      "3565/4744 pairs merged. (1760, 335) -> b' communist' occured 2 times.\n",
      "3566/4744 pairs merged. (116, 114) -> b'tr' occured 2 times.\n",
      "3567/4744 pairs merged. (543, 115) -> b' diss' occured 2 times.\n",
      "3568/4744 pairs merged. (271, 852) -> b' crac' occured 2 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3335/4744 [00:30<00:11, 126.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3569/4744 pairs merged. (3568, 2558) -> b' crackdown' occured 2 times.\n",
      "3570/4744 pairs merged. (1189, 2499) -> b' democratic' occured 2 times.\n",
      "3571/4744 pairs merged. (1007, 1353) -> b' elected' occured 2 times.\n",
      "3572/4744 pairs merged. (1007, 1688) -> b' election' occured 2 times.\n",
      "3573/4744 pairs merged. (1359, 101) -> b' See' occured 2 times.\n",
      "3574/4744 pairs merged. (283, 314) -> b' pul' occured 2 times.\n",
      "3575/4744 pairs merged. (1526, 263) -> b' resulted' occured 2 times.\n",
      "3576/4744 pairs merged. (425, 116) -> b' mot' occured 2 times.\n",
      "3577/4744 pairs merged. (3576, 1867) -> b' motivated' occured 2 times.\n",
      "3578/4744 pairs merged. (2531, 1528) -> b'-Soviet' occured 2 times.\n",
      "3579/4744 pairs merged. (282, 2368) -> b' distribution' occured 2 times.\n",
      "3580/4744 pairs merged. (330, 100) -> b' cond' occured 2 times.\n",
      "3581/4744 pairs merged. (762, 261) -> b' enter' occured 2 times.\n",
      "3582/4744 pairs merged. (259, 1226) -> b'anmen' occured 2 times.\n",
      "3583/4744 pairs merged. (409, 1340) -> b'quare' occured 2 times.\n",
      "3584/4744 pairs merged. (414, 722) -> b' Jiang' occured 2 times.\n",
      "3585/4744 pairs merged. (109, 1148) -> b'mier' occured 2 times.\n",
      "3586/4744 pairs merged. (367, 646) -> b' rural' occured 2 times.\n",
      "3587/4744 pairs merged. (1143, 772) -> b' detained' occured 2 times.\n",
      "3588/4744 pairs merged. (923, 115) -> b' camps' occured 2 times.\n",
      "3589/4744 pairs merged. (1143, 376) -> b' detain' occured 2 times.\n",
      "3590/4744 pairs merged. (121, 115) -> b'ys' occured 2 times.\n",
      "3591/4744 pairs merged. (592, 828) -> b' abuse' occured 2 times.\n",
      "3592/4744 pairs merged. (476, 287) -> b'emic' occured 2 times.\n",
      "3593/4744 pairs merged. (1143, 2347) -> b' detention' occured 2 times.\n",
      "3594/4744 pairs merged. (748, 1121) -> b' Refer' occured 2 times.\n",
      "3595/4744 pairs merged. (582, 626) -> b' spans' occured 1 times.\n",
      "3596/4744 pairs merged. (687, 427) -> b' experi' occured 1 times.\n",
      "3597/4744 pairs merged. (3596, 268) -> b' experien' occured 1 times.\n",
      "3598/4744 pairs merged. (3597, 664) -> b' experienced' occured 1 times.\n",
      "3599/4744 pairs merged. (2568, 381) -> b' fracture' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 3361/4744 [00:31<00:11, 118.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600/4744 pairs merged. (971, 258) -> b' basin' occured 1 times.\n",
      "3601/4744 pairs merged. (2570, 281) -> b' constitutes' occured 1 times.\n",
      "3602/4744 pairs merged. (1770, 287) -> b' geographic' occured 1 times.\n",
      "3603/4744 pairs merged. (841, 116) -> b' maint' occured 1 times.\n",
      "3604/4744 pairs merged. (3603, 1084) -> b' maintains' occured 1 times.\n",
      "3605/4744 pairs merged. (367, 406) -> b' rich' occured 1 times.\n",
      "3606/4744 pairs merged. (842, 393) -> b' divers' occured 1 times.\n",
      "3607/4744 pairs merged. (3606, 467) -> b' diversity' occured 1 times.\n",
      "3608/4744 pairs merged. (300, 2572) -> b' lingu' occured 1 times.\n",
      "3609/4744 pairs merged. (3608, 1531) -> b' linguistic' occured 1 times.\n",
      "3610/4744 pairs merged. (2574, 2575) -> b' viewing' occured 1 times.\n",
      "3611/4744 pairs merged. (271, 121) -> b' cy' occured 1 times.\n",
      "3612/4744 pairs merged. (3611, 99) -> b' cyc' occured 1 times.\n",
      "3613/4744 pairs merged. (3612, 345) -> b' cycle' occured 1 times.\n",
      "3614/4744 pairs merged. (327, 1533) -> b' ascribed' occured 1 times.\n",
      "3615/4744 pairs merged. (256, 534) -> b' tend' occured 1 times.\n",
      "3616/4744 pairs merged. (3615, 115) -> b' tends' occured 1 times.\n",
      "3617/4744 pairs merged. (2579, 101) -> b' assume' occured 1 times.\n",
      "3618/4744 pairs merged. (401, 1087) -> b' traced' occured 1 times.\n",
      "3619/4744 pairs merged. (423, 98) -> b' unb' occured 1 times.\n",
      "3620/4744 pairs merged. (3619, 332) -> b' unbro' occured 1 times.\n",
      "3621/4744 pairs merged. (3620, 107) -> b' unbrok' occured 1 times.\n",
      "3622/4744 pairs merged. (3621, 268) -> b' unbroken' occured 1 times.\n",
      "3623/4744 pairs merged. (342, 1029) -> b' thread' occured 1 times.\n",
      "3624/4744 pairs merged. (342, 418) -> b' thous' occured 1 times.\n",
      "3625/4744 pairs merged. (3624, 1535) -> b' thousands' occured 1 times.\n",
      "3626/4744 pairs merged. (283, 303) -> b' past' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████▏  | 3389/4744 [00:31<00:11, 119.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3627/4744 pairs merged. (293, 2073) -> b' making' occured 1 times.\n",
      "3628/4744 pairs merged. (1375, 321) -> b' crad' occured 1 times.\n",
      "3629/4744 pairs merged. (3628, 1376) -> b' cradles' occured 1 times.\n",
      "3630/4744 pairs merged. (2076, 806) -> b' representative' occured 1 times.\n",
      "3631/4744 pairs merged. (2581, 341) -> b' stretch' occured 1 times.\n",
      "3632/4744 pairs merged. (3631, 278) -> b' stretching' occured 1 times.\n",
      "3633/4744 pairs merged. (356, 2583) -> b' Himal' occured 1 times.\n",
      "3634/4744 pairs merged. (3633, 571) -> b' Himalay' occured 1 times.\n",
      "3635/4744 pairs merged. (3634, 295) -> b' Himalayas' occured 1 times.\n",
      "3636/4744 pairs merged. (306, 2081) -> b' Sayan' occured 1 times.\n",
      "3637/4744 pairs merged. (2584, 1084) -> b' Mountains' occured 1 times.\n",
      "3638/4744 pairs merged. (552, 273) -> b' polit' occured 1 times.\n",
      "3639/4744 pairs merged. (3638, 1782) -> b' politics' occured 1 times.\n",
      "3640/4744 pairs merged. (927, 434) -> b' emerge' occured 1 times.\n",
      "3641/4744 pairs merged. (2586, 393) -> b' rivers' occured 1 times.\n",
      "3642/4744 pairs merged. (1279, 1084) -> b' plains' occured 1 times.\n",
      "3643/4744 pairs merged. (114, 100) -> b'rd' occured 1 times.\n",
      "3644/4744 pairs merged. (541, 335) -> b' consist' occured 1 times.\n",
      "3645/4744 pairs merged. (3644, 278) -> b' consisting' occured 1 times.\n",
      "3646/4744 pairs merged. (842, 2090) -> b' divinations' occured 1 times.\n",
      "3647/4744 pairs merged. (1280, 1533) -> b' inscribed' occured 1 times.\n",
      "3648/4744 pairs merged. (2591, 649) -> b' ritual' occured 1 times.\n",
      "3649/4744 pairs merged. (282, 263) -> b' ded' occured 1 times.\n",
      "3650/4744 pairs merged. (3649, 1167) -> b' dedicated' occured 1 times.\n",
      "3651/4744 pairs merged. (1541, 112) -> b' corp' occured 1 times.\n",
      "3652/4744 pairs merged. (3651, 413) -> b' corpus' occured 1 times.\n",
      "3653/4744 pairs merged. (645, 269) -> b' strat' occured 1 times.\n",
      "3654/4744 pairs merged. (3653, 97) -> b' strata' occured 1 times.\n",
      "3655/4744 pairs merged. (2097, 319) -> b' speec' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3416/4744 [00:31<00:10, 121.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3656/4744 pairs merged. (3655, 2597) -> b' speeches' occured 1 times.\n",
      "3657/4744 pairs merged. (1092, 105) -> b' loci' occured 1 times.\n",
      "3658/4744 pairs merged. (1792, 571) -> b' display' occured 1 times.\n",
      "3659/4744 pairs merged. (2102, 1790) -> b'-mature' occured 1 times.\n",
      "3660/4744 pairs merged. (692, 1169) -> b' rememb' occured 1 times.\n",
      "3661/4744 pairs merged. (3660, 562) -> b' remembered' occured 1 times.\n",
      "3662/4744 pairs merged. (346, 120) -> b' Ax' occured 1 times.\n",
      "3663/4744 pairs merged. (3662, 372) -> b' Axial' occured 1 times.\n",
      "3664/4744 pairs merged. (564, 573) -> b' foundations' occured 1 times.\n",
      "3665/4744 pairs merged. (1556, 350) -> b' philosophies' occured 1 times.\n",
      "3666/4744 pairs merged. (2606, 348) -> b' Orth' occured 1 times.\n",
      "3667/4744 pairs merged. (3666, 1784) -> b' Orthography' occured 1 times.\n",
      "3668/4744 pairs merged. (429, 601) -> b' Short' occured 1 times.\n",
      "3669/4744 pairs merged. (3668, 304) -> b' Shortly' occured 1 times.\n",
      "3670/4744 pairs merged. (978, 97) -> b' therea' occured 1 times.\n",
      "3671/4744 pairs merged. (3670, 527) -> b' thereafter' occured 1 times.\n",
      "3672/4744 pairs merged. (271, 497) -> b' crit' occured 1 times.\n",
      "3673/4744 pairs merged. (3672, 417) -> b' critical' occured 1 times.\n",
      "3674/4744 pairs merged. (807, 344) -> b' farthe' occured 1 times.\n",
      "3675/4744 pairs merged. (3674, 264) -> b' farthest' occured 1 times.\n",
      "3676/4744 pairs merged. (1564, 115) -> b' extents' occured 1 times.\n",
      "3677/4744 pairs merged. (2613, 99) -> b' sanc' occured 1 times.\n",
      "3678/4744 pairs merged. (3677, 789) -> b' sanction' occured 1 times.\n",
      "3679/4744 pairs merged. (3678, 263) -> b' sanctioned' occured 1 times.\n",
      "3680/4744 pairs merged. (2614, 899) -> b' edited' occured 1 times.\n",
      "3681/4744 pairs merged. (895, 115) -> b' forms' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3444/4744 [00:31<00:10, 122.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3682/4744 pairs merged. (270, 1569) -> b' wield' occured 1 times.\n",
      "3683/4744 pairs merged. (267, 1041) -> b' aided' occured 1 times.\n",
      "3684/4744 pairs merged. (2620, 333) -> b' proliferation' occured 1 times.\n",
      "3685/4744 pairs merged. (282, 440) -> b' doc' occured 1 times.\n",
      "3686/4744 pairs merged. (3685, 117) -> b' docu' occured 1 times.\n",
      "3687/4744 pairs merged. (3686, 667) -> b' documents' occured 1 times.\n",
      "3688/4744 pairs merged. (1101, 108) -> b' empl' occured 1 times.\n",
      "3689/4744 pairs merged. (3688, 2621) -> b' employed' occured 1 times.\n",
      "3690/4744 pairs merged. (718, 2111) -> b' afterwards' occured 1 times.\n",
      "3691/4744 pairs merged. (1573, 333) -> b' internation' occured 1 times.\n",
      "3692/4744 pairs merged. (3691, 452) -> b' internationally' occured 1 times.\n",
      "3693/4744 pairs merged. (1042, 287) -> b' seric' occured 1 times.\n",
      "3694/4744 pairs merged. (3693, 1043) -> b' sericulture' occured 1 times.\n",
      "3695/4744 pairs merged. (2622, 2623) -> b' collapsed' occured 1 times.\n",
      "3696/4744 pairs merged. (1574, 452) -> b' equally' occured 1 times.\n",
      "3697/4744 pairs merged. (763, 583) -> b' impact' occured 1 times.\n",
      "3698/4744 pairs merged. (1803, 2628) -> b' calligraphy' occured 1 times.\n",
      "3699/4744 pairs merged. (337, 1575) -> b' story' occured 1 times.\n",
      "3700/4744 pairs merged. (3699, 116) -> b' storyt' occured 1 times.\n",
      "3701/4744 pairs merged. (3700, 485) -> b' storytell' occured 1 times.\n",
      "3702/4744 pairs merged. (3701, 278) -> b' storytelling' occured 1 times.\n",
      "3703/4744 pairs merged. (271, 2629) -> b' cases' occured 1 times.\n",
      "3704/4744 pairs merged. (1186, 56) -> b'608' occured 1 times.\n",
      "3705/4744 pairs merged. (2120, 278) -> b' flourishing' occured 1 times.\n",
      "3706/4744 pairs merged. (792, 115) -> b' economics' occured 1 times.\n",
      "3707/4744 pairs merged. (84, 311) -> b'Tang' occured 1 times.\n",
      "3708/4744 pairs merged. (1189, 1807) -> b' demony' occured 1 times.\n",
      "3709/4744 pairs merged. (3708, 109) -> b' demonym' occured 1 times.\n",
      "3710/4744 pairs merged. (2568, 307) -> b' fractur' occured 1 times.\n",
      "3711/4744 pairs merged. (3710, 263) -> b' fractured' occured 1 times.\n",
      "3712/4744 pairs merged. (293, 1191) -> b' max' occured 1 times.\n",
      "3713/4744 pairs merged. (3712, 2583) -> b' maximal' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 3484/4744 [00:32<00:10, 121.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3714/4744 pairs merged. (315, 2640) -> b' Mechanical' occured 1 times.\n",
      "3715/4744 pairs merged. (270, 2641) -> b' witness' occured 1 times.\n",
      "3716/4744 pairs merged. (3715, 281) -> b' witnesses' occured 1 times.\n",
      "3717/4744 pairs merged. (45, 2642) -> b'-block' occured 1 times.\n",
      "3718/4744 pairs merged. (1410, 412) -> b' prints' occured 1 times.\n",
      "3719/4744 pairs merged. (2130, 1192) -> b' ideological' occured 1 times.\n",
      "3720/4744 pairs merged. (587, 273) -> b' knit' occured 1 times.\n",
      "3721/4744 pairs merged. (69, 2652) -> b'Eventually' occured 1 times.\n",
      "3722/4744 pairs merged. (1106, 278) -> b' establishing' occured 1 times.\n",
      "3723/4744 pairs merged. (2653, 583) -> b' Contact' occured 1 times.\n",
      "3724/4744 pairs merged. (346, 2072) -> b' Achievements' occured 1 times.\n",
      "3725/4744 pairs merged. (2136, 2137) -> b' exploration' occured 1 times.\n",
      "3726/4744 pairs merged. (983, 101) -> b' fine' occured 1 times.\n",
      "3727/4744 pairs merged. (1814, 1815) -> b' restoring' occured 1 times.\n",
      "3728/4744 pairs merged. (2658, 565) -> b' Class' occured 1 times.\n",
      "3729/4744 pairs merged. (3728, 287) -> b' Classic' occured 1 times.\n",
      "3730/4744 pairs merged. (1418, 51) -> b'173' occured 1 times.\n",
      "3731/4744 pairs merged. (636, 2143) -> b' commission' occured 1 times.\n",
      "3732/4744 pairs merged. (3731, 263) -> b' commissioned' occured 1 times.\n",
      "3733/4744 pairs merged. (2666, 97) -> b' encyclopa' occured 1 times.\n",
      "3734/4744 pairs merged. (3733, 1819) -> b' encyclopaedia' occured 1 times.\n",
      "3735/4744 pairs merged. (300, 2146) -> b' libr' occured 1 times.\n",
      "3736/4744 pairs merged. (3735, 2667) -> b' libraries' occured 1 times.\n",
      "3737/4744 pairs merged. (2669, 278) -> b' totaling' occured 1 times.\n",
      "3738/4744 pairs merged. (288, 717) -> b' bill' occured 1 times.\n",
      "3739/4744 pairs merged. (3738, 290) -> b' billion' occured 1 times.\n",
      "3740/4744 pairs merged. (270, 526) -> b' word' occured 1 times.\n",
      "3741/4744 pairs merged. (3740, 115) -> b' words' occured 1 times.\n",
      "3742/4744 pairs merged. (2672, 1198) -> b' conflict' occured 1 times.\n",
      "3743/4744 pairs merged. (2674, 940) -> b' culminating' occured 1 times.\n",
      "3744/4744 pairs merged. (1822, 1823) -> b' Xinhai' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3511/4744 [00:32<00:09, 126.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3745/4744 pairs merged. (2678, 304) -> b' costly' occured 1 times.\n",
      "3746/4744 pairs merged. (1109, 2155) -> b' roiled' occured 1 times.\n",
      "3747/4744 pairs merged. (863, 259) -> b' Republican' occured 1 times.\n",
      "3748/4744 pairs merged. (45, 275) -> b'-al' occured 1 times.\n",
      "3749/4744 pairs merged. (3748, 2156) -> b'-aligned' occured 1 times.\n",
      "3750/4744 pairs merged. (2683, 715) -> b' industrialized' occured 1 times.\n",
      "3751/4744 pairs merged. (80, 794) -> b'PRC' occured 1 times.\n",
      "3752/4744 pairs merged. (2686, 278) -> b' retreating' occured 1 times.\n",
      "3753/4744 pairs merged. (331, 909) -> b' Both' occured 1 times.\n",
      "3754/4744 pairs merged. (520, 115) -> b' governments' occured 1 times.\n",
      "3755/4744 pairs merged. (2688, 2162) -> b' legitimacy' occured 1 times.\n",
      "3756/4744 pairs merged. (1308, 463) -> b' accum' occured 1 times.\n",
      "3757/4744 pairs merged. (3756, 1612) -> b' accumulated' occured 1 times.\n",
      "3758/4744 pairs merged. (1408, 495) -> b' recognition' occured 1 times.\n",
      "3759/4744 pairs merged. (2691, 263) -> b' disputed' occured 1 times.\n",
      "3760/4744 pairs merged. (282, 571) -> b' day' occured 1 times.\n",
      "3761/4744 pairs merged. (284, 303) -> b' fast' occured 1 times.\n",
      "3762/4744 pairs merged. (3761, 370) -> b' fastest' occured 1 times.\n",
      "3763/4744 pairs merged. (45, 1836) -> b'-gr' occured 1 times.\n",
      "3764/4744 pairs merged. (3763, 322) -> b'-grow' occured 1 times.\n",
      "3765/4744 pairs merged. (3764, 278) -> b'-growing' occured 1 times.\n",
      "3766/4744 pairs merged. (423, 853) -> b' unific' occured 1 times.\n",
      "3767/4744 pairs merged. (3766, 333) -> b' unification' occured 1 times.\n",
      "3768/4744 pairs merged. (846, 112) -> b' surp' occured 1 times.\n",
      "3769/4744 pairs merged. (3768, 1838) -> b' surpassed' occured 1 times.\n",
      "3770/4744 pairs merged. (2166, 104) -> b' Preh' occured 1 times.\n",
      "3771/4744 pairs merged. (3770, 2700) -> b' Prehistory' occured 1 times.\n",
      "3772/4744 pairs merged. (446, 97) -> b' ka' occured 1 times.\n",
      "3773/4744 pairs merged. (1434, 287) -> b' archaic' occured 1 times.\n",
      "3774/4744 pairs merged. (1435, 350) -> b' species' occured 1 times.\n",
      "3775/4744 pairs merged. (1413, 295) -> b' Euras' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▍  | 3538/4744 [00:32<00:10, 119.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3776/4744 pairs merged. (3775, 389) -> b' Eurasia' occured 1 times.\n",
      "3777/4744 pairs merged. (1783, 608) -> b' sometime' occured 1 times.\n",
      "3778/4744 pairs merged. (77, 97) -> b'Ma' occured 1 times.\n",
      "3779/4744 pairs merged. (2702, 112) -> b' subsp' occured 1 times.\n",
      "3780/4744 pairs merged. (3779, 319) -> b' subspec' occured 1 times.\n",
      "3781/4744 pairs merged. (3780, 350) -> b' subspecies' occured 1 times.\n",
      "3782/4744 pairs merged. (266, 474) -> b' old' occured 1 times.\n",
      "3783/4744 pairs merged. (3782, 370) -> b' oldest' occured 1 times.\n",
      "3784/4744 pairs merged. (691, 2170) -> b' southwestern' occured 1 times.\n",
      "3785/4744 pairs merged. (657, 109) -> b' Yuanm' occured 1 times.\n",
      "3786/4744 pairs merged. (3785, 286) -> b' Yuanmou' occured 1 times.\n",
      "3787/4744 pairs merged. (229, 133) -> b'\\xe5\\x85' occured 1 times.\n",
      "3788/4744 pairs merged. (3787, 131) -> b'\\xe5\\x85\\x83' occured 1 times.\n",
      "3789/4744 pairs merged. (3788, 232) -> b'\\xe5\\x85\\x83\\xe8' occured 1 times.\n",
      "3790/4744 pairs merged. (3789, 176) -> b'\\xe5\\x85\\x83\\xe8\\xb0' occured 1 times.\n",
      "3791/4744 pairs merged. (3790, 139) -> b'\\xe5\\x85\\x83\\xe8\\xb0\\x8b' occured 1 times.\n",
      "3792/4744 pairs merged. (3791, 2703) -> b'\\xe5\\x85\\x83\\xe8\\xb0\\x8b\\xe4\\xba\\xba' occured 1 times.\n",
      "3793/4744 pairs merged. (395, 334) -> b' Yun' occured 1 times.\n",
      "3794/4744 pairs merged. (3793, 110) -> b' Yunn' occured 1 times.\n",
      "3795/4744 pairs merged. (3794, 259) -> b' Yunnan' occured 1 times.\n",
      "3796/4744 pairs merged. (288, 413) -> b' bus' occured 1 times.\n",
      "3797/4744 pairs merged. (3796, 104) -> b' bush' occured 1 times.\n",
      "3798/4744 pairs merged. (3797, 867) -> b' bushland' occured 1 times.\n",
      "3799/4744 pairs merged. (1436, 548) -> b'-fore' occured 1 times.\n",
      "3800/4744 pairs merged. (3799, 264) -> b'-forest' occured 1 times.\n",
      "3801/4744 pairs merged. (611, 275) -> b' chal' occured 1 times.\n",
      "3802/4744 pairs merged. (3801, 287) -> b' chalic' occured 1 times.\n",
      "3803/4744 pairs merged. (3802, 111) -> b' chalico' occured 1 times.\n",
      "3804/4744 pairs merged. (3803, 344) -> b' chalicothe' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3566/4744 [00:32<00:09, 126.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3805/4744 pairs merged. (3804, 501) -> b' chalicotheres' occured 1 times.\n",
      "3806/4744 pairs merged. (387, 261) -> b' deer' occured 1 times.\n",
      "3807/4744 pairs merged. (1621, 112) -> b' elep' occured 1 times.\n",
      "3808/4744 pairs merged. (3807, 104) -> b' eleph' occured 1 times.\n",
      "3809/4744 pairs merged. (3808, 488) -> b' elephant' occured 1 times.\n",
      "3810/4744 pairs merged. (367, 1172) -> b' rhin' occured 1 times.\n",
      "3811/4744 pairs merged. (3810, 599) -> b' rhinos' occured 1 times.\n",
      "3812/4744 pairs merged. (283, 2709) -> b' pigs' occured 1 times.\n",
      "3813/4744 pairs merged. (1436, 1087) -> b'-faced' occured 1 times.\n",
      "3814/4744 pairs merged. (45, 2177) -> b'-known' occured 1 times.\n",
      "3815/4744 pairs merged. (1609, 1208) -> b' Peking' occured 1 times.\n",
      "3816/4744 pairs merged. (229, 140) -> b'\\xe5\\x8c' occured 1 times.\n",
      "3817/4744 pairs merged. (3816, 151) -> b'\\xe5\\x8c\\x97' occured 1 times.\n",
      "3818/4744 pairs merged. (3817, 1845) -> b'\\xe5\\x8c\\x97\\xe4\\xba' occured 1 times.\n",
      "3819/4744 pairs merged. (3818, 172) -> b'\\xe5\\x8c\\x97\\xe4\\xba\\xac' occured 1 times.\n",
      "3820/4744 pairs merged. (3819, 231) -> b'\\xe5\\x8c\\x97\\xe4\\xba\\xac\\xe7' occured 1 times.\n",
      "3821/4744 pairs merged. (3820, 140) -> b'\\xe5\\x8c\\x97\\xe4\\xba\\xac\\xe7\\x8c' occured 1 times.\n",
      "3822/4744 pairs merged. (3821, 191) -> b'\\xe5\\x8c\\x97\\xe4\\xba\\xac\\xe7\\x8c\\xbf' occured 1 times.\n",
      "3823/4744 pairs merged. (3822, 2703) -> b'\\xe5\\x8c\\x97\\xe4\\xba\\xac\\xe7\\x8c\\xbf\\xe4\\xba\\xba' occured 1 times.\n",
      "3824/4744 pairs merged. (52, 437) -> b'400' occured 1 times.\n",
      "3825/4744 pairs merged. (618, 107) -> b' Zhouk' occured 1 times.\n",
      "3826/4744 pairs merged. (3825, 286) -> b' Zhoukou' occured 1 times.\n",
      "3827/4744 pairs merged. (3826, 100) -> b' Zhoukoud' occured 1 times.\n",
      "3828/4744 pairs merged. (3827, 379) -> b' Zhoukoudian' occured 1 times.\n",
      "3829/4744 pairs merged. (271, 585) -> b' cave' occured 1 times.\n",
      "3830/4744 pairs merged. (280, 804) -> b' scr' occured 1 times.\n",
      "3831/4744 pairs merged. (3830, 374) -> b' scrap' occured 1 times.\n",
      "3832/4744 pairs merged. (3831, 393) -> b' scrapers' occured 1 times.\n",
      "3833/4744 pairs merged. (611, 362) -> b' chop' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 3594/4744 [00:33<00:09, 126.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3834/4744 pairs merged. (3833, 112) -> b' chopp' occured 1 times.\n",
      "3835/4744 pairs merged. (3834, 393) -> b' choppers' occured 1 times.\n",
      "3836/4744 pairs merged. (1611, 871) -> b' slight' occured 1 times.\n",
      "3837/4744 pairs merged. (3836, 304) -> b' slightly' occured 1 times.\n",
      "3838/4744 pairs merged. (2715, 412) -> b' points' occured 1 times.\n",
      "3839/4744 pairs merged. (1848, 1849) -> b' burins' occured 1 times.\n",
      "3840/4744 pairs merged. (267, 119) -> b' aw' occured 1 times.\n",
      "3841/4744 pairs merged. (3840, 2716) -> b' awls' occured 1 times.\n",
      "3842/4744 pairs merged. (2718, 115) -> b' fossils' occured 1 times.\n",
      "3843/4744 pairs merged. (890, 2170) -> b' northwestern' occured 1 times.\n",
      "3844/4744 pairs merged. (397, 488) -> b' Lant' occured 1 times.\n",
      "3845/4744 pairs merged. (3844, 379) -> b' Lantian' occured 1 times.\n",
      "3846/4744 pairs merged. (1435, 353) -> b' specim' occured 1 times.\n",
      "3847/4744 pairs merged. (3846, 803) -> b' specimens' occured 1 times.\n",
      "3848/4744 pairs merged. (293, 2724) -> b' magn' occured 1 times.\n",
      "3849/4744 pairs merged. (3848, 338) -> b' magnet' occured 1 times.\n",
      "3850/4744 pairs merged. (3849, 111) -> b' magneto' occured 1 times.\n",
      "3851/4744 pairs merged. (3850, 749) -> b' magnetostr' occured 1 times.\n",
      "3852/4744 pairs merged. (3851, 269) -> b' magnetostrat' occured 1 times.\n",
      "3853/4744 pairs merged. (3852, 2628) -> b' magnetostratigraphy' occured 1 times.\n",
      "3854/4744 pairs merged. (2725, 674) -> b' Majuang' occured 1 times.\n",
      "3855/4744 pairs merged. (3854, 286) -> b' Majuangou' occured 1 times.\n",
      "3856/4744 pairs merged. (397, 259) -> b' Lan' occured 1 times.\n",
      "3857/4744 pairs merged. (3856, 1853) -> b' Lanpo' occured 1 times.\n",
      "3858/4744 pairs merged. (736, 111) -> b' Xiao' occured 1 times.\n",
      "3859/4744 pairs merged. (3858, 1211) -> b' Xiaochang' occured 1 times.\n",
      "3860/4744 pairs merged. (3859, 670) -> b' Xiaochangli' occured 1 times.\n",
      "3861/4744 pairs merged. (3860, 311) -> b' Xiaochangliang' occured 1 times.\n",
      "3862/4744 pairs merged. (1212, 116) -> b' Xiant' occured 1 times.\n",
      "3863/4744 pairs merged. (3862, 529) -> b' Xiantai' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▋  | 3622/4744 [00:33<00:09, 117.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3864/4744 pairs merged. (331, 626) -> b' Bans' occured 1 times.\n",
      "3865/4744 pairs merged. (3864, 694) -> b' Banshan' occured 1 times.\n",
      "3866/4744 pairs merged. (51, 50) -> b'32' occured 1 times.\n",
      "3867/4744 pairs merged. (2727, 308) -> b' Feil' occured 1 times.\n",
      "3868/4744 pairs merged. (3867, 722) -> b' Feiliang' occured 1 times.\n",
      "3869/4744 pairs merged. (455, 323) -> b' Dong' occured 1 times.\n",
      "3870/4744 pairs merged. (3869, 103) -> b' Dongg' occured 1 times.\n",
      "3871/4744 pairs merged. (3870, 361) -> b' Donggut' occured 1 times.\n",
      "3872/4744 pairs merged. (3871, 702) -> b' Donggutuo' occured 1 times.\n",
      "3873/4744 pairs merged. (1216, 104) -> b' Xih' occured 1 times.\n",
      "3874/4744 pairs merged. (3873, 286) -> b' Xihou' occured 1 times.\n",
      "3875/4744 pairs merged. (3874, 1854) -> b' Xihoudu' occured 1 times.\n",
      "3876/4744 pairs merged. (429, 1440) -> b' Shanxi' occured 1 times.\n",
      "3877/4744 pairs merged. (271, 382) -> b' cir' occured 1 times.\n",
      "3878/4744 pairs merged. (3877, 99) -> b' circ' occured 1 times.\n",
      "3879/4744 pairs merged. (3878, 463) -> b' circum' occured 1 times.\n",
      "3880/4744 pairs merged. (3879, 264) -> b' circumst' occured 1 times.\n",
      "3881/4744 pairs merged. (3880, 259) -> b' circumstan' occured 1 times.\n",
      "3882/4744 pairs merged. (3881, 500) -> b' circumstances' occured 1 times.\n",
      "3883/4744 pairs merged. (291, 1199) -> b' evolution' occured 1 times.\n",
      "3884/4744 pairs merged. (280, 374) -> b' sap' occured 1 times.\n",
      "3885/4744 pairs merged. (3884, 105) -> b' sapi' occured 1 times.\n",
      "3886/4744 pairs merged. (3885, 803) -> b' sapiens' occured 1 times.\n",
      "3887/4744 pairs merged. (79, 361) -> b'Out' occured 1 times.\n",
      "3888/4744 pairs merged. (260, 1575) -> b' theory' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3647/4744 [00:33<00:09, 114.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3889/4744 pairs merged. (79, 2736) -> b'OOA' occured 1 times.\n",
      "3890/4744 pairs merged. (914, 467) -> b' continuity' occured 1 times.\n",
      "3891/4744 pairs merged. (293, 378) -> b' mod' occured 1 times.\n",
      "3892/4744 pairs merged. (3891, 358) -> b' model' occured 1 times.\n",
      "3893/4744 pairs merged. (2195, 699) -> b' admix' occured 1 times.\n",
      "3894/4744 pairs merged. (3893, 1193) -> b' admixture' occured 1 times.\n",
      "3895/4744 pairs merged. (1088, 1622) -> b' variant' occured 1 times.\n",
      "3896/4744 pairs merged. (619, 2736) -> b' OOA' occured 1 times.\n",
      "3897/4744 pairs merged. (748, 103) -> b' Reg' occured 1 times.\n",
      "3898/4744 pairs merged. (3897, 600) -> b' Regard' occured 1 times.\n",
      "3899/4744 pairs merged. (3898, 1633) -> b' Regardless' occured 1 times.\n",
      "3900/4744 pairs merged. (2718, 715) -> b' fossilized' occured 1 times.\n",
      "3901/4744 pairs merged. (256, 101) -> b' te' occured 1 times.\n",
      "3902/4744 pairs merged. (3901, 338) -> b' teet' occured 1 times.\n",
      "3903/4744 pairs merged. (3902, 104) -> b' teeth' occured 1 times.\n",
      "3904/4744 pairs merged. (2197, 121) -> b' Fuy' occured 1 times.\n",
      "3905/4744 pairs merged. (3904, 259) -> b' Fuyan' occured 1 times.\n",
      "3906/4744 pairs merged. (455, 502) -> b' Dao' occured 1 times.\n",
      "3907/4744 pairs merged. (289, 648) -> b' Count' occured 1 times.\n",
      "3908/4744 pairs merged. (3907, 121) -> b' County' occured 1 times.\n",
      "3909/4744 pairs merged. (356, 334) -> b' Hun' occured 1 times.\n",
      "3910/4744 pairs merged. (3909, 259) -> b' Hunan' occured 1 times.\n",
      "3911/4744 pairs merged. (673, 2744) -> b' extinct' occured 1 times.\n",
      "3912/4744 pairs merged. (346, 308) -> b' Ail' occured 1 times.\n",
      "3913/4744 pairs merged. (3912, 307) -> b' Ailur' occured 1 times.\n",
      "3914/4744 pairs merged. (3913, 362) -> b' Ailurop' occured 1 times.\n",
      "3915/4744 pairs merged. (3914, 378) -> b' Ailuropod' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 3675/4744 [00:33<00:08, 123.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3916/4744 pairs merged. (3915, 97) -> b' Ailuropoda' occured 1 times.\n",
      "3917/4744 pairs merged. (288, 360) -> b' bac' occured 1 times.\n",
      "3918/4744 pairs merged. (3917, 262) -> b' bacon' occured 1 times.\n",
      "3919/4744 pairs merged. (3918, 105) -> b' baconi' occured 1 times.\n",
      "3920/4744 pairs merged. (2745, 97) -> b' panda' occured 1 times.\n",
      "3921/4744 pairs merged. (289, 1858) -> b' Croc' occured 1 times.\n",
      "3922/4744 pairs merged. (3921, 361) -> b' Crocut' occured 1 times.\n",
      "3923/4744 pairs merged. (3922, 97) -> b' Crocuta' occured 1 times.\n",
      "3924/4744 pairs merged. (1859, 1860) -> b' ultima' occured 1 times.\n",
      "3925/4744 pairs merged. (256, 374) -> b' tap' occured 1 times.\n",
      "3926/4744 pairs merged. (3925, 382) -> b' tapir' occured 1 times.\n",
      "3927/4744 pairs merged. (315, 2746) -> b' Middle' occured 1 times.\n",
      "3928/4744 pairs merged. (1839, 97) -> b' Pala' occured 1 times.\n",
      "3929/4744 pairs merged. (3928, 2167) -> b' Palaeolithic' occured 1 times.\n",
      "3930/4744 pairs merged. (1862, 118) -> b' Lev' occured 1 times.\n",
      "3931/4744 pairs merged. (3930, 514) -> b' Levall' occured 1 times.\n",
      "3932/4744 pairs merged. (3931, 111) -> b' Levallo' occured 1 times.\n",
      "3933/4744 pairs merged. (3932, 294) -> b' Levallois' occured 1 times.\n",
      "3934/4744 pairs merged. (300, 930) -> b' lithic' occured 1 times.\n",
      "3935/4744 pairs merged. (2199, 786) -> b' assemblage' occured 1 times.\n",
      "3936/4744 pairs merged. (466, 528) -> b' Guan' occured 1 times.\n",
      "3937/4744 pairs merged. (3936, 121) -> b' Guany' occured 1 times.\n",
      "3938/4744 pairs merged. (3937, 1315) -> b' Guanyind' occured 1 times.\n",
      "3939/4744 pairs merged. (3938, 323) -> b' Guanyindong' occured 1 times.\n",
      "3940/4744 pairs merged. (691, 2747) -> b' southwest' occured 1 times.\n",
      "3941/4744 pairs merged. (1418, 48) -> b'170' occured 1 times.\n",
      "3942/4744 pairs merged. (712, 334) -> b' begun' occured 1 times.\n",
      "3943/4744 pairs merged. (331, 319) -> b' Bec' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 3703/4744 [00:33<00:08, 125.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3944/4744 pairs merged. (3943, 1864) -> b' Because' occured 1 times.\n",
      "3945/4744 pairs merged. (330, 2751) -> b' convention' occured 1 times.\n",
      "3946/4744 pairs merged. (3945, 452) -> b' conventionally' occured 1 times.\n",
      "3947/4744 pairs merged. (723, 1442) -> b' defined' occured 1 times.\n",
      "3948/4744 pairs merged. (1002, 512) -> b' presence' occured 1 times.\n",
      "3949/4744 pairs merged. (949, 115) -> b' follows' occured 1 times.\n",
      "3950/4744 pairs merged. (346, 103) -> b' Ag' occured 1 times.\n",
      "3951/4744 pairs merged. (3950, 830) -> b' Agric' occured 1 times.\n",
      "3952/4744 pairs merged. (3951, 1043) -> b' Agriculture' occured 1 times.\n",
      "3953/4744 pairs merged. (1637, 1866) -> b' domestication' occured 1 times.\n",
      "3954/4744 pairs merged. (687, 2757) -> b' expanding' occured 1 times.\n",
      "3955/4744 pairs merged. (1868, 98) -> b' carb' occured 1 times.\n",
      "3956/4744 pairs merged. (3955, 262) -> b' carbon' occured 1 times.\n",
      "3957/4744 pairs merged. (615, 338) -> b' millet' occured 1 times.\n",
      "3958/4744 pairs merged. (2762, 105) -> b' radi' occured 1 times.\n",
      "3959/4744 pairs merged. (3958, 440) -> b' radioc' occured 1 times.\n",
      "3960/4744 pairs merged. (3959, 2202) -> b' radiocarb' occured 1 times.\n",
      "3961/4744 pairs merged. (3960, 262) -> b' radiocarbon' occured 1 times.\n",
      "3962/4744 pairs merged. (462, 717) -> b' vill' occured 1 times.\n",
      "3963/4744 pairs merged. (3962, 1869) -> b' villages' occured 1 times.\n",
      "3964/4744 pairs merged. (1418, 50) -> b'172' occured 1 times.\n",
      "3965/4744 pairs merged. (788, 438) -> b' clif' occured 1 times.\n",
      "3966/4744 pairs merged. (3965, 102) -> b' cliff' occured 1 times.\n",
      "3967/4744 pairs merged. (1868, 118) -> b' carv' occured 1 times.\n",
      "3968/4744 pairs merged. (3967, 725) -> b' carvings' occured 1 times.\n",
      "3969/4744 pairs merged. (2773, 269) -> b'feat' occured 1 times.\n",
      "3970/4744 pairs merged. (3969, 458) -> b'featuring' occured 1 times.\n",
      "3971/4744 pairs merged. (52, 53) -> b'45' occured 1 times.\n",
      "3972/4744 pairs merged. (3971, 51) -> b'453' occured 1 times.\n",
      "3973/4744 pairs merged. (2207, 649) -> b' individual' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 3745/4744 [00:34<00:08, 124.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3974/4744 pairs merged. (280, 334) -> b' sun' occured 1 times.\n",
      "3975/4744 pairs merged. (425, 262) -> b' moon' occured 1 times.\n",
      "3976/4744 pairs merged. (2774, 115) -> b' stars' occured 1 times.\n",
      "3977/4744 pairs merged. (2777, 268) -> b' scen' occured 1 times.\n",
      "3978/4744 pairs merged. (3977, 281) -> b' scenes' occured 1 times.\n",
      "3979/4744 pairs merged. (310, 334) -> b' hun' occured 1 times.\n",
      "3980/4744 pairs merged. (3979, 987) -> b' hunting' occured 1 times.\n",
      "3981/4744 pairs merged. (508, 2778) -> b' graz' occured 1 times.\n",
      "3982/4744 pairs merged. (3981, 278) -> b' grazing' occured 1 times.\n",
      "3983/4744 pairs merged. (301, 377) -> b' rese' occured 1 times.\n",
      "3984/4744 pairs merged. (3983, 2779) -> b' researc' occured 1 times.\n",
      "3985/4744 pairs merged. (3984, 988) -> b' researcher' occured 1 times.\n",
      "3986/4744 pairs merged. (457, 722) -> b' Xiang' occured 1 times.\n",
      "3987/4744 pairs merged. (3986, 2780) -> b' Xiangshi' occured 1 times.\n",
      "3988/4744 pairs merged. (354, 497) -> b' Writ' occured 1 times.\n",
      "3989/4744 pairs merged. (3988, 893) -> b' Written' occured 1 times.\n",
      "3990/4744 pairs merged. (621, 2209) -> b' symb' occured 1 times.\n",
      "3991/4744 pairs merged. (3990, 2210) -> b' symbols' occured 1 times.\n",
      "3992/4744 pairs merged. (1319, 111) -> b' proto' occured 1 times.\n",
      "3993/4744 pairs merged. (2781, 2782) -> b'-writing' occured 1 times.\n",
      "3994/4744 pairs merged. (2783, 105) -> b' Dadi' occured 1 times.\n",
      "3995/4744 pairs merged. (3994, 908) -> b' Dadiwan' occured 1 times.\n",
      "3996/4744 pairs merged. (53, 2784) -> b'540' occured 1 times.\n",
      "3997/4744 pairs merged. (1873, 1853) -> b' Banpo' occured 1 times.\n",
      "3998/4744 pairs merged. (337, 548) -> b' store' occured 1 times.\n",
      "3999/4744 pairs merged. (1641, 1642) -> b' redistribut' occured 1 times.\n",
      "4000/4744 pairs merged. (3999, 101) -> b' redistribute' occured 1 times.\n",
      "4001/4744 pairs merged. (2213, 335) -> b' specialist' occured 1 times.\n",
      "4002/4744 pairs merged. (1375, 97) -> b' cra' occured 1 times.\n",
      "4003/4744 pairs merged. (4002, 102) -> b' craf' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 3771/4744 [00:34<00:07, 126.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4004/4744 pairs merged. (4003, 412) -> b' crafts' occured 1 times.\n",
      "4005/4744 pairs merged. (4004, 1226) -> b' craftsmen' occured 1 times.\n",
      "4006/4744 pairs merged. (1004, 269) -> b' administrat' occured 1 times.\n",
      "4007/4744 pairs merged. (4006, 812) -> b' administrators' occured 1 times.\n",
      "4008/4744 pairs merged. (1557, 115) -> b' Taos' occured 1 times.\n",
      "4009/4744 pairs merged. (4008, 105) -> b' Taosi' occured 1 times.\n",
      "4010/4744 pairs merged. (1644, 703) -> b' Liangzh' occured 1 times.\n",
      "4011/4744 pairs merged. (4010, 117) -> b' Liangzhu' occured 1 times.\n",
      "4012/4744 pairs merged. (293, 2746) -> b' middle' occured 1 times.\n",
      "4013/4744 pairs merged. (886, 1318) -> b' Yangsh' occured 1 times.\n",
      "4014/4744 pairs merged. (4013, 502) -> b' Yangshao' occured 1 times.\n",
      "4015/4744 pairs merged. (2217, 2790) -> b' Longshan' occured 1 times.\n",
      "4016/4744 pairs merged. (399, 2709) -> b' Pigs' occured 1 times.\n",
      "4017/4744 pairs merged. (2791, 115) -> b' dogs' occured 1 times.\n",
      "4018/4744 pairs merged. (1317, 1221) -> b'-domest' occured 1 times.\n",
      "4019/4744 pairs merged. (4018, 1167) -> b'-domesticated' occured 1 times.\n",
      "4020/4744 pairs merged. (2793, 515) -> b' sheep' occured 1 times.\n",
      "4021/4744 pairs merged. (354, 257) -> b' Whe' occured 1 times.\n",
      "4022/4744 pairs merged. (4021, 269) -> b' Wheat' occured 1 times.\n",
      "4023/4744 pairs merged. (2154, 117) -> b' Fru' occured 1 times.\n",
      "4024/4744 pairs merged. (4023, 273) -> b' Fruit' occured 1 times.\n",
      "4025/4744 pairs merged. (549, 360) -> b' peac' occured 1 times.\n",
      "4026/4744 pairs merged. (4025, 2597) -> b' peaches' occured 1 times.\n",
      "4027/4744 pairs merged. (271, 988) -> b' cher' occured 1 times.\n",
      "4028/4744 pairs merged. (4027, 1878) -> b' cherries' occured 1 times.\n",
      "4029/4744 pairs merged. (525, 311) -> b' orang' occured 1 times.\n",
      "4030/4744 pairs merged. (4029, 281) -> b' oranges' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 3797/4744 [00:34<00:07, 127.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4031/4744 pairs merged. (611, 1646) -> b' chick' occured 1 times.\n",
      "4032/4744 pairs merged. (4031, 803) -> b' chickens' occured 1 times.\n",
      "4033/4744 pairs merged. (462, 934) -> b' veg' occured 1 times.\n",
      "4034/4744 pairs merged. (4033, 338) -> b' veget' occured 1 times.\n",
      "4035/4744 pairs merged. (4034, 622) -> b' vegetabl' occured 1 times.\n",
      "4036/4744 pairs merged. (4035, 281) -> b' vegetables' occured 1 times.\n",
      "4037/4744 pairs merged. (66, 1647) -> b'Bronze' occured 1 times.\n",
      "4038/4744 pairs merged. (2725, 389) -> b' Majia' occured 1 times.\n",
      "4039/4744 pairs merged. (4038, 121) -> b' Majiay' occured 1 times.\n",
      "4040/4744 pairs merged. (4039, 502) -> b' Majiayao' occured 1 times.\n",
      "4041/4744 pairs merged. (51, 738) -> b'310' occured 1 times.\n",
      "4042/4744 pairs merged. (50, 55) -> b'27' occured 1 times.\n",
      "4043/4744 pairs merged. (4042, 48) -> b'270' occured 1 times.\n",
      "4044/4744 pairs merged. (2076, 263) -> b' represented' occured 1 times.\n",
      "4045/4744 pairs merged. (397, 2218) -> b' Lower' occured 1 times.\n",
      "4046/4744 pairs merged. (736, 1648) -> b' Xiaji' occured 1 times.\n",
      "4047/4744 pairs merged. (4046, 321) -> b' Xiajiad' occured 1 times.\n",
      "4048/4744 pairs merged. (4047, 379) -> b' Xiajiadian' occured 1 times.\n",
      "4049/4744 pairs merged. (423, 2177) -> b' unknown' occured 1 times.\n",
      "4050/4744 pairs merged. (1317, 294) -> b'-dis' occured 1 times.\n",
      "4051/4744 pairs merged. (4050, 1438) -> b'-discovered' occured 1 times.\n",
      "4052/4744 pairs merged. (508, 2806) -> b' graves' occured 1 times.\n",
      "4053/4744 pairs merged. (315, 473) -> b' Mog' occured 1 times.\n",
      "4054/4744 pairs merged. (4053, 286) -> b' Mogou' occured 1 times.\n",
      "4055/4744 pairs merged. (301, 688) -> b' reve' occured 1 times.\n",
      "4056/4744 pairs merged. (4055, 275) -> b' reveal' occured 1 times.\n",
      "4057/4744 pairs merged. (4056, 263) -> b' revealed' occured 1 times.\n",
      "4058/4744 pairs merged. (2225, 512) -> b' violence' occured 1 times.\n",
      "4059/4744 pairs merged. (2226, 2807) -> b' Qijia' occured 1 times.\n",
      "4060/4744 pairs merged. (70, 2808) -> b'Ferr' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 3823/4744 [00:34<00:07, 120.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4061/4744 pairs merged. (4060, 418) -> b'Ferrous' occured 1 times.\n",
      "4062/4744 pairs merged. (1653, 514) -> b' metall' occured 1 times.\n",
      "4063/4744 pairs merged. (4062, 2227) -> b' metallurg' occured 1 times.\n",
      "4064/4744 pairs merged. (4063, 121) -> b' metallurgy' occured 1 times.\n",
      "4065/4744 pairs merged. (1538, 115) -> b' begins' occured 1 times.\n",
      "4066/4744 pairs merged. (310, 269) -> b' hat' occured 1 times.\n",
      "4067/4744 pairs merged. (4066, 99) -> b' hatc' occured 1 times.\n",
      "4068/4744 pairs merged. (4067, 257) -> b' hatche' occured 1 times.\n",
      "4069/4744 pairs merged. (4068, 116) -> b' hatchet' occured 1 times.\n",
      "4070/4744 pairs merged. (1452, 917) -> b' blade' occured 1 times.\n",
      "4071/4744 pairs merged. (1653, 101) -> b' mete' occured 1 times.\n",
      "4072/4744 pairs merged. (4071, 276) -> b' meteor' occured 1 times.\n",
      "4073/4744 pairs merged. (4072, 287) -> b' meteoric' occured 1 times.\n",
      "4074/4744 pairs merged. (466, 97) -> b' Ga' occured 1 times.\n",
      "4075/4744 pairs merged. (4074, 440) -> b' Gaoc' occured 1 times.\n",
      "4076/4744 pairs merged. (4075, 876) -> b' Gaocheng' occured 1 times.\n",
      "4077/4744 pairs merged. (935, 2807) -> b' Shijia' occured 1 times.\n",
      "4078/4744 pairs merged. (4077, 2810) -> b' Shijiazhuang' occured 1 times.\n",
      "4079/4744 pairs merged. (976, 1323) -> b' Hebei' occured 1 times.\n",
      "4080/4744 pairs merged. (405, 916) -> b' Iron' occured 1 times.\n",
      "4081/4744 pairs merged. (2813, 390) -> b' Plate' occured 1 times.\n",
      "4082/4744 pairs merged. (4081, 1654) -> b' Plateau' occured 1 times.\n",
      "4083/4744 pairs merged. (256, 292) -> b' tent' occured 1 times.\n",
      "4084/4744 pairs merged. (4083, 2229) -> b' tentatively' occured 1 times.\n",
      "4085/4744 pairs merged. (464, 2231) -> b' Zhung' occured 1 times.\n",
      "4086/4744 pairs merged. (810, 725) -> b' writings' occured 1 times.\n",
      "4087/4744 pairs merged. (798, 1098) -> b' Ancient' occured 1 times.\n",
      "4088/4744 pairs merged. (1394, 347) -> b'Chinese' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 3850/4744 [00:35<00:07, 122.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4089/4744 pairs merged. (1308, 2815) -> b' accustom' occured 1 times.\n",
      "4090/4744 pairs merged. (4089, 263) -> b' accustomed' occured 1 times.\n",
      "4091/4744 pairs merged. (877, 290) -> b' notion' occured 1 times.\n",
      "4092/4744 pairs merged. (1851, 117) -> b' situ' occured 1 times.\n",
      "4093/4744 pairs merged. (4092, 333) -> b' situation' occured 1 times.\n",
      "4094/4744 pairs merged. (1596, 1167) -> b' complicated' occured 1 times.\n",
      "4095/4744 pairs merged. (356, 512) -> b' Hence' occured 1 times.\n",
      "4096/4744 pairs merged. (762, 773) -> b' entities' occured 1 times.\n",
      "4097/4744 pairs merged. (2824, 115) -> b' bears' occured 1 times.\n",
      "4098/4744 pairs merged. (280, 2825) -> b' similar' occured 1 times.\n",
      "4099/4744 pairs merged. (4098, 773) -> b' similarities' occured 1 times.\n",
      "4100/4744 pairs merged. (1571, 1457) -> b' contemporaneously' occured 1 times.\n",
      "4101/4744 pairs merged. (945, 452) -> b' legally' occured 1 times.\n",
      "4102/4744 pairs merged. (386, 343) -> b' once' occured 1 times.\n",
      "4103/4744 pairs merged. (280, 786) -> b' sage' occured 1 times.\n",
      "4104/4744 pairs merged. (2236, 454) -> b'-emperor' occured 1 times.\n",
      "4105/4744 pairs merged. (4104, 115) -> b'-emperors' occured 1 times.\n",
      "4106/4744 pairs merged. (628, 1569) -> b' yield' occured 1 times.\n",
      "4107/4744 pairs merged. (4106, 278) -> b' yielding' occured 1 times.\n",
      "4108/4744 pairs merged. (331, 2832) -> b' Bamboo' occured 1 times.\n",
      "4109/4744 pairs merged. (57, 49) -> b'91' occured 1 times.\n",
      "4110/4744 pairs merged. (919, 452) -> b' generally' occured 1 times.\n",
      "4111/4744 pairs merged. (2835, 417) -> b' mythical' occured 1 times.\n",
      "4112/4744 pairs merged. (419, 53) -> b'195' occured 1 times.\n",
      "4113/4744 pairs merged. (433, 489) -> b' enough' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 3876/4744 [00:35<00:07, 115.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4114/4744 pairs merged. (271, 1458) -> b' case' occured 1 times.\n",
      "4115/4744 pairs merged. (2846, 779) -> b' organization' occured 1 times.\n",
      "4116/4744 pairs merged. (2251, 269) -> b' incompat' occured 1 times.\n",
      "4117/4744 pairs merged. (4116, 468) -> b' incompatib' occured 1 times.\n",
      "4118/4744 pairs merged. (4117, 345) -> b' incompatible' occured 1 times.\n",
      "4119/4744 pairs merged. (1883, 115) -> b' legends' occured 1 times.\n",
      "4120/4744 pairs merged. (2847, 304) -> b' importantly' occured 1 times.\n",
      "4121/4744 pairs merged. (330, 847) -> b' conduc' occured 1 times.\n",
      "4122/4744 pairs merged. (4121, 416) -> b' conducted' occured 1 times.\n",
      "4123/4744 pairs merged. (2591, 1326) -> b' rituals' occured 1 times.\n",
      "4124/4744 pairs merged. (271, 303) -> b' cast' occured 1 times.\n",
      "4125/4744 pairs merged. (66, 909) -> b'Both' occured 1 times.\n",
      "4126/4744 pairs merged. (1789, 122) -> b' bronz' occured 1 times.\n",
      "4127/4744 pairs merged. (4126, 281) -> b' bronzes' occured 1 times.\n",
      "4128/4744 pairs merged. (1327, 109) -> b' transm' occured 1 times.\n",
      "4129/4744 pairs merged. (4128, 1663) -> b' transmitted' occured 1 times.\n",
      "4130/4744 pairs merged. (1328, 370) -> b' attest' occured 1 times.\n",
      "4131/4744 pairs merged. (450, 101) -> b' come' occured 1 times.\n",
      "4132/4744 pairs merged. (1886, 573) -> b' excavations' occured 1 times.\n",
      "4133/4744 pairs merged. (1165, 108) -> b' Erl' occured 1 times.\n",
      "4134/4744 pairs merged. (4133, 368) -> b' Erlig' occured 1 times.\n",
      "4135/4744 pairs merged. (4134, 311) -> b' Erligang' occured 1 times.\n",
      "4136/4744 pairs merged. (1462, 1008) -> b' Zhengzhou' occured 1 times.\n",
      "4137/4744 pairs merged. (2257, 2853) -> b' Yinxu' occured 1 times.\n",
      "4138/4744 pairs merged. (738, 53) -> b'105' occured 1 times.\n",
      "4139/4744 pairs merged. (2793, 1664) -> b' shell' occured 1 times.\n",
      "4140/4744 pairs merged. (4139, 115) -> b' shells' occured 1 times.\n",
      "4141/4744 pairs merged. (1330, 344) -> b'\\xe2\\x80\\x94the' occured 1 times.\n",
      "4142/4744 pairs merged. (1230, 292) -> b' twent' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 3903/4744 [00:35<00:06, 122.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4143/4744 pairs merged. (4142, 121) -> b' twenty' occured 1 times.\n",
      "4144/4744 pairs merged. (45, 110) -> b'-n' occured 1 times.\n",
      "4145/4744 pairs merged. (4144, 1127) -> b'-nine' occured 1 times.\n",
      "4146/4744 pairs merged. (2858, 701) -> b' Throughout' occured 1 times.\n",
      "4147/4744 pairs merged. (1187, 115) -> b' reigns' occured 1 times.\n",
      "4148/4744 pairs merged. (280, 316) -> b' syn' occured 1 times.\n",
      "4149/4744 pairs merged. (4148, 1807) -> b' synony' occured 1 times.\n",
      "4150/4744 pairs merged. (4149, 1464) -> b' synonymous' occured 1 times.\n",
      "4151/4744 pairs merged. (915, 304) -> b' lately' occured 1 times.\n",
      "4152/4744 pairs merged. (1435, 438) -> b' specif' occured 1 times.\n",
      "4153/4744 pairs merged. (4152, 1062) -> b' specifically' occured 1 times.\n",
      "4154/4744 pairs merged. (300, 2861) -> b' latter' occured 1 times.\n",
      "4155/4744 pairs merged. (2864, 382) -> b' confir' occured 1 times.\n",
      "4156/4744 pairs merged. (4155, 109) -> b' confirm' occured 1 times.\n",
      "4157/4744 pairs merged. (521, 115) -> b' hes' occured 1 times.\n",
      "4158/4744 pairs merged. (4157, 273) -> b' hesit' occured 1 times.\n",
      "4159/4744 pairs merged. (4158, 488) -> b' hesitant' occured 1 times.\n",
      "4160/4744 pairs merged. (2230, 105) -> b' associ' occured 1 times.\n",
      "4161/4744 pairs merged. (4160, 390) -> b' associate' occured 1 times.\n",
      "4162/4744 pairs merged. (1100, 675) -> b' technolog' occured 1 times.\n",
      "4163/4744 pairs merged. (4162, 1062) -> b' technologically' occured 1 times.\n",
      "4164/4744 pairs merged. (423, 670) -> b' unli' occured 1 times.\n",
      "4165/4744 pairs merged. (4164, 1122) -> b' unlike' occured 1 times.\n",
      "4166/4744 pairs merged. (456, 262) -> b' incon' occured 1 times.\n",
      "4167/4744 pairs merged. (4166, 1818) -> b' inconcl' occured 1 times.\n",
      "4168/4744 pairs merged. (4167, 413) -> b' inconclus' occured 1 times.\n",
      "4169/4744 pairs merged. (4168, 422) -> b' inconclusive' occured 1 times.\n",
      "4170/4744 pairs merged. (1331, 278) -> b' proving' occured 1 times.\n",
      "4171/4744 pairs merged. (2264, 109) -> b' realm' occured 1 times.\n",
      "4172/4744 pairs merged. (282, 707) -> b' diver' occured 1 times.\n",
      "4173/4744 pairs merged. (4172, 377) -> b' diverse' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 3947/4744 [00:35<00:06, 130.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4174/4744 pairs merged. (1656, 872) -> b' referred' occured 1 times.\n",
      "4175/4744 pairs merged. (1184, 370) -> b' longest' occured 1 times.\n",
      "4176/4744 pairs merged. (1185, 303) -> b'-last' occured 1 times.\n",
      "4177/4744 pairs merged. (4176, 278) -> b'-lasting' occured 1 times.\n",
      "4178/4744 pairs merged. (337, 2870) -> b' stead' occured 1 times.\n",
      "4179/4744 pairs merged. (4178, 1131) -> b' steadily' occured 1 times.\n",
      "4180/4744 pairs merged. (267, 332) -> b' aro' occured 1 times.\n",
      "4181/4744 pairs merged. (4180, 377) -> b' arose' occured 1 times.\n",
      "4182/4744 pairs merged. (1119, 2269) -> b' appointed' occured 1 times.\n",
      "4183/4744 pairs merged. (2875, 2876) -> b' Protectors' occured 1 times.\n",
      "4184/4744 pairs merged. (2270, 495) -> b' coalition' occured 1 times.\n",
      "4185/4744 pairs merged. (315, 117) -> b' Mu' occured 1 times.\n",
      "4186/4744 pairs merged. (4185, 1236) -> b' Muye' occured 1 times.\n",
      "4187/4744 pairs merged. (300, 2218) -> b' lower' occured 1 times.\n",
      "4188/4744 pairs merged. (433, 2773) -> b' enfe' occured 1 times.\n",
      "4189/4744 pairs merged. (4188, 2273) -> b' enfeof' occured 1 times.\n",
      "4190/4744 pairs merged. (4189, 102) -> b' enfeoff' occured 1 times.\n",
      "4191/4744 pairs merged. (4190, 263) -> b' enfeoffed' occured 1 times.\n",
      "4192/4744 pairs merged. (280, 476) -> b' sem' occured 1 times.\n",
      "4193/4744 pairs merged. (4192, 105) -> b' semi' occured 1 times.\n",
      "4194/4744 pairs merged. (45, 1315) -> b'-ind' occured 1 times.\n",
      "4195/4744 pairs merged. (4194, 1034) -> b'-independ' occured 1 times.\n",
      "4196/4744 pairs merged. (4195, 292) -> b'-independent' occured 1 times.\n",
      "4197/4744 pairs merged. (864, 1237) -> b' invok' occured 1 times.\n",
      "4198/4744 pairs merged. (4197, 263) -> b' invoked' occured 1 times.\n",
      "4199/4744 pairs merged. (2688, 1902) -> b' legitimize' occured 1 times.\n",
      "4200/4744 pairs merged. (291, 1548) -> b' every' occured 1 times.\n",
      "4201/4744 pairs merged. (1055, 1122) -> b' Like' occured 1 times.\n",
      "4202/4744 pairs merged. (704, 2277) -> b' Shangdi' occured 1 times.\n",
      "4203/4744 pairs merged. (116, 379) -> b'tian' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 3975/4744 [00:36<00:06, 127.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4204/4744 pairs merged. (578, 1041) -> b' decided' occured 1 times.\n",
      "4205/4744 pairs merged. (2264, 335) -> b' realist' occured 1 times.\n",
      "4206/4744 pairs merged. (4205, 1062) -> b' realistically' occured 1 times.\n",
      "4207/4744 pairs merged. (280, 426) -> b' sover' occured 1 times.\n",
      "4208/4744 pairs merged. (4207, 101) -> b' sovere' occured 1 times.\n",
      "4209/4744 pairs merged. (4208, 465) -> b' sovereign' occured 1 times.\n",
      "4210/4744 pairs merged. (1119, 97) -> b' appa' occured 1 times.\n",
      "4211/4744 pairs merged. (4210, 726) -> b' apparen' occured 1 times.\n",
      "4212/4744 pairs merged. (4211, 1658) -> b' apparently' occured 1 times.\n",
      "4213/4744 pairs merged. (2882, 509) -> b' overthrown' occured 1 times.\n",
      "4214/4744 pairs merged. (310, 2883) -> b' having' occured 1 times.\n",
      "4215/4744 pairs merged. (2884, 1008) -> b' Zongzhou' occured 1 times.\n",
      "4216/4744 pairs merged. (1906, 1008) -> b' Chengzhou' occured 1 times.\n",
      "4217/4744 pairs merged. (76, 1471) -> b'Luoyang' occured 1 times.\n",
      "4218/4744 pairs merged. (2284, 278) -> b' moving' occured 1 times.\n",
      "4219/4744 pairs merged. (524, 2285) -> b' regularly' occured 1 times.\n",
      "4220/4744 pairs merged. (2286, 982) -> b' eastward' occured 1 times.\n",
      "4221/4744 pairs merged. (2888, 982) -> b' southeastward' occured 1 times.\n",
      "4222/4744 pairs merged. (55, 50) -> b'72' occured 1 times.\n",
      "4223/4744 pairs merged. (4222, 50) -> b'722' occured 1 times.\n",
      "4224/4744 pairs merged. (32, 10) -> b' \\n' occured 1 times.\n",
      "4225/4744 pairs merged. (55, 55) -> b'77' occured 1 times.\n",
      "4226/4744 pairs merged. (4225, 49) -> b'771' occured 1 times.\n",
      "4227/4744 pairs merged. (2891, 114) -> b' Quanr' occured 1 times.\n",
      "4228/4744 pairs merged. (4227, 323) -> b' Quanrong' occured 1 times.\n",
      "4229/4744 pairs merged. (2893, 1229) -> b' barbarians' occured 1 times.\n",
      "4230/4744 pairs merged. (399, 278) -> b' Ping' occured 1 times.\n",
      "4231/4744 pairs merged. (2897, 1458) -> b' phase' occured 1 times.\n",
      "4232/4744 pairs merged. (2898, 263) -> b' named' occured 1 times.\n",
      "4233/4744 pairs merged. (469, 261) -> b' center' occured 1 times.\n",
      "4234/4744 pairs merged. (387, 2296) -> b' deleg' occured 1 times.\n",
      "4235/4744 pairs merged. (4234, 375) -> b' delegated' occured 1 times.\n",
      "4236/4744 pairs merged. (2297, 115) -> b' hundreds' occured 1 times.\n",
      "4237/4744 pairs merged. (2905, 263) -> b' walled' occured 1 times.\n",
      "4238/4744 pairs merged. (296, 1478) -> b' town' occured 1 times.\n",
      "4239/4744 pairs merged. (256, 1233) -> b' tended' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 4003/4744 [00:36<00:06, 121.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4240/4744 pairs merged. (2116, 390) -> b' incorporate' occured 1 times.\n",
      "4241/4744 pairs merged. (1012, 261) -> b' weaker' occured 1 times.\n",
      "4242/4744 pairs merged. (386, 281) -> b' ones' occured 1 times.\n",
      "4243/4744 pairs merged. (2909, 263) -> b' disappeared' occured 1 times.\n",
      "4244/4744 pairs merged. (1410, 2303) -> b' princip' occured 1 times.\n",
      "4245/4744 pairs merged. (4244, 2910) -> b' principalities' occured 1 times.\n",
      "4246/4744 pairs merged. (2912, 111) -> b' underto' occured 1 times.\n",
      "4247/4744 pairs merged. (4246, 1237) -> b' undertook' occured 1 times.\n",
      "4248/4744 pairs merged. (87, 117) -> b'Wu' occured 1 times.\n",
      "4249/4744 pairs merged. (395, 728) -> b' Yue' occured 1 times.\n",
      "4250/4744 pairs merged. (1916, 715) -> b' urbanized' occured 1 times.\n",
      "4251/4744 pairs merged. (2913, 715) -> b' commercialized' occured 1 times.\n",
      "4252/4744 pairs merged. (397, 2915) -> b' Laoz' occured 1 times.\n",
      "4253/4744 pairs merged. (4252, 105) -> b' Laozi' occured 1 times.\n",
      "4254/4744 pairs merged. (848, 933) -> b' Confuc' occured 1 times.\n",
      "4255/4744 pairs merged. (4254, 105) -> b' Confuci' occured 1 times.\n",
      "4256/4744 pairs merged. (4255, 413) -> b' Confucius' occured 1 times.\n",
      "4257/4744 pairs merged. (299, 122) -> b' Tz' occured 1 times.\n",
      "4258/4744 pairs merged. (4257, 117) -> b' Tzu' occured 1 times.\n",
      "4259/4744 pairs merged. (2307, 116) -> b' chaot' occured 1 times.\n",
      "4260/4744 pairs merged. (4259, 287) -> b' chaotic' occured 1 times.\n",
      "4261/4744 pairs merged. (67, 262) -> b'Con' occured 1 times.\n",
      "4262/4744 pairs merged. (4261, 719) -> b'Confl' occured 1 times.\n",
      "4263/4744 pairs merged. (4262, 1198) -> b'Conflict' occured 1 times.\n",
      "4264/4744 pairs merged. (640, 1918) -> b' Warfare' occured 1 times.\n",
      "4265/4744 pairs merged. (2917, 308) -> b' mobil' occured 1 times.\n",
      "4266/4744 pairs merged. (4265, 1902) -> b' mobilize' occured 1 times.\n",
      "4267/4744 pairs merged. (280, 814) -> b' sold' occured 1 times.\n",
      "4268/4744 pairs merged. (4267, 105) -> b' soldi' occured 1 times.\n",
      "4269/4744 pairs merged. (4268, 393) -> b' soldiers' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 4031/4744 [00:36<00:05, 129.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4270/4744 pairs merged. (1224, 258) -> b' Within' occured 1 times.\n",
      "4271/4744 pairs merged. (330, 1920) -> b' constant' occured 1 times.\n",
      "4272/4744 pairs merged. (1125, 440) -> b' joc' occured 1 times.\n",
      "4273/4744 pairs merged. (4272, 1122) -> b' jocke' occured 1 times.\n",
      "4274/4744 pairs merged. (4273, 2918) -> b' jockeying' occured 1 times.\n",
      "4275/4744 pairs merged. (1330, 90) -> b'\\xe2\\x80\\x94Z' occured 1 times.\n",
      "4276/4744 pairs merged. (4275, 104) -> b'\\xe2\\x80\\x94Zh' occured 1 times.\n",
      "4277/4744 pairs merged. (4276, 502) -> b'\\xe2\\x80\\x94Zhao' occured 1 times.\n",
      "4278/4744 pairs merged. (1330, 101) -> b'\\xe2\\x80\\x94e' occured 1 times.\n",
      "4279/4744 pairs merged. (4278, 2652) -> b'\\xe2\\x80\\x94eventually' occured 1 times.\n",
      "4280/4744 pairs merged. (686, 495) -> b' partition' occured 1 times.\n",
      "4281/4744 pairs merged. (4280, 263) -> b' partitioned' occured 1 times.\n",
      "4282/4744 pairs merged. (2921, 2922) -> b' Schools' occured 1 times.\n",
      "4283/4744 pairs merged. (550, 922) -> b' Thought' occured 1 times.\n",
      "4284/4744 pairs merged. (1452, 1210) -> b' bloss' occured 1 times.\n",
      "4285/4744 pairs merged. (4284, 2923) -> b' blossoming' occured 1 times.\n",
      "4286/4744 pairs merged. (306, 918) -> b' Such' occured 1 times.\n",
      "4287/4744 pairs merged. (425, 1534) -> b' movements' occured 1 times.\n",
      "4288/4744 pairs merged. (1683, 104) -> b' Moh' occured 1 times.\n",
      "4289/4744 pairs merged. (4288, 519) -> b' Mohism' occured 1 times.\n",
      "4290/4744 pairs merged. (686, 304) -> b' partly' occured 1 times.\n",
      "4291/4744 pairs merged. (1556, 417) -> b' philosophical' occured 1 times.\n",
      "4292/4744 pairs merged. (2266, 412) -> b' thoughts' occured 1 times.\n",
      "4293/4744 pairs merged. (1615, 573) -> b' consolidations' occured 1 times.\n",
      "4294/4744 pairs merged. (288, 1687) -> b' batt' occured 1 times.\n",
      "4295/4744 pairs merged. (4294, 1248) -> b' battled' occured 1 times.\n",
      "4296/4744 pairs merged. (550, 489) -> b' Though' occured 1 times.\n",
      "4297/4744 pairs merged. (284, 368) -> b' fig' occured 1 times.\n",
      "4298/4744 pairs merged. (4297, 381) -> b' figure' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 4058/4744 [00:36<00:05, 120.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4299/4744 pairs merged. (4298, 257) -> b' figurehe' occured 1 times.\n",
      "4300/4744 pairs merged. (4299, 321) -> b' figurehead' occured 1 times.\n",
      "4301/4744 pairs merged. (1282, 684) -> b' little' occured 1 times.\n",
      "4302/4744 pairs merged. (78, 463) -> b'Num' occured 1 times.\n",
      "4303/4744 pairs merged. (4302, 1207) -> b'Numerous' occured 1 times.\n",
      "4304/4744 pairs merged. (2928, 1052) -> b' mathematic' occured 1 times.\n",
      "4305/4744 pairs merged. (4304, 115) -> b' mathematics' occured 1 times.\n",
      "4306/4744 pairs merged. (1330, 2931) -> b'\\xe2\\x80\\x94including' occured 1 times.\n",
      "4307/4744 pairs merged. (464, 528) -> b' Zhuan' occured 1 times.\n",
      "4308/4744 pairs merged. (2934, 109) -> b' summ' occured 1 times.\n",
      "4309/4744 pairs merged. (4308, 285) -> b' summar' occured 1 times.\n",
      "4310/4744 pairs merged. (4309, 2935) -> b' summarizing' occured 1 times.\n",
      "4311/4744 pairs merged. (288, 1338) -> b' bund' occured 1 times.\n",
      "4312/4744 pairs merged. (4311, 345) -> b' bundle' occured 1 times.\n",
      "4313/4744 pairs merged. (288, 2832) -> b' bamboo' occured 1 times.\n",
      "4314/4744 pairs merged. (1611, 2314) -> b' slips' occured 1 times.\n",
      "4315/4744 pairs merged. (1924, 53) -> b'305' occured 1 times.\n",
      "4316/4744 pairs merged. (1330, 98) -> b'\\xe2\\x80\\x94b' occured 1 times.\n",
      "4317/4744 pairs merged. (4316, 101) -> b'\\xe2\\x80\\x94be' occured 1 times.\n",
      "4318/4744 pairs merged. (4317, 278) -> b'\\xe2\\x80\\x94being' occured 1 times.\n",
      "4319/4744 pairs merged. (1317, 368) -> b'-dig' occured 1 times.\n",
      "4320/4744 pairs merged. (4319, 273) -> b'-digit' occured 1 times.\n",
      "4321/4744 pairs merged. (2315, 1309) -> b' multipl' occured 1 times.\n",
      "4322/4744 pairs merged. (4321, 1866) -> b' multiplication' occured 1 times.\n",
      "4323/4744 pairs merged. (256, 1014) -> b' table' occured 1 times.\n",
      "4324/4744 pairs merged. (633, 287) -> b' indic' occured 1 times.\n",
      "4325/4744 pairs merged. (4324, 811) -> b' indicates' occured 1 times.\n",
      "4326/4744 pairs merged. (2942, 335) -> b' sophist' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 4086/4744 [00:37<00:05, 127.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4327/4744 pairs merged. (4326, 1167) -> b' sophisticated' occured 1 times.\n",
      "4328/4744 pairs merged. (461, 339) -> b' arith' occured 1 times.\n",
      "4329/4744 pairs merged. (4328, 109) -> b' arithm' occured 1 times.\n",
      "4330/4744 pairs merged. (4329, 338) -> b' arithmet' occured 1 times.\n",
      "4331/4744 pairs merged. (4330, 287) -> b' arithmetic' occured 1 times.\n",
      "4332/4744 pairs merged. (65, 115) -> b'As' occured 1 times.\n",
      "4333/4744 pairs merged. (498, 263) -> b' governed' occured 1 times.\n",
      "4334/4744 pairs merged. (1007, 377) -> b' else' occured 1 times.\n",
      "4335/4744 pairs merged. (4334, 119) -> b' elsew' occured 1 times.\n",
      "4336/4744 pairs merged. (4335, 1161) -> b' elsewhere' occured 1 times.\n",
      "4337/4744 pairs merged. (593, 2946) -> b' resili' occured 1 times.\n",
      "4338/4744 pairs merged. (4337, 292) -> b' resilient' occured 1 times.\n",
      "4339/4744 pairs merged. (1330, 273) -> b'\\xe2\\x80\\x94it' occured 1 times.\n",
      "4340/4744 pairs merged. (4339, 115) -> b'\\xe2\\x80\\x94its' occured 1 times.\n",
      "4341/4744 pairs merged. (634, 818) -> b' termin' occured 1 times.\n",
      "4342/4744 pairs merged. (4341, 1040) -> b' terminology' occured 1 times.\n",
      "4343/4744 pairs merged. (280, 576) -> b' seen' occured 1 times.\n",
      "4344/4744 pairs merged. (280, 876) -> b' sheng' occured 1 times.\n",
      "4345/4744 pairs merged. (112, 332) -> b'pro' occured 1 times.\n",
      "4346/4744 pairs merged. (4345, 118) -> b'prov' occured 1 times.\n",
      "4347/4744 pairs merged. (4346, 1927) -> b'provinces' occured 1 times.\n",
      "4348/4744 pairs merged. (99, 648) -> b'count' occured 1 times.\n",
      "4349/4744 pairs merged. (4348, 350) -> b'counties' occured 1 times.\n",
      "4350/4744 pairs merged. (2950, 278) -> b' waning' occured 1 times.\n",
      "4351/4744 pairs merged. (1912, 278) -> b' conquering' occured 1 times.\n",
      "4352/4744 pairs merged. (594, 1318) -> b' Jinsh' occured 1 times.\n",
      "4353/4744 pairs merged. (4352, 97) -> b' Jinsha' occured 1 times.\n",
      "4354/4744 pairs merged. (1249, 1032) -> b' driving' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4114/4744 [00:37<00:04, 127.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4355/4744 pairs merged. (1928, 1929) -> b' imitated' occured 1 times.\n",
      "4356/4744 pairs merged. (978, 2953) -> b' thereby' occured 1 times.\n",
      "4357/4744 pairs merged. (589, 2923) -> b' becoming' occured 1 times.\n",
      "4358/4744 pairs merged. (575, 104) -> b' powerh' occured 1 times.\n",
      "4359/4744 pairs merged. (4358, 1672) -> b' powerhouse' occured 1 times.\n",
      "4360/4744 pairs merged. (423, 1930) -> b' unify' occured 1 times.\n",
      "4361/4744 pairs merged. (4360, 278) -> b' unifying' occured 1 times.\n",
      "4362/4744 pairs merged. (433, 622) -> b' enabl' occured 1 times.\n",
      "4363/4744 pairs merged. (4362, 278) -> b' enabling' occured 1 times.\n",
      "4364/4744 pairs merged. (1051, 820) -> b' proclaim' occured 1 times.\n",
      "4365/4744 pairs merged. (1330, 2177) -> b'\\xe2\\x80\\x94known' occured 1 times.\n",
      "4366/4744 pairs merged. (89, 278) -> b'Ying' occured 1 times.\n",
      "4367/4744 pairs merged. (2959, 230) -> b'\\xe7\\xa7\\xa6\\xe6' occured 1 times.\n",
      "4368/4744 pairs merged. (4367, 156) -> b'\\xe7\\xa7\\xa6\\xe6\\x9c' occured 1 times.\n",
      "4369/4744 pairs merged. (4368, 157) -> b'\\xe7\\xa7\\xa6\\xe6\\x9c\\x9d' occured 1 times.\n",
      "4370/4744 pairs merged. (2960, 956) -> b' formalised' occured 1 times.\n",
      "4371/4744 pairs merged. (401, 728) -> b' true' occured 1 times.\n",
      "4372/4744 pairs merged. (81, 258) -> b'Qin' occured 1 times.\n",
      "4373/4744 pairs merged. (291, 793) -> b' evol' occured 1 times.\n",
      "4374/4744 pairs merged. (4373, 2964) -> b' evolving' occured 1 times.\n",
      "4375/4744 pairs merged. (1693, 1372) -> b' emphasise' occured 1 times.\n",
      "4376/4744 pairs merged. (229, 167) -> b'\\xe5\\xa7' occured 1 times.\n",
      "4377/4744 pairs merged. (4376, 139) -> b'\\xe5\\xa7\\x8b' occured 1 times.\n",
      "4378/4744 pairs merged. (4377, 231) -> b'\\xe5\\xa7\\x8b\\xe7' occured 1 times.\n",
      "4379/4744 pairs merged. (4378, 154) -> b'\\xe5\\xa7\\x8b\\xe7\\x9a' occured 1 times.\n",
      "4380/4744 pairs merged. (4379, 135) -> b'\\xe5\\xa7\\x8b\\xe7\\x9a\\x87' occured 1 times.\n",
      "4381/4744 pairs merged. (4380, 229) -> b'\\xe5\\xa7\\x8b\\xe7\\x9a\\x87\\xe5' occured 1 times.\n",
      "4382/4744 pairs merged. (4381, 184) -> b'\\xe5\\xa7\\x8b\\xe7\\x9a\\x87\\xe5\\xb8' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4140/4744 [00:37<00:04, 127.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4383/4744 pairs merged. (4382, 157) -> b'\\xe5\\xa7\\x8b\\xe7\\x9a\\x87\\xe5\\xb8\\x9d' occured 1 times.\n",
      "4384/4744 pairs merged. (70, 627) -> b'First' occured 1 times.\n",
      "4385/4744 pairs merged. (2949, 59) -> b'\");' occured 1 times.\n",
      "4386/4744 pairs merged. (2835, 1040) -> b' mythology' occured 1 times.\n",
      "4387/4744 pairs merged. (1536, 263) -> b' Based' occured 1 times.\n",
      "4388/4744 pairs merged. (1212, 754) -> b' Xianyang' occured 1 times.\n",
      "4389/4744 pairs merged. (498, 278) -> b' governing' occured 1 times.\n",
      "4390/4744 pairs merged. (2777, 2311) -> b' schem' occured 1 times.\n",
      "4391/4744 pairs merged. (4390, 101) -> b' scheme' occured 1 times.\n",
      "4392/4744 pairs merged. (284, 361) -> b' fut' occured 1 times.\n",
      "4393/4744 pairs merged. (4392, 381) -> b' future' occured 1 times.\n",
      "4394/4744 pairs merged. (1694, 688) -> b' improve' occured 1 times.\n",
      "4395/4744 pairs merged. (1489, 343) -> b' perce' occured 1 times.\n",
      "4396/4744 pairs merged. (4395, 713) -> b' perceived' occured 1 times.\n",
      "4397/4744 pairs merged. (1490, 1174) -> b' failures' occured 1 times.\n",
      "4398/4744 pairs merged. (541, 2265) -> b' consisted' occured 1 times.\n",
      "4399/4744 pairs merged. (233, 131) -> b'\\xe9\\x83' occured 1 times.\n",
      "4400/4744 pairs merged. (4399, 161) -> b'\\xe9\\x83\\xa1' occured 1 times.\n",
      "4401/4744 pairs merged. (1125, 334) -> b' jun' occured 1 times.\n",
      "4402/4744 pairs merged. (865, 350) -> b' counties' occured 1 times.\n",
      "4403/4744 pairs merged. (229, 142) -> b'\\xe5\\x8e' occured 1 times.\n",
      "4404/4744 pairs merged. (4403, 191) -> b'\\xe5\\x8e\\xbf' occured 1 times.\n",
      "4405/4744 pairs merged. (2976, 950) -> b' progressively' occured 1 times.\n",
      "4406/4744 pairs merged. (1491, 553) -> b' divisions' occured 1 times.\n",
      "4407/4744 pairs merged. (77, 647) -> b'Many' occured 1 times.\n",
      "4408/4744 pairs merged. (277, 2334) -> b' informed' occured 1 times.\n",
      "4409/4744 pairs merged. (2130, 1040) -> b' ideology' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 4170/4744 [00:37<00:04, 131.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4410/4744 pairs merged. (539, 1618) -> b' promo' occured 1 times.\n",
      "4411/4744 pairs merged. (4410, 416) -> b' promoted' occured 1 times.\n",
      "4412/4744 pairs merged. (2981, 276) -> b' chancellor' occured 1 times.\n",
      "4413/4744 pairs merged. (306, 105) -> b' Si' occured 1 times.\n",
      "4414/4744 pairs merged. (1693, 956) -> b' emphasised' occured 1 times.\n",
      "4415/4744 pairs merged. (293, 361) -> b' mut' occured 1 times.\n",
      "4416/4744 pairs merged. (4415, 649) -> b' mutual' occured 1 times.\n",
      "4417/4744 pairs merged. (1227, 1695) -> b' respons' occured 1 times.\n",
      "4418/4744 pairs merged. (4417, 468) -> b' responsib' occured 1 times.\n",
      "4419/4744 pairs merged. (4418, 1225) -> b' responsibility' occured 1 times.\n",
      "4420/4744 pairs merged. (2691, 281) -> b' disputes' occured 1 times.\n",
      "4421/4744 pairs merged. (2986, 653) -> b' punish' occured 1 times.\n",
      "4422/4744 pairs merged. (4421, 667) -> b' punishments' occured 1 times.\n",
      "4423/4744 pairs merged. (1375, 608) -> b' crime' occured 1 times.\n",
      "4424/4744 pairs merged. (2335, 287) -> b' practic' occured 1 times.\n",
      "4425/4744 pairs merged. (4424, 281) -> b' practices' occured 1 times.\n",
      "4426/4744 pairs merged. (2337, 2987) -> b' encouragement' occured 1 times.\n",
      "4427/4744 pairs merged. (669, 743) -> b' repress' occured 1 times.\n",
      "4428/4744 pairs merged. (4427, 290) -> b' repression' occured 1 times.\n",
      "4429/4744 pairs merged. (2988, 115) -> b' Reforms' occured 1 times.\n",
      "4430/4744 pairs merged. (337, 121) -> b' sty' occured 1 times.\n",
      "4431/4744 pairs merged. (4430, 1376) -> b' styles' occured 1 times.\n",
      "4432/4744 pairs merged. (377, 275) -> b'seal' occured 1 times.\n",
      "4433/4744 pairs merged. (280, 2094) -> b' script' occured 1 times.\n",
      "4434/4744 pairs merged. (1653, 275) -> b' metal' occured 1 times.\n",
      "4435/4744 pairs merged. (66, 259) -> b'Ban' occured 1 times.\n",
      "4436/4744 pairs merged. (1400, 278) -> b' ordering' occured 1 times.\n",
      "4437/4744 pairs merged. (1848, 1243) -> b' burning' occured 1 times.\n",
      "4438/4744 pairs merged. (1848, 372) -> b' burial' occured 1 times.\n",
      "4439/4744 pairs merged. (1934, 1372) -> b' guise' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 4198/4744 [00:37<00:04, 130.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4440/4744 pairs merged. (687, 743) -> b' express' occured 1 times.\n",
      "4441/4744 pairs merged. (2993, 98) -> b' doub' occured 1 times.\n",
      "4442/4744 pairs merged. (4441, 116) -> b' doubt' occured 1 times.\n",
      "4443/4744 pairs merged. (2994, 467) -> b' historicity' occured 1 times.\n",
      "4444/4744 pairs merged. (1894, 745) -> b' importance' occured 1 times.\n",
      "4445/4744 pairs merged. (2996, 263) -> b' supplemented' occured 1 times.\n",
      "4446/4744 pairs merged. (45, 112) -> b'-p' occured 1 times.\n",
      "4447/4744 pairs merged. (4446, 2997) -> b'-political' occured 1 times.\n",
      "4448/4744 pairs merged. (2236, 1698) -> b'-element' occured 1 times.\n",
      "4449/4744 pairs merged. (1845, 148) -> b'\\xe4\\xba\\x94' occured 1 times.\n",
      "4450/4744 pairs merged. (4449, 232) -> b'\\xe4\\xba\\x94\\xe8' occured 1 times.\n",
      "4451/4744 pairs merged. (4450, 161) -> b'\\xe4\\xba\\x94\\xe8\\xa1' occured 1 times.\n",
      "4452/4744 pairs merged. (4451, 140) -> b'\\xe4\\xba\\x94\\xe8\\xa1\\x8c' occured 1 times.\n",
      "4453/4744 pairs merged. (2124, 1192) -> b' cosmological' occured 1 times.\n",
      "4454/4744 pairs merged. (342, 922) -> b' thought' occured 1 times.\n",
      "4455/4744 pairs merged. (385, 104) -> b' exh' occured 1 times.\n",
      "4456/4744 pairs merged. (4455, 1654) -> b' exhau' occured 1 times.\n",
      "4457/4744 pairs merged. (4456, 264) -> b' exhaust' occured 1 times.\n",
      "4458/4744 pairs merged. (4457, 422) -> b' exhaustive' occured 1 times.\n",
      "4459/4744 pairs merged. (3004, 278) -> b' collecting' occured 1 times.\n",
      "4460/4744 pairs merged. (277, 642) -> b' inform' occured 1 times.\n",
      "4461/4744 pairs merged. (4460, 333) -> b' information' occured 1 times.\n",
      "4462/4744 pairs merged. (593, 1117) -> b' residence' occured 1 times.\n",
      "4463/4744 pairs merged. (993, 262) -> b' Common' occured 1 times.\n",
      "4464/4744 pairs merged. (4463, 393) -> b' Commoners' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 4226/4744 [00:38<00:04, 123.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4465/4744 pairs merged. (1700, 3007) -> b'suffered' occured 1 times.\n",
      "4466/4744 pairs merged. (1821, 357) -> b' treatment' occured 1 times.\n",
      "4467/4744 pairs merged. (523, 379) -> b' historian' occured 1 times.\n",
      "4468/4744 pairs merged. (331, 436) -> b' Buc' occured 1 times.\n",
      "4469/4744 pairs merged. (4468, 107) -> b' Buck' occured 1 times.\n",
      "4470/4744 pairs merged. (4469, 345) -> b' Buckle' occured 1 times.\n",
      "4471/4744 pairs merged. (4470, 121) -> b' Buckley' occured 1 times.\n",
      "4472/4744 pairs merged. (3016, 115) -> b' highways' occured 1 times.\n",
      "4473/4744 pairs merged. (367, 311) -> b' rang' occured 1 times.\n",
      "4474/4744 pairs merged. (4473, 263) -> b' ranged' occured 1 times.\n",
      "4475/4744 pairs merged. (1392, 48) -> b'250' occured 1 times.\n",
      "4476/4744 pairs merged. (1938, 48) -> b'840' occured 1 times.\n",
      "4477/4744 pairs merged. (929, 2156) -> b' assigned' occured 1 times.\n",
      "4478/4744 pairs merged. (50, 738) -> b'210' occured 1 times.\n",
      "4479/4744 pairs merged. (1939, 304) -> b' reportedly' occured 1 times.\n",
      "4480/4744 pairs merged. (3027, 393) -> b' orders' occured 1 times.\n",
      "4481/4744 pairs merged. (373, 665) -> b' super' occured 1 times.\n",
      "4482/4744 pairs merged. (4481, 118) -> b' superv' occured 1 times.\n",
      "4483/4744 pairs merged. (4482, 956) -> b' supervised' occured 1 times.\n",
      "4484/4744 pairs merged. (2341, 3028) -> b' combining' occured 1 times.\n",
      "4485/4744 pairs merged. (2905, 115) -> b' walls' occured 1 times.\n",
      "4486/4744 pairs merged. (3029, 278) -> b' building' occured 1 times.\n",
      "4487/4744 pairs merged. (56, 437) -> b'800' occured 1 times.\n",
      "4488/4744 pairs merged. (645, 97) -> b' stra' occured 1 times.\n",
      "4489/4744 pairs merged. (4488, 871) -> b' straight' occured 1 times.\n",
      "4490/4744 pairs merged. (1139, 117) -> b' monu' occured 1 times.\n",
      "4491/4744 pairs merged. (4490, 357) -> b' monument' occured 1 times.\n",
      "4492/4744 pairs merged. (4491, 275) -> b' monumental' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 4254/4744 [00:38<00:03, 130.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4493/4744 pairs merged. (293, 97) -> b' ma' occured 1 times.\n",
      "4494/4744 pairs merged. (4493, 413) -> b' maus' occured 1 times.\n",
      "4495/4744 pairs merged. (4494, 1610) -> b' mausole' occured 1 times.\n",
      "4496/4744 pairs merged. (4495, 463) -> b' mausoleum' occured 1 times.\n",
      "4497/4744 pairs merged. (299, 261) -> b' Ter' occured 1 times.\n",
      "4498/4744 pairs merged. (4497, 852) -> b' Terrac' occured 1 times.\n",
      "4499/4744 pairs merged. (4498, 545) -> b' Terracot' occured 1 times.\n",
      "4500/4744 pairs merged. (4499, 1779) -> b' Terracotta' occured 1 times.\n",
      "4501/4744 pairs merged. (1143, 3030) -> b' deterior' occured 1 times.\n",
      "4502/4744 pairs merged. (4501, 375) -> b' deteriorated' occured 1 times.\n",
      "4503/4744 pairs merged. (643, 1612) -> b' capitulated' occured 1 times.\n",
      "4504/4744 pairs merged. (800, 10) -> b' ====\\n\\n\\n' occured 1 times.\n",
      "4505/4744 pairs merged. (755, 61) -> b'=====' occured 1 times.\n",
      "4506/4744 pairs merged. (756, 796) -> b' =====\\n\\n' occured 1 times.\n",
      "4507/4744 pairs merged. (331, 311) -> b' Bang' occured 1 times.\n",
      "4508/4744 pairs merged. (1608, 276) -> b' victor' occured 1 times.\n",
      "4509/4744 pairs merged. (4508, 629) -> b' victorious' occured 1 times.\n",
      "4510/4744 pairs merged. (441, 1563) -> b'\\xe2\\x80\\x93Han' occured 1 times.\n",
      "4511/4744 pairs merged. (2653, 2347) -> b' Contention' occured 1 times.\n",
      "4512/4744 pairs merged. (1603, 3035) -> b' intermit' occured 1 times.\n",
      "4513/4744 pairs merged. (4512, 116) -> b' intermitt' occured 1 times.\n",
      "4514/4744 pairs merged. (4513, 2350) -> b' intermittently' occured 1 times.\n",
      "4515/4744 pairs merged. (525, 348) -> b' orth' occured 1 times.\n",
      "4516/4744 pairs merged. (4515, 378) -> b' orthod' occured 1 times.\n",
      "4517/4744 pairs merged. (4516, 1255) -> b' orthodox' occured 1 times.\n",
      "4518/4744 pairs merged. (3038, 101) -> b' shape' occured 1 times.\n",
      "4519/4744 pairs merged. (1304, 116) -> b' Art' occured 1 times.\n",
      "4520/4744 pairs merged. (521, 1796) -> b' heights' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 4282/4744 [00:38<00:03, 122.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4521/4744 pairs merged. (400, 102) -> b' prof' occured 1 times.\n",
      "4522/4744 pairs merged. (4521, 480) -> b' profound' occured 1 times.\n",
      "4523/4744 pairs merged. (763, 1880) -> b' impacts' occured 1 times.\n",
      "4524/4744 pairs merged. (1045, 304) -> b' commonly' occured 1 times.\n",
      "4525/4744 pairs merged. (898, 294) -> b' lais' occured 1 times.\n",
      "4526/4744 pairs merged. (4525, 377) -> b' laisse' occured 1 times.\n",
      "4527/4744 pairs merged. (4526, 122) -> b' laissez' occured 1 times.\n",
      "4528/4744 pairs merged. (1436, 97) -> b'-fa' occured 1 times.\n",
      "4529/4744 pairs merged. (4528, 432) -> b'-faire' occured 1 times.\n",
      "4530/4744 pairs merged. (2351, 273) -> b' ambit' occured 1 times.\n",
      "4531/4744 pairs merged. (4530, 629) -> b' ambitious' occured 1 times.\n",
      "4532/4744 pairs merged. (543, 268) -> b' disen' occured 1 times.\n",
      "4533/4744 pairs merged. (4532, 1944) -> b' disenfr' occured 1 times.\n",
      "4534/4744 pairs merged. (4533, 259) -> b' disenfran' occured 1 times.\n",
      "4535/4744 pairs merged. (4534, 341) -> b' disenfranch' occured 1 times.\n",
      "4536/4744 pairs merged. (4535, 956) -> b' disenfranchised' occured 1 times.\n",
      "4537/4744 pairs merged. (1119, 826) -> b' appoin' occured 1 times.\n",
      "4538/4744 pairs merged. (4537, 987) -> b' appointing' occured 1 times.\n",
      "4539/4744 pairs merged. (620, 115) -> b' lands' occured 1 times.\n",
      "4540/4744 pairs merged. (337, 515) -> b' step' occured 1 times.\n",
      "4541/4744 pairs merged. (2353, 916) -> b' patron' occured 1 times.\n",
      "4542/4744 pairs merged. (4541, 786) -> b' patronage' occured 1 times.\n",
      "4543/4744 pairs merged. (1693, 3049) -> b' emphasizes' occured 1 times.\n",
      "4544/4744 pairs merged. (45, 1346) -> b'-struc' occured 1 times.\n",
      "4545/4744 pairs merged. (4544, 1708) -> b'-structured' occured 1 times.\n",
      "4546/4744 pairs merged. (883, 313) -> b' Univ' occured 1 times.\n",
      "4547/4744 pairs merged. (4546, 393) -> b' Univers' occured 1 times.\n",
      "4548/4744 pairs merged. (4547, 773) -> b' Universities' occured 1 times.\n",
      "4549/4744 pairs merged. (2354, 121) -> b' study' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4311/4744 [00:38<00:03, 130.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4550/4744 pairs merged. (32, 2227) -> b' urg' occured 1 times.\n",
      "4551/4744 pairs merged. (4550, 278) -> b' urging' occured 1 times.\n",
      "4552/4744 pairs merged. (1393, 335) -> b' Legalist' occured 1 times.\n",
      "4553/4744 pairs merged. (1047, 294) -> b' advis' occured 1 times.\n",
      "4554/4744 pairs merged. (4553, 812) -> b' advisors' occured 1 times.\n",
      "4555/4744 pairs merged. (3050, 1714) -> b' strengthened' occured 1 times.\n",
      "4556/4744 pairs merged. (284, 294) -> b' fis' occured 1 times.\n",
      "4557/4744 pairs merged. (4556, 2357) -> b' fiscal' occured 1 times.\n",
      "4558/4744 pairs merged. (1139, 2125) -> b' monopol' occured 1 times.\n",
      "4559/4744 pairs merged. (4558, 350) -> b' monopolies' occured 1 times.\n",
      "4560/4744 pairs merged. (300, 353) -> b' lim' occured 1 times.\n",
      "4561/4744 pairs merged. (4560, 3053) -> b' limiting' occured 1 times.\n",
      "4562/4744 pairs merged. (2332, 412) -> b' efforts' occured 1 times.\n",
      "4563/4744 pairs merged. (3056, 940) -> b' stimulating' occured 1 times.\n",
      "4564/4744 pairs merged. (288, 308) -> b' bil' occured 1 times.\n",
      "4565/4744 pairs merged. (4564, 660) -> b' bilater' occured 1 times.\n",
      "4566/4744 pairs merged. (4565, 275) -> b' bilateral' occured 1 times.\n",
      "4567/4744 pairs merged. (1146, 967) -> b' Valley' occured 1 times.\n",
      "4568/4744 pairs merged. (1284, 3061) -> b' dispatched' occured 1 times.\n",
      "4569/4744 pairs merged. (3062, 3063) -> b' Baiyue' occured 1 times.\n",
      "4570/4744 pairs merged. (2360, 3063) -> b' Minyue' occured 1 times.\n",
      "4571/4744 pairs merged. (939, 53) -> b'135' occured 1 times.\n",
      "4572/4744 pairs merged. (407, 647) -> b' Nany' occured 1 times.\n",
      "4573/4744 pairs merged. (4572, 728) -> b' Nanyue' occured 1 times.\n",
      "4574/4744 pairs merged. (455, 379) -> b' Dian' occured 1 times.\n",
      "4575/4744 pairs merged. (315, 1951) -> b' Migr' occured 1 times.\n",
      "4576/4744 pairs merged. (4575, 333) -> b' Migration' occured 1 times.\n",
      "4577/4744 pairs merged. (3065, 1259) -> b' expeditions' occured 1 times.\n",
      "4578/4744 pairs merged. (777, 1650) -> b' Southeast' occured 1 times.\n",
      "4579/4744 pairs merged. (1794, 278) -> b' introducing' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████▏| 4340/4744 [00:39<00:03, 129.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4580/4744 pairs merged. (1427, 2162) -> b' diplomacy' occured 1 times.\n",
      "4581/4744 pairs merged. (1611, 2362) -> b' slipped' occured 1 times.\n",
      "4582/4744 pairs merged. (337, 2724) -> b' stagn' occured 1 times.\n",
      "4583/4744 pairs merged. (4582, 333) -> b' stagnation' occured 1 times.\n",
      "4584/4744 pairs merged. (369, 590) -> b' Econom' occured 1 times.\n",
      "4585/4744 pairs merged. (4584, 1062) -> b' Economically' occured 1 times.\n",
      "4586/4744 pairs merged. (645, 772) -> b' strained' occured 1 times.\n",
      "4587/4744 pairs merged. (1249, 772) -> b' drained' occured 1 times.\n",
      "4588/4744 pairs merged. (1146, 285) -> b' Var' occured 1 times.\n",
      "4589/4744 pairs merged. (4588, 629) -> b' Various' occured 1 times.\n",
      "4590/4744 pairs merged. (385, 261) -> b' exer' occured 1 times.\n",
      "4591/4744 pairs merged. (4590, 416) -> b' exerted' occured 1 times.\n",
      "4592/4744 pairs merged. (737, 2364) -> b' brief' occured 1 times.\n",
      "4593/4744 pairs merged. (4592, 304) -> b' briefly' occured 1 times.\n",
      "4594/4744 pairs merged. (2365, 665) -> b' usurper' occured 1 times.\n",
      "4595/4744 pairs merged. (2774, 416) -> b' started' occured 1 times.\n",
      "4596/4744 pairs merged. (760, 641) -> b' outla' occured 1 times.\n",
      "4597/4744 pairs merged. (4596, 2575) -> b' outlawing' occured 1 times.\n",
      "4598/4744 pairs merged. (1721, 779) -> b' nationalization' occured 1 times.\n",
      "4599/4744 pairs merged. (1641, 2368) -> b' redistribution' occured 1 times.\n",
      "4600/4744 pairs merged. (3082, 115) -> b' programs' occured 1 times.\n",
      "4601/4744 pairs merged. (2370, 2371) -> b' favored' occured 1 times.\n",
      "4602/4744 pairs merged. (3085, 1709) -> b' instability' occured 1 times.\n",
      "4603/4744 pairs merged. (735, 2373) -> b' compounded' occured 1 times.\n",
      "4604/4744 pairs merged. (854, 1105) -> b' flood' occured 1 times.\n",
      "4605/4744 pairs merged. (4604, 278) -> b' flooding' occured 1 times.\n",
      "4606/4744 pairs merged. (2374, 116) -> b' silt' occured 1 times.\n",
      "4607/4744 pairs merged. (3029, 609) -> b' buildup' occured 1 times.\n",
      "4608/4744 pairs merged. (611, 259) -> b' chan' occured 1 times.\n",
      "4609/4744 pairs merged. (4608, 110) -> b' chann' occured 1 times.\n",
      "4610/4744 pairs merged. (4609, 1461) -> b' channels' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 4369/4744 [00:39<00:02, 134.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4611/4744 pairs merged. (1132, 754) -> b' Weiyang' occured 1 times.\n",
      "4612/4744 pairs merged. (1839, 1960) -> b' Palace' occured 1 times.\n",
      "4613/4744 pairs merged. (3090, 1358) -> b' enraged' occured 1 times.\n",
      "4614/4744 pairs merged. (50, 51) -> b'23' occured 1 times.\n",
      "4615/4744 pairs merged. (756, 10) -> b' ====\\n' occured 1 times.\n",
      "4616/4744 pairs merged. (1116, 1961) -> b' Guangwu' occured 1 times.\n",
      "4617/4744 pairs merged. (301, 258) -> b' rein' occured 1 times.\n",
      "4618/4744 pairs merged. (4617, 264) -> b' reinst' occured 1 times.\n",
      "4619/4744 pairs merged. (4618, 375) -> b' reinstated' occured 1 times.\n",
      "4620/4744 pairs merged. (550, 413) -> b' Thus' occured 1 times.\n",
      "4621/4744 pairs merged. (561, 1014) -> b' capable' occured 1 times.\n",
      "4622/4744 pairs merged. (2134, 1441) -> b' glories' occured 1 times.\n",
      "4623/4744 pairs merged. (617, 943) -> b' reclaimed' occured 1 times.\n",
      "4624/4744 pairs merged. (737, 717) -> b' brill' occured 1 times.\n",
      "4625/4744 pairs merged. (4624, 1622) -> b' brilliant' occured 1 times.\n",
      "4626/4744 pairs merged. (1427, 269) -> b' diplomat' occured 1 times.\n",
      "4627/4744 pairs merged. (399, 384) -> b' Pam' occured 1 times.\n",
      "4628/4744 pairs merged. (4627, 382) -> b' Pamir' occured 1 times.\n",
      "4629/4744 pairs merged. (4628, 115) -> b' Pamirs' occured 1 times.\n",
      "4630/4744 pairs merged. (724, 111) -> b' sho' occured 1 times.\n",
      "4631/4744 pairs merged. (4630, 501) -> b' shores' occured 1 times.\n",
      "4632/4744 pairs merged. (289, 295) -> b' Cas' occured 1 times.\n",
      "4633/4744 pairs merged. (4632, 112) -> b' Casp' occured 1 times.\n",
      "4634/4744 pairs merged. (4633, 379) -> b' Caspian' occured 1 times.\n",
      "4635/4744 pairs merged. (301, 362) -> b' reop' occured 1 times.\n",
      "4636/4744 pairs merged. (4635, 268) -> b' reopen' occured 1 times.\n",
      "4637/4744 pairs merged. (4636, 278) -> b' reopening' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 4397/4744 [00:39<00:02, 130.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4638/4744 pairs merged. (1843, 1962) -> b' arrival' occured 1 times.\n",
      "4639/4744 pairs merged. (1963, 553) -> b' connections' occured 1 times.\n",
      "4640/4744 pairs merged. (3097, 565) -> b' embass' occured 1 times.\n",
      "4641/4744 pairs merged. (4640, 350) -> b' embassies' occured 1 times.\n",
      "4642/4744 pairs merged. (280, 1482) -> b' sources' occured 1 times.\n",
      "4643/4744 pairs merged. (450, 278) -> b' coming' occured 1 times.\n",
      "4644/4744 pairs merged. (50, 1938) -> b'284' occured 1 times.\n",
      "4645/4744 pairs merged. (716, 295) -> b' eras' occured 1 times.\n",
      "4646/4744 pairs merged. (1294, 109) -> b' paperm' occured 1 times.\n",
      "4647/4744 pairs merged. (4646, 2073) -> b' papermaking' occured 1 times.\n",
      "4648/4744 pairs merged. (289, 529) -> b' Cai' occured 1 times.\n",
      "4649/4744 pairs merged. (397, 334) -> b' Lun' occured 1 times.\n",
      "4650/4744 pairs merged. (2928, 269) -> b' mathemat' occured 1 times.\n",
      "4651/4744 pairs merged. (4650, 417) -> b' mathematical' occured 1 times.\n",
      "4652/4744 pairs merged. (2383, 553) -> b' contributions' occured 1 times.\n",
      "4653/4744 pairs merged. (1283, 304) -> b' poly' occured 1 times.\n",
      "4654/4744 pairs merged. (4653, 109) -> b' polym' occured 1 times.\n",
      "4655/4744 pairs merged. (4654, 795) -> b' polymath' occured 1 times.\n",
      "4656/4744 pairs merged. (356, 742) -> b' Heng' occured 1 times.\n",
      "4657/4744 pairs merged. (3103, 278) -> b' feuding' occured 1 times.\n",
      "4658/4744 pairs merged. (299, 1481) -> b' Turban' occured 1 times.\n",
      "4659/4744 pairs merged. (1725, 109) -> b' turm' occured 1 times.\n",
      "4660/4744 pairs merged. (4659, 111) -> b' turmo' occured 1 times.\n",
      "4661/4744 pairs merged. (4660, 308) -> b' turmoil' occured 1 times.\n",
      "4662/4744 pairs merged. (401, 2918) -> b' trying' occured 1 times.\n",
      "4663/4744 pairs merged. (325, 376) -> b' gain' occured 1 times.\n",
      "4664/4744 pairs merged. (1971, 745) -> b' predominance' occured 1 times.\n",
      "4665/4744 pairs merged. (1397, 287) -> b' classic' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 4425/4744 [00:39<00:02, 129.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4666/4744 pairs merged. (2109, 745) -> b' Romance' occured 1 times.\n",
      "4667/4744 pairs merged. (1249, 384) -> b' dram' occured 1 times.\n",
      "4668/4744 pairs merged. (4667, 269) -> b' dramat' occured 1 times.\n",
      "4669/4744 pairs merged. (4668, 3049) -> b' dramatizes' occured 1 times.\n",
      "4670/4744 pairs merged. (557, 56) -> b'208' occured 1 times.\n",
      "4671/4744 pairs merged. (761, 1901) -> b' accep' occured 1 times.\n",
      "4672/4744 pairs merged. (4671, 416) -> b' accepted' occured 1 times.\n",
      "4673/4744 pairs merged. (1220, 105) -> b' initi' occured 1 times.\n",
      "4674/4744 pairs merged. (4673, 940) -> b' initiating' occured 1 times.\n",
      "4675/4744 pairs merged. (306, 111) -> b' So' occured 1 times.\n",
      "4676/4744 pairs merged. (4675, 262) -> b' Soon' occured 1 times.\n",
      "4677/4744 pairs merged. (2586, 1118) -> b' rivals' occured 1 times.\n",
      "4678/4744 pairs merged. (1871, 427) -> b' characteri' occured 1 times.\n",
      "4679/4744 pairs merged. (4678, 122) -> b' characteriz' occured 1 times.\n",
      "4680/4744 pairs merged. (4679, 263) -> b' characterized' occured 1 times.\n",
      "4681/4744 pairs merged. (578, 1509) -> b' decentral' occured 1 times.\n",
      "4682/4744 pairs merged. (4681, 779) -> b' decentralization' occured 1 times.\n",
      "4683/4744 pairs merged. (423, 290) -> b' union' occured 1 times.\n",
      "4684/4744 pairs merged. (1508, 899) -> b' reunited' occured 1 times.\n",
      "4685/4744 pairs merged. (2985, 304) -> b' severely' occured 1 times.\n",
      "4686/4744 pairs merged. (2390, 1927) -> b' Princes' occured 1 times.\n",
      "4687/4744 pairs merged. (2391, 108) -> b' settl' occured 1 times.\n",
      "4688/4744 pairs merged. (4687, 393) -> b' settlers' occured 1 times.\n",
      "4689/4744 pairs merged. (3120, 263) -> b' rebelled' occured 1 times.\n",
      "4690/4744 pairs merged. (51, 1418) -> b'317' occured 1 times.\n",
      "4691/4744 pairs merged. (539, 910) -> b' prince' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 4453/4744 [00:39<00:02, 122.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4692/4744 pairs merged. (391, 855) -> b' Rui' occured 1 times.\n",
      "4693/4744 pairs merged. (2390, 105) -> b' Pri' occured 1 times.\n",
      "4694/4744 pairs merged. (4693, 276) -> b' Prior' occured 1 times.\n",
      "4695/4744 pairs merged. (1924, 52) -> b'304' occured 1 times.\n",
      "4696/4744 pairs merged. (78, 276) -> b'Nor' occured 1 times.\n",
      "4697/4744 pairs merged. (4696, 447) -> b'Northern' occured 1 times.\n",
      "4698/4744 pairs merged. (414, 709) -> b' Jie' occured 1 times.\n",
      "4699/4744 pairs merged. (455, 105) -> b' Di' occured 1 times.\n",
      "4700/4744 pairs merged. (115, 1729) -> b'sinic' occured 1 times.\n",
      "4701/4744 pairs merged. (4700, 715) -> b'sinicized' occured 1 times.\n",
      "4702/4744 pairs merged. (327, 2397) -> b' ascent' occured 1 times.\n",
      "4703/4744 pairs merged. (539, 1460) -> b' promp' occured 1 times.\n",
      "4704/4744 pairs merged. (4703, 416) -> b' prompted' occured 1 times.\n",
      "4705/4744 pairs merged. (2399, 333) -> b' migration' occured 1 times.\n",
      "4706/4744 pairs merged. (455, 2082) -> b' Delta' occured 1 times.\n",
      "4707/4744 pairs merged. (1570, 928) -> b' paralle' occured 1 times.\n",
      "4708/4744 pairs merged. (4707, 108) -> b' parallel' occured 1 times.\n",
      "4709/4744 pairs merged. (1465, 3133) -> b' halves' occured 1 times.\n",
      "4710/4744 pairs merged. (414, 379) -> b' Jian' occured 1 times.\n",
      "4711/4744 pairs merged. (4710, 3135) -> b' Jiankang' occured 1 times.\n",
      "4712/4744 pairs merged. (3137, 765) -> b' attacks' occured 1 times.\n",
      "4713/4744 pairs merged. (2893, 379) -> b' barbarian' occured 1 times.\n",
      "4714/4744 pairs merged. (280, 258) -> b' sin' occured 1 times.\n",
      "4715/4744 pairs merged. (4714, 1930) -> b' sinify' occured 1 times.\n",
      "4716/4744 pairs merged. (673, 2572) -> b' extingu' occured 1 times.\n",
      "4717/4744 pairs merged. (4716, 693) -> b' extinguished' occured 1 times.\n",
      "4718/4744 pairs merged. (446, 837) -> b' kingdom' occured 1 times.\n",
      "4719/4744 pairs merged. (740, 2400) -> b' married' occured 1 times.\n",
      "4720/4744 pairs merged. (846, 1980) -> b' surnam' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 4483/4744 [00:40<00:02, 129.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4721/4744 pairs merged. (4720, 281) -> b' surnames' occured 1 times.\n",
      "4722/4744 pairs merged. (1852, 811) -> b' debates' occured 1 times.\n",
      "4723/4744 pairs merged. (724, 920) -> b' should' occured 1 times.\n",
      "4724/4744 pairs merged. (1981, 409) -> b' frequ' occured 1 times.\n",
      "4725/4744 pairs merged. (4724, 2350) -> b' frequently' occured 1 times.\n",
      "4726/4744 pairs merged. (1661, 591) -> b' nobl' occured 1 times.\n",
      "4727/4744 pairs merged. (4726, 281) -> b' nobles' occured 1 times.\n",
      "4728/4744 pairs merged. (986, 834) -> b' Buddhists' occured 1 times.\n",
      "4729/4744 pairs merged. (1557, 834) -> b' Taoists' occured 1 times.\n",
      "4730/4744 pairs merged. (589, 1893) -> b' become' occured 1 times.\n",
      "4731/4744 pairs merged. (3139, 488) -> b' tolerant' occured 1 times.\n",
      "4732/4744 pairs merged. (315, 349) -> b' Mid' occured 1 times.\n",
      "4733/4744 pairs merged. (45, 105) -> b'-i' occured 1 times.\n",
      "4734/4744 pairs merged. (4733, 533) -> b'-imperial' occured 1 times.\n",
      "4735/4744 pairs merged. (283, 290) -> b' pion' occured 1 times.\n",
      "4736/4744 pairs merged. (4735, 101) -> b' pione' occured 1 times.\n",
      "4737/4744 pairs merged. (4736, 562) -> b' pioneered' occured 1 times.\n",
      "4738/4744 pairs merged. (3149, 494) -> b' select' occured 1 times.\n",
      "4739/4744 pairs merged. (4738, 278) -> b' selecting' occured 1 times.\n",
      "4740/4744 pairs merged. (1045, 393) -> b' commoners' occured 1 times.\n",
      "4741/4744 pairs merged. (1574, 275) -> b' equal' occured 1 times.\n",
      "4742/4744 pairs merged. (282, 1642) -> b' distribut' occured 1 times.\n",
      "4743/4744 pairs merged. (4742, 553) -> b' distributions' occured 1 times.\n",
      "4744/4744 pairs merged. (813, 275) -> b' weal' occured 1 times.\n",
      "4745/4744 pairs merged. (4744, 348) -> b' wealth' occured 1 times.\n",
      "4746/4744 pairs merged. (997, 274) -> b' Stand' occured 1 times.\n",
      "4747/4744 pairs merged. (4746, 600) -> b' Standard' occured 1 times.\n",
      "4748/4744 pairs merged. (4747, 715) -> b' Standardized' occured 1 times.\n",
      "4749/4744 pairs merged. (1109, 545) -> b' root' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 4512/4744 [00:40<00:01, 130.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4750/4744 pairs merged. (293, 934) -> b' meg' occured 1 times.\n",
      "4751/4744 pairs merged. (4750, 97) -> b' mega' occured 1 times.\n",
      "4752/4744 pairs merged. (45, 3158) -> b'-construc' occured 1 times.\n",
      "4753/4744 pairs merged. (4752, 789) -> b'-construction' occured 1 times.\n",
      "4754/4744 pairs merged. (1735, 1233) -> b' Intended' occured 1 times.\n",
      "4755/4744 pairs merged. (3159, 357) -> b' shipment' occured 1 times.\n",
      "4756/4744 pairs merged. (1327, 112) -> b' transp' occured 1 times.\n",
      "4757/4744 pairs merged. (4756, 601) -> b' transport' occured 1 times.\n",
      "4758/4744 pairs merged. (4757, 278) -> b' transporting' occured 1 times.\n",
      "4759/4744 pairs merged. (1937, 416) -> b' constructed' occured 1 times.\n",
      "4760/4744 pairs merged. (455, 1191) -> b' Dax' occured 1 times.\n",
      "4761/4744 pairs merged. (4760, 278) -> b' Daxing' occured 1 times.\n",
      "4762/4744 pairs merged. (67, 104) -> b'Ch' occured 1 times.\n",
      "4763/4744 pairs merged. (4762, 311) -> b'Chang' occured 1 times.\n",
      "4764/4744 pairs merged. (813, 2107) -> b' wealthy' occured 1 times.\n",
      "4765/4744 pairs merged. (283, 360) -> b' pac' occured 1 times.\n",
      "4766/4744 pairs merged. (4765, 891) -> b' pacified' occured 1 times.\n",
      "4767/4744 pairs merged. (1987, 259) -> b' Korean' occured 1 times.\n",
      "4768/4744 pairs merged. (3162, 1849) -> b' Penins' occured 1 times.\n",
      "4769/4744 pairs merged. (4768, 314) -> b' Peninsul' occured 1 times.\n",
      "4770/4744 pairs merged. (4769, 97) -> b' Peninsula' occured 1 times.\n",
      "4771/4744 pairs merged. (466, 473) -> b' Gog' occured 1 times.\n",
      "4772/4744 pairs merged. (4771, 654) -> b' Gogury' occured 1 times.\n",
      "4773/4744 pairs merged. (4772, 101) -> b' Gogurye' occured 1 times.\n",
      "4774/4744 pairs merged. (4773, 111) -> b' Goguryeo' occured 1 times.\n",
      "4775/4744 pairs merged. (441, 83) -> b'\\xe2\\x80\\x93S' occured 1 times.\n",
      "4776/4744 pairs merged. (4775, 855) -> b'\\xe2\\x80\\x93Sui' occured 1 times.\n",
      "4777/4744 pairs merged. (1903, 114) -> b' disastr' occured 1 times.\n",
      "4778/4744 pairs merged. (4777, 1457) -> b' disastrously' occured 1 times.\n",
      "4779/4744 pairs merged. (3165, 261) -> b' trigger' occured 1 times.\n",
      "4780/4744 pairs merged. (4779, 278) -> b' triggering' occured 1 times.\n",
      "4781/4744 pairs merged. (271, 505) -> b' creat' occured 1 times.\n",
      "4782/4744 pairs merged. (4781, 422) -> b' creative' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 4555/4744 [00:40<00:01, 128.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4783/4744 pairs merged. (466, 2915) -> b' Gaoz' occured 1 times.\n",
      "4784/4744 pairs merged. (4783, 117) -> b' Gaozu' occured 1 times.\n",
      "4785/4744 pairs merged. (429, 353) -> b' Shim' occured 1 times.\n",
      "4786/4744 pairs merged. (4785, 258) -> b' Shimin' occured 1 times.\n",
      "4787/4744 pairs merged. (3172, 323) -> b' Taizong' occured 1 times.\n",
      "4788/4744 pairs merged. (906, 98) -> b' Comb' occured 1 times.\n",
      "4789/4744 pairs merged. (4788, 1442) -> b' Combined' occured 1 times.\n",
      "4790/4744 pairs merged. (2415, 115) -> b' threats' occured 1 times.\n",
      "4791/4744 pairs merged. (315, 308) -> b' Mil' occured 1 times.\n",
      "4792/4744 pairs merged. (4791, 614) -> b' Military' occured 1 times.\n",
      "4793/4744 pairs merged. (1608, 1441) -> b' victories' occured 1 times.\n",
      "4794/4744 pairs merged. (1963, 278) -> b' connecting' occured 1 times.\n",
      "4795/4744 pairs merged. (300, 3173) -> b' lucrative' occured 1 times.\n",
      "4796/4744 pairs merged. (2419, 488) -> b' distant' occured 1 times.\n",
      "4797/4744 pairs merged. (2337, 530) -> b' encourag' occured 1 times.\n",
      "4798/4744 pairs merged. (4797, 278) -> b' encouraging' occured 1 times.\n",
      "4799/4744 pairs merged. (266, 2421) -> b' obs' occured 1 times.\n",
      "4800/4744 pairs merged. (4799, 261) -> b' obser' occured 1 times.\n",
      "4801/4744 pairs merged. (4800, 785) -> b' observed' occured 1 times.\n",
      "4802/4744 pairs merged. (3177, 416) -> b' adapted' occured 1 times.\n",
      "4803/4744 pairs merged. (1735, 1994) -> b' Internally' occured 1 times.\n",
      "4804/4744 pairs merged. (1882, 2422) -> b' linked' occured 1 times.\n",
      "4805/4744 pairs merged. (3179, 311) -> b' Xuanzang' occured 1 times.\n",
      "4806/4744 pairs merged. (1139, 107) -> b' monk' occured 1 times.\n",
      "4807/4744 pairs merged. (3181, 261) -> b' traveller' occured 1 times.\n",
      "4808/4744 pairs merged. (1327, 108) -> b' transl' occured 1 times.\n",
      "4809/4744 pairs merged. (4808, 269) -> b' translat' occured 1 times.\n",
      "4810/4744 pairs merged. (4809, 276) -> b' translator' occured 1 times.\n",
      "4811/4744 pairs merged. (3181, 263) -> b' travelled' occured 1 times.\n",
      "4812/4744 pairs merged. (3182, 1714) -> b' returned' occured 1 times.\n",
      "4813/4744 pairs merged. (996, 104) -> b' Mah' occured 1 times.\n",
      "4814/4744 pairs merged. (4813, 3183) -> b' Mahayana' occured 1 times.\n",
      "4815/4744 pairs merged. (356, 258) -> b' Hin' occured 1 times.\n",
      "4816/4744 pairs merged. (4815, 3183) -> b' Hinayana' occured 1 times.\n",
      "4817/4744 pairs merged. (487, 117) -> b' statu' occured 1 times.\n",
      "4818/4744 pairs merged. (4817, 281) -> b' statues' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 4584/4744 [00:40<00:01, 135.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4819/4744 pairs merged. (986, 97) -> b' Buddha' occured 1 times.\n",
      "4820/4744 pairs merged. (280, 285) -> b' sar' occured 1 times.\n",
      "4821/4744 pairs merged. (4820, 382) -> b' sarir' occured 1 times.\n",
      "4822/4744 pairs merged. (4821, 97) -> b' sarira' occured 1 times.\n",
      "4823/4744 pairs merged. (750, 1782) -> b' relics' occured 1 times.\n",
      "4824/4744 pairs merged. (46, 34) -> b'.\"' occured 1 times.\n",
      "4825/4744 pairs merged. (4824, 10) -> b'.\"\\n' occured 1 times.\n",
      "4826/4744 pairs merged. (592, 338) -> b' abet' occured 1 times.\n",
      "4827/4744 pairs merged. (4826, 416) -> b' abetted' occured 1 times.\n",
      "4828/4744 pairs merged. (2846, 715) -> b' organized' occured 1 times.\n",
      "4829/4744 pairs merged. (3184, 695) -> b'Three' occured 1 times.\n",
      "4830/4744 pairs merged. (280, 515) -> b' sep' occured 1 times.\n",
      "4831/4744 pairs merged. (4830, 285) -> b' separ' occured 1 times.\n",
      "4832/4744 pairs merged. (4831, 390) -> b' separate' occured 1 times.\n",
      "4833/4744 pairs merged. (4832, 304) -> b' separately' occured 1 times.\n",
      "4834/4744 pairs merged. (1249, 97) -> b' dra' occured 1 times.\n",
      "4835/4744 pairs merged. (4834, 1911) -> b' draft' occured 1 times.\n",
      "4836/4744 pairs merged. (3185, 709) -> b' revie' occured 1 times.\n",
      "4837/4744 pairs merged. (4836, 119) -> b' review' occured 1 times.\n",
      "4838/4744 pairs merged. (3187, 2404) -> b' departments' occured 1 times.\n",
      "4839/4744 pairs merged. (367, 334) -> b' run' occured 1 times.\n",
      "4840/4744 pairs merged. (620, 263) -> b' landed' occured 1 times.\n",
      "4841/4744 pairs merged. (270, 548) -> b' wore' occured 1 times.\n",
      "4842/4744 pairs merged. (3149, 1353) -> b' selected' occured 1 times.\n",
      "4843/4744 pairs merged. (283, 1687) -> b' patt' occured 1 times.\n",
      "4844/4744 pairs merged. (4843, 404) -> b' pattern' occured 1 times.\n",
      "4845/4744 pairs merged. (4844, 115) -> b' patterns' occured 1 times.\n",
      "4846/4744 pairs merged. (3191, 460) -> b'Under' occured 1 times.\n",
      "4847/4744 pairs merged. (1955, 263) -> b' owned' occured 1 times.\n",
      "4848/4744 pairs merged. (1904, 1290) -> b' household' occured 1 times.\n",
      "4849/4744 pairs merged. (280, 1902) -> b' size' occured 1 times.\n",
      "4850/4744 pairs merged. (315, 268) -> b' Men' occured 1 times.\n",
      "4851/4744 pairs merged. (1042, 118) -> b' serv' occured 1 times.\n",
      "4852/4744 pairs merged. (4851, 2201) -> b' service' occured 1 times.\n",
      "4853/4744 pairs merged. (284, 2172) -> b' fixed' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 4613/4744 [00:41<00:00, 132.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4854/4744 pairs merged. (1350, 121) -> b' policy' occured 1 times.\n",
      "4855/4744 pairs merged. (3193, 313) -> b' productiv' occured 1 times.\n",
      "4856/4744 pairs merged. (4855, 467) -> b' productivity' occured 1 times.\n",
      "4857/4744 pairs merged. (365, 701) -> b' without' occured 1 times.\n",
      "4858/4744 pairs merged. (1848, 100) -> b' burd' occured 1 times.\n",
      "4859/4744 pairs merged. (4858, 268) -> b' burden' occured 1 times.\n",
      "4860/4744 pairs merged. (3194, 112) -> b' midp' occured 1 times.\n",
      "4861/4744 pairs merged. (4860, 826) -> b' midpoin' occured 1 times.\n",
      "4862/4744 pairs merged. (4861, 116) -> b' midpoint' occured 1 times.\n",
      "4863/4744 pairs merged. (914, 1457) -> b' continuously' occured 1 times.\n",
      "4864/4744 pairs merged. (1086, 278) -> b' falling' occured 1 times.\n",
      "4865/4744 pairs merged. (1955, 393) -> b' owners' occured 1 times.\n",
      "4866/4744 pairs merged. (385, 981) -> b' exemp' occured 1 times.\n",
      "4867/4744 pairs merged. (4866, 116) -> b' exempt' occured 1 times.\n",
      "4868/4744 pairs merged. (4867, 553) -> b' exemptions' occured 1 times.\n",
      "4869/4744 pairs merged. (524, 110) -> b' regn' occured 1 times.\n",
      "4870/4744 pairs merged. (4869, 488) -> b' regnant' occured 1 times.\n",
      "4871/4744 pairs merged. (3179, 323) -> b' Xuanzong' occured 1 times.\n",
      "4872/4744 pairs merged. (2581, 1257) -> b' stretched' occured 1 times.\n",
      "4873/4744 pairs merged. (399, 360) -> b' Pac' occured 1 times.\n",
      "4874/4744 pairs merged. (4873, 853) -> b' Pacific' occured 1 times.\n",
      "4875/4744 pairs merged. (346, 630) -> b' Aral' occured 1 times.\n",
      "4876/4744 pairs merged. (53, 48) -> b'50' occured 1 times.\n",
      "4877/4744 pairs merged. (1404, 1531) -> b' artistic' occured 1 times.\n",
      "4878/4744 pairs merged. (1200, 573) -> b' creations' occured 1 times.\n",
      "4879/4744 pairs merged. (1544, 115) -> b' poets' occured 1 times.\n",
      "4880/4744 pairs merged. (455, 117) -> b' Du' occured 1 times.\n",
      "4881/4744 pairs merged. (397, 413) -> b' Lus' occured 1 times.\n",
      "4882/4744 pairs merged. (4881, 694) -> b' Lushan' occured 1 times.\n",
      "4883/4744 pairs merged. (55, 2726) -> b'755' occured 1 times.\n",
      "4884/4744 pairs merged. (2289, 51) -> b'763' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 4658/4744 [00:41<00:00, 132.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4885/4744 pairs merged. (3199, 393) -> b' waters' occured 1 times.\n",
      "4886/4744 pairs merged. (4885, 503) -> b' watershed' occured 1 times.\n",
      "4887/4744 pairs merged. (543, 3202) -> b' disruption' occured 1 times.\n",
      "4888/4744 pairs merged. (1125, 572) -> b' jied' occured 1 times.\n",
      "4889/4744 pairs merged. (4888, 413) -> b' jiedus' occured 1 times.\n",
      "4890/4744 pairs merged. (4889, 2434) -> b' jiedushi' occured 1 times.\n",
      "4891/4744 pairs merged. (301, 1686) -> b' reven' occured 1 times.\n",
      "4892/4744 pairs merged. (4891, 728) -> b' revenue' occured 1 times.\n",
      "4893/4744 pairs merged. (301, 304) -> b' rely' occured 1 times.\n",
      "4894/4744 pairs merged. (521, 411) -> b' heav' occured 1 times.\n",
      "4895/4744 pairs merged. (4894, 1131) -> b' heavily' occured 1 times.\n",
      "4896/4744 pairs merged. (280, 275) -> b' sal' occured 1 times.\n",
      "4897/4744 pairs merged. (4896, 116) -> b' salt' occured 1 times.\n",
      "4898/4744 pairs merged. (1139, 362) -> b' monop' occured 1 times.\n",
      "4899/4744 pairs merged. (4898, 3207) -> b' monopoly' occured 1 times.\n",
      "4900/4744 pairs merged. (3208, 1994) -> b' Externally' occured 1 times.\n",
      "4901/4744 pairs merged. (3209, 294) -> b' submis' occured 1 times.\n",
      "4902/4744 pairs merged. (4901, 1743) -> b' submissive' occured 1 times.\n",
      "4903/4744 pairs merged. (3210, 1041) -> b' raided' occured 1 times.\n",
      "4904/4744 pairs merged. (781, 329) -> b' Never' occured 1 times.\n",
      "4905/4744 pairs merged. (4904, 344) -> b' Neverthe' occured 1 times.\n",
      "4906/4744 pairs merged. (4905, 1633) -> b' Nevertheless' occured 1 times.\n",
      "4907/4744 pairs merged. (2436, 263) -> b' recovered' occured 1 times.\n",
      "4908/4744 pairs merged. (342, 114) -> b' thr' occured 1 times.\n",
      "4909/4744 pairs merged. (4908, 713) -> b' thrived' occured 1 times.\n",
      "4910/4744 pairs merged. (595, 110) -> b' worn' occured 1 times.\n",
      "4911/4744 pairs merged. (617, 307) -> b' recur' occured 1 times.\n",
      "4912/4744 pairs merged. (4911, 880) -> b' recurring' occured 1 times.\n",
      "4913/4744 pairs merged. (1263, 3214) -> b' factional' occured 1 times.\n",
      "4914/4744 pairs merged. (1541, 2157) -> b' corrupted' occured 1 times.\n",
      "4915/4744 pairs merged. (289, 3216) -> b' Catastrop' occured 1 times.\n",
      "4916/4744 pairs merged. (4915, 104) -> b' Catastroph' occured 1 times.\n",
      "4917/4744 pairs merged. (4916, 1062) -> b' Catastrophically' occured 1 times.\n",
      "4918/4744 pairs merged. (2440, 52) -> b'874' occured 1 times.\n",
      "4919/4744 pairs merged. (56, 1938) -> b'884' occured 1 times.\n",
      "4920/4744 pairs merged. (2440, 57) -> b'879' occured 1 times.\n",
      "4921/4744 pairs merged. (3217, 265) -> b' massacre' occured 1 times.\n",
      "4922/4744 pairs merged. (32, 1140) -> b' esp' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 4687/4744 [00:41<00:00, 128.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4923/4744 pairs merged. (4922, 319) -> b' espec' occured 1 times.\n",
      "4924/4744 pairs merged. (4923, 2441) -> b' especially' occured 1 times.\n",
      "4925/4744 pairs merged. (1301, 108) -> b' encl' occured 1 times.\n",
      "4926/4744 pairs merged. (4925, 2806) -> b' enclaves' occured 1 times.\n",
      "4927/4744 pairs merged. (56, 56) -> b'88' occured 1 times.\n",
      "4928/4744 pairs merged. (4927, 49) -> b'881' occured 1 times.\n",
      "4929/4744 pairs merged. (1253, 950) -> b' successively' occured 1 times.\n",
      "4930/4744 pairs merged. (750, 1064) -> b' reliance' occured 1 times.\n",
      "4931/4744 pairs merged. (1518, 278) -> b' suppressing' occured 1 times.\n",
      "4932/4744 pairs merged. (1634, 56) -> b'808' occured 1 times.\n",
      "4933/4744 pairs merged. (723, 1353) -> b' defected' occured 1 times.\n",
      "4934/4744 pairs merged. (2986, 693) -> b' punished' occured 1 times.\n",
      "4935/4744 pairs merged. (1502, 278) -> b' killing' occured 1 times.\n",
      "4936/4744 pairs merged. (3228, 278) -> b' chasing' occured 1 times.\n",
      "4937/4744 pairs merged. (331, 281) -> b' Bes' occured 1 times.\n",
      "4938/4744 pairs merged. (4937, 104) -> b' Besh' occured 1 times.\n",
      "4939/4744 pairs merged. (4938, 2444) -> b' Beshbali' occured 1 times.\n",
      "4940/4744 pairs merged. (4939, 107) -> b' Beshbalik' occured 1 times.\n",
      "4941/4744 pairs merged. (76, 105) -> b'Li' occured 1 times.\n",
      "4942/4744 pairs merged. (2010, 1211) -> b' Guochang' occured 1 times.\n",
      "4943/4744 pairs merged. (284, 1159) -> b' fellow' occured 1 times.\n",
      "4944/4744 pairs merged. (56, 2392) -> b'839' occured 1 times.\n",
      "4945/4744 pairs merged. (72, 117) -> b'Hu' occured 1 times.\n",
      "4946/4744 pairs merged. (4945, 368) -> b'Huig' occured 1 times.\n",
      "4947/4744 pairs merged. (4946, 117) -> b'Huigu' occured 1 times.\n",
      "4948/4744 pairs merged. (414, 117) -> b' Ju' occured 1 times.\n",
      "4949/4744 pairs merged. (4948, 358) -> b' Juel' occured 1 times.\n",
      "4950/4744 pairs merged. (4949, 117) -> b' Juelu' occured 1 times.\n",
      "4951/4744 pairs merged. (4950, 322) -> b' Jueluow' occured 1 times.\n",
      "4952/4744 pairs merged. (4951, 117) -> b' Jueluowu' occured 1 times.\n",
      "4953/4744 pairs merged. (230, 142) -> b'\\xe6\\x8e' occured 1 times.\n",
      "4954/4744 pairs merged. (4953, 152) -> b'\\xe6\\x8e\\x98' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 4716/4744 [00:41<00:00, 134.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4955/4744 pairs merged. (4954, 231) -> b'\\xe6\\x8e\\x98\\xe7' occured 1 times.\n",
      "4956/4744 pairs merged. (4955, 190) -> b'\\xe6\\x8e\\x98\\xe7\\xbe' occured 1 times.\n",
      "4957/4744 pairs merged. (4956, 133) -> b'\\xe6\\x8e\\x98\\xe7\\xbe\\x85' occured 1 times.\n",
      "4958/4744 pairs merged. (4957, 229) -> b'\\xe6\\x8e\\x98\\xe7\\xbe\\x85\\xe5' occured 1 times.\n",
      "4959/4744 pairs merged. (4958, 139) -> b'\\xe6\\x8e\\x98\\xe7\\xbe\\x85\\xe5\\x8b' occured 1 times.\n",
      "4960/4744 pairs merged. (4959, 191) -> b'\\xe6\\x8e\\x98\\xe7\\xbe\\x85\\xe5\\x8b\\xbf' occured 1 times.\n",
      "4961/4744 pairs merged. (1109, 377) -> b' rose' occured 1 times.\n",
      "4962/4744 pairs merged. (45, 265) -> b'-re' occured 1 times.\n",
      "4963/4744 pairs merged. (4962, 465) -> b'-reign' occured 1 times.\n",
      "4964/4744 pairs merged. (4963, 278) -> b'-reigning' occured 1 times.\n",
      "4965/4744 pairs merged. (1007, 287) -> b' elic' occured 1 times.\n",
      "4966/4744 pairs merged. (4965, 899) -> b' elicited' occured 1 times.\n",
      "4967/4744 pairs merged. (2163, 112) -> b' help' occured 1 times.\n",
      "4968/4744 pairs merged. (310, 812) -> b' hors' occured 1 times.\n",
      "4969/4744 pairs merged. (4968, 281) -> b' horses' occured 1 times.\n",
      "4970/4744 pairs merged. (3239, 940) -> b' precipitating' occured 1 times.\n",
      "4971/4744 pairs merged. (2622, 377) -> b' collapse' occured 1 times.\n",
      "4972/4744 pairs merged. (1956, 950) -> b' extensively' occured 1 times.\n",
      "4973/4744 pairs merged. (271, 403) -> b' coun' occured 1 times.\n",
      "4974/4744 pairs merged. (4973, 471) -> b' counter' occured 1 times.\n",
      "4975/4744 pairs merged. (4974, 1687) -> b' counteratt' occured 1 times.\n",
      "4976/4744 pairs merged. (4975, 360) -> b' counterattac' occured 1 times.\n",
      "4977/4744 pairs merged. (4976, 1208) -> b' counterattacking' occured 1 times.\n",
      "4978/4744 pairs merged. (1938, 51) -> b'843' occured 1 times.\n",
      "4979/4744 pairs merged. (3243, 261) -> b' officer' occured 1 times.\n",
      "4980/4744 pairs merged. (3244, 121) -> b' Tuy' occured 1 times.\n",
      "4981/4744 pairs merged. (4980, 117) -> b' Tuyu' occured 1 times.\n",
      "4982/4744 pairs merged. (4981, 104) -> b' Tuyuh' occured 1 times.\n",
      "4983/4744 pairs merged. (4982, 334) -> b' Tuyuhun' occured 1 times.\n",
      "4984/4744 pairs merged. (2367, 117) -> b' slau' occured 1 times.\n",
      "4985/4744 pairs merged. (4984, 435) -> b' slaugh' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4744/4744 [00:42<00:00, 112.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4986/4744 pairs merged. (4985, 471) -> b' slaughter' occured 1 times.\n",
      "4987/4744 pairs merged. (1439, 1639) -> b' Shahu' occured 1 times.\n",
      "4988/4744 pairs merged. (1227, 1107) -> b' respects' occured 1 times.\n",
      "4989/4744 pairs merged. (2315, 105) -> b' multi' occured 1 times.\n",
      "4990/4744 pairs merged. (3252, 390) -> b'-state' occured 1 times.\n",
      "4991/4744 pairs merged. (3256, 323) -> b' Among' occured 1 times.\n",
      "4992/4744 pairs merged. (610, 304) -> b' mostly' occured 1 times.\n",
      "4993/4744 pairs merged. (271, 463) -> b' cum' occured 1 times.\n",
      "4994/4744 pairs merged. (4993, 314) -> b' cumul' occured 1 times.\n",
      "4995/4744 pairs merged. (4994, 2229) -> b' cumulatively' occured 1 times.\n",
      "4996/4744 pairs merged. (2570, 263) -> b' constituted' occured 1 times.\n",
      "4997/4744 pairs merged. (34, 394) -> b'\".\\n' occured 1 times.\n",
      "4998/4744 pairs merged. (65, 109) -> b'Am' occured 1 times.\n",
      "4999/4744 pairs merged. (4998, 1967) -> b'Amidst' occured 1 times.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BPETokenizer(pattern=None)\n",
    "tokenizer.train(text, vocab_size=5000, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "29a13927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text to token id: 256\n",
      "token id to text:  t\n",
      "text to token id: 257\n",
      "token id to text: he\n",
      "text to token id: 258\n",
      "token id to text: in\n",
      "text to token id: 259\n",
      "token id to text: an\n",
      "text to token id: 260\n",
      "token id to text:  the\n",
      "text to token id: 261\n",
      "token id to text: er\n",
      "text to token id: 262\n",
      "token id to text: on\n",
      "text to token id: 263\n",
      "token id to text: ed\n",
      "text to token id: 264\n",
      "token id to text: st\n",
      "text to token id: 265\n",
      "token id to text: re\n",
      "text to token id: 266\n",
      "token id to text:  o\n",
      "text to token id: 267\n",
      "token id to text:  a\n",
      "text to token id: 268\n",
      "token id to text: en\n",
      "text to token id: 269\n",
      "token id to text: at\n",
      "text to token id: 270\n",
      "token id to text:  w\n",
      "text to token id: 271\n",
      "token id to text:  c\n",
      "text to token id: 272\n",
      "token id to text:  of\n",
      "text to token id: 273\n",
      "token id to text: it\n",
      "text to token id: 274\n",
      "token id to text: and\n",
      "text to token id: 275\n",
      "token id to text: al\n",
      "text to token id: 276\n",
      "token id to text: or\n",
      "text to token id: 277\n",
      "token id to text:  in\n",
      "text to token id: 278\n",
      "token id to text: ing\n",
      "text to token id: 279\n",
      "token id to text:  and\n",
      "text to token id: 280\n",
      "token id to text:  s\n",
      "text to token id: 281\n",
      "token id to text: es\n",
      "text to token id: 282\n",
      "token id to text:  d\n",
      "text to token id: 283\n",
      "token id to text:  p\n",
      "text to token id: 284\n",
      "token id to text:  f\n",
      "text to token id: 285\n",
      "token id to text: ar\n",
      "text to token id: 286\n",
      "token id to text: ou\n",
      "text to token id: 287\n",
      "token id to text: ic\n",
      "text to token id: 288\n",
      "token id to text:  b\n",
      "text to token id: 289\n",
      "token id to text:  C\n",
      "text to token id: 290\n",
      "token id to text: ion\n",
      "text to token id: 291\n",
      "token id to text:  e\n",
      "text to token id: 292\n",
      "token id to text: ent\n",
      "text to token id: 293\n",
      "token id to text:  m\n",
      "text to token id: 294\n",
      "token id to text: is\n",
      "text to token id: 295\n",
      "token id to text: as\n",
      "text to token id: 296\n",
      "token id to text:  to\n",
      "text to token id: 297\n",
      "token id to text:  Ch\n",
      "text to token id: 298\n",
      "token id to text: om\n",
      "text to token id: 299\n",
      "token id to text:  T\n",
      "text to token id: 300\n",
      "token id to text:  l\n",
      "text to token id: 301\n",
      "token id to text:  re\n",
      "text to token id: 302\n",
      "token id to text:  Chin\n",
      "text to token id: 303\n",
      "token id to text: ast\n",
      "text to token id: 304\n",
      "token id to text: ly\n",
      "text to token id: 305\n",
      "token id to text: ol\n",
      "text to token id: 306\n",
      "token id to text:  S\n",
      "text to token id: 307\n",
      "token id to text: ur\n",
      "text to token id: 308\n",
      "token id to text: il\n",
      "text to token id: 309\n",
      "token id to text: ==\n",
      "text to token id: 310\n",
      "token id to text:  h\n",
      "text to token id: 311\n",
      "token id to text: ang\n",
      "text to token id: 312\n",
      "token id to text: mp\n",
      "text to token id: 313\n",
      "token id to text: iv\n",
      "text to token id: 314\n",
      "token id to text: ul\n",
      "text to token id: 315\n",
      "token id to text:  M\n",
      "text to token id: 316\n",
      "token id to text: yn\n",
      "text to token id: 317\n",
      "token id to text: ynast\n",
      "text to token id: 318\n",
      "token id to text:  dynast\n",
      "text to token id: 319\n",
      "token id to text: ec\n",
      "text to token id: 320\n",
      "token id to text:  n\n",
      "text to token id: 321\n",
      "token id to text: ad\n",
      "text to token id: 322\n",
      "token id to text: ow\n",
      "text to token id: 323\n",
      "token id to text: ong\n",
      "text to token id: 324\n",
      "token id to text:  dynasty\n",
      "text to token id: 325\n",
      "token id to text:  g\n",
      "text to token id: 326\n",
      "token id to text:  was\n",
      "text to token id: 327\n",
      "token id to text:  as\n",
      "text to token id: 328\n",
      "token id to text:  China\n",
      "text to token id: 329\n",
      "token id to text: ver\n",
      "text to token id: 330\n",
      "token id to text:  con\n",
      "text to token id: 331\n",
      "token id to text:  B\n",
      "text to token id: 332\n",
      "token id to text: ro\n",
      "text to token id: 333\n",
      "token id to text: ation\n",
      "text to token id: 334\n",
      "token id to text: un\n",
      "text to token id: 335\n",
      "token id to text: ist\n",
      "text to token id: 336\n",
      "token id to text:  The\n",
      "text to token id: 337\n",
      "token id to text:  st\n",
      "text to token id: 338\n",
      "token id to text: et\n",
      "text to token id: 339\n",
      "token id to text: ith\n",
      "text to token id: 340\n",
      "token id to text: \n",
      "\n",
      "\n",
      "text to token id: 341\n",
      "token id to text: ch\n",
      "text to token id: 342\n",
      "token id to text:  th\n",
      "text to token id: 343\n",
      "token id to text: ce\n",
      "text to token id: 344\n",
      "token id to text: the\n",
      "text to token id: 345\n",
      "token id to text: le\n",
      "text to token id: 346\n",
      "token id to text:  A\n",
      "text to token id: 347\n",
      "token id to text: ese\n",
      "text to token id: 348\n",
      "token id to text: th\n",
      "text to token id: 349\n",
      "token id to text: id\n",
      "text to token id: 350\n",
      "token id to text: ies\n",
      "text to token id: 351\n",
      "token id to text:  (\n",
      "text to token id: 352\n",
      "token id to text:  by\n",
      "text to token id: 353\n",
      "token id to text: im\n",
      "text to token id: 354\n",
      "token id to text:  W\n",
      "text to token id: 355\n",
      "token id to text:  for\n",
      "text to token id: 356\n",
      "token id to text:  H\n",
      "text to token id: 357\n",
      "token id to text: ment\n",
      "text to token id: 358\n",
      "token id to text: el\n",
      "text to token id: 359\n",
      "token id to text: ther\n",
      "text to token id: 360\n",
      "token id to text: ac\n",
      "text to token id: 361\n",
      "token id to text: ut\n",
      "text to token id: 362\n",
      "token id to text: op\n",
      "text to token id: 363\n",
      "token id to text:  wh\n",
      "text to token id: 364\n",
      "token id to text: ere\n",
      "text to token id: 365\n",
      "token id to text:  with\n",
      "text to token id: 366\n",
      "token id to text:  were\n",
      "text to token id: 367\n",
      "token id to text:  r\n",
      "text to token id: 368\n",
      "token id to text: ig\n",
      "text to token id: 369\n",
      "token id to text:  E\n",
      "text to token id: 370\n",
      "token id to text: est\n",
      "text to token id: 371\n",
      "token id to text:  Chinese\n",
      "text to token id: 372\n",
      "token id to text: ial\n",
      "text to token id: 373\n",
      "token id to text:  su\n",
      "text to token id: 374\n",
      "token id to text: ap\n",
      "text to token id: 375\n",
      "token id to text: ated\n",
      "text to token id: 376\n",
      "token id to text: ain\n",
      "text to token id: 377\n",
      "token id to text: se\n",
      "text to token id: 378\n",
      "token id to text: od\n",
      "text to token id: 379\n",
      "token id to text: ian\n",
      "text to token id: 380\n",
      "token id to text:  be\n",
      "text to token id: 381\n",
      "token id to text: ure\n",
      "text to token id: 382\n",
      "token id to text: ir\n",
      "text to token id: 383\n",
      "token id to text: mper\n",
      "text to token id: 384\n",
      "token id to text: am\n",
      "text to token id: 385\n",
      "token id to text:  ex\n",
      "text to token id: 386\n",
      "token id to text:  on\n",
      "text to token id: 387\n",
      "token id to text:  de\n",
      "text to token id: 388\n",
      "token id to text: ult\n",
      "text to token id: 389\n",
      "token id to text: ia\n",
      "text to token id: 390\n",
      "token id to text: ate\n",
      "text to token id: 391\n",
      "token id to text:  R\n",
      "text to token id: 392\n",
      "token id to text:  al\n",
      "text to token id: 393\n",
      "token id to text: ers\n",
      "text to token id: 394\n",
      "token id to text: .\n",
      "\n",
      "text to token id: 395\n",
      "token id to text:  Y\n",
      "text to token id: 396\n",
      "token id to text: �\n",
      "text to token id: 397\n",
      "token id to text:  L\n",
      "text to token id: 398\n",
      "token id to text:  at\n",
      "text to token id: 399\n",
      "token id to text:  P\n",
      "text to token id: 400\n",
      "token id to text:  pro\n",
      "text to token id: 401\n",
      "token id to text:  tr\n",
      "text to token id: 402\n",
      "token id to text:  it\n",
      "text to token id: 403\n",
      "token id to text: oun\n",
      "text to token id: 404\n",
      "token id to text: ern\n",
      "text to token id: 405\n",
      "token id to text:  I\n",
      "text to token id: 406\n",
      "token id to text: ich\n",
      "text to token id: 407\n",
      "token id to text:  N\n",
      "text to token id: 408\n",
      "token id to text:  Z\n",
      "text to token id: 409\n",
      "token id to text: qu\n",
      "text to token id: 410\n",
      "token id to text:  an\n",
      "text to token id: 411\n",
      "token id to text: av\n",
      "text to token id: 412\n",
      "token id to text: ts\n",
      "text to token id: 413\n",
      "token id to text: us\n",
      "text to token id: 414\n",
      "token id to text:  J\n",
      "text to token id: 415\n",
      "token id to text:  fr\n",
      "text to token id: 416\n",
      "token id to text: ted\n",
      "text to token id: 417\n",
      "token id to text: ical\n",
      "text to token id: 418\n",
      "token id to text: ous\n",
      "text to token id: 419\n",
      "token id to text: 19\n",
      "text to token id: 420\n",
      "token id to text:  K\n",
      "text to token id: 421\n",
      "token id to text:  which\n",
      "text to token id: 422\n",
      "token id to text: ive\n",
      "text to token id: 423\n",
      "token id to text:  un\n",
      "text to token id: 424\n",
      "token id to text: 's\n",
      "text to token id: 425\n",
      "token id to text:  mo\n",
      "text to token id: 426\n",
      "token id to text: over\n",
      "text to token id: 427\n",
      "token id to text: eri\n",
      "text to token id: 428\n",
      "token id to text:  its\n",
      "text to token id: 429\n",
      "token id to text:  Sh\n",
      "text to token id: 430\n",
      "token id to text:  from\n",
      "text to token id: 431\n",
      "token id to text: ab\n",
      "text to token id: 432\n",
      "token id to text: ire\n",
      "text to token id: 433\n",
      "token id to text:  en\n",
      "text to token id: 434\n",
      "token id to text: ge\n",
      "text to token id: 435\n",
      "token id to text: gh\n",
      "text to token id: 436\n",
      "token id to text: uc\n",
      "text to token id: 437\n",
      "token id to text: 00\n",
      "text to token id: 438\n",
      "token id to text: if\n",
      "text to token id: 439\n",
      "token id to text:  BC\n",
      "text to token id: 440\n",
      "token id to text: oc\n",
      "text to token id: 441\n",
      "token id to text: –\n",
      "text to token id: 442\n",
      "token id to text:  peri\n",
      "text to token id: 443\n",
      "token id to text:  period\n",
      "text to token id: 444\n",
      "token id to text:  int\n",
      "text to token id: 445\n",
      "token id to text:  cont\n",
      "text to token id: 446\n",
      "token id to text:  k\n",
      "text to token id: 447\n",
      "token id to text: thern\n",
      "text to token id: 448\n",
      "token id to text: ary\n",
      "text to token id: 449\n",
      "token id to text:  mil\n",
      "text to token id: 450\n",
      "token id to text:  com\n",
      "text to token id: 451\n",
      "token id to text:  Q\n",
      "text to token id: 452\n",
      "token id to text: ally\n",
      "text to token id: 453\n",
      "token id to text: iz\n",
      "text to token id: 454\n",
      "token id to text: mperor\n",
      "text to token id: 455\n",
      "token id to text:  D\n",
      "text to token id: 456\n",
      "token id to text:  inc\n",
      "text to token id: 457\n",
      "token id to text:  X\n",
      "text to token id: 458\n",
      "token id to text: uring\n",
      "text to token id: 459\n",
      "token id to text:  In\n",
      "text to token id: 460\n",
      "token id to text: der\n",
      "text to token id: 461\n",
      "token id to text:  ar\n",
      "text to token id: 462\n",
      "token id to text:  v\n",
      "text to token id: 463\n",
      "token id to text: um\n",
      "text to token id: 464\n",
      "token id to text:  Zh\n",
      "text to token id: 465\n",
      "token id to text: ign\n",
      "text to token id: 466\n",
      "token id to text:  G\n",
      "text to token id: 467\n",
      "token id to text: ity\n",
      "text to token id: 468\n",
      "token id to text: ib\n",
      "text to token id: 469\n",
      "token id to text:  cent\n",
      "text to token id: 470\n",
      "token id to text:  that\n",
      "text to token id: 471\n",
      "token id to text: ter\n",
      "text to token id: 472\n",
      "token id to text: The\n",
      "text to token id: 473\n",
      "token id to text: og\n",
      "text to token id: 474\n",
      "token id to text: ld\n",
      "text to token id: 475\n",
      "token id to text:  cult\n",
      "text to token id: 476\n",
      "token id to text: em\n",
      "text to token id: 477\n",
      "token id to text:  Han\n",
      "text to token id: 478\n",
      "token id to text:  ad\n",
      "text to token id: 479\n",
      "token id to text:  i\n",
      "text to token id: 480\n",
      "token id to text: ound\n",
      "text to token id: 481\n",
      "token id to text: mpire\n",
      "text to token id: 482\n",
      "token id to text: hen\n",
      "text to token id: 483\n",
      "token id to text:  rul\n",
      "text to token id: 484\n",
      "token id to text:  F\n",
      "text to token id: 485\n",
      "token id to text: ell\n",
      "text to token id: 486\n",
      "token id to text:  is\n",
      "text to token id: 487\n",
      "token id to text:  stat\n",
      "text to token id: 488\n",
      "token id to text: ant\n",
      "text to token id: 489\n",
      "token id to text: ough\n",
      "text to token id: 490\n",
      "token id to text: ud\n",
      "text to token id: 491\n",
      "token id to text: overn\n",
      "text to token id: 492\n",
      "token id to text: .\n",
      "\n",
      "\n",
      "text to token id: 493\n",
      "token id to text:  ==\n",
      "text to token id: 494\n",
      "token id to text: ect\n",
      "text to token id: 495\n",
      "token id to text: ition\n",
      "text to token id: 496\n",
      "token id to text: ear\n",
      "text to token id: 497\n",
      "token id to text: rit\n",
      "text to token id: 498\n",
      "token id to text:  govern\n",
      "text to token id: 499\n",
      "token id to text:  Song\n",
      "text to token id: 500\n",
      "token id to text: ces\n",
      "text to token id: 501\n",
      "token id to text: res\n",
      "text to token id: 502\n",
      "token id to text: ao\n",
      "text to token id: 503\n",
      "token id to text: hed\n",
      "text to token id: 504\n",
      "token id to text: ame\n",
      "text to token id: 505\n",
      "token id to text: reat\n",
      "text to token id: 506\n",
      "token id to text:  ag\n",
      "text to token id: 507\n",
      "token id to text:  Ming\n",
      "text to token id: 508\n",
      "token id to text:  gr\n",
      "text to token id: 509\n",
      "token id to text: own\n",
      "text to token id: 510\n",
      "token id to text: ip\n",
      "text to token id: 511\n",
      "token id to text: our\n",
      "text to token id: 512\n",
      "token id to text: ence\n",
      "text to token id: 513\n",
      "token id to text: istor\n",
      "text to token id: 514\n",
      "token id to text: all\n",
      "text to token id: 515\n",
      "token id to text: ep\n",
      "text to token id: 516\n",
      "token id to text:  during\n",
      "text to token id: 517\n",
      "token id to text:  trad\n",
      "text to token id: 518\n",
      "token id to text:  sou\n",
      "text to token id: 519\n",
      "token id to text: ism\n",
      "text to token id: 520\n",
      "token id to text:  government\n",
      "text to token id: 521\n",
      "token id to text:  he\n",
      "text to token id: 522\n",
      "token id to text:  over\n",
      "text to token id: 523\n",
      "token id to text:  histor\n",
      "text to token id: 524\n",
      "token id to text:  reg\n",
      "text to token id: 525\n",
      "token id to text:  or\n",
      "text to token id: 526\n",
      "token id to text: ord\n",
      "text to token id: 527\n",
      "token id to text: fter\n",
      "text to token id: 528\n",
      "token id to text: uan\n",
      "text to token id: 529\n",
      "token id to text: ai\n",
      "text to token id: 530\n",
      "token id to text: ag\n",
      "text to token id: 531\n",
      "token id to text: art\n",
      "text to token id: 532\n",
      "token id to text:  le\n",
      "text to token id: 533\n",
      "token id to text: mperial\n",
      "text to token id: 534\n",
      "token id to text: end\n",
      "text to token id: 535\n",
      "token id to text: reas\n",
      "text to token id: 536\n",
      "token id to text:  ear\n",
      "text to token id: 537\n",
      "token id to text:  this\n",
      "text to token id: 538\n",
      "token id to text:  pow\n",
      "text to token id: 539\n",
      "token id to text:  pr\n",
      "text to token id: 540\n",
      "token id to text: ei\n",
      "text to token id: 541\n",
      "token id to text:  cons\n",
      "text to token id: 542\n",
      "token id to text:  nor\n",
      "text to token id: 543\n",
      "token id to text:  dis\n",
      "text to token id: 544\n",
      "token id to text: con\n",
      "text to token id: 545\n",
      "token id to text: ot\n",
      "text to token id: 546\n",
      "token id to text:  U\n",
      "text to token id: 547\n",
      "token id to text: mer\n",
      "text to token id: 548\n",
      "token id to text: ore\n",
      "text to token id: 549\n",
      "token id to text:  pe\n",
      "text to token id: 550\n",
      "token id to text:  Th\n",
      "text to token id: 551\n",
      "token id to text:  culture\n",
      "text to token id: 552\n",
      "token id to text:  pol\n",
      "text to token id: 553\n",
      "token id to text: ions\n",
      "text to token id: 554\n",
      "token id to text: vent\n",
      "text to token id: 555\n",
      "token id to text:  such\n",
      "text to token id: 556\n",
      "token id to text:  all\n",
      "text to token id: 557\n",
      "token id to text: 20\n",
      "text to token id: 558\n",
      "token id to text:  Mong\n",
      "text to token id: 559\n",
      "token id to text:  Mongol\n",
      "text to token id: 560\n",
      "token id to text:  had\n",
      "text to token id: 561\n",
      "token id to text:  cap\n",
      "text to token id: 562\n",
      "token id to text: ered\n",
      "text to token id: 563\n",
      "token id to text:  into\n",
      "text to token id: 564\n",
      "token id to text:  found\n",
      "text to token id: 565\n",
      "token id to text: ass\n",
      "text to token id: 566\n",
      "token id to text:  his\n",
      "text to token id: 567\n",
      "token id to text: for\n",
      "text to token id: 568\n",
      "token id to text: ite\n",
      "text to token id: 569\n",
      "token id to text: ak\n",
      "text to token id: 570\n",
      "token id to text: oll\n",
      "text to token id: 571\n",
      "token id to text: ay\n",
      "text to token id: 572\n",
      "token id to text: ied\n",
      "text to token id: 573\n",
      "token id to text: ations\n",
      "text to token id: 574\n",
      "token id to text: igh\n",
      "text to token id: 575\n",
      "token id to text:  power\n",
      "text to token id: 576\n",
      "token id to text: een\n",
      "text to token id: 577\n",
      "token id to text:  been\n",
      "text to token id: 578\n",
      "token id to text:  dec\n",
      "text to token id: 579\n",
      "token id to text: .\n",
      "\n",
      "\n",
      "\n",
      "text to token id: 580\n",
      "token id to text: pp\n",
      "text to token id: 581\n",
      "token id to text:  Emperor\n",
      "text to token id: 582\n",
      "token id to text:  sp\n",
      "text to token id: 583\n",
      "token id to text: act\n",
      "text to token id: 584\n",
      "token id to text:  states\n",
      "text to token id: 585\n",
      "token id to text: ave\n",
      "text to token id: 586\n",
      "token id to text:  under\n",
      "text to token id: 587\n",
      "token id to text:  kn\n",
      "text to token id: 588\n",
      "token id to text:  empire\n",
      "text to token id: 589\n",
      "token id to text:  bec\n",
      "text to token id: 590\n",
      "token id to text: conom\n",
      "text to token id: 591\n",
      "token id to text: bl\n",
      "text to token id: 592\n",
      "token id to text:  ab\n",
      "text to token id: 593\n",
      "token id to text:  res\n",
      "text to token id: 594\n",
      "token id to text:  Jin\n",
      "text to token id: 595\n",
      "token id to text:  wor\n",
      "text to token id: 596\n",
      "token id to text:  imperial\n",
      "text to token id: 597\n",
      "token id to text:  contr\n",
      "text to token id: 598\n",
      "token id to text: ),\n",
      "text to token id: 599\n",
      "token id to text: os\n",
      "text to token id: 600\n",
      "token id to text: ard\n",
      "text to token id: 601\n",
      "token id to text: ort\n",
      "text to token id: 602\n",
      "token id to text:  \"\n",
      "text to token id: 603\n",
      "token id to text:  their\n",
      "text to token id: 604\n",
      "token id to text:  econom\n",
      "text to token id: 605\n",
      "token id to text:  other\n",
      "text to token id: 606\n",
      "token id to text:  led\n",
      "text to token id: 607\n",
      "token id to text:  est\n",
      "text to token id: 608\n",
      "token id to text: ime\n",
      "text to token id: 609\n",
      "token id to text: up\n",
      "text to token id: 610\n",
      "token id to text:  most\n",
      "text to token id: 611\n",
      "token id to text:  ch\n",
      "text to token id: 612\n",
      "token id to text:  ne\n",
      "text to token id: 613\n",
      "token id to text:  again\n",
      "text to token id: 614\n",
      "token id to text: itary\n",
      "text to token id: 615\n",
      "token id to text:  mill\n",
      "text to token id: 616\n",
      "token id to text: omin\n",
      "text to token id: 617\n",
      "token id to text:  rec\n",
      "text to token id: 618\n",
      "token id to text:  Zhou\n",
      "text to token id: 619\n",
      "token id to text:  O\n",
      "text to token id: 620\n",
      "token id to text:  land\n",
      "text to token id: 621\n",
      "token id to text:  sy\n",
      "text to token id: 622\n",
      "token id to text: abl\n",
      "text to token id: 623\n",
      "token id to text:  war\n",
      "text to token id: 624\n",
      "token id to text: estern\n",
      "text to token id: 625\n",
      "token id to text:  against\n",
      "text to token id: 626\n",
      "token id to text: ans\n",
      "text to token id: 627\n",
      "token id to text: irst\n",
      "text to token id: 628\n",
      "token id to text:  y\n",
      "text to token id: 629\n",
      "token id to text: ious\n",
      "text to token id: 630\n",
      "token id to text: ral\n",
      "text to token id: 631\n",
      "token id to text: 12\n",
      "text to token id: 632\n",
      "token id to text: lud\n",
      "text to token id: 633\n",
      "token id to text:  ind\n",
      "text to token id: 634\n",
      "token id to text:  ter\n",
      "text to token id: 635\n",
      "token id to text:  known\n",
      "text to token id: 636\n",
      "token id to text:  comm\n",
      "text to token id: 637\n",
      "token id to text:  syst\n",
      "text to token id: 638\n",
      "token id to text:  system\n",
      "text to token id: 639\n",
      "token id to text: itical\n",
      "text to token id: 640\n",
      "token id to text:  War\n",
      "text to token id: 641\n",
      "token id to text: la\n",
      "text to token id: 642\n",
      "token id to text: form\n",
      "text to token id: 643\n",
      "token id to text:  capit\n",
      "text to token id: 644\n",
      "token id to text:  military\n",
      "text to token id: 645\n",
      "token id to text:  str\n",
      "text to token id: 646\n",
      "token id to text: ural\n",
      "text to token id: 647\n",
      "token id to text: any\n",
      "text to token id: 648\n",
      "token id to text: ount\n",
      "text to token id: 649\n",
      "token id to text: ual\n",
      "text to token id: 650\n",
      "token id to text: ry\n",
      "text to token id: 651\n",
      "token id to text: fic\n",
      "text to token id: 652\n",
      "token id to text:  Tang\n",
      "text to token id: 653\n",
      "token id to text: ish\n",
      "text to token id: 654\n",
      "token id to text: ury\n",
      "text to token id: 655\n",
      "token id to text: ually\n",
      "text to token id: 656\n",
      "token id to text:  establ\n",
      "text to token id: 657\n",
      "token id to text:  Yuan\n",
      "text to token id: 658\n",
      "token id to text:  Qing\n",
      "text to token id: 659\n",
      "token id to text:  end\n",
      "text to token id: 660\n",
      "token id to text: ater\n",
      "text to token id: 661\n",
      "token id to text:  pre\n",
      "text to token id: 662\n",
      "token id to text:  capital\n",
      "text to token id: 663\n",
      "token id to text: ide\n",
      "text to token id: 664\n",
      "token id to text: ced\n",
      "text to token id: 665\n",
      "token id to text: per\n",
      "text to token id: 666\n",
      "token id to text: ivil\n",
      "text to token id: 667\n",
      "token id to text: ments\n",
      "text to token id: 668\n",
      "token id to text: so\n",
      "text to token id: 669\n",
      "token id to text:  rep\n",
      "text to token id: 670\n",
      "token id to text: li\n",
      "text to token id: 671\n",
      "token id to text:  lar\n",
      "text to token id: 672\n",
      "token id to text:  includ\n",
      "text to token id: 673\n",
      "token id to text:  ext\n",
      "text to token id: 674\n",
      "token id to text: uang\n",
      "text to token id: 675\n",
      "token id to text: olog\n",
      "text to token id: 676\n",
      "token id to text:  became\n",
      "text to token id: 677\n",
      "token id to text: vel\n",
      "text to token id: 678\n",
      "token id to text:  political\n",
      "text to token id: 679\n",
      "token id to text:  sub\n",
      "text to token id: 680\n",
      "token id to text: 16\n",
      "text to token id: 681\n",
      "token id to text: etw\n",
      "text to token id: 682\n",
      "token id to text:  pop\n",
      "text to token id: 683\n",
      "token id to text:  popul\n",
      "text to token id: 684\n",
      "token id to text: tle\n",
      "text to token id: 685\n",
      "token id to text:  ca\n",
      "text to token id: 686\n",
      "token id to text:  part\n",
      "text to token id: 687\n",
      "token id to text:  exp\n",
      "text to token id: 688\n",
      "token id to text: ve\n",
      "text to token id: 689\n",
      "token id to text:  year\n",
      "text to token id: 690\n",
      "token id to text:  one\n",
      "text to token id: 691\n",
      "token id to text:  south\n",
      "text to token id: 692\n",
      "token id to text:  rem\n",
      "text to token id: 693\n",
      "token id to text: ished\n",
      "text to token id: 694\n",
      "token id to text: han\n",
      "text to token id: 695\n",
      "token id to text: ree\n",
      "text to token id: 696\n",
      "token id to text: etween\n",
      "text to token id: 697\n",
      "token id to text: apan\n",
      "text to token id: 698\n",
      "token id to text: aj\n",
      "text to token id: 699\n",
      "token id to text: ix\n",
      "text to token id: 700\n",
      "token id to text: jing\n",
      "text to token id: 701\n",
      "token id to text: out\n",
      "text to token id: 702\n",
      "token id to text: uo\n",
      "text to token id: 703\n",
      "token id to text: zh\n",
      "text to token id: 704\n",
      "token id to text:  Shang\n",
      "text to token id: 705\n",
      "token id to text: iet\n",
      "text to token id: 706\n",
      "token id to text:  first\n",
      "text to token id: 707\n",
      "token id to text: iver\n",
      "text to token id: 708\n",
      "token id to text: ze\n",
      "text to token id: 709\n",
      "token id to text: ie\n",
      "text to token id: 710\n",
      "token id to text:  also\n",
      "text to token id: 711\n",
      "token id to text:  have\n",
      "text to token id: 712\n",
      "token id to text:  beg\n",
      "text to token id: 713\n",
      "token id to text: ived\n",
      "text to token id: 714\n",
      "token id to text: ficial\n",
      "text to token id: 715\n",
      "token id to text: ized\n",
      "text to token id: 716\n",
      "token id to text:  er\n",
      "text to token id: 717\n",
      "token id to text: ill\n",
      "text to token id: 718\n",
      "token id to text:  after\n",
      "text to token id: 719\n",
      "token id to text: fl\n",
      "text to token id: 720\n",
      "token id to text:  conqu\n",
      "text to token id: 721\n",
      "token id to text: ubl\n",
      "text to token id: 722\n",
      "token id to text: iang\n",
      "text to token id: 723\n",
      "token id to text:  def\n",
      "text to token id: 724\n",
      "token id to text:  sh\n",
      "text to token id: 725\n",
      "token id to text: ings\n",
      "text to token id: 726\n",
      "token id to text: ren\n",
      "text to token id: 727\n",
      "token id to text:  who\n",
      "text to token id: 728\n",
      "token id to text: ue\n",
      "text to token id: 729\n",
      "token id to text: ational\n",
      "text to token id: 730\n",
      "token id to text:  history\n",
      "text to token id: 731\n",
      "token id to text:  se\n",
      "text to token id: 732\n",
      "token id to text:  civil\n",
      "text to token id: 733\n",
      "token id to text:  River\n",
      "text to token id: 734\n",
      "token id to text: ople\n",
      "text to token id: 735\n",
      "token id to text:  comp\n",
      "text to token id: 736\n",
      "token id to text:  Xia\n",
      "text to token id: 737\n",
      "token id to text:  br\n",
      "text to token id: 738\n",
      "token id to text: 10\n",
      "text to token id: 739\n",
      "token id to text:  state\n",
      "text to token id: 740\n",
      "token id to text:  mar\n",
      "text to token id: 741\n",
      "token id to text:  fam\n",
      "text to token id: 742\n",
      "token id to text: eng\n",
      "text to token id: 743\n",
      "token id to text: ress\n",
      "text to token id: 744\n",
      "token id to text:  emperor\n",
      "text to token id: 745\n",
      "token id to text: ance\n",
      "text to token id: 746\n",
      "token id to text: ublic\n",
      "text to token id: 747\n",
      "token id to text:  but\n",
      "text to token id: 748\n",
      "token id to text:  Re\n",
      "text to token id: 749\n",
      "token id to text: str\n",
      "text to token id: 750\n",
      "token id to text:  rel\n",
      "text to token id: 751\n",
      "token id to text: ).\n",
      "text to token id: 752\n",
      "token id to text: istr\n",
      "text to token id: 753\n",
      "token id to text: ingd\n",
      "text to token id: 754\n",
      "token id to text: yang\n",
      "text to token id: 755\n",
      "token id to text: ====\n",
      "text to token id: 756\n",
      "token id to text:  ====\n",
      "text to token id: 757\n",
      "token id to text: In\n",
      "text to token id: 758\n",
      "token id to text:  soc\n",
      "text to token id: 759\n",
      "token id to text:  trade\n",
      "text to token id: 760\n",
      "token id to text:  out\n",
      "text to token id: 761\n",
      "token id to text:  ac\n",
      "text to token id: 762\n",
      "token id to text:  ent\n",
      "text to token id: 763\n",
      "token id to text:  imp\n",
      "text to token id: 764\n",
      "token id to text:  more\n",
      "text to token id: 765\n",
      "token id to text: ks\n",
      "text to token id: 766\n",
      "token id to text:  Man\n",
      "text to token id: 767\n",
      "token id to text:  between\n",
      "text to token id: 768\n",
      "token id to text:  Japan\n",
      "text to token id: 769\n",
      "token id to text: ajor\n",
      "text to token id: 770\n",
      "token id to text:  later\n",
      "text to token id: 771\n",
      "token id to text: ibut\n",
      "text to token id: 772\n",
      "token id to text: ained\n",
      "text to token id: 773\n",
      "token id to text: ities\n",
      "text to token id: 774\n",
      "token id to text:  set\n",
      "text to token id: 775\n",
      "token id to text:  event\n",
      "text to token id: 776\n",
      "token id to text:  Al\n",
      "text to token id: 777\n",
      "token id to text:  Sou\n",
      "text to token id: 778\n",
      "token id to text:  world\n",
      "text to token id: 779\n",
      "token id to text: ization\n",
      "text to token id: 780\n",
      "token id to text: imes\n",
      "text to token id: 781\n",
      "token id to text:  Ne\n",
      "text to token id: 782\n",
      "token id to text:  central\n",
      "text to token id: 783\n",
      "token id to text:  earli\n",
      "text to token id: 784\n",
      "token id to text:  official\n",
      "text to token id: 785\n",
      "token id to text: ved\n",
      "text to token id: 786\n",
      "token id to text: age\n",
      "text to token id: 787\n",
      "token id to text:  Wu\n",
      "text to token id: 788\n",
      "token id to text:  cl\n",
      "text to token id: 789\n",
      "token id to text: tion\n",
      "text to token id: 790\n",
      "token id to text:  Empire\n",
      "text to token id: 791\n",
      "token id to text: ile\n",
      "text to token id: 792\n",
      "token id to text:  economic\n",
      "text to token id: 793\n",
      "token id to text: vol\n",
      "text to token id: 794\n",
      "token id to text: RC\n",
      "text to token id: 795\n",
      "token id to text: ath\n",
      "text to token id: 796\n",
      "token id to text: =\n",
      "\n",
      "\n",
      "text to token id: 797\n",
      "token id to text: odern\n",
      "text to token id: 798\n",
      "token id to text:  An\n",
      "text to token id: 799\n",
      "token id to text:  rule\n",
      "text to token id: 800\n",
      "token id to text:  ====\n",
      "\n",
      "\n",
      "text to token id: 801\n",
      "token id to text: ants\n",
      "text to token id: 802\n",
      "token id to text:  consid\n",
      "text to token id: 803\n",
      "token id to text: ens\n",
      "text to token id: 804\n",
      "token id to text: cr\n",
      "text to token id: 805\n",
      "token id to text:  many\n",
      "text to token id: 806\n",
      "token id to text: ative\n",
      "text to token id: 807\n",
      "token id to text:  far\n",
      "text to token id: 808\n",
      "token id to text:  increas\n",
      "text to token id: 809\n",
      "token id to text:  som\n",
      "text to token id: 810\n",
      "token id to text:  writ\n",
      "text to token id: 811\n",
      "token id to text: ates\n",
      "text to token id: 812\n",
      "token id to text: ors\n",
      "text to token id: 813\n",
      "token id to text:  we\n",
      "text to token id: 814\n",
      "token id to text: old\n",
      "text to token id: 815\n",
      "token id to text:  century\n",
      "text to token id: 816\n",
      "token id to text: ess\n",
      "text to token id: 817\n",
      "token id to text: sequ\n",
      "text to token id: 818\n",
      "token id to text: min\n",
      "text to token id: 819\n",
      "token id to text: ost\n",
      "text to token id: 820\n",
      "token id to text: laim\n",
      "text to token id: 821\n",
      "token id to text:  PRC\n",
      "text to token id: 822\n",
      "token id to text:  major\n",
      "text to token id: 823\n",
      "token id to text:  reform\n",
      "text to token id: 824\n",
      "token id to text: ===\n",
      "text to token id: 825\n",
      "token id to text:  ===\n",
      "\n",
      "\n",
      "text to token id: 826\n",
      "token id to text: oin\n",
      "text to token id: 827\n",
      "token id to text:  Lia\n",
      "text to token id: 828\n",
      "token id to text: use\n",
      "text to token id: 829\n",
      "token id to text:  site\n",
      "text to token id: 830\n",
      "token id to text: ric\n",
      "text to token id: 831\n",
      "token id to text: ollow\n",
      "text to token id: 832\n",
      "token id to text:  population\n",
      "text to token id: 833\n",
      "token id to text:  As\n",
      "text to token id: 834\n",
      "token id to text: ists\n",
      "text to token id: 835\n",
      "token id to text:  us\n",
      "text to token id: 836\n",
      "token id to text:  control\n",
      "text to token id: 837\n",
      "token id to text: ingdom\n",
      "text to token id: 838\n",
      "token id to text: 18\n",
      "text to token id: 839\n",
      "token id to text:  Nor\n",
      "text to token id: 840\n",
      "token id to text:  are\n",
      "text to token id: 841\n",
      "token id to text:  main\n",
      "text to token id: 842\n",
      "token id to text:  div\n",
      "text to token id: 843\n",
      "token id to text:  people\n",
      "text to token id: 844\n",
      "token id to text:  This\n",
      "text to token id: 845\n",
      "token id to text:  years\n",
      "text to token id: 846\n",
      "token id to text:  sur\n",
      "text to token id: 847\n",
      "token id to text: duc\n",
      "text to token id: 848\n",
      "token id to text:  Con\n",
      "text to token id: 849\n",
      "token id to text:  Qin\n",
      "text to token id: 850\n",
      "token id to text:  era\n",
      "text to token id: 851\n",
      "token id to text: ci\n",
      "text to token id: 852\n",
      "token id to text: rac\n",
      "text to token id: 853\n",
      "token id to text: ific\n",
      "text to token id: 854\n",
      "token id to text:  fl\n",
      "text to token id: 855\n",
      "token id to text: ui\n",
      "text to token id: 856\n",
      "token id to text:  devel\n",
      "text to token id: 857\n",
      "token id to text:  develop\n",
      "text to token id: 858\n",
      "token id to text:  time\n",
      "text to token id: 859\n",
      "token id to text: sequent\n",
      "text to token id: 860\n",
      "token id to text:  territ\n",
      "text to token id: 861\n",
      "token id to text:  territor\n",
      "text to token id: 862\n",
      "token id to text:  Rep\n",
      "text to token id: 863\n",
      "token id to text:  Republic\n",
      "text to token id: 864\n",
      "token id to text:  inv\n",
      "text to token id: 865\n",
      "token id to text:  count\n",
      "text to token id: 866\n",
      "token id to text:  defe\n",
      "text to token id: 867\n",
      "token id to text: land\n",
      "text to token id: 868\n",
      "token id to text:  status\n",
      "text to token id: 869\n",
      "token id to text:  death\n",
      "text to token id: 870\n",
      "token id to text: 000\n",
      "text to token id: 871\n",
      "token id to text: ight\n",
      "text to token id: 872\n",
      "token id to text: red\n",
      "text to token id: 873\n",
      "token id to text:  contin\n",
      "text to token id: 874\n",
      "token id to text:  supp\n",
      "text to token id: 875\n",
      "token id to text:  Western\n",
      "text to token id: 876\n",
      "token id to text: heng\n",
      "text to token id: 877\n",
      "token id to text:  not\n",
      "text to token id: 878\n",
      "token id to text:  gen\n",
      "text to token id: 879\n",
      "token id to text:  they\n",
      "text to token id: 880\n",
      "token id to text: ring\n",
      "text to token id: 881\n",
      "token id to text:  reb\n",
      "text to token id: 882\n",
      "token id to text:  up\n",
      "text to token id: 883\n",
      "token id to text:  Un\n",
      "text to token id: 884\n",
      "token id to text: ened\n",
      "text to token id: 885\n",
      "token id to text:  Southern\n",
      "text to token id: 886\n",
      "token id to text:  Yang\n",
      "text to token id: 887\n",
      "token id to text: itional\n",
      "text to token id: 888\n",
      "token id to text:  dynasties\n",
      "text to token id: 889\n",
      "token id to text:  domin\n",
      "text to token id: 890\n",
      "token id to text:  north\n",
      "text to token id: 891\n",
      "token id to text: ified\n",
      "text to token id: 892\n",
      "token id to text:  earliest\n",
      "text to token id: 893\n",
      "token id to text: ten\n",
      "text to token id: 894\n",
      "token id to text: ex\n",
      "text to token id: 895\n",
      "token id to text:  form\n",
      "text to token id: 896\n",
      "token id to text:  large\n",
      "text to token id: 897\n",
      "token id to text:  early\n",
      "text to token id: 898\n",
      "token id to text:  la\n",
      "text to token id: 899\n",
      "token id to text: ited\n",
      "text to token id: 900\n",
      "token id to text:  began\n",
      "text to token id: 901\n",
      "token id to text:  mass\n",
      "text to token id: 902\n",
      "token id to text:  infl\n",
      "text to token id: 903\n",
      "token id to text:  Great\n",
      "text to token id: 904\n",
      "token id to text:  suc\n",
      "text to token id: 905\n",
      "token id to text:  Manch\n",
      "text to token id: 906\n",
      "token id to text:  Com\n",
      "text to token id: 907\n",
      "token id to text:  Tai\n",
      "text to token id: 908\n",
      "token id to text: wan\n",
      "text to token id: 909\n",
      "token id to text: oth\n",
      "text to token id: 910\n",
      "token id to text: ince\n",
      "text to token id: 911\n",
      "token id to text:  num\n",
      "text to token id: 912\n",
      "token id to text: astern\n",
      "text to token id: 913\n",
      "token id to text:  established\n",
      "text to token id: 914\n",
      "token id to text:  continu\n",
      "text to token id: 915\n",
      "token id to text:  late\n",
      "text to token id: 916\n",
      "token id to text: ron\n",
      "text to token id: 917\n",
      "token id to text: ade\n",
      "text to token id: 918\n",
      "token id to text: uch\n",
      "text to token id: 919\n",
      "token id to text:  gener\n",
      "text to token id: 920\n",
      "token id to text: ould\n",
      "text to token id: 921\n",
      "token id to text:  forces\n",
      "text to token id: 922\n",
      "token id to text: ought\n",
      "text to token id: 923\n",
      "token id to text:  camp\n",
      "text to token id: 924\n",
      "token id to text: aph\n",
      "text to token id: 925\n",
      "token id to text:  region\n",
      "text to token id: 926\n",
      "token id to text:  has\n",
      "text to token id: 927\n",
      "token id to text:  emer\n",
      "text to token id: 928\n",
      "token id to text: alle\n",
      "text to token id: 929\n",
      "token id to text:  ass\n",
      "text to token id: 930\n",
      "token id to text: ithic\n",
      "text to token id: 931\n",
      "token id to text: ident\n",
      "text to token id: 932\n",
      "token id to text:  record\n",
      "text to token id: 933\n",
      "token id to text: fuc\n",
      "text to token id: 934\n",
      "token id to text: eg\n",
      "text to token id: 935\n",
      "token id to text:  Shi\n",
      "text to token id: 936\n",
      "token id to text:  while\n",
      "text to token id: 937\n",
      "token id to text:  than\n",
      "text to token id: 938\n",
      "token id to text:  influ\n",
      "text to token id: 939\n",
      "token id to text: 13\n",
      "text to token id: 940\n",
      "token id to text: ating\n",
      "text to token id: 941\n",
      "token id to text: ution\n",
      "text to token id: 942\n",
      "token id to text: my\n",
      "text to token id: 943\n",
      "token id to text: laimed\n",
      "text to token id: 944\n",
      "token id to text:  Taiwan\n",
      "text to token id: 945\n",
      "token id to text:  leg\n",
      "text to token id: 946\n",
      "token id to text:  million\n",
      "text to token id: 947\n",
      "token id to text:  Bei\n",
      "text to token id: 948\n",
      "token id to text:  modern\n",
      "text to token id: 949\n",
      "token id to text:  follow\n",
      "text to token id: 950\n",
      "token id to text: ively\n",
      "text to token id: 951\n",
      "token id to text:  sch\n",
      "text to token id: 952\n",
      "token id to text:  founded\n",
      "text to token id: 953\n",
      "token id to text:  decl\n",
      "text to token id: 954\n",
      "token id to text:  eventually\n",
      "text to token id: 955\n",
      "token id to text: urther\n",
      "text to token id: 956\n",
      "token id to text: ised\n",
      "text to token id: 957\n",
      "token id to text: ail\n",
      "text to token id: 958\n",
      "token id to text:  northern\n",
      "text to token id: 959\n",
      "token id to text: ingdoms\n",
      "text to token id: 960\n",
      "token id to text: oreign\n",
      "text to token id: 961\n",
      "token id to text:  Northern\n",
      "text to token id: 962\n",
      "token id to text:  Zhu\n",
      "text to token id: 963\n",
      "token id to text:  Liao\n",
      "text to token id: 964\n",
      "token id to text: raph\n",
      "text to token id: 965\n",
      "token id to text:  considered\n",
      "text to token id: 966\n",
      "token id to text:  emerg\n",
      "text to token id: 967\n",
      "token id to text: alley\n",
      "text to token id: 968\n",
      "token id to text:  along\n",
      "text to token id: 969\n",
      "token id to text:  Yangt\n",
      "text to token id: 970\n",
      "token id to text:  Yangtze\n",
      "text to token id: 971\n",
      "token id to text:  bas\n",
      "text to token id: 972\n",
      "token id to text: oup\n",
      "text to token id: 973\n",
      "token id to text: olithic\n",
      "text to token id: 974\n",
      "token id to text:  fe\n",
      "text to token id: 975\n",
      "token id to text:  \n",
      "text to token id: 976\n",
      "token id to text:  He\n",
      "text to token id: 977\n",
      "token id to text: fucian\n",
      "text to token id: 978\n",
      "token id to text:  there\n",
      "text to token id: 979\n",
      "token id to text:  mark\n",
      "text to token id: 980\n",
      "token id to text:  some\n",
      "text to token id: 981\n",
      "token id to text: emp\n",
      "text to token id: 982\n",
      "token id to text: ward\n",
      "text to token id: 983\n",
      "token id to text:  fin\n",
      "text to token id: 984\n",
      "token id to text:  Bud\n",
      "text to token id: 985\n",
      "token id to text:  Budd\n",
      "text to token id: 986\n",
      "token id to text:  Buddh\n",
      "text to token id: 987\n",
      "token id to text: ting\n",
      "text to token id: 988\n",
      "token id to text: her\n",
      "text to token id: 989\n",
      "token id to text:  subsequent\n",
      "text to token id: 990\n",
      "token id to text:  ruled\n",
      "text to token id: 991\n",
      "token id to text: 191\n",
      "text to token id: 992\n",
      "token id to text: 194\n",
      "text to token id: 993\n",
      "token id to text:  Comm\n",
      "text to token id: 994\n",
      "token id to text:  country\n",
      "text to token id: 995\n",
      "token id to text:  Mao\n",
      "text to token id: 996\n",
      "token id to text:  Ma\n",
      "text to token id: 997\n",
      "token id to text:  St\n",
      "text to token id: 998\n",
      "token id to text: attle\n",
      "text to token id: 999\n",
      "token id to text:  Beijing\n",
      "text to token id: 1000\n",
      "token id to text:  including\n",
      "text to token id: 1001\n",
      "token id to text:  southern\n",
      "text to token id: 1002\n",
      "token id to text:  pres\n",
      "text to token id: 1003\n",
      "token id to text:  admin\n",
      "text to token id: 1004\n",
      "token id to text:  administr\n",
      "text to token id: 1005\n",
      "token id to text:  prev\n",
      "text to token id: 1006\n",
      "token id to text: olar\n",
      "text to token id: 1007\n",
      "token id to text:  el\n",
      "text to token id: 1008\n",
      "token id to text: zhou\n",
      "text to token id: 1009\n",
      "token id to text: ever\n",
      "text to token id: 1010\n",
      "token id to text:  when\n",
      "text to token id: 1011\n",
      "token id to text: 'an\n",
      "text to token id: 1012\n",
      "token id to text:  weak\n",
      "text to token id: 1013\n",
      "token id to text:  being\n",
      "text to token id: 1014\n",
      "token id to text: able\n",
      "text to token id: 1015\n",
      "token id to text: fect\n",
      "text to token id: 1016\n",
      "token id to text:  general\n",
      "text to token id: 1017\n",
      "token id to text: cess\n",
      "text to token id: 1018\n",
      "token id to text:  peas\n",
      "text to token id: 1019\n",
      "token id to text:  foreign\n",
      "text to token id: 1020\n",
      "token id to text:  All\n",
      "text to token id: 1021\n",
      "token id to text: CP\n",
      "text to token id: 1022\n",
      "token id to text:  National\n",
      "text to token id: 1023\n",
      "token id to text:  valley\n",
      "text to token id: 1024\n",
      "token id to text: stit\n",
      "text to token id: 1025\n",
      "token id to text:  eth\n",
      "text to token id: 1026\n",
      "token id to text:  ethn\n",
      "text to token id: 1027\n",
      "token id to text:  ethnic\n",
      "text to token id: 1028\n",
      "token id to text:  traditional\n",
      "text to token id: 1029\n",
      "token id to text: read\n",
      "text to token id: 1030\n",
      "token id to text:  areas\n",
      "text to token id: 1031\n",
      "token id to text: lit\n",
      "text to token id: 1032\n",
      "token id to text: iving\n",
      "text to token id: 1033\n",
      "token id to text: other\n",
      "text to token id: 1034\n",
      "token id to text: epend\n",
      "text to token id: 1035\n",
      "token id to text: hil\n",
      "text to token id: 1036\n",
      "token id to text:  famil\n",
      "text to token id: 1037\n",
      "token id to text:  families\n",
      "text to token id: 1038\n",
      "token id to text: racy\n",
      "text to token id: 1039\n",
      "token id to text: ech\n",
      "text to token id: 1040\n",
      "token id to text: ology\n",
      "text to token id: 1041\n",
      "token id to text: ided\n",
      "text to token id: 1042\n",
      "token id to text:  ser\n",
      "text to token id: 1043\n",
      "token id to text: ulture\n",
      "text to token id: 1044\n",
      "token id to text:  influence\n",
      "text to token id: 1045\n",
      "token id to text:  common\n",
      "text to token id: 1046\n",
      "token id to text: 127\n",
      "text to token id: 1047\n",
      "token id to text:  adv\n",
      "text to token id: 1048\n",
      "token id to text:  Wall\n",
      "text to token id: 1049\n",
      "token id to text: -s\n",
      "text to token id: 1050\n",
      "token id to text:  Commun\n",
      "text to token id: 1051\n",
      "token id to text:  proc\n",
      "text to token id: 1052\n",
      "token id to text: atic\n",
      "text to token id: 1053\n",
      "token id to text: rough\n",
      "text to token id: 1054\n",
      "token id to text: cc\n",
      "text to token id: 1055\n",
      "token id to text:  Li\n",
      "text to token id: 1056\n",
      "token id to text:  exist\n",
      "text to token id: 1057\n",
      "token id to text:  then\n",
      "text to token id: 1058\n",
      "token id to text:  much\n",
      "text to token id: 1059\n",
      "token id to text:  scholar\n",
      "text to token id: 1060\n",
      "token id to text: 15\n",
      "text to token id: 1061\n",
      "token id to text:  would\n",
      "text to token id: 1062\n",
      "token id to text: ically\n",
      "text to token id: 1063\n",
      "token id to text:  them\n",
      "text to token id: 1064\n",
      "token id to text: iance\n",
      "text to token id: 1065\n",
      "token id to text:  former\n",
      "text to token id: 1066\n",
      "token id to text:  These\n",
      "text to token id: 1067\n",
      "token id to text:  ann\n",
      "text to token id: 1068\n",
      "token id to text:  campa\n",
      "text to token id: 1069\n",
      "token id to text:  campaign\n",
      "text to token id: 1070\n",
      "token id to text:  tro\n",
      "text to token id: 1071\n",
      "token id to text:  troop\n",
      "text to token id: 1072\n",
      "token id to text:  last\n",
      "text to token id: 1073\n",
      "token id to text:  During\n",
      "text to token id: 1074\n",
      "token id to text:  conquest\n",
      "text to token id: 1075\n",
      "token id to text:  Kingdoms\n",
      "text to token id: 1076\n",
      "token id to text: ellion\n",
      "text to token id: 1077\n",
      "token id to text:  continued\n",
      "text to token id: 1078\n",
      "token id to text: ov\n",
      "text to token id: 1079\n",
      "token id to text: ug\n",
      "text to token id: 1080\n",
      "token id to text:  Japanese\n",
      "text to token id: 1081\n",
      "token id to text: ograph\n",
      "text to token id: 1082\n",
      "token id to text: ach\n",
      "text to token id: 1083\n",
      "token id to text:  now\n",
      "text to token id: 1084\n",
      "token id to text: ains\n",
      "text to token id: 1085\n",
      "token id to text:  group\n",
      "text to token id: 1086\n",
      "token id to text:  fall\n",
      "text to token id: 1087\n",
      "token id to text: aced\n",
      "text to token id: 1088\n",
      "token id to text:  var\n",
      "text to token id: 1089\n",
      "token id to text:  written\n",
      "text to token id: 1090\n",
      "token id to text: crip\n",
      "text to token id: 1091\n",
      "token id to text:  another\n",
      "text to token id: 1092\n",
      "token id to text:  loc\n",
      "text to token id: 1093\n",
      "token id to text:  independ\n",
      "text to token id: 1094\n",
      "token id to text:  –\n",
      "text to token id: 1095\n",
      "token id to text:  Age\n",
      "text to token id: 1096\n",
      "token id to text: fucianism\n",
      "text to token id: 1097\n",
      "token id to text:  stand\n",
      "text to token id: 1098\n",
      "token id to text: cient\n",
      "text to token id: 1099\n",
      "token id to text:  tech\n",
      "text to token id: 1100\n",
      "token id to text:  techn\n",
      "text to token id: 1101\n",
      "token id to text:  emp\n",
      "text to token id: 1102\n",
      "token id to text: ful\n",
      "text to token id: 1103\n",
      "token id to text:  only\n",
      "text to token id: 1104\n",
      "token id to text:  adop\n",
      "text to token id: 1105\n",
      "token id to text: ood\n",
      "text to token id: 1106\n",
      "token id to text:  establish\n",
      "text to token id: 1107\n",
      "token id to text: ects\n",
      "text to token id: 1108\n",
      "token id to text:  great\n",
      "text to token id: 1109\n",
      "token id to text:  ro\n",
      "text to token id: 1110\n",
      "token id to text: ond\n",
      "text to token id: 1111\n",
      "token id to text:  proclaimed\n",
      "text to token id: 1112\n",
      "token id to text:  economy\n",
      "text to token id: 1113\n",
      "token id to text:  what\n",
      "text to token id: 1114\n",
      "token id to text:  these\n",
      "text to token id: 1115\n",
      "token id to text: anx\n",
      "text to token id: 1116\n",
      "token id to text:  Guang\n",
      "text to token id: 1117\n",
      "token id to text: idence\n",
      "text to token id: 1118\n",
      "token id to text: als\n",
      "text to token id: 1119\n",
      "token id to text:  app\n",
      "text to token id: 1120\n",
      "token id to text:  agric\n",
      "text to token id: 1121\n",
      "token id to text: fer\n",
      "text to token id: 1122\n",
      "token id to text: ke\n",
      "text to token id: 1123\n",
      "token id to text:  previous\n",
      "text to token id: 1124\n",
      "token id to text: urren\n",
      "text to token id: 1125\n",
      "token id to text:  j\n",
      "text to token id: 1126\n",
      "token id to text:  how\n",
      "text to token id: 1127\n",
      "token id to text: ine\n",
      "text to token id: 1128\n",
      "token id to text:  For\n",
      "text to token id: 1129\n",
      "token id to text:  lead\n",
      "text to token id: 1130\n",
      "token id to text:  proper\n",
      "text to token id: 1131\n",
      "token id to text: ily\n",
      "text to token id: 1132\n",
      "token id to text:  Wei\n",
      "text to token id: 1133\n",
      "token id to text:  new\n",
      "text to token id: 1134\n",
      "token id to text:  Sp\n",
      "text to token id: 1135\n",
      "token id to text:  sec\n",
      "text to token id: 1136\n",
      "token id to text:  societ\n",
      "text to token id: 1137\n",
      "token id to text:  further\n",
      "text to token id: 1138\n",
      "token id to text:  ef\n",
      "text to token id: 1139\n",
      "token id to text:  mon\n",
      "text to token id: 1140\n",
      "token id to text: esp\n",
      "text to token id: 1141\n",
      "token id to text:  social\n",
      "text to token id: 1142\n",
      "token id to text:  troops\n",
      "text to token id: 1143\n",
      "token id to text:  det\n",
      "text to token id: 1144\n",
      "token id to text:  am\n",
      "text to token id: 1145\n",
      "token id to text:  op\n",
      "text to token id: 1146\n",
      "token id to text:  V\n",
      "text to token id: 1147\n",
      "token id to text:  invas\n",
      "text to token id: 1148\n",
      "token id to text: ier\n",
      "text to token id: 1149\n",
      "token id to text:  Uy\n",
      "text to token id: 1150\n",
      "token id to text:  Uygh\n",
      "text to token id: 1151\n",
      "token id to text:  Uyghur\n",
      "text to token id: 1152\n",
      "token id to text:  Khan\n",
      "text to token id: 1153\n",
      "token id to text:  qu\n",
      "text to token id: 1154\n",
      "token id to text:  Hong\n",
      "text to token id: 1155\n",
      "token id to text:  CCP\n",
      "text to token id: 1156\n",
      "token id to text: ros\n",
      "text to token id: 1157\n",
      "token id to text:  wide\n",
      "text to token id: 1158\n",
      "token id to text:  civilization\n",
      "text to token id: 1159\n",
      "token id to text: ellow\n",
      "text to token id: 1160\n",
      "token id to text:  cultural\n",
      "text to token id: 1161\n",
      "token id to text: here\n",
      "text to token id: 1162\n",
      "token id to text: ct\n",
      "text to token id: 1163\n",
      "token id to text:  Neolithic\n",
      "text to token id: 1164\n",
      "token id to text: aw\n",
      "text to token id: 1165\n",
      "token id to text:  Er\n",
      "text to token id: 1166\n",
      "token id to text: ium\n",
      "text to token id: 1167\n",
      "token id to text: icated\n",
      "text to token id: 1168\n",
      "token id to text:  few\n",
      "text to token id: 1169\n",
      "token id to text: emb\n",
      "text to token id: 1170\n",
      "token id to text: aven\n",
      "text to token id: 1171\n",
      "token id to text: oph\n",
      "text to token id: 1172\n",
      "token id to text: hin\n",
      "text to token id: 1173\n",
      "token id to text:  Huang\n",
      "text to token id: 1174\n",
      "token id to text: ures\n",
      "text to token id: 1175\n",
      "token id to text:  reac\n",
      "text to token id: 1176\n",
      "token id to text:  reached\n",
      "text to token id: 1177\n",
      "token id to text:  sign\n",
      "text to token id: 1178\n",
      "token id to text:  contemp\n",
      "text to token id: 1179\n",
      "token id to text:  contempor\n",
      "text to token id: 1180\n",
      "token id to text: ane\n",
      "text to token id: 1181\n",
      "token id to text:  produc\n",
      "text to token id: 1182\n",
      "token id to text: aper\n",
      "text to token id: 1183\n",
      "token id to text: oy\n",
      "text to token id: 1184\n",
      "token id to text:  long\n",
      "text to token id: 1185\n",
      "token id to text: -l\n",
      "text to token id: 1186\n",
      "token id to text: 60\n",
      "text to token id: 1187\n",
      "token id to text:  reign\n",
      "text to token id: 1188\n",
      "token id to text:  adopted\n",
      "text to token id: 1189\n",
      "token id to text:  dem\n",
      "text to token id: 1190\n",
      "token id to text:  After\n",
      "text to token id: 1191\n",
      "token id to text: ax\n",
      "text to token id: 1192\n",
      "token id to text: ological\n",
      "text to token id: 1193\n",
      "token id to text: ture\n",
      "text to token id: 1194\n",
      "token id to text:  bure\n",
      "text to token id: 1195\n",
      "token id to text:  burea\n",
      "text to token id: 1196\n",
      "token id to text:  bureauc\n",
      "text to token id: 1197\n",
      "token id to text: eded\n",
      "text to token id: 1198\n",
      "token id to text: ict\n",
      "text to token id: 1199\n",
      "token id to text: volution\n",
      "text to token id: 1200\n",
      "token id to text:  cre\n",
      "text to token id: 1201\n",
      "token id to text: 192\n",
      "text to token id: 1202\n",
      "token id to text: til\n",
      "text to token id: 1203\n",
      "token id to text:  mainland\n",
      "text to token id: 1204\n",
      "token id to text: ped\n",
      "text to token id: 1205\n",
      "token id to text:  reforms\n",
      "text to token id: 1206\n",
      "token id to text:  ==\n",
      "\n",
      "\n",
      "text to token id: 1207\n",
      "token id to text: erous\n",
      "text to token id: 1208\n",
      "token id to text: king\n",
      "text to token id: 1209\n",
      "token id to text: cover\n",
      "text to token id: 1210\n",
      "token id to text: oss\n",
      "text to token id: 1211\n",
      "token id to text: chang\n",
      "text to token id: 1212\n",
      "token id to text:  Xian\n",
      "text to token id: 1213\n",
      "token id to text: vidence\n",
      "text to token id: 1214\n",
      "token id to text:  use\n",
      "text to token id: 1215\n",
      "token id to text:  occ\n",
      "text to token id: 1216\n",
      "token id to text:  Xi\n",
      "text to token id: 1217\n",
      "token id to text:  larg\n",
      "text to token id: 1218\n",
      "token id to text:  about\n",
      "text to token id: 1219\n",
      "token id to text:  grad\n",
      "text to token id: 1220\n",
      "token id to text:  init\n",
      "text to token id: 1221\n",
      "token id to text: omest\n",
      "text to token id: 1222\n",
      "token id to text: aid\n",
      "text to token id: 1223\n",
      "token id to text:  around\n",
      "text to token id: 1224\n",
      "token id to text:  With\n",
      "text to token id: 1225\n",
      "token id to text: ility\n",
      "text to token id: 1226\n",
      "token id to text: men\n",
      "text to token id: 1227\n",
      "token id to text:  resp\n",
      "text to token id: 1228\n",
      "token id to text:  Asia\n",
      "text to token id: 1229\n",
      "token id to text: ians\n",
      "text to token id: 1230\n",
      "token id to text:  tw\n",
      "text to token id: 1231\n",
      "token id to text: though\n",
      "text to token id: 1232\n",
      "token id to text:  settle\n",
      "text to token id: 1233\n",
      "token id to text: ended\n",
      "text to token id: 1234\n",
      "token id to text:  co\n",
      "text to token id: 1235\n",
      "token id to text:  Battle\n",
      "text to token id: 1236\n",
      "token id to text: ye\n",
      "text to token id: 1237\n",
      "token id to text: ok\n",
      "text to token id: 1238\n",
      "token id to text:  It\n",
      "text to token id: 1239\n",
      "token id to text:  lost\n",
      "text to token id: 1240\n",
      "token id to text:  cour\n",
      "text to token id: 1241\n",
      "token id to text:  court\n",
      "text to token id: 1242\n",
      "token id to text: anded\n",
      "text to token id: 1243\n",
      "token id to text: ning\n",
      "text to token id: 1244\n",
      "token id to text:  By\n",
      "text to token id: 1245\n",
      "token id to text: ban\n",
      "text to token id: 1246\n",
      "token id to text:  within\n",
      "text to token id: 1247\n",
      "token id to text:  forced\n",
      "text to token id: 1248\n",
      "token id to text: led\n",
      "text to token id: 1249\n",
      "token id to text:  dr\n",
      "text to token id: 1250\n",
      "token id to text: ably\n",
      "text to token id: 1251\n",
      "token id to text:  rulers\n",
      "text to token id: 1252\n",
      "token id to text: arch\n",
      "text to token id: 1253\n",
      "token id to text:  success\n",
      "text to token id: 1254\n",
      "token id to text: orted\n",
      "text to token id: 1255\n",
      "token id to text: ox\n",
      "text to token id: 1256\n",
      "token id to text:  brought\n",
      "text to token id: 1257\n",
      "token id to text: ched\n",
      "text to token id: 1258\n",
      "token id to text: omad\n",
      "text to token id: 1259\n",
      "token id to text: itions\n",
      "text to token id: 1260\n",
      "token id to text: ris\n",
      "text to token id: 1261\n",
      "token id to text: lord\n",
      "text to token id: 1262\n",
      "token id to text:  Nan\n",
      "text to token id: 1263\n",
      "token id to text:  fact\n",
      "text to token id: 1264\n",
      "token id to text:  regimes\n",
      "text to token id: 1265\n",
      "token id to text:  grow\n",
      "text to token id: 1266\n",
      "token id to text:  tribut\n",
      "text to token id: 1267\n",
      "token id to text:  Kh\n",
      "text to token id: 1268\n",
      "token id to text:  ended\n",
      "text to token id: 1269\n",
      "token id to text: 199\n",
      "text to token id: 1270\n",
      "token id to text:  millen\n",
      "text to token id: 1271\n",
      "token id to text:  millenn\n",
      "text to token id: 1272\n",
      "token id to text: ross\n",
      "text to token id: 1273\n",
      "token id to text:  area\n",
      "text to token id: 1274\n",
      "token id to text:  pros\n",
      "text to token id: 1275\n",
      "token id to text:  emerged\n",
      "text to token id: 1276\n",
      "token id to text:  Yellow\n",
      "text to token id: 1277\n",
      "token id to text:  west\n",
      "text to token id: 1278\n",
      "token id to text:  increasing\n",
      "text to token id: 1279\n",
      "token id to text:  pl\n",
      "text to token id: 1280\n",
      "token id to text:  ins\n",
      "text to token id: 1281\n",
      "token id to text:  tex\n",
      "text to token id: 1282\n",
      "token id to text:  lit\n",
      "text to token id: 1283\n",
      "token id to text:  po\n",
      "text to token id: 1284\n",
      "token id to text:  disp\n",
      "text to token id: 1285\n",
      "token id to text:  Heaven\n",
      "text to token id: 1286\n",
      "token id to text:  Confucianism\n",
      "text to token id: 1287\n",
      "token id to text:  Leg\n",
      "text to token id: 1288\n",
      "token id to text:  AD\n",
      "text to token id: 1289\n",
      "token id to text:  term\n",
      "text to token id: 1290\n",
      "token id to text: hold\n",
      "text to token id: 1291\n",
      "token id to text:  signific\n",
      "text to token id: 1292\n",
      "token id to text:  significant\n",
      "text to token id: 1293\n",
      "token id to text:  technology\n",
      "text to token id: 1294\n",
      "token id to text:  paper\n",
      "text to token id: 1295\n",
      "token id to text:  Buddhism\n",
      "text to token id: 1296\n",
      "token id to text:  flour\n",
      "text to token id: 1297\n",
      "token id to text:  powerful\n",
      "text to token id: 1298\n",
      "token id to text: 58\n",
      "text to token id: 1299\n",
      "token id to text:  development\n",
      "text to token id: 1300\n",
      "token id to text:  Three\n",
      "text to token id: 1301\n",
      "token id to text:  enc\n",
      "text to token id: 1302\n",
      "token id to text:  came\n",
      "text to token id: 1303\n",
      "token id to text:  Chiang\n",
      "text to token id: 1304\n",
      "token id to text:  Ar\n",
      "text to token id: 1305\n",
      "token id to text: rup\n",
      "text to token id: 1306\n",
      "token id to text:  indu\n",
      "text to token id: 1307\n",
      "token id to text:  defeat\n",
      "text to token id: 1308\n",
      "token id to text:  acc\n",
      "text to token id: 1309\n",
      "token id to text: ipl\n",
      "text to token id: 1310\n",
      "token id to text: ultural\n",
      "text to token id: 1311\n",
      "token id to text:  numerous\n",
      "text to token id: 1312\n",
      "token id to text:  dated\n",
      "text to token id: 1313\n",
      "token id to text:  through\n",
      "text to token id: 1314\n",
      "token id to text:  three\n",
      "text to token id: 1315\n",
      "token id to text: ind\n",
      "text to token id: 1316\n",
      "token id to text: imate\n",
      "text to token id: 1317\n",
      "token id to text: -d\n",
      "text to token id: 1318\n",
      "token id to text: sh\n",
      "text to token id: 1319\n",
      "token id to text:  prot\n",
      "text to token id: 1320\n",
      "token id to text: rop\n",
      "text to token id: 1321\n",
      "token id to text:  remained\n",
      "text to token id: 1322\n",
      "token id to text:  city\n",
      "text to token id: 1323\n",
      "token id to text: bei\n",
      "text to token id: 1324\n",
      "token id to text: iated\n",
      "text to token id: 1325\n",
      "token id to text:  both\n",
      "text to token id: 1326\n",
      "token id to text: uals\n",
      "text to token id: 1327\n",
      "token id to text:  trans\n",
      "text to token id: 1328\n",
      "token id to text:  att\n",
      "text to token id: 1329\n",
      "token id to text:  Anyang\n",
      "text to token id: 1330\n",
      "token id to text: —\n",
      "text to token id: 1331\n",
      "token id to text:  prov\n",
      "text to token id: 1332\n",
      "token id to text:  defeated\n",
      "text to token id: 1333\n",
      "token id to text: ives\n",
      "text to token id: 1334\n",
      "token id to text:  two\n",
      "text to token id: 1335\n",
      "token id to text:  Hu\n",
      "text to token id: 1336\n",
      "token id to text:  Eastern\n",
      "text to token id: 1337\n",
      "token id to text:  States\n",
      "text to token id: 1338\n",
      "token id to text: und\n",
      "text to token id: 1339\n",
      "token id to text:  society\n",
      "text to token id: 1340\n",
      "token id to text: are\n",
      "text to token id: 1341\n",
      "token id to text: ellect\n",
      "text to token id: 1342\n",
      "token id to text:  made\n",
      "text to token id: 1343\n",
      "token id to text: sel\n",
      "text to token id: 1344\n",
      "token id to text:  ===\n",
      "\n",
      "\n",
      "\n",
      "text to token id: 1345\n",
      "token id to text:  curren\n",
      "text to token id: 1346\n",
      "token id to text: struc\n",
      "text to token id: 1347\n",
      "token id to text: tur\n",
      "text to token id: 1348\n",
      "token id to text:  unified\n",
      "text to token id: 1349\n",
      "token id to text: xt\n",
      "text to token id: 1350\n",
      "token id to text:  polic\n",
      "text to token id: 1351\n",
      "token id to text:  nomad\n",
      "text to token id: 1352\n",
      "token id to text:  nomadic\n",
      "text to token id: 1353\n",
      "token id to text: ected\n",
      "text to token id: 1354\n",
      "token id to text:  trib\n",
      "text to token id: 1355\n",
      "token id to text:  tribes\n",
      "text to token id: 1356\n",
      "token id to text: 11\n",
      "text to token id: 1357\n",
      "token id to text:  caus\n",
      "text to token id: 1358\n",
      "token id to text: aged\n",
      "text to token id: 1359\n",
      "token id to text:  Se\n",
      "text to token id: 1360\n",
      "token id to text:  Six\n",
      "text to token id: 1361\n",
      "token id to text:  weakened\n",
      "text to token id: 1362\n",
      "token id to text:  officials\n",
      "text to token id: 1363\n",
      "token id to text:  army\n",
      "text to token id: 1364\n",
      "token id to text: agan\n",
      "text to token id: 1365\n",
      "token id to text: ty\n",
      "text to token id: 1366\n",
      "token id to text:  market\n",
      "text to token id: 1367\n",
      "token id to text:  United\n",
      "text to token id: 1368\n",
      "token id to text:  sever\n",
      "text to token id: 1369\n",
      "token id to text:  prosper\n",
      "text to token id: 1370\n",
      "token id to text: stitut\n",
      "text to token id: 1371\n",
      "token id to text:  groups\n",
      "text to token id: 1372\n",
      "token id to text: ise\n",
      "text to token id: 1373\n",
      "token id to text: tain\n",
      "text to token id: 1374\n",
      "token id to text:  can\n",
      "text to token id: 1375\n",
      "token id to text:  cr\n",
      "text to token id: 1376\n",
      "token id to text: les\n",
      "text to token id: 1377\n",
      "token id to text:  various\n",
      "text to token id: 1378\n",
      "token id to text:  dominant\n",
      "text to token id: 1379\n",
      "token id to text:  controll\n",
      "text to token id: 1380\n",
      "token id to text:  controlled\n",
      "text to token id: 1381\n",
      "token id to text: ret\n",
      "text to token id: 1382\n",
      "token id to text:  Erlit\n",
      "text to token id: 1383\n",
      "token id to text:  Erlitou\n",
      "text to token id: 1384\n",
      "token id to text:  surv\n",
      "text to token id: 1385\n",
      "token id to text:  texts\n",
      "text to token id: 1386\n",
      "token id to text:  liter\n",
      "text to token id: 1387\n",
      "token id to text:  records\n",
      "text to token id: 1388\n",
      "token id to text:  independent\n",
      "text to token id: 1389\n",
      "token id to text:  lang\n",
      "text to token id: 1390\n",
      "token id to text:  langu\n",
      "text to token id: 1391\n",
      "token id to text: 104\n",
      "text to token id: 1392\n",
      "token id to text: 25\n",
      "text to token id: 1393\n",
      "token id to text:  Legal\n",
      "text to token id: 1394\n",
      "token id to text: Chin\n",
      "text to token id: 1395\n",
      "token id to text: 21\n",
      "text to token id: 1396\n",
      "token id to text:  entered\n",
      "text to token id: 1397\n",
      "token id to text:  class\n",
      "text to token id: 1398\n",
      "token id to text: 220\n",
      "text to token id: 1399\n",
      "token id to text:  ancient\n",
      "text to token id: 1400\n",
      "token id to text:  order\n",
      "text to token id: 1401\n",
      "token id to text:  coll\n",
      "text to token id: 1402\n",
      "token id to text:  centur\n",
      "text to token id: 1403\n",
      "token id to text:  centuries\n",
      "text to token id: 1404\n",
      "token id to text:  art\n",
      "text to token id: 1405\n",
      "token id to text:  Sui\n",
      "text to token id: 1406\n",
      "token id to text: 90\n",
      "text to token id: 1407\n",
      "token id to text:  recog\n",
      "text to token id: 1408\n",
      "token id to text:  recogn\n",
      "text to token id: 1409\n",
      "token id to text: 960\n",
      "text to token id: 1410\n",
      "token id to text:  prin\n",
      "text to token id: 1411\n",
      "token id to text: ucture\n",
      "text to token id: 1412\n",
      "token id to text:  bureaucracy\n",
      "text to token id: 1413\n",
      "token id to text:  Eur\n",
      "text to token id: 1414\n",
      "token id to text: ob\n",
      "text to token id: 1415\n",
      "token id to text: ose\n",
      "text to token id: 1416\n",
      "token id to text: rand\n",
      "text to token id: 1417\n",
      "token id to text:  Manchu\n",
      "text to token id: 1418\n",
      "token id to text: 17\n",
      "text to token id: 1419\n",
      "token id to text: ean\n",
      "text to token id: 1420\n",
      "token id to text:  Sun\n",
      "text to token id: 1421\n",
      "token id to text: ading\n",
      "text to token id: 1422\n",
      "token id to text:  until\n",
      "text to token id: 1423\n",
      "token id to text:  RO\n",
      "text to token id: 1424\n",
      "token id to text:  ROC\n",
      "text to token id: 1425\n",
      "token id to text:  entire\n",
      "text to token id: 1426\n",
      "token id to text:  dipl\n",
      "text to token id: 1427\n",
      "token id to text:  diplom\n",
      "text to token id: 1428\n",
      "token id to text: 197\n",
      "text to token id: 1429\n",
      "token id to text:  decad\n",
      "text to token id: 1430\n",
      "token id to text:  decades\n",
      "text to token id: 1431\n",
      "token id to text:  Ind\n",
      "text to token id: 1432\n",
      "token id to text:  ==\n",
      "\n",
      "\n",
      "\n",
      "text to token id: 1433\n",
      "token id to text:  arch\n",
      "text to token id: 1434\n",
      "token id to text:  archa\n",
      "text to token id: 1435\n",
      "token id to text:  spec\n",
      "text to token id: 1436\n",
      "token id to text: -f\n",
      "text to token id: 1437\n",
      "token id to text:  hy\n",
      "text to token id: 1438\n",
      "token id to text: covered\n",
      "text to token id: 1439\n",
      "token id to text:  Sha\n",
      "text to token id: 1440\n",
      "token id to text: anxi\n",
      "text to token id: 1441\n",
      "token id to text: ories\n",
      "text to token id: 1442\n",
      "token id to text: ined\n",
      "text to token id: 1443\n",
      "token id to text:  agriculture\n",
      "text to token id: 1444\n",
      "token id to text:  gradually\n",
      "text to token id: 1445\n",
      "token id to text:  add\n",
      "text to token id: 1446\n",
      "token id to text:  evidence\n",
      "text to token id: 1447\n",
      "token id to text:  Jia\n",
      "text to token id: 1448\n",
      "token id to text:  char\n",
      "text to token id: 1449\n",
      "token id to text: ording\n",
      "text to token id: 1450\n",
      "token id to text:  increased\n",
      "text to token id: 1451\n",
      "token id to text: 200\n",
      "text to token id: 1452\n",
      "token id to text:  bl\n",
      "text to token id: 1453\n",
      "token id to text:  Tib\n",
      "text to token id: 1454\n",
      "token id to text:  Tibet\n",
      "text to token id: 1455\n",
      "token id to text:  Zhang\n",
      "text to token id: 1456\n",
      "token id to text:  des\n",
      "text to token id: 1457\n",
      "token id to text: ously\n",
      "text to token id: 1458\n",
      "token id to text: ase\n",
      "text to token id: 1459\n",
      "token id to text: gan\n",
      "text to token id: 1460\n",
      "token id to text: omp\n",
      "text to token id: 1461\n",
      "token id to text: els\n",
      "text to token id: 1462\n",
      "token id to text:  Zheng\n",
      "text to token id: 1463\n",
      "token id to text:  series\n",
      "text to token id: 1464\n",
      "token id to text: mous\n",
      "text to token id: 1465\n",
      "token id to text:  hal\n",
      "text to token id: 1466\n",
      "token id to text:  extended\n",
      "text to token id: 1467\n",
      "token id to text:  western\n",
      "text to token id: 1468\n",
      "token id to text:  nat\n",
      "text to token id: 1469\n",
      "token id to text:  numb\n",
      "text to token id: 1470\n",
      "token id to text:  gran\n",
      "text to token id: 1471\n",
      "token id to text: uoyang\n",
      "text to token id: 1472\n",
      "token id to text:  expanded\n",
      "text to token id: 1473\n",
      "token id to text:  Spring\n",
      "text to token id: 1474\n",
      "token id to text:  Aut\n",
      "text to token id: 1475\n",
      "token id to text:  Autum\n",
      "text to token id: 1476\n",
      "token id to text:  Autumn\n",
      "text to token id: 1477\n",
      "token id to text: ority\n",
      "text to token id: 1478\n",
      "token id to text: wn\n",
      "text to token id: 1479\n",
      "token id to text:  sm\n",
      "text to token id: 1480\n",
      "token id to text:  small\n",
      "text to token id: 1481\n",
      "token id to text: urban\n",
      "text to token id: 1482\n",
      "token id to text: ources\n",
      "text to token id: 1483\n",
      "token id to text:  each\n",
      "text to token id: 1484\n",
      "token id to text:  held\n",
      "text to token id: 1485\n",
      "token id to text:  territories\n",
      "text to token id: 1486\n",
      "token id to text:  him\n",
      "text to token id: 1487\n",
      "token id to text: self\n",
      "text to token id: 1488\n",
      "token id to text:  effect\n",
      "text to token id: 1489\n",
      "token id to text:  per\n",
      "text to token id: 1490\n",
      "token id to text:  fail\n",
      "text to token id: 1491\n",
      "token id to text:  divis\n",
      "text to token id: 1492\n",
      "token id to text:  Xion\n",
      "text to token id: 1493\n",
      "token id to text:  Xiong\n",
      "text to token id: 1494\n",
      "token id to text: uil\n",
      "text to token id: 1495\n",
      "token id to text: ack\n",
      "text to token id: 1496\n",
      "token id to text:  followed\n",
      "text to token id: 1497\n",
      "token id to text:  territory\n",
      "text to token id: 1498\n",
      "token id to text:  policies\n",
      "text to token id: 1499\n",
      "token id to text:  laun\n",
      "text to token id: 1500\n",
      "token id to text:  conn\n",
      "text to token id: 1501\n",
      "token id to text:  upris\n",
      "text to token id: 1502\n",
      "token id to text:  kill\n",
      "text to token id: 1503\n",
      "token id to text:  peasant\n",
      "text to token id: 1504\n",
      "token id to text: erch\n",
      "text to token id: 1505\n",
      "token id to text:  Reb\n",
      "text to token id: 1506\n",
      "token id to text:  Rebellion\n",
      "text to token id: 1507\n",
      "token id to text:  warlord\n",
      "text to token id: 1508\n",
      "token id to text:  reun\n",
      "text to token id: 1509\n",
      "token id to text: entral\n",
      "text to token id: 1510\n",
      "token id to text:  Chang\n",
      "text to token id: 1511\n",
      "token id to text:  Nanjing\n",
      "text to token id: 1512\n",
      "token id to text:  growth\n",
      "text to token id: 1513\n",
      "token id to text:  relig\n",
      "text to token id: 1514\n",
      "token id to text:  largest\n",
      "text to token id: 1515\n",
      "token id to text:  marit\n",
      "text to token id: 1516\n",
      "token id to text:  maritime\n",
      "text to token id: 1517\n",
      "token id to text:  memb\n",
      "text to token id: 1518\n",
      "token id to text:  suppress\n",
      "text to token id: 1519\n",
      "token id to text:  Zhuye\n",
      "text to token id: 1520\n",
      "token id to text: aganate\n",
      "text to token id: 1521\n",
      "token id to text: reaty\n",
      "text to token id: 1522\n",
      "token id to text: yle\n",
      "text to token id: 1523\n",
      "token id to text: ared\n",
      "text to token id: 1524\n",
      "token id to text: ired\n",
      "text to token id: 1525\n",
      "token id to text: ake\n",
      "text to token id: 1526\n",
      "token id to text:  result\n",
      "text to token id: 1527\n",
      "token id to text: vement\n",
      "text to token id: 1528\n",
      "token id to text: oviet\n",
      "text to token id: 1529\n",
      "token id to text:  Nationalist\n",
      "text to token id: 1530\n",
      "token id to text:  across\n",
      "text to token id: 1531\n",
      "token id to text: istic\n",
      "text to token id: 1532\n",
      "token id to text: crib\n",
      "text to token id: 1533\n",
      "token id to text: cribed\n",
      "text to token id: 1534\n",
      "token id to text: vements\n",
      "text to token id: 1535\n",
      "token id to text: ands\n",
      "text to token id: 1536\n",
      "token id to text:  Bas\n",
      "text to token id: 1537\n",
      "token id to text:  increasingly\n",
      "text to token id: 1538\n",
      "token id to text:  begin\n",
      "text to token id: 1539\n",
      "token id to text:  rough\n",
      "text to token id: 1540\n",
      "token id to text:  roughly\n",
      "text to token id: 1541\n",
      "token id to text:  cor\n",
      "text to token id: 1542\n",
      "token id to text:  writing\n",
      "text to token id: 1543\n",
      "token id to text:  include\n",
      "text to token id: 1544\n",
      "token id to text:  poet\n",
      "text to token id: 1545\n",
      "token id to text: ination\n",
      "text to token id: 1546\n",
      "token id to text:  bel\n",
      "text to token id: 1547\n",
      "token id to text:  belie\n",
      "text to token id: 1548\n",
      "token id to text: very\n",
      "text to token id: 1549\n",
      "token id to text:  invent\n",
      "text to token id: 1550\n",
      "token id to text:  language\n",
      "text to token id: 1551\n",
      "token id to text:  Mand\n",
      "text to token id: 1552\n",
      "token id to text:  Mandate\n",
      "text to token id: 1553\n",
      "token id to text: roduc\n",
      "text to token id: 1554\n",
      "token id to text:  phil\n",
      "text to token id: 1555\n",
      "token id to text:  philos\n",
      "text to token id: 1556\n",
      "token id to text:  philosoph\n",
      "text to token id: 1557\n",
      "token id to text:  Tao\n",
      "text to token id: 1558\n",
      "token id to text:  Legalism\n",
      "text to token id: 1559\n",
      "token id to text: China\n",
      "text to token id: 1560\n",
      "token id to text:  standard\n",
      "text to token id: 1561\n",
      "token id to text: 202\n",
      "text to token id: 1562\n",
      "token id to text:  still\n",
      "text to token id: 1563\n",
      "token id to text: Han\n",
      "text to token id: 1564\n",
      "token id to text:  extent\n",
      "text to token id: 1565\n",
      "token id to text:  officially\n",
      "text to token id: 1566\n",
      "token id to text: thy\n",
      "text to token id: 1567\n",
      "token id to text:  landhold\n",
      "text to token id: 1568\n",
      "token id to text: iel\n",
      "text to token id: 1569\n",
      "token id to text: ield\n",
      "text to token id: 1570\n",
      "token id to text:  par\n",
      "text to token id: 1571\n",
      "token id to text:  contemporane\n",
      "text to token id: 1572\n",
      "token id to text:  prol\n",
      "text to token id: 1573\n",
      "token id to text:  intern\n",
      "text to token id: 1574\n",
      "token id to text:  equ\n",
      "text to token id: 1575\n",
      "token id to text: ory\n",
      "text to token id: 1576\n",
      "token id to text:  so\n",
      "text to token id: 1577\n",
      "token id to text: -lived\n",
      "text to token id: 1578\n",
      "token id to text: 907\n",
      "text to token id: 1579\n",
      "token id to text: olden\n",
      "text to token id: 1580\n",
      "token id to text:  age\n",
      "text to token id: 1581\n",
      "token id to text:  sci\n",
      "text to token id: 1582\n",
      "token id to text:  science\n",
      "text to token id: 1583\n",
      "token id to text:  emperors\n",
      "text to token id: 1584\n",
      "token id to text:  conquered\n",
      "text to token id: 1585\n",
      "token id to text:  Europ\n",
      "text to token id: 1586\n",
      "token id to text: 136\n",
      "text to token id: 1587\n",
      "token id to text: 164\n",
      "text to token id: 1588\n",
      "token id to text:  por\n",
      "text to token id: 1589\n",
      "token id to text: lain\n",
      "text to token id: 1590\n",
      "token id to text:  proj\n",
      "text to token id: 1591\n",
      "token id to text:  projects\n",
      "text to token id: 1592\n",
      "token id to text:  Grand\n",
      "text to token id: 1593\n",
      "token id to text:  Can\n",
      "text to token id: 1594\n",
      "token id to text:  Canal\n",
      "text to token id: 1595\n",
      "token id to text:  succe\n",
      "text to token id: 1596\n",
      "token id to text:  compl\n",
      "text to token id: 1597\n",
      "token id to text:  near\n",
      "text to token id: 1598\n",
      "token id to text:  Imperial\n",
      "text to token id: 1599\n",
      "token id to text:  Revolution\n",
      "text to token id: 1600\n",
      "token id to text:  created\n",
      "text to token id: 1601\n",
      "token id to text:  Communist\n",
      "text to token id: 1602\n",
      "token id to text:  Army\n",
      "text to token id: 1603\n",
      "token id to text:  inter\n",
      "text to token id: 1604\n",
      "token id to text:  industr\n",
      "text to token id: 1605\n",
      "token id to text:  Wor\n",
      "text to token id: 1606\n",
      "token id to text:  World\n",
      "text to token id: 1607\n",
      "token id to text: After\n",
      "text to token id: 1608\n",
      "token id to text:  vict\n",
      "text to token id: 1609\n",
      "token id to text:  Pe\n",
      "text to token id: 1610\n",
      "token id to text: ole\n",
      "text to token id: 1611\n",
      "token id to text:  sl\n",
      "text to token id: 1612\n",
      "token id to text: ulated\n",
      "text to token id: 1613\n",
      "token id to text:  majority\n",
      "text to token id: 1614\n",
      "token id to text:  consol\n",
      "text to token id: 1615\n",
      "token id to text:  consolid\n",
      "text to token id: 1616\n",
      "token id to text:  since\n",
      "text to token id: 1617\n",
      "token id to text:  hum\n",
      "text to token id: 1618\n",
      "token id to text: omo\n",
      "text to token id: 1619\n",
      "token id to text: iron\n",
      "text to token id: 1620\n",
      "token id to text: side\n",
      "text to token id: 1621\n",
      "token id to text:  ele\n",
      "text to token id: 1622\n",
      "token id to text: iant\n",
      "text to token id: 1623\n",
      "token id to text:  short\n",
      "text to token id: 1624\n",
      "token id to text:  discovered\n",
      "text to token id: 1625\n",
      "token id to text:  throughout\n",
      "text to token id: 1626\n",
      "token id to text:  Shaanxi\n",
      "text to token id: 1627\n",
      "token id to text:  well\n",
      "text to token id: 1628\n",
      "token id to text:  min\n",
      "text to token id: 1629\n",
      "token id to text:  occur\n",
      "text to token id: 1630\n",
      "token id to text:  occurred\n",
      "text to token id: 1631\n",
      "token id to text:  archae\n",
      "text to token id: 1632\n",
      "token id to text:  regional\n",
      "text to token id: 1633\n",
      "token id to text: less\n",
      "text to token id: 1634\n",
      "token id to text: 80\n",
      "text to token id: 1635\n",
      "token id to text: imately\n",
      "text to token id: 1636\n",
      "token id to text:  regions\n",
      "text to token id: 1637\n",
      "token id to text:  domest\n",
      "text to token id: 1638\n",
      "token id to text: arly\n",
      "text to token id: 1639\n",
      "token id to text: hu\n",
      "text to token id: 1640\n",
      "token id to text:  preser\n",
      "text to token id: 1641\n",
      "token id to text:  red\n",
      "text to token id: 1642\n",
      "token id to text: istribut\n",
      "text to token id: 1643\n",
      "token id to text:  existed\n",
      "text to token id: 1644\n",
      "token id to text:  Liang\n",
      "text to token id: 1645\n",
      "token id to text: 300\n",
      "text to token id: 1646\n",
      "token id to text: ick\n",
      "text to token id: 1647\n",
      "token id to text: ronze\n",
      "text to token id: 1648\n",
      "token id to text: ji\n",
      "text to token id: 1649\n",
      "token id to text: 160\n",
      "text to token id: 1650\n",
      "token id to text: theast\n",
      "text to token id: 1651\n",
      "token id to text:  kings\n",
      "text to token id: 1652\n",
      "token id to text:  high\n",
      "text to token id: 1653\n",
      "token id to text:  met\n",
      "text to token id: 1654\n",
      "token id to text: au\n",
      "text to token id: 1655\n",
      "token id to text:  scholars\n",
      "text to token id: 1656\n",
      "token id to text:  refer\n",
      "text to token id: 1657\n",
      "token id to text:  conc\n",
      "text to token id: 1658\n",
      "token id to text: tly\n",
      "text to token id: 1659\n",
      "token id to text:  same\n",
      "text to token id: 1660\n",
      "token id to text:  historical\n",
      "text to token id: 1661\n",
      "token id to text:  no\n",
      "text to token id: 1662\n",
      "token id to text:  elite\n",
      "text to token id: 1663\n",
      "token id to text: itted\n",
      "text to token id: 1664\n",
      "token id to text: ll\n",
      "text to token id: 1665\n",
      "token id to text:  used\n",
      "text to token id: 1666\n",
      "token id to text: amp\n",
      "text to token id: 1667\n",
      "token id to text:  advan\n",
      "text to token id: 1668\n",
      "token id to text:  They\n",
      "text to token id: 1669\n",
      "token id to text:  natural\n",
      "text to token id: 1670\n",
      "token id to text:  roy\n",
      "text to token id: 1671\n",
      "token id to text:  royal\n",
      "text to token id: 1672\n",
      "token id to text: ouse\n",
      "text to token id: 1673\n",
      "token id to text:  granted\n",
      "text to token id: 1674\n",
      "token id to text: ocr\n",
      "text to token id: 1675\n",
      "token id to text:  Luoyang\n",
      "text to token id: 1676\n",
      "token id to text:  second\n",
      "text to token id: 1677\n",
      "token id to text:  Warring\n",
      "text to token id: 1678\n",
      "token id to text:  local\n",
      "text to token id: 1679\n",
      "token id to text: undred\n",
      "text to token id: 1680\n",
      "token id to text: rew\n",
      "text to token id: 1681\n",
      "token id to text:  family\n",
      "text to token id: 1682\n",
      "token id to text:  intellect\n",
      "text to token id: 1683\n",
      "token id to text:  Mo\n",
      "text to token id: 1684\n",
      "token id to text:  chang\n",
      "text to token id: 1685\n",
      "token id to text: ormous\n",
      "text to token id: 1686\n",
      "token id to text: ven\n",
      "text to token id: 1687\n",
      "token id to text: att\n",
      "text to token id: 1688\n",
      "token id to text: ection\n",
      "text to token id: 1689\n",
      "token id to text:  base\n",
      "text to token id: 1690\n",
      "token id to text:  administrative\n",
      "text to token id: 1691\n",
      "token id to text:  himself\n",
      "text to token id: 1692\n",
      "token id to text:  emph\n",
      "text to token id: 1693\n",
      "token id to text:  emphas\n",
      "text to token id: 1694\n",
      "token id to text:  impro\n",
      "text to token id: 1695\n",
      "token id to text: ons\n",
      "text to token id: 1696\n",
      "token id to text: cy\n",
      "text to token id: 1697\n",
      "token id to text: espite\n",
      "text to token id: 1698\n",
      "token id to text: lement\n",
      "text to token id: 1699\n",
      "token id to text:  non\n",
      "text to token id: 1700\n",
      "token id to text: su\n",
      "text to token id: 1701\n",
      "token id to text:  conscrip\n",
      "text to token id: 1702\n",
      "token id to text:  lab\n",
      "text to token id: 1703\n",
      "token id to text:  labor\n",
      "text to token id: 1704\n",
      "token id to text:  massive\n",
      "text to token id: 1705\n",
      "token id to text:  Xiongn\n",
      "text to token id: 1706\n",
      "token id to text:  Xiongnu\n",
      "text to token id: 1707\n",
      "token id to text:  buil\n",
      "text to token id: 1708\n",
      "token id to text: tured\n",
      "text to token id: 1709\n",
      "token id to text: ability\n",
      "text to token id: 1710\n",
      "token id to text:  next\n",
      "text to token id: 1711\n",
      "token id to text:  name\n",
      "text to token id: 1712\n",
      "token id to text:  z\n",
      "text to token id: 1713\n",
      "token id to text:  however\n",
      "text to token id: 1714\n",
      "token id to text: ned\n",
      "text to token id: 1715\n",
      "token id to text:  campaigns\n",
      "text to token id: 1716\n",
      "token id to text:  launched\n",
      "text to token id: 1717\n",
      "token id to text: ilk\n",
      "text to token id: 1718\n",
      "token id to text:  decline\n",
      "text to token id: 1719\n",
      "token id to text:  treas\n",
      "text to token id: 1720\n",
      "token id to text:  Wang\n",
      "text to token id: 1721\n",
      "token id to text:  national\n",
      "text to token id: 1722\n",
      "token id to text:  peasants\n",
      "text to token id: 1723\n",
      "token id to text:  loss\n",
      "text to token id: 1724\n",
      "token id to text:  merch\n",
      "text to token id: 1725\n",
      "token id to text:  tur\n",
      "text to token id: 1726\n",
      "token id to text: teen\n",
      "text to token id: 1727\n",
      "token id to text:  Xianbei\n",
      "text to token id: 1728\n",
      "token id to text:  Tur\n",
      "text to token id: 1729\n",
      "token id to text: inic\n",
      "text to token id: 1730\n",
      "token id to text:  allow\n",
      "text to token id: 1731\n",
      "token id to text:  allowed\n",
      "text to token id: 1732\n",
      "token id to text:  division\n",
      "text to token id: 1733\n",
      "token id to text:  fier\n",
      "text to token id: 1734\n",
      "token id to text:  fierce\n",
      "text to token id: 1735\n",
      "token id to text:  Int\n",
      "text to token id: 1736\n",
      "token id to text:  partic\n",
      "text to token id: 1737\n",
      "token id to text:  Ta\n",
      "text to token id: 1738\n",
      "token id to text:  Central\n",
      "text to token id: 1739\n",
      "token id to text:  centers\n",
      "text to token id: 1740\n",
      "token id to text:  trav\n",
      "text to token id: 1741\n",
      "token id to text:  members\n",
      "text to token id: 1742\n",
      "token id to text: ivate\n",
      "text to token id: 1743\n",
      "token id to text: sive\n",
      "text to token id: 1744\n",
      "token id to text:  fell\n",
      "text to token id: 1745\n",
      "token id to text:  following\n",
      "text to token id: 1746\n",
      "token id to text:  Shat\n",
      "text to token id: 1747\n",
      "token id to text:  Shatuo\n",
      "text to token id: 1748\n",
      "token id to text: osed\n",
      "text to token id: 1749\n",
      "token id to text:  Treaty\n",
      "text to token id: 1750\n",
      "token id to text: avy\n",
      "text to token id: 1751\n",
      "token id to text:  invasion\n",
      "text to token id: 1752\n",
      "token id to text:  fac\n",
      "text to token id: 1753\n",
      "token id to text:  facil\n",
      "text to token id: 1754\n",
      "token id to text:  strong\n",
      "text to token id: 1755\n",
      "token id to text:  Sin\n",
      "text to token id: 1756\n",
      "token id to text:  Sino\n",
      "text to token id: 1757\n",
      "token id to text:  Manchus\n",
      "text to token id: 1758\n",
      "token id to text: ird\n",
      "text to token id: 1759\n",
      "token id to text:  Brit\n",
      "text to token id: 1760\n",
      "token id to text:  commun\n",
      "text to token id: 1761\n",
      "token id to text:  Box\n",
      "text to token id: 1762\n",
      "token id to text: 193\n",
      "text to token id: 1763\n",
      "token id to text: ugg\n",
      "text to token id: 1764\n",
      "token id to text: MT\n",
      "text to token id: 1765\n",
      "token id to text:  Communists\n",
      "text to token id: 1766\n",
      "token id to text: 201\n",
      "text to token id: 1767\n",
      "token id to text:  several\n",
      "text to token id: 1768\n",
      "token id to text:  millennia\n",
      "text to token id: 1769\n",
      "token id to text:  ge\n",
      "text to token id: 1770\n",
      "token id to text:  geograph\n",
      "text to token id: 1771\n",
      "token id to text:  periods\n",
      "text to token id: 1772\n",
      "token id to text:  prosperity\n",
      "text to token id: 1773\n",
      "token id to text: ife\n",
      "text to token id: 1774\n",
      "token id to text:  sphere\n",
      "text to token id: 1775\n",
      "token id to text: ertain\n",
      "text to token id: 1776\n",
      "token id to text:  times\n",
      "text to token id: 1777\n",
      "token id to text:  Tian\n",
      "text to token id: 1778\n",
      "token id to text:  Basin\n",
      "text to token id: 1779\n",
      "token id to text: ta\n",
      "text to token id: 1780\n",
      "token id to text:  saw\n",
      "text to token id: 1781\n",
      "token id to text: lex\n",
      "text to token id: 1782\n",
      "token id to text: ics\n",
      "text to token id: 1783\n",
      "token id to text:  somet\n",
      "text to token id: 1784\n",
      "token id to text: ography\n",
      "text to token id: 1785\n",
      "token id to text:  surviving\n",
      "text to token id: 1786\n",
      "token id to text: 125\n",
      "text to token id: 1787\n",
      "token id to text:  bon\n",
      "text to token id: 1788\n",
      "token id to text:  bones\n",
      "text to token id: 1789\n",
      "token id to text:  bron\n",
      "text to token id: 1790\n",
      "token id to text: ature\n",
      "text to token id: 1791\n",
      "token id to text:  poetry\n",
      "text to token id: 1792\n",
      "token id to text:  displ\n",
      "text to token id: 1793\n",
      "token id to text: 256\n",
      "text to token id: 1794\n",
      "token id to text:  introduc\n",
      "text to token id: 1795\n",
      "token id to text: 221\n",
      "text to token id: 1796\n",
      "token id to text: ights\n",
      "text to token id: 1797\n",
      "token id to text:  law\n",
      "text to token id: 1798\n",
      "token id to text:  arist\n",
      "text to token id: 1799\n",
      "token id to text: ocracy\n",
      "text to token id: 1800\n",
      "token id to text:  contemporaneous\n",
      "text to token id: 1801\n",
      "token id to text:  finally\n",
      "text to token id: 1802\n",
      "token id to text:  four\n",
      "text to token id: 1803\n",
      "token id to text:  call\n",
      "text to token id: 1804\n",
      "token id to text:  flourished\n",
      "text to token id: 1805\n",
      "token id to text:  way\n",
      "text to token id: 1806\n",
      "token id to text:  golden\n",
      "text to token id: 1807\n",
      "token id to text: ony\n",
      "text to token id: 1808\n",
      "token id to text: itan\n",
      "text to token id: 1809\n",
      "token id to text: ock\n",
      "text to token id: 1810\n",
      "token id to text:  exam\n",
      "text to token id: 1811\n",
      "token id to text: ether\n",
      "text to token id: 1812\n",
      "token id to text: -C\n",
      "text to token id: 1813\n",
      "token id to text:  works\n",
      "text to token id: 1814\n",
      "token id to text:  rest\n",
      "text to token id: 1815\n",
      "token id to text: oring\n",
      "text to token id: 1816\n",
      "token id to text:  Qian\n",
      "text to token id: 1817\n",
      "token id to text:  complet\n",
      "text to token id: 1818\n",
      "token id to text: cl\n",
      "text to token id: 1819\n",
      "token id to text: edia\n",
      "text to token id: 1820\n",
      "token id to text:  powers\n",
      "text to token id: 1821\n",
      "token id to text:  treat\n",
      "text to token id: 1822\n",
      "token id to text:  Xin\n",
      "text to token id: 1823\n",
      "token id to text: hai\n",
      "text to token id: 1824\n",
      "token id to text:  Yat\n",
      "text to token id: 1825\n",
      "token id to text: -sen\n",
      "text to token id: 1826\n",
      "token id to text:  others\n",
      "text to token id: 1827\n",
      "token id to text:  invading\n",
      "text to token id: 1828\n",
      "token id to text:  divided\n",
      "text to token id: 1829\n",
      "token id to text:  Sec\n",
      "text to token id: 1830\n",
      "token id to text:  establishment\n",
      "text to token id: 1831\n",
      "token id to text:  People\n",
      "text to token id: 1832\n",
      "token id to text:  legit\n",
      "text to token id: 1833\n",
      "token id to text:  diplomatic\n",
      "text to token id: 1834\n",
      "token id to text:  remains\n",
      "text to token id: 1835\n",
      "token id to text:  Cultural\n",
      "text to token id: 1836\n",
      "token id to text: gr\n",
      "text to token id: 1837\n",
      "token id to text:  nation\n",
      "text to token id: 1838\n",
      "token id to text: assed\n",
      "text to token id: 1839\n",
      "token id to text:  Pal\n",
      "text to token id: 1840\n",
      "token id to text:  Homo\n",
      "text to token id: 1841\n",
      "token id to text:  erect\n",
      "text to token id: 1842\n",
      "token id to text:  erectus\n",
      "text to token id: 1843\n",
      "token id to text:  arr\n",
      "text to token id: 1844\n",
      "token id to text:  ago\n",
      "text to token id: 1845\n",
      "token id to text: �\n",
      "text to token id: 1846\n",
      "token id to text:  env\n",
      "text to token id: 1847\n",
      "token id to text: 700\n",
      "text to token id: 1848\n",
      "token id to text:  bur\n",
      "text to token id: 1849\n",
      "token id to text: ins\n",
      "text to token id: 1850\n",
      "token id to text:  widely\n",
      "text to token id: 1851\n",
      "token id to text:  sit\n",
      "text to token id: 1852\n",
      "token id to text:  deb\n",
      "text to token id: 1853\n",
      "token id to text: po\n",
      "text to token id: 1854\n",
      "token id to text: du\n",
      "text to token id: 1855\n",
      "token id to text:  Pro\n",
      "text to token id: 1856\n",
      "token id to text:  anim\n",
      "text to token id: 1857\n",
      "token id to text:  animals\n",
      "text to token id: 1858\n",
      "token id to text: roc\n",
      "text to token id: 1859\n",
      "token id to text:  ult\n",
      "text to token id: 1860\n",
      "token id to text: ima\n",
      "text to token id: 1861\n",
      "token id to text: idd\n",
      "text to token id: 1862\n",
      "token id to text:  Le\n",
      "text to token id: 1863\n",
      "token id to text: sem\n",
      "text to token id: 1864\n",
      "token id to text: ause\n",
      "text to token id: 1865\n",
      "token id to text:  initial\n",
      "text to token id: 1866\n",
      "token id to text: ication\n",
      "text to token id: 1867\n",
      "token id to text: ivated\n",
      "text to token id: 1868\n",
      "token id to text:  car\n",
      "text to token id: 1869\n",
      "token id to text: ages\n",
      "text to token id: 1870\n",
      "token id to text: 500\n",
      "text to token id: 1871\n",
      "token id to text:  charact\n",
      "text to token id: 1872\n",
      "token id to text:  according\n",
      "text to token id: 1873\n",
      "token id to text:  Ban\n",
      "text to token id: 1874\n",
      "token id to text: ential\n",
      "text to token id: 1875\n",
      "token id to text:  support\n",
      "text to token id: 1876\n",
      "token id to text:  li\n",
      "text to token id: 1877\n",
      "token id to text:  like\n",
      "text to token id: 1878\n",
      "token id to text: ries\n",
      "text to token id: 1879\n",
      "token id to text:  Bronze\n",
      "text to token id: 1880\n",
      "token id to text: acts\n",
      "text to token id: 1881\n",
      "token id to text: 198\n",
      "text to token id: 1882\n",
      "token id to text:  lin\n",
      "text to token id: 1883\n",
      "token id to text:  legend\n",
      "text to token id: 1884\n",
      "token id to text:  appear\n",
      "text to token id: 1885\n",
      "token id to text:  exc\n",
      "text to token id: 1886\n",
      "token id to text:  excav\n",
      "text to token id: 1887\n",
      "token id to text: 14\n",
      "text to token id: 1888\n",
      "token id to text: ust\n",
      "text to token id: 1889\n",
      "token id to text: imil\n",
      "text to token id: 1890\n",
      "token id to text:  Tr\n",
      "text to token id: 1891\n",
      "token id to text:  abd\n",
      "text to token id: 1892\n",
      "token id to text: oo\n",
      "text to token id: 1893\n",
      "token id to text: ome\n",
      "text to token id: 1894\n",
      "token id to text:  import\n",
      "text to token id: 1895\n",
      "token id to text:  final\n",
      "text to token id: 1896\n",
      "token id to text:  six\n",
      "text to token id: 1897\n",
      "token id to text:  although\n",
      "text to token id: 1898\n",
      "token id to text:  examp\n",
      "text to token id: 1899\n",
      "token id to text:  example\n",
      "text to token id: 1900\n",
      "token id to text:  King\n",
      "text to token id: 1901\n",
      "token id to text: cep\n",
      "text to token id: 1902\n",
      "token id to text: ize\n",
      "text to token id: 1903\n",
      "token id to text:  disast\n",
      "text to token id: 1904\n",
      "token id to text:  house\n",
      "text to token id: 1905\n",
      "token id to text:  overth\n",
      "text to token id: 1906\n",
      "token id to text:  Cheng\n",
      "text to token id: 1907\n",
      "token id to text:  alliance\n",
      "text to token id: 1908\n",
      "token id to text:  rebel\n",
      "text to token id: 1909\n",
      "token id to text:  au\n",
      "text to token id: 1910\n",
      "token id to text:  auth\n",
      "text to token id: 1911\n",
      "token id to text: ft\n",
      "text to token id: 1912\n",
      "token id to text:  conquer\n",
      "text to token id: 1913\n",
      "token id to text:  wars\n",
      "text to token id: 1914\n",
      "token id to text:  Many\n",
      "text to token id: 1915\n",
      "token id to text:  cities\n",
      "text to token id: 1916\n",
      "token id to text:  urban\n",
      "text to token id: 1917\n",
      "token id to text: cial\n",
      "text to token id: 1918\n",
      "token id to text: fare\n",
      "text to token id: 1919\n",
      "token id to text:  resources\n",
      "text to token id: 1920\n",
      "token id to text: stant\n",
      "text to token id: 1921\n",
      "token id to text:  ruling\n",
      "text to token id: 1922\n",
      "token id to text:  enormous\n",
      "text to token id: 1923\n",
      "token id to text:  nomin\n",
      "text to token id: 1924\n",
      "token id to text: 30\n",
      "text to token id: 1925\n",
      "token id to text:  neigh\n",
      "text to token id: 1926\n",
      "token id to text:  neighb\n",
      "text to token id: 1927\n",
      "token id to text: inces\n",
      "text to token id: 1928\n",
      "token id to text:  im\n",
      "text to token id: 1929\n",
      "token id to text: itated\n",
      "text to token id: 1930\n",
      "token id to text: ify\n",
      "text to token id: 1931\n",
      "token id to text:  To\n",
      "text to token id: 1932\n",
      "token id to text: archy\n",
      "text to token id: 1933\n",
      "token id to text:  currency\n",
      "text to token id: 1934\n",
      "token id to text:  gu\n",
      "text to token id: 1935\n",
      "token id to text:  consider\n",
      "text to token id: 1936\n",
      "token id to text: ept\n",
      "text to token id: 1937\n",
      "token id to text:  construc\n",
      "text to token id: 1938\n",
      "token id to text: 84\n",
      "text to token id: 1939\n",
      "token id to text:  reported\n",
      "text to token id: 1940\n",
      "token id to text:  captured\n",
      "text to token id: 1941\n",
      "token id to text:  Wen\n",
      "text to token id: 1942\n",
      "token id to text:  zen\n",
      "text to token id: 1943\n",
      "token id to text:  zenith\n",
      "text to token id: 1944\n",
      "token id to text: fr\n",
      "text to token id: 1945\n",
      "token id to text:  Silk\n",
      "text to token id: 1946\n",
      "token id to text:  Ro\n",
      "text to token id: 1947\n",
      "token id to text:  Road\n",
      "text to token id: 1948\n",
      "token id to text:  stim\n",
      "text to token id: 1949\n",
      "token id to text:  exchang\n",
      "text to token id: 1950\n",
      "token id to text:  exchange\n",
      "text to token id: 1951\n",
      "token id to text: igr\n",
      "text to token id: 1952\n",
      "token id to text:  treasury\n",
      "text to token id: 1953\n",
      "token id to text:  tax\n",
      "text to token id: 1954\n",
      "token id to text:  Mang\n",
      "text to token id: 1955\n",
      "token id to text:  own\n",
      "text to token id: 1956\n",
      "token id to text:  extens\n",
      "text to token id: 1957\n",
      "token id to text:  never\n",
      "text to token id: 1958\n",
      "token id to text:  split\n",
      "text to token id: 1959\n",
      "token id to text:  killed\n",
      "text to token id: 1960\n",
      "token id to text: ace\n",
      "text to token id: 1961\n",
      "token id to text: wu\n",
      "text to token id: 1962\n",
      "token id to text: ival\n",
      "text to token id: 1963\n",
      "token id to text:  connect\n",
      "text to token id: 1964\n",
      "token id to text:  rout\n",
      "text to token id: 1965\n",
      "token id to text:  notably\n",
      "text to token id: 1966\n",
      "token id to text: AD\n",
      "text to token id: 1967\n",
      "token id to text: idst\n",
      "text to token id: 1968\n",
      "token id to text:  invasions\n",
      "text to token id: 1969\n",
      "token id to text:  warlords\n",
      "text to token id: 1970\n",
      "token id to text:  pred\n",
      "text to token id: 1971\n",
      "token id to text:  predomin\n",
      "text to token id: 1972\n",
      "token id to text:  ending\n",
      "text to token id: 1973\n",
      "token id to text:  How\n",
      "text to token id: 1974\n",
      "token id to text:  However\n",
      "text to token id: 1975\n",
      "token id to text:  Eight\n",
      "text to token id: 1976\n",
      "token id to text:  Sixteen\n",
      "text to token id: 1977\n",
      "token id to text:  Mongols\n",
      "text to token id: 1978\n",
      "token id to text:  Tibetans\n",
      "text to token id: 1979\n",
      "token id to text: fore\n",
      "text to token id: 1980\n",
      "token id to text: nam\n",
      "text to token id: 1981\n",
      "token id to text:  fre\n",
      "text to token id: 1982\n",
      "token id to text:  institut\n",
      "text to token id: 1983\n",
      "token id to text: ub\n",
      "text to token id: 1984\n",
      "token id to text:  coin\n",
      "text to token id: 1985\n",
      "token id to text: order\n",
      "text to token id: 1986\n",
      "token id to text: vers\n",
      "text to token id: 1987\n",
      "token id to text:  Kore\n",
      "text to token id: 1988\n",
      "token id to text:  revol\n",
      "text to token id: 1989\n",
      "token id to text:  Jun\n",
      "text to token id: 1990\n",
      "token id to text:  June\n",
      "text to token id: 1991\n",
      "token id to text:  Asian\n",
      "text to token id: 1992\n",
      "token id to text:  tributary\n",
      "text to token id: 1993\n",
      "token id to text:  open\n",
      "text to token id: 1994\n",
      "token id to text: ernally\n",
      "text to token id: 1995\n",
      "token id to text:  repl\n",
      "text to token id: 1996\n",
      "token id to text:  rap\n",
      "text to token id: 1997\n",
      "token id to text:  rapid\n",
      "text to token id: 1998\n",
      "token id to text:  standing\n",
      "text to token id: 1999\n",
      "token id to text:  arm\n",
      "text to token id: 2000\n",
      "token id to text:  armies\n",
      "text to token id: 2001\n",
      "token id to text:  private\n",
      "text to token id: 2002\n",
      "token id to text:  dev\n",
      "text to token id: 2003\n",
      "token id to text:  devast\n",
      "text to token id: 2004\n",
      "token id to text:  rebellion\n",
      "text to token id: 2005\n",
      "token id to text:  gained\n",
      "text to token id: 2006\n",
      "token id to text:  aut\n",
      "text to token id: 2007\n",
      "token id to text: onom\n",
      "text to token id: 2008\n",
      "token id to text:  eng\n",
      "text to token id: 2009\n",
      "token id to text:  decade\n",
      "text to token id: 2010\n",
      "token id to text:  Guo\n",
      "text to token id: 2011\n",
      "token id to text:  Khaganate\n",
      "text to token id: 2012\n",
      "token id to text:  remn\n",
      "text to token id: 2013\n",
      "token id to text:  remnants\n",
      "text to token id: 2014\n",
      "token id to text:  raid\n",
      "text to token id: 2015\n",
      "token id to text:  sinic\n",
      "text to token id: 2016\n",
      "token id to text:  emerging\n",
      "text to token id: 2017\n",
      "token id to text: ense\n",
      "text to token id: 2018\n",
      "token id to text:  empires\n",
      "text to token id: 2019\n",
      "token id to text:  Ka\n",
      "text to token id: 2020\n",
      "token id to text:  Kaif\n",
      "text to token id: 2021\n",
      "token id to text:  Kaifeng\n",
      "text to token id: 2022\n",
      "token id to text:  sw\n",
      "text to token id: 2023\n",
      "token id to text: hile\n",
      "text to token id: 2024\n",
      "token id to text: aval\n",
      "text to token id: 2025\n",
      "token id to text:  annual\n",
      "text to token id: 2026\n",
      "token id to text:  dominance\n",
      "text to token id: 2027\n",
      "token id to text: urc\n",
      "text to token id: 2028\n",
      "token id to text: urchen\n",
      "text to token id: 2029\n",
      "token id to text:  fled\n",
      "text to token id: 2030\n",
      "token id to text:  Hang\n",
      "text to token id: 2031\n",
      "token id to text:  Hangzhou\n",
      "text to token id: 2032\n",
      "token id to text:  Indian\n",
      "text to token id: 2033\n",
      "token id to text:  Oce\n",
      "text to token id: 2034\n",
      "token id to text:  Ocean\n",
      "text to token id: 2035\n",
      "token id to text:  inn\n",
      "text to token id: 2036\n",
      "token id to text: rehen\n",
      "text to token id: 2037\n",
      "token id to text: rehensive\n",
      "text to token id: 2038\n",
      "token id to text:  navy\n",
      "text to token id: 2039\n",
      "token id to text:  East\n",
      "text to token id: 2040\n",
      "token id to text:  down\n",
      "text to token id: 2041\n",
      "token id to text:  Yong\n",
      "text to token id: 2042\n",
      "token id to text:  Yongle\n",
      "text to token id: 2043\n",
      "token id to text:  New\n",
      "text to token id: 2044\n",
      "token id to text:  requ\n",
      "text to token id: 2045\n",
      "token id to text: ests\n",
      "text to token id: 2046\n",
      "token id to text:  Port\n",
      "text to token id: 2047\n",
      "token id to text:  Portug\n",
      "text to token id: 2048\n",
      "token id to text:  Portugu\n",
      "text to token id: 2049\n",
      "token id to text:  Portuguese\n",
      "text to token id: 2050\n",
      "token id to text: utch\n",
      "text to token id: 2051\n",
      "token id to text: ner\n",
      "text to token id: 2052\n",
      "token id to text:  Kang\n",
      "text to token id: 2053\n",
      "token id to text:  British\n",
      "text to token id: 2054\n",
      "token id to text:  millions\n",
      "text to token id: 2055\n",
      "token id to text:  opp\n",
      "text to token id: 2056\n",
      "token id to text:  Alliance\n",
      "text to token id: 2057\n",
      "token id to text:  Ex\n",
      "text to token id: 2058\n",
      "token id to text: man\n",
      "text to token id: 2059\n",
      "token id to text:  formed\n",
      "text to token id: 2060\n",
      "token id to text:  March\n",
      "text to token id: 2061\n",
      "token id to text:  strugg\n",
      "text to token id: 2062\n",
      "token id to text:  Soviet\n",
      "text to token id: 2063\n",
      "token id to text:  Part\n",
      "text to token id: 2064\n",
      "token id to text:  Party\n",
      "text to token id: 2065\n",
      "token id to text:  Nations\n",
      "text to token id: 2066\n",
      "token id to text:  deaths\n",
      "text to token id: 2067\n",
      "token id to text:  KMT\n",
      "text to token id: 2068\n",
      "token id to text:  president\n",
      "text to token id: 2069\n",
      "token id to text:  geographical\n",
      "text to token id: 2070\n",
      "token id to text:  certain\n",
      "text to token id: 2071\n",
      "token id to text: chie\n",
      "text to token id: 2072\n",
      "token id to text: chievements\n",
      "text to token id: 2073\n",
      "token id to text: aking\n",
      "text to token id: 2074\n",
      "token id to text:  At\n",
      "text to token id: 2075\n",
      "token id to text:  repres\n",
      "text to token id: 2076\n",
      "token id to text:  represent\n",
      "text to token id: 2077\n",
      "token id to text:  dire\n",
      "text to token id: 2078\n",
      "token id to text:  direct\n",
      "text to token id: 2079\n",
      "token id to text:  Tar\n",
      "text to token id: 2080\n",
      "token id to text:  Tarim\n",
      "text to token id: 2081\n",
      "token id to text: ayan\n",
      "text to token id: 2082\n",
      "token id to text: elta\n",
      "text to token id: 2083\n",
      "token id to text:  Red\n",
      "text to token id: 2084\n",
      "token id to text:  complex\n",
      "text to token id: 2085\n",
      "token id to text:  sometimes\n",
      "text to token id: 2086\n",
      "token id to text:  ident\n",
      "text to token id: 2087\n",
      "token id to text:  millennium\n",
      "text to token id: 2088\n",
      "token id to text:  histori\n",
      "text to token id: 2089\n",
      "token id to text:  historiography\n",
      "text to token id: 2090\n",
      "token id to text: inations\n",
      "text to token id: 2091\n",
      "token id to text:  orac\n",
      "text to token id: 2092\n",
      "token id to text:  oracle\n",
      "text to token id: 2093\n",
      "token id to text:  bronze\n",
      "text to token id: 2094\n",
      "token id to text: cript\n",
      "text to token id: 2095\n",
      "token id to text:  rece\n",
      "text to token id: 2096\n",
      "token id to text:  literature\n",
      "text to token id: 2097\n",
      "token id to text:  spe\n",
      "text to token id: 2098\n",
      "token id to text:  believed\n",
      "text to token id: 2099\n",
      "token id to text:  invention\n",
      "text to token id: 2100\n",
      "token id to text:  alread\n",
      "text to token id: 2101\n",
      "token id to text:  already\n",
      "text to token id: 2102\n",
      "token id to text: -m\n",
      "text to token id: 2103\n",
      "token id to text:  introduced\n",
      "text to token id: 2104\n",
      "token id to text:  Taoism\n",
      "text to token id: 2105\n",
      "token id to text:  classical\n",
      "text to token id: 2106\n",
      "token id to text: \",\n",
      "text to token id: 2107\n",
      "token id to text: althy\n",
      "text to token id: 2108\n",
      "token id to text:  landholding\n",
      "text to token id: 2109\n",
      "token id to text:  Rom\n",
      "text to token id: 2110\n",
      "token id to text:  production\n",
      "text to token id: 2111\n",
      "token id to text: wards\n",
      "text to token id: 2112\n",
      "token id to text:  When\n",
      "text to token id: 2113\n",
      "token id to text:  leng\n",
      "text to token id: 2114\n",
      "token id to text:  incor\n",
      "text to token id: 2115\n",
      "token id to text:  incorp\n",
      "text to token id: 2116\n",
      "token id to text:  incorpor\n",
      "text to token id: 2117\n",
      "token id to text: 581\n",
      "text to token id: 2118\n",
      "token id to text:  gave\n",
      "text to token id: 2119\n",
      "token id to text:  regard\n",
      "text to token id: 2120\n",
      "token id to text:  flourish\n",
      "text to token id: 2121\n",
      "token id to text:  developments\n",
      "text to token id: 2122\n",
      "token id to text: etian\n",
      "text to token id: 2123\n",
      "token id to text:  cos\n",
      "text to token id: 2124\n",
      "token id to text:  cosm\n",
      "text to token id: 2125\n",
      "token id to text: opol\n",
      "text to token id: 2126\n",
      "token id to text:  printing\n",
      "text to token id: 2127\n",
      "token id to text: ness\n",
      "text to token id: 2128\n",
      "token id to text:  wood\n",
      "text to token id: 2129\n",
      "token id to text:  advance\n",
      "text to token id: 2130\n",
      "token id to text:  ide\n",
      "text to token id: 2131\n",
      "token id to text:  structure\n",
      "text to token id: 2132\n",
      "token id to text:  Neo\n",
      "text to token id: 2133\n",
      "token id to text: -Con\n",
      "text to token id: 2134\n",
      "token id to text:  gl\n",
      "text to token id: 2135\n",
      "token id to text: obal\n",
      "text to token id: 2136\n",
      "token id to text:  expl\n",
      "text to token id: 2137\n",
      "token id to text: oration\n",
      "text to token id: 2138\n",
      "token id to text:  porce\n",
      "text to token id: 2139\n",
      "token id to text:  porcelain\n",
      "text to token id: 2140\n",
      "token id to text:  those\n",
      "text to token id: 2141\n",
      "token id to text:  succeeded\n",
      "text to token id: 2142\n",
      "token id to text: iss\n",
      "text to token id: 2143\n",
      "token id to text: ission\n",
      "text to token id: 2144\n",
      "token id to text:  complete\n",
      "text to token id: 2145\n",
      "token id to text: clop\n",
      "text to token id: 2146\n",
      "token id to text: ibr\n",
      "text to token id: 2147\n",
      "token id to text:  greatest\n",
      "text to token id: 2148\n",
      "token id to text:  European\n",
      "text to token id: 2149\n",
      "token id to text:  Op\n",
      "text to token id: 2150\n",
      "token id to text:  Opium\n",
      "text to token id: 2151\n",
      "token id to text: equ\n",
      "text to token id: 2152\n",
      "token id to text: equal\n",
      "text to token id: 2153\n",
      "token id to text:  treaties\n",
      "text to token id: 2154\n",
      "token id to text:  Fr\n",
      "text to token id: 2155\n",
      "token id to text: iled\n",
      "text to token id: 2156\n",
      "token id to text: igned\n",
      "text to token id: 2157\n",
      "token id to text: rupted\n",
      "text to token id: 2158\n",
      "token id to text:  Zed\n",
      "text to token id: 2159\n",
      "token id to text:  Zedong\n",
      "text to token id: 2160\n",
      "token id to text:  ret\n",
      "text to token id: 2161\n",
      "token id to text:  sole\n",
      "text to token id: 2162\n",
      "token id to text: acy\n",
      "text to token id: 2163\n",
      "token id to text:  hel\n",
      "text to token id: 2164\n",
      "token id to text:  Xiaop\n",
      "text to token id: 2165\n",
      "token id to text:  Xiaoping\n",
      "text to token id: 2166\n",
      "token id to text:  Pre\n",
      "text to token id: 2167\n",
      "token id to text: eolithic\n",
      "text to token id: 2168\n",
      "token id to text:  human\n",
      "text to token id: 2169\n",
      "token id to text:  arrived\n",
      "text to token id: 2170\n",
      "token id to text: western\n",
      "text to token id: 2171\n",
      "token id to text:  lived\n",
      "text to token id: 2172\n",
      "token id to text: ixed\n",
      "text to token id: 2173\n",
      "token id to text:  environ\n",
      "text to token id: 2174\n",
      "token id to text:  environment\n",
      "text to token id: 2175\n",
      "token id to text:  alongside\n",
      "text to token id: 2176\n",
      "token id to text: kn\n",
      "text to token id: 2177\n",
      "token id to text: known\n",
      "text to token id: 2178\n",
      "token id to text:  BP\n",
      "text to token id: 2179\n",
      "token id to text:  Other\n",
      "text to token id: 2180\n",
      "token id to text:  minor\n",
      "text to token id: 2181\n",
      "token id to text: theastern\n",
      "text to token id: 2182\n",
      "token id to text:  Guangd\n",
      "text to token id: 2183\n",
      "token id to text:  Guangdong\n",
      "text to token id: 2184\n",
      "token id to text:  sites\n",
      "text to token id: 2185\n",
      "token id to text:  debated\n",
      "text to token id: 2186\n",
      "token id to text: bly\n",
      "text to token id: 2187\n",
      "token id to text:  based\n",
      "text to token id: 2188\n",
      "token id to text: 66\n",
      "text to token id: 2189\n",
      "token id to text: 36\n",
      "text to token id: 2190\n",
      "token id to text:  archaeological\n",
      "text to token id: 2191\n",
      "token id to text:  contemporary\n",
      "text to token id: 2192\n",
      "token id to text:  Af\n",
      "text to token id: 2193\n",
      "token id to text:  Afric\n",
      "text to token id: 2194\n",
      "token id to text:  Africa\n",
      "text to token id: 2195\n",
      "token id to text:  adm\n",
      "text to token id: 2196\n",
      "token id to text: 120\n",
      "text to token id: 2197\n",
      "token id to text:  Fu\n",
      "text to token id: 2198\n",
      "token id to text:  assem\n",
      "text to token id: 2199\n",
      "token id to text:  assembl\n",
      "text to token id: 2200\n",
      "token id to text:  addition\n",
      "text to token id: 2201\n",
      "token id to text: ice\n",
      "text to token id: 2202\n",
      "token id to text: arb\n",
      "text to token id: 2203\n",
      "token id to text:  preserved\n",
      "text to token id: 2204\n",
      "token id to text:  agricultural\n",
      "text to token id: 2205\n",
      "token id to text:  dating\n",
      "text to token id: 2206\n",
      "token id to text:  indiv\n",
      "text to token id: 2207\n",
      "token id to text:  individ\n",
      "text to token id: 2208\n",
      "token id to text:  characters\n",
      "text to token id: 2209\n",
      "token id to text: mb\n",
      "text to token id: 2210\n",
      "token id to text: ols\n",
      "text to token id: 2211\n",
      "token id to text:  called\n",
      "text to token id: 2212\n",
      "token id to text:  crop\n",
      "text to token id: 2213\n",
      "token id to text:  special\n",
      "text to token id: 2214\n",
      "token id to text:  cultures\n",
      "text to token id: 2215\n",
      "token id to text:  respect\n",
      "text to token id: 2216\n",
      "token id to text:  respectively\n",
      "text to token id: 2217\n",
      "token id to text:  Long\n",
      "text to token id: 2218\n",
      "token id to text: ower\n",
      "text to token id: 2219\n",
      "token id to text:  Sanx\n",
      "text to token id: 2220\n",
      "token id to text:  Sanxingd\n",
      "text to token id: 2221\n",
      "token id to text:  Sanxingdui\n",
      "text to token id: 2222\n",
      "token id to text:  Shu\n",
      "text to token id: 2223\n",
      "token id to text:  level\n",
      "text to token id: 2224\n",
      "token id to text:  vi\n",
      "text to token id: 2225\n",
      "token id to text:  viol\n",
      "text to token id: 2226\n",
      "token id to text:  Qi\n",
      "text to token id: 2227\n",
      "token id to text: urg\n",
      "text to token id: 2228\n",
      "token id to text:  excavated\n",
      "text to token id: 2229\n",
      "token id to text: atively\n",
      "text to token id: 2230\n",
      "token id to text:  assoc\n",
      "text to token id: 2231\n",
      "token id to text: ung\n",
      "text to token id: 2232\n",
      "token id to text:  described\n",
      "text to token id: 2233\n",
      "token id to text:  historians\n",
      "text to token id: 2234\n",
      "token id to text:  cultur\n",
      "text to token id: 2235\n",
      "token id to text:  culturally\n",
      "text to token id: 2236\n",
      "token id to text: -e\n",
      "text to token id: 2237\n",
      "token id to text:  Yao\n",
      "text to token id: 2238\n",
      "token id to text:  Shun\n",
      "text to token id: 2239\n",
      "token id to text:  Yu\n",
      "text to token id: 2240\n",
      "token id to text:  Trad\n",
      "text to token id: 2241\n",
      "token id to text:  promin\n",
      "text to token id: 2242\n",
      "token id to text:  prominent\n",
      "text to token id: 2243\n",
      "token id to text:  thron\n",
      "text to token id: 2244\n",
      "token id to text:  throne\n",
      "text to token id: 2245\n",
      "token id to text: 207\n",
      "text to token id: 2246\n",
      "token id to text:  Ann\n",
      "text to token id: 2247\n",
      "token id to text:  Annals\n",
      "text to token id: 2248\n",
      "token id to text:  Sima\n",
      "text to token id: 2249\n",
      "token id to text: 150\n",
      "text to token id: 2250\n",
      "token id to text:  any\n",
      "text to token id: 2251\n",
      "token id to text:  incomp\n",
      "text to token id: 2252\n",
      "token id to text:  recorded\n",
      "text to token id: 2253\n",
      "token id to text:  More\n",
      "text to token id: 2254\n",
      "token id to text:  existence\n",
      "text to token id: 2255\n",
      "token id to text:  earlier\n",
      "text to token id: 2256\n",
      "token id to text: modern\n",
      "text to token id: 2257\n",
      "token id to text:  Yin\n",
      "text to token id: 2258\n",
      "token id to text:  least\n",
      "text to token id: 2259\n",
      "token id to text:  moved\n",
      "text to token id: 2260\n",
      "token id to text:  half\n",
      "text to token id: 2261\n",
      "token id to text:  often\n",
      "text to token id: 2262\n",
      "token id to text:  settlement\n",
      "text to token id: 2263\n",
      "token id to text:  advanced\n",
      "text to token id: 2264\n",
      "token id to text:  real\n",
      "text to token id: 2265\n",
      "token id to text: isted\n",
      "text to token id: 2266\n",
      "token id to text:  though\n",
      "text to token id: 2267\n",
      "token id to text:  declined\n",
      "text to token id: 2268\n",
      "token id to text:  where\n",
      "text to token id: 2269\n",
      "token id to text: ointed\n",
      "text to token id: 2270\n",
      "token id to text:  coal\n",
      "text to token id: 2271\n",
      "token id to text:  ruler\n",
      "text to token id: 2272\n",
      "token id to text:  took\n",
      "text to token id: 2273\n",
      "token id to text: of\n",
      "text to token id: 2274\n",
      "token id to text: atives\n",
      "text to token id: 2275\n",
      "token id to text:  concep\n",
      "text to token id: 2276\n",
      "token id to text:  concept\n",
      "text to token id: 2277\n",
      "token id to text: di\n",
      "text to token id: 2278\n",
      "token id to text:  disasters\n",
      "text to token id: 2279\n",
      "token id to text:  number\n",
      "text to token id: 2280\n",
      "token id to text:  concern\n",
      "text to token id: 2281\n",
      "token id to text:  respon\n",
      "text to token id: 2282\n",
      "token id to text:  response\n",
      "text to token id: 2283\n",
      "token id to text:  capitals\n",
      "text to token id: 2284\n",
      "token id to text:  mov\n",
      "text to token id: 2285\n",
      "token id to text: ularly\n",
      "text to token id: 2286\n",
      "token id to text:  east\n",
      "text to token id: 2287\n",
      "token id to text:  Huai\n",
      "text to token id: 2288\n",
      "token id to text:  southward\n",
      "text to token id: 2289\n",
      "token id to text: 76\n",
      "text to token id: 2290\n",
      "token id to text:  beginning\n",
      "text to token id: 2291\n",
      "token id to text:  famous\n",
      "text to token id: 2292\n",
      "token id to text: uced\n",
      "text to token id: 2293\n",
      "token id to text:  authority\n",
      "text to token id: 2294\n",
      "token id to text:  left\n",
      "text to token id: 2295\n",
      "token id to text: acu\n",
      "text to token id: 2296\n",
      "token id to text: leg\n",
      "text to token id: 2297\n",
      "token id to text:  hundred\n",
      "text to token id: 2298\n",
      "token id to text:  fight\n",
      "text to token id: 2299\n",
      "token id to text:  disap\n",
      "text to token id: 2300\n",
      "token id to text:  disapp\n",
      "text to token id: 2301\n",
      "token id to text:  annex\n",
      "text to token id: 2302\n",
      "token id to text:  annexed\n",
      "text to token id: 2303\n",
      "token id to text: cip\n",
      "text to token id: 2304\n",
      "token id to text:  Chu\n",
      "text to token id: 2305\n",
      "token id to text:  independence\n",
      "text to token id: 2306\n",
      "token id to text:  commer\n",
      "text to token id: 2307\n",
      "token id to text:  chao\n",
      "text to token id: 2308\n",
      "token id to text:  philosophy\n",
      "text to token id: 2309\n",
      "token id to text:  intellectual\n",
      "text to token id: 2310\n",
      "token id to text:  seven\n",
      "text to token id: 2311\n",
      "token id to text: hem\n",
      "text to token id: 2312\n",
      "token id to text:  literary\n",
      "text to token id: 2313\n",
      "token id to text:  preced\n",
      "text to token id: 2314\n",
      "token id to text: ips\n",
      "text to token id: 2315\n",
      "token id to text:  mult\n",
      "text to token id: 2316\n",
      "token id to text:  neighboring\n",
      "text to token id: 2317\n",
      "token id to text:  command\n",
      "text to token id: 2318\n",
      "token id to text:  prefect\n",
      "text to token id: 2319\n",
      "token id to text:  administration\n",
      "text to token id: 2320\n",
      "token id to text:  x\n",
      "text to token id: 2321\n",
      "token id to text:  pla\n",
      "text to token id: 2322\n",
      "token id to text:  place\n",
      "text to token id: 2323\n",
      "token id to text:  Ying\n",
      "text to token id: 2324\n",
      "token id to text:  ultimately\n",
      "text to token id: 2325\n",
      "token id to text:  effectively\n",
      "text to token id: 2326\n",
      "token id to text:  rat\n",
      "text to token id: 2327\n",
      "token id to text:  rather\n",
      "text to token id: 2328\n",
      "token id to text:  prob\n",
      "text to token id: 2329\n",
      "token id to text:  probably\n",
      "text to token id: 2330\n",
      "token id to text:  centralized\n",
      "text to token id: 2331\n",
      "token id to text:  monarchy\n",
      "text to token id: 2332\n",
      "token id to text:  effor\n",
      "text to token id: 2333\n",
      "token id to text:  leader\n",
      "text to token id: 2334\n",
      "token id to text: formed\n",
      "text to token id: 2335\n",
      "token id to text:  pract\n",
      "text to token id: 2336\n",
      "token id to text:  included\n",
      "text to token id: 2337\n",
      "token id to text:  encour\n",
      "text to token id: 2338\n",
      "token id to text:  har\n",
      "text to token id: 2339\n",
      "token id to text:  construction\n",
      "text to token id: 2340\n",
      "token id to text: way\n",
      "text to token id: 2341\n",
      "token id to text:  comb\n",
      "text to token id: 2342\n",
      "token id to text:  overs\n",
      "text to token id: 2343\n",
      "token id to text:  oversaw\n",
      "text to token id: 2344\n",
      "token id to text:  drast\n",
      "text to token id: 2345\n",
      "token id to text:  drastically\n",
      "text to token id: 2346\n",
      "token id to text:  sack\n",
      "text to token id: 2347\n",
      "token id to text: ention\n",
      "text to token id: 2348\n",
      "token id to text:  stability\n",
      "text to token id: 2349\n",
      "token id to text:  foundation\n",
      "text to token id: 2350\n",
      "token id to text: ently\n",
      "text to token id: 2351\n",
      "token id to text:  amb\n",
      "text to token id: 2352\n",
      "token id to text:  governors\n",
      "text to token id: 2353\n",
      "token id to text:  pat\n",
      "text to token id: 2354\n",
      "token id to text:  stud\n",
      "text to token id: 2355\n",
      "token id to text:  stren\n",
      "text to token id: 2356\n",
      "token id to text: gthe\n",
      "text to token id: 2357\n",
      "token id to text: cal\n",
      "text to token id: 2358\n",
      "token id to text:  opened\n",
      "text to token id: 2359\n",
      "token id to text:  formally\n",
      "text to token id: 2360\n",
      "token id to text:  Min\n",
      "text to token id: 2361\n",
      "token id to text: 111\n",
      "text to token id: 2362\n",
      "token id to text: ipped\n",
      "text to token id: 2363\n",
      "token id to text:  excess\n",
      "text to token id: 2364\n",
      "token id to text: ief\n",
      "text to token id: 2365\n",
      "token id to text:  usur\n",
      "text to token id: 2366\n",
      "token id to text:  extensive\n",
      "text to token id: 2367\n",
      "token id to text:  sla\n",
      "text to token id: 2368\n",
      "token id to text: istribution\n",
      "text to token id: 2369\n",
      "token id to text:  because\n",
      "text to token id: 2370\n",
      "token id to text:  fav\n",
      "text to token id: 2371\n",
      "token id to text: ored\n",
      "text to token id: 2372\n",
      "token id to text:  uprisings\n",
      "text to token id: 2373\n",
      "token id to text: ounded\n",
      "text to token id: 2374\n",
      "token id to text:  sil\n",
      "text to token id: 2375\n",
      "token id to text:  caused\n",
      "text to token id: 2376\n",
      "token id to text:  numbers\n",
      "text to token id: 2377\n",
      "token id to text:  conquests\n",
      "text to token id: 2378\n",
      "token id to text:  Sea\n",
      "text to token id: 2379\n",
      "token id to text:  bring\n",
      "text to token id: 2380\n",
      "token id to text:  bringing\n",
      "text to token id: 2381\n",
      "token id to text: 166\n",
      "text to token id: 2382\n",
      "token id to text:  prolific\n",
      "text to token id: 2383\n",
      "token id to text:  contribut\n",
      "text to token id: 2384\n",
      "token id to text:  Dynast\n",
      "text to token id: 2385\n",
      "token id to text:  Dynasties\n",
      "text to token id: 2386\n",
      "token id to text:  bro\n",
      "text to token id: 2387\n",
      "token id to text: 184\n",
      "text to token id: 2388\n",
      "token id to text:  reunified\n",
      "text to token id: 2389\n",
      "token id to text:  son\n",
      "text to token id: 2390\n",
      "token id to text:  Pr\n",
      "text to token id: 2391\n",
      "token id to text:  sett\n",
      "text to token id: 2392\n",
      "token id to text: 39\n",
      "text to token id: 2393\n",
      "token id to text:  frag\n",
      "text to token id: 2394\n",
      "token id to text:  fragment\n",
      "text to token id: 2395\n",
      "token id to text:  fragmented\n",
      "text to token id: 2396\n",
      "token id to text:  Turks\n",
      "text to token id: 2397\n",
      "token id to text: cent\n",
      "text to token id: 2398\n",
      "token id to text:  warfare\n",
      "text to token id: 2399\n",
      "token id to text:  migr\n",
      "text to token id: 2400\n",
      "token id to text: ried\n",
      "text to token id: 2401\n",
      "token id to text: Despite\n",
      "text to token id: 2402\n",
      "token id to text:  spread\n",
      "text to token id: 2403\n",
      "token id to text: 618\n",
      "text to token id: 2404\n",
      "token id to text: artments\n",
      "text to token id: 2405\n",
      "token id to text:  improved\n",
      "text to token id: 2406\n",
      "token id to text:  conscription\n",
      "text to token id: 2407\n",
      "token id to text:  religion\n",
      "text to token id: 2408\n",
      "token id to text:  border\n",
      "text to token id: 2409\n",
      "token id to text: aneu\n",
      "text to token id: 2410\n",
      "token id to text:  bord\n",
      "text to token id: 2411\n",
      "token id to text:  borders\n",
      "text to token id: 2412\n",
      "token id to text:  wid\n",
      "text to token id: 2413\n",
      "token id to text:  widesp\n",
      "text to token id: 2414\n",
      "token id to text:  widespread\n",
      "text to token id: 2415\n",
      "token id to text:  threat\n",
      "text to token id: 2416\n",
      "token id to text: rative\n",
      "text to token id: 2417\n",
      "token id to text:  port\n",
      "text to token id: 2418\n",
      "token id to text:  Guangzhou\n",
      "text to token id: 2419\n",
      "token id to text:  dist\n",
      "text to token id: 2420\n",
      "token id to text:  merchants\n",
      "text to token id: 2421\n",
      "token id to text: bs\n",
      "text to token id: 2422\n",
      "token id to text: ked\n",
      "text to token id: 2423\n",
      "token id to text:  heart\n",
      "text to token id: 2424\n",
      "token id to text:  heartland\n",
      "text to token id: 2425\n",
      "token id to text:  eastern\n",
      "text to token id: 2426\n",
      "token id to text:  parts\n",
      "text to token id: 2427\n",
      "token id to text:  join\n",
      "text to token id: 2428\n",
      "token id to text:  religious\n",
      "text to token id: 2429\n",
      "token id to text:  Emp\n",
      "text to token id: 2430\n",
      "token id to text:  Empress\n",
      "text to token id: 2431\n",
      "token id to text:  There\n",
      "text to token id: 2432\n",
      "token id to text:  Up\n",
      "text to token id: 2433\n",
      "token id to text:  suppression\n",
      "text to token id: 2434\n",
      "token id to text: hi\n",
      "text to token id: 2435\n",
      "token id to text:  vast\n",
      "text to token id: 2436\n",
      "token id to text:  recover\n",
      "text to token id: 2437\n",
      "token id to text: ficials\n",
      "text to token id: 2438\n",
      "token id to text:  immen\n",
      "text to token id: 2439\n",
      "token id to text:  immense\n",
      "text to token id: 2440\n",
      "token id to text: 87\n",
      "text to token id: 2441\n",
      "token id to text: ially\n",
      "text to token id: 2442\n",
      "token id to text:  fought\n",
      "text to token id: 2443\n",
      "token id to text: bal\n",
      "text to token id: 2444\n",
      "token id to text: bali\n",
      "text to token id: 2445\n",
      "token id to text:  Chix\n",
      "text to token id: 2446\n",
      "token id to text:  Chixin\n",
      "text to token id: 2447\n",
      "token id to text:  committed\n",
      "text to token id: 2448\n",
      "token id to text:  loy\n",
      "text to token id: 2449\n",
      "token id to text:  loyal\n",
      "text to token id: 2450\n",
      "token id to text:  Five\n",
      "text to token id: 2451\n",
      "token id to text:  tod\n",
      "text to token id: 2452\n",
      "token id to text:  today\n",
      "text to token id: 2453\n",
      "token id to text:  Viet\n",
      "text to token id: 2454\n",
      "token id to text:  Vietnam\n",
      "text to token id: 2455\n",
      "token id to text:  anni\n",
      "text to token id: 2456\n",
      "token id to text:  annihil\n",
      "text to token id: 2457\n",
      "token id to text:  occup\n",
      "text to token id: 2458\n",
      "token id to text: 112\n",
      "text to token id: 2459\n",
      "token id to text:  Mongolia\n",
      "text to token id: 2460\n",
      "token id to text:  Mean\n",
      "text to token id: 2461\n",
      "token id to text:  Meanw\n",
      "text to token id: 2462\n",
      "token id to text:  Meanwhile\n",
      "text to token id: 2463\n",
      "token id to text:  failure\n",
      "text to token id: 2464\n",
      "token id to text: 100\n",
      "text to token id: 2465\n",
      "token id to text:  North\n",
      "text to token id: 2466\n",
      "token id to text:  forc\n",
      "text to token id: 2467\n",
      "token id to text:  good\n",
      "text to token id: 2468\n",
      "token id to text:  Jurchen\n",
      "text to token id: 2469\n",
      "token id to text:  initiated\n",
      "text to token id: 2470\n",
      "token id to text:  facilitated\n",
      "text to token id: 2471\n",
      "token id to text:  tre\n",
      "text to token id: 2472\n",
      "token id to text: mend\n",
      "text to token id: 2473\n",
      "token id to text:  subsequently\n",
      "text to token id: 2474\n",
      "token id to text:  facto\n",
      "text to token id: 2475\n",
      "token id to text:  travel\n",
      "text to token id: 2476\n",
      "token id to text:  innov\n",
      "text to token id: 2477\n",
      "token id to text: -t\n",
      "text to token id: 2478\n",
      "token id to text:  En\n",
      "text to token id: 2479\n",
      "token id to text: pe\n",
      "text to token id: 2480\n",
      "token id to text: wor\n",
      "text to token id: 2481\n",
      "token id to text:  put\n",
      "text to token id: 2482\n",
      "token id to text:  insp\n",
      "text to token id: 2483\n",
      "token id to text: ines\n",
      "text to token id: 2484\n",
      "token id to text:  Further\n",
      "text to token id: 2485\n",
      "token id to text:  defeats\n",
      "text to token id: 2486\n",
      "token id to text: ollowing\n",
      "text to token id: 2487\n",
      "token id to text:  substant\n",
      "text to token id: 2488\n",
      "token id to text:  style\n",
      "text to token id: 2489\n",
      "token id to text:  nec\n",
      "text to token id: 2490\n",
      "token id to text:  necess\n",
      "text to token id: 2491\n",
      "token id to text: ague\n",
      "text to token id: 2492\n",
      "token id to text:  quar\n",
      "text to token id: 2493\n",
      "token id to text:  sent\n",
      "text to token id: 2494\n",
      "token id to text: zhang\n",
      "text to token id: 2495\n",
      "token id to text: ailed\n",
      "text to token id: 2496\n",
      "token id to text:  Hongwu\n",
      "text to token id: 2497\n",
      "token id to text:  grew\n",
      "text to token id: 2498\n",
      "token id to text:  industries\n",
      "text to token id: 2499\n",
      "token id to text: ocratic\n",
      "text to token id: 2500\n",
      "token id to text:  able\n",
      "text to token id: 2501\n",
      "token id to text:  tribute\n",
      "text to token id: 2502\n",
      "token id to text:  built\n",
      "text to token id: 2503\n",
      "token id to text:  coast\n",
      "text to token id: 2504\n",
      "token id to text:  nations\n",
      "text to token id: 2505\n",
      "token id to text:  Mac\n",
      "text to token id: 2506\n",
      "token id to text:  Macau\n",
      "text to token id: 2507\n",
      "token id to text:  Span\n",
      "text to token id: 2508\n",
      "token id to text:  Spanish\n",
      "text to token id: 2509\n",
      "token id to text:  Dutch\n",
      "text to token id: 2510\n",
      "token id to text: istance\n",
      "text to token id: 2511\n",
      "token id to text:  surren\n",
      "text to token id: 2512\n",
      "token id to text:  surrender\n",
      "text to token id: 2513\n",
      "token id to text:  Korea\n",
      "text to token id: 2514\n",
      "token id to text:  declared\n",
      "text to token id: 2515\n",
      "token id to text:  lives\n",
      "text to token id: 2516\n",
      "token id to text:  required\n",
      "text to token id: 2517\n",
      "token id to text:  cloth\n",
      "text to token id: 2518\n",
      "token id to text: iven\n",
      "text to token id: 2519\n",
      "token id to text:  Kangx\n",
      "text to token id: 2520\n",
      "token id to text:  Kangxi\n",
      "text to token id: 2521\n",
      "token id to text:  uprising\n",
      "text to token id: 2522\n",
      "token id to text:  resulting\n",
      "text to token id: 2523\n",
      "token id to text:  Kong\n",
      "text to token id: 2524\n",
      "token id to text:  Taip\n",
      "text to token id: 2525\n",
      "token id to text: 186\n",
      "text to token id: 2526\n",
      "token id to text:  Chr\n",
      "text to token id: 2527\n",
      "token id to text:  Christ\n",
      "text to token id: 2528\n",
      "token id to text:  Zeng\n",
      "text to token id: 2529\n",
      "token id to text:  Guof\n",
      "text to token id: 2530\n",
      "token id to text:  Third\n",
      "text to token id: 2531\n",
      "token id to text: -S\n",
      "text to token id: 2532\n",
      "token id to text:  Movement\n",
      "text to token id: 2533\n",
      "token id to text: stitution\n",
      "text to token id: 2534\n",
      "token id to text: -J\n",
      "text to token id: 2535\n",
      "token id to text: -Japan\n",
      "text to token id: 2536\n",
      "token id to text: -Japanese\n",
      "text to token id: 2537\n",
      "token id to text: 189\n",
      "text to token id: 2538\n",
      "token id to text:  comprehensive\n",
      "text to token id: 2539\n",
      "token id to text:  Boxer\n",
      "text to token id: 2540\n",
      "token id to text:  Exped\n",
      "text to token id: 2541\n",
      "token id to text:  Expedition\n",
      "text to token id: 2542\n",
      "token id to text:  Four\n",
      "text to token id: 2543\n",
      "token id to text:  Vers\n",
      "text to token id: 2544\n",
      "token id to text:  Versa\n",
      "text to token id: 2545\n",
      "token id to text:  Versaill\n",
      "text to token id: 2546\n",
      "token id to text:  Versailles\n",
      "text to token id: 2547\n",
      "token id to text:  freed\n",
      "text to token id: 2548\n",
      "token id to text:  freedom\n",
      "text to token id: 2549\n",
      "token id to text:  Union\n",
      "text to token id: 2550\n",
      "token id to text:  Civil\n",
      "text to token id: 2551\n",
      "token id to text:  Nationalists\n",
      "text to token id: 2552\n",
      "token id to text:  Fron\n",
      "text to token id: 2553\n",
      "token id to text:  Front\n",
      "text to token id: 2554\n",
      "token id to text:  atroc\n",
      "text to token id: 2555\n",
      "token id to text:  atrocities\n",
      "text to token id: 2556\n",
      "token id to text:  party\n",
      "text to token id: 2557\n",
      "token id to text: kd\n",
      "text to token id: 2558\n",
      "token id to text: kdown\n",
      "text to token id: 2559\n",
      "token id to text:  infr\n",
      "text to token id: 2560\n",
      "token id to text:  infrast\n",
      "text to token id: 2561\n",
      "token id to text:  infrastr\n",
      "text to token id: 2562\n",
      "token id to text:  infrastructure\n",
      "text to token id: 2563\n",
      "token id to text:  free\n",
      "text to token id: 2564\n",
      "token id to text:  secret\n",
      "text to token id: 2565\n",
      "token id to text:  secretary\n",
      "text to token id: 2566\n",
      "token id to text:  Each\n",
      "text to token id: 2567\n",
      "token id to text:  unity\n",
      "text to token id: 2568\n",
      "token id to text:  fract\n",
      "text to token id: 2569\n",
      "token id to text:  strife\n",
      "text to token id: 2570\n",
      "token id to text:  constitut\n",
      "text to token id: 2571\n",
      "token id to text:  core\n",
      "text to token id: 2572\n",
      "token id to text: ingu\n",
      "text to token id: 2573\n",
      "token id to text:  lens\n",
      "text to token id: 2574\n",
      "token id to text:  vie\n",
      "text to token id: 2575\n",
      "token id to text: wing\n",
      "text to token id: 2576\n",
      "token id to text:  dynastic\n",
      "text to token id: 2577\n",
      "token id to text:  rise\n",
      "text to token id: 2578\n",
      "token id to text:  achievements\n",
      "text to token id: 2579\n",
      "token id to text:  assum\n",
      "text to token id: 2580\n",
      "token id to text:  directly\n",
      "text to token id: 2581\n",
      "token id to text:  stret\n",
      "text to token id: 2582\n",
      "token id to text:  Shan\n",
      "text to token id: 2583\n",
      "token id to text: imal\n",
      "text to token id: 2584\n",
      "token id to text:  Mount\n",
      "text to token id: 2585\n",
      "token id to text:  delta\n",
      "text to token id: 2586\n",
      "token id to text:  riv\n",
      "text to token id: 2587\n",
      "token id to text:  identified\n",
      "text to token id: 2588\n",
      "token id to text:  dates\n",
      "text to token id: 2589\n",
      "token id to text:  inscript\n",
      "text to token id: 2590\n",
      "token id to text:  inscriptions\n",
      "text to token id: 2591\n",
      "token id to text:  rit\n",
      "text to token id: 2592\n",
      "token id to text:  ance\n",
      "text to token id: 2593\n",
      "token id to text:  ancest\n",
      "text to token id: 2594\n",
      "token id to text:  ancestors\n",
      "text to token id: 2595\n",
      "token id to text:  received\n",
      "text to token id: 2596\n",
      "token id to text:  divination\n",
      "text to token id: 2597\n",
      "token id to text: hes\n",
      "text to token id: 2598\n",
      "token id to text:  very\n",
      "text to token id: 2599\n",
      "token id to text:  extant\n",
      "text to token id: 2600\n",
      "token id to text:  laid\n",
      "text to token id: 2601\n",
      "token id to text:  Wux\n",
      "text to token id: 2602\n",
      "token id to text:  Wuxing\n",
      "text to token id: 2603\n",
      "token id to text:  united\n",
      "text to token id: 2604\n",
      "token id to text:  sing\n",
      "text to token id: 2605\n",
      "token id to text:  single\n",
      "text to token id: 2606\n",
      "token id to text:  Or\n",
      "text to token id: 2607\n",
      "token id to text:  weights\n",
      "text to token id: 2608\n",
      "token id to text:  me\n",
      "text to token id: 2609\n",
      "token id to text:  meas\n",
      "text to token id: 2610\n",
      "token id to text:  measures\n",
      "text to token id: 2611\n",
      "token id to text:  standardized\n",
      "text to token id: 2612\n",
      "token id to text:  marking\n",
      "text to token id: 2613\n",
      "token id to text:  san\n",
      "text to token id: 2614\n",
      "token id to text:  ed\n",
      "text to token id: 2615\n",
      "token id to text:  We\n",
      "text to token id: 2616\n",
      "token id to text:  Wealthy\n",
      "text to token id: 2617\n",
      "token id to text:  aristocracy\n",
      "text to token id: 2618\n",
      "token id to text:  Roman\n",
      "text to token id: 2619\n",
      "token id to text:  prolif\n",
      "text to token id: 2620\n",
      "token id to text:  prolifer\n",
      "text to token id: 2621\n",
      "token id to text: oyed\n",
      "text to token id: 2622\n",
      "token id to text:  collap\n",
      "text to token id: 2623\n",
      "token id to text: sed\n",
      "text to token id: 2624\n",
      "token id to text:  lengthy\n",
      "text to token id: 2625\n",
      "token id to text:  disun\n",
      "text to token id: 2626\n",
      "token id to text:  disunity\n",
      "text to token id: 2627\n",
      "token id to text: igraph\n",
      "text to token id: 2628\n",
      "token id to text: igraphy\n",
      "text to token id: 2629\n",
      "token id to text: ases\n",
      "text to token id: 2630\n",
      "token id to text:  incorporated\n",
      "text to token id: 2631\n",
      "token id to text:  soon\n",
      "text to token id: 2632\n",
      "token id to text:  regarded\n",
      "text to token id: 2633\n",
      "token id to text:  recognized\n",
      "text to token id: 2634\n",
      "token id to text:  empress\n",
      "text to token id: 2635\n",
      "token id to text:  Zetian\n",
      "text to token id: 2636\n",
      "token id to text:  reigned\n",
      "text to token id: 2637\n",
      "token id to text:  cosmopol\n",
      "text to token id: 2638\n",
      "token id to text:  cosmopolitan\n",
      "text to token id: 2639\n",
      "token id to text: echan\n",
      "text to token id: 2640\n",
      "token id to text: echanical\n",
      "text to token id: 2641\n",
      "token id to text: itness\n",
      "text to token id: 2642\n",
      "token id to text: block\n",
      "text to token id: 2643\n",
      "token id to text:  scient\n",
      "text to token id: 2644\n",
      "token id to text:  scientific\n",
      "text to token id: 2645\n",
      "token id to text:  advancement\n",
      "text to token id: 2646\n",
      "token id to text:  examination\n",
      "text to token id: 2647\n",
      "token id to text:  ful\n",
      "text to token id: 2648\n",
      "token id to text:  fully\n",
      "text to token id: 2649\n",
      "token id to text:  tog\n",
      "text to token id: 2650\n",
      "token id to text:  together\n",
      "text to token id: 2651\n",
      "token id to text: -Confucianism\n",
      "text to token id: 2652\n",
      "token id to text: ventually\n",
      "text to token id: 2653\n",
      "token id to text:  Cont\n",
      "text to token id: 2654\n",
      "token id to text:  Europe\n",
      "text to token id: 2655\n",
      "token id to text:  increase\n",
      "text to token id: 2656\n",
      "token id to text:  global\n",
      "text to token id: 2657\n",
      "token id to text:  public\n",
      "text to token id: 2658\n",
      "token id to text:  Cl\n",
      "text to token id: 2659\n",
      "token id to text:  No\n",
      "text to token id: 2660\n",
      "token id to text:  Novel\n",
      "text to token id: 2661\n",
      "token id to text:  Novels\n",
      "text to token id: 2662\n",
      "token id to text:  Qianl\n",
      "text to token id: 2663\n",
      "token id to text:  Qianlong\n",
      "text to token id: 2664\n",
      "token id to text: 179\n",
      "text to token id: 2665\n",
      "token id to text:  ency\n",
      "text to token id: 2666\n",
      "token id to text:  encyclop\n",
      "text to token id: 2667\n",
      "token id to text: aries\n",
      "text to token id: 2668\n",
      "token id to text:  tot\n",
      "text to token id: 2669\n",
      "token id to text:  total\n",
      "text to token id: 2670\n",
      "token id to text:  nearly\n",
      "text to token id: 2671\n",
      "token id to text:  territorial\n",
      "text to token id: 2672\n",
      "token id to text:  confl\n",
      "text to token id: 2673\n",
      "token id to text:  cul\n",
      "text to token id: 2674\n",
      "token id to text:  culmin\n",
      "text to token id: 2675\n",
      "token id to text:  Wars\n",
      "text to token id: 2676\n",
      "token id to text:  unequal\n",
      "text to token id: 2677\n",
      "token id to text:  From\n",
      "text to token id: 2678\n",
      "token id to text:  cost\n",
      "text to token id: 2679\n",
      "token id to text:  Kai\n",
      "text to token id: 2680\n",
      "token id to text: -she\n",
      "text to token id: 2681\n",
      "token id to text: -shek\n",
      "text to token id: 2682\n",
      "token id to text:  interrupted\n",
      "text to token id: 2683\n",
      "token id to text:  industrial\n",
      "text to token id: 2684\n",
      "token id to text:  Second\n",
      "text to token id: 2685\n",
      "token id to text:  victory\n",
      "text to token id: 2686\n",
      "token id to text:  retreat\n",
      "text to token id: 2687\n",
      "token id to text:  claim\n",
      "text to token id: 2688\n",
      "token id to text:  legitim\n",
      "text to token id: 2689\n",
      "token id to text:  slow\n",
      "text to token id: 2690\n",
      "token id to text:  slowly\n",
      "text to token id: 2691\n",
      "token id to text:  disput\n",
      "text to token id: 2692\n",
      "token id to text: 196\n",
      "text to token id: 2693\n",
      "token id to text:  helped\n",
      "text to token id: 2694\n",
      "token id to text:  consolidate\n",
      "text to token id: 2695\n",
      "token id to text:  towards\n",
      "text to token id: 2696\n",
      "token id to text:  life\n",
      "text to token id: 2697\n",
      "token id to text:  Deng\n",
      "text to token id: 2698\n",
      "token id to text:  populous\n",
      "text to token id: 2699\n",
      "token id to text:  India\n",
      "text to token id: 2700\n",
      "token id to text: istory\n",
      "text to token id: 2701\n",
      "token id to text:  Paleolithic\n",
      "text to token id: 2702\n",
      "token id to text:  subs\n",
      "text to token id: 2703\n",
      "token id to text: 人\n",
      "text to token id: 2704\n",
      "token id to text:  mixed\n",
      "text to token id: 2705\n",
      "token id to text:  Steg\n",
      "text to token id: 2706\n",
      "token id to text:  Stegod\n",
      "text to token id: 2707\n",
      "token id to text:  Stegodon\n",
      "text to token id: 2708\n",
      "token id to text:  cattle\n",
      "text to token id: 2709\n",
      "token id to text: igs\n",
      "text to token id: 2710\n",
      "token id to text:  giant\n",
      "text to token id: 2711\n",
      "token id to text:  hyen\n",
      "text to token id: 2712\n",
      "token id to text:  hyena\n",
      "text to token id: 2713\n",
      "token id to text:  bet\n",
      "text to token id: 2714\n",
      "token id to text:  better\n",
      "text to token id: 2715\n",
      "token id to text:  poin\n",
      "text to token id: 2716\n",
      "token id to text: ls\n",
      "text to token id: 2717\n",
      "token id to text:  foss\n",
      "text to token id: 2718\n",
      "token id to text:  fossil\n",
      "text to token id: 2719\n",
      "token id to text:  northeastern\n",
      "text to token id: 2720\n",
      "token id to text:  Liaon\n",
      "text to token id: 2721\n",
      "token id to text:  Liaoning\n",
      "text to token id: 2722\n",
      "token id to text:  relia\n",
      "text to token id: 2723\n",
      "token id to text:  reliably\n",
      "text to token id: 2724\n",
      "token id to text: agn\n",
      "text to token id: 2725\n",
      "token id to text:  Maj\n",
      "text to token id: 2726\n",
      "token id to text: 55\n",
      "text to token id: 2727\n",
      "token id to text:  Fe\n",
      "text to token id: 2728\n",
      "token id to text:  Evidence\n",
      "text to token id: 2729\n",
      "token id to text:  fire\n",
      "text to token id: 2730\n",
      "token id to text:  Prov\n",
      "text to token id: 2731\n",
      "token id to text:  Province\n",
      "text to token id: 2732\n",
      "token id to text:  surr\n",
      "text to token id: 2733\n",
      "token id to text:  surround\n",
      "text to token id: 2734\n",
      "token id to text:  surrounding\n",
      "text to token id: 2735\n",
      "token id to text:  theories\n",
      "text to token id: 2736\n",
      "token id to text: OA\n",
      "text to token id: 2737\n",
      "token id to text:  hypo\n",
      "text to token id: 2738\n",
      "token id to text:  hypothe\n",
      "text to token id: 2739\n",
      "token id to text:  hypothes\n",
      "text to token id: 2740\n",
      "token id to text:  hypothesis\n",
      "text to token id: 2741\n",
      "token id to text:  humans\n",
      "text to token id: 2742\n",
      "token id to text:  Cave\n",
      "text to token id: 2743\n",
      "token id to text:  larger\n",
      "text to token id: 2744\n",
      "token id to text: inct\n",
      "text to token id: 2745\n",
      "token id to text:  pand\n",
      "text to token id: 2746\n",
      "token id to text: iddle\n",
      "text to token id: 2747\n",
      "token id to text: west\n",
      "text to token id: 2748\n",
      "token id to text:  appro\n",
      "text to token id: 2749\n",
      "token id to text:  approx\n",
      "text to token id: 2750\n",
      "token id to text:  approximately\n",
      "text to token id: 2751\n",
      "token id to text: vention\n",
      "text to token id: 2752\n",
      "token id to text:  dif\n",
      "text to token id: 2753\n",
      "token id to text:  differ\n",
      "text to token id: 2754\n",
      "token id to text:  different\n",
      "text to token id: 2755\n",
      "token id to text:  developed\n",
      "text to token id: 2756\n",
      "token id to text:  grains\n",
      "text to token id: 2757\n",
      "token id to text: anding\n",
      "text to token id: 2758\n",
      "token id to text:  cultivated\n",
      "text to token id: 2759\n",
      "token id to text:  rice\n",
      "text to token id: 2760\n",
      "token id to text: -dated\n",
      "text to token id: 2761\n",
      "token id to text:  Early\n",
      "text to token id: 2762\n",
      "token id to text:  rad\n",
      "text to token id: 2763\n",
      "token id to text:  Jiahu\n",
      "text to token id: 2764\n",
      "token id to text:  best\n",
      "text to token id: 2765\n",
      "token id to text: 580\n",
      "text to token id: 2766\n",
      "token id to text:  Dam\n",
      "text to token id: 2767\n",
      "token id to text:  Damaid\n",
      "text to token id: 2768\n",
      "token id to text:  Damaidi\n",
      "text to token id: 2769\n",
      "token id to text:  Ning\n",
      "text to token id: 2770\n",
      "token id to text:  Ningx\n",
      "text to token id: 2771\n",
      "token id to text:  Ningxia\n",
      "text to token id: 2772\n",
      "token id to text: 600\n",
      "text to token id: 2773\n",
      "token id to text: fe\n",
      "text to token id: 2774\n",
      "token id to text:  star\n",
      "text to token id: 2775\n",
      "token id to text:  god\n",
      "text to token id: 2776\n",
      "token id to text:  gods\n",
      "text to token id: 2777\n",
      "token id to text:  sc\n",
      "text to token id: 2778\n",
      "token id to text: az\n",
      "text to token id: 2779\n",
      "token id to text: arc\n",
      "text to token id: 2780\n",
      "token id to text: shi\n",
      "text to token id: 2781\n",
      "token id to text: -w\n",
      "text to token id: 2782\n",
      "token id to text: riting\n",
      "text to token id: 2783\n",
      "token id to text:  Dad\n",
      "text to token id: 2784\n",
      "token id to text: 40\n",
      "text to token id: 2785\n",
      "token id to text:  ability\n",
      "text to token id: 2786\n",
      "token id to text:  crops\n",
      "text to token id: 2787\n",
      "token id to text:  pot\n",
      "text to token id: 2788\n",
      "token id to text:  potential\n",
      "text to token id: 2789\n",
      "token id to text:  may\n",
      "text to token id: 2790\n",
      "token id to text: shan\n",
      "text to token id: 2791\n",
      "token id to text:  dog\n",
      "text to token id: 2792\n",
      "token id to text:  domesticated\n",
      "text to token id: 2793\n",
      "token id to text:  she\n",
      "text to token id: 2794\n",
      "token id to text:  artif\n",
      "text to token id: 2795\n",
      "token id to text:  artifacts\n",
      "text to token id: 2796\n",
      "token id to text: between\n",
      "text to token id: 2797\n",
      "token id to text:  northeast\n",
      "text to token id: 2798\n",
      "token id to text:  located\n",
      "text to token id: 2799\n",
      "token id to text:  Sich\n",
      "text to token id: 2800\n",
      "token id to text:  Sichuan\n",
      "text to token id: 2801\n",
      "token id to text:  previously\n",
      "text to token id: 2802\n",
      "token id to text:  archaeolog\n",
      "text to token id: 2803\n",
      "token id to text:  archaeologists\n",
      "text to token id: 2804\n",
      "token id to text:  linking\n",
      "text to token id: 2805\n",
      "token id to text:  legendary\n",
      "text to token id: 2806\n",
      "token id to text: aves\n",
      "text to token id: 2807\n",
      "token id to text: jia\n",
      "text to token id: 2808\n",
      "token id to text: err\n",
      "text to token id: 2809\n",
      "token id to text:  iron\n",
      "text to token id: 2810\n",
      "token id to text: zhuang\n",
      "text to token id: 2811\n",
      "token id to text: now\n",
      "text to token id: 2812\n",
      "token id to text:  Tibetan\n",
      "text to token id: 2813\n",
      "token id to text:  Pl\n",
      "text to token id: 2814\n",
      "token id to text:  associated\n",
      "text to token id: 2815\n",
      "token id to text: ustom\n",
      "text to token id: 2816\n",
      "token id to text:  succeed\n",
      "text to token id: 2817\n",
      "token id to text:  succeeding\n",
      "text to token id: 2818\n",
      "token id to text:  sug\n",
      "text to token id: 2819\n",
      "token id to text:  sugg\n",
      "text to token id: 2820\n",
      "token id to text:  suggest\n",
      "text to token id: 2821\n",
      "token id to text:  concurren\n",
      "text to token id: 2822\n",
      "token id to text:  concurrently\n",
      "text to token id: 2823\n",
      "token id to text:  just\n",
      "text to token id: 2824\n",
      "token id to text:  bear\n",
      "text to token id: 2825\n",
      "token id to text: imilar\n",
      "text to token id: 2826\n",
      "token id to text:  Tradition\n",
      "text to token id: 2827\n",
      "token id to text:  Traditionally\n",
      "text to token id: 2828\n",
      "token id to text:  abdication\n",
      "text to token id: 2829\n",
      "token id to text:  abdicated\n",
      "text to token id: 2830\n",
      "token id to text:  includes\n",
      "text to token id: 2831\n",
      "token id to text: amb\n",
      "text to token id: 2832\n",
      "token id to text: amboo\n",
      "text to token id: 2833\n",
      "token id to text:  Shiji\n",
      "text to token id: 2834\n",
      "token id to text:  my\n",
      "text to token id: 2835\n",
      "token id to text:  myth\n",
      "text to token id: 2836\n",
      "token id to text:  usually\n",
      "text to token id: 2837\n",
      "token id to text: 190\n",
      "text to token id: 2838\n",
      "token id to text:  Hen\n",
      "text to token id: 2839\n",
      "token id to text:  Henan\n",
      "text to token id: 2840\n",
      "token id to text:  Since\n",
      "text to token id: 2841\n",
      "token id to text:  prove\n",
      "text to token id: 2842\n",
      "token id to text:  whe\n",
      "text to token id: 2843\n",
      "token id to text:  whether\n",
      "text to token id: 2844\n",
      "token id to text:  ever\n",
      "text to token id: 2845\n",
      "token id to text:  Some\n",
      "text to token id: 2846\n",
      "token id to text:  organ\n",
      "text to token id: 2847\n",
      "token id to text:  important\n",
      "text to token id: 2848\n",
      "token id to text:  using\n",
      "text to token id: 2849\n",
      "token id to text:  vess\n",
      "text to token id: 2850\n",
      "token id to text:  vessels\n",
      "text to token id: 2851\n",
      "token id to text:  Find\n",
      "text to token id: 2852\n",
      "token id to text:  Findings\n",
      "text to token id: 2853\n",
      "token id to text: xu\n",
      "text to token id: 2854\n",
      "token id to text: near\n",
      "text to token id: 2855\n",
      "token id to text:  Late\n",
      "text to token id: 2856\n",
      "token id to text:  find\n",
      "text to token id: 2857\n",
      "token id to text:  findings\n",
      "text to token id: 2858\n",
      "token id to text:  Through\n",
      "text to token id: 2859\n",
      "token id to text:  move\n",
      "text to token id: 2860\n",
      "token id to text:  Ding\n",
      "text to token id: 2861\n",
      "token id to text: atter\n",
      "text to token id: 2862\n",
      "token id to text: Al\n",
      "text to token id: 2863\n",
      "token id to text: Although\n",
      "text to token id: 2864\n",
      "token id to text:  conf\n",
      "text to token id: 2865\n",
      "token id to text:  settlements\n",
      "text to token id: 2866\n",
      "token id to text:  leading\n",
      "text to token id: 2867\n",
      "token id to text:  coex\n",
      "text to token id: 2868\n",
      "token id to text:  coexisted\n",
      "text to token id: 2869\n",
      "token id to text:  traded\n",
      "text to token id: 2870\n",
      "token id to text: ead\n",
      "text to token id: 2871\n",
      "token id to text:  alm\n",
      "text to token id: 2872\n",
      "token id to text:  almost\n",
      "text to token id: 2873\n",
      "token id to text:  eight\n",
      "text to token id: 2874\n",
      "token id to text: nd\n",
      "text to token id: 2875\n",
      "token id to text:  Prot\n",
      "text to token id: 2876\n",
      "token id to text: ectors\n",
      "text to token id: 2877\n",
      "token id to text:  relatives\n",
      "text to token id: 2878\n",
      "token id to text:  allies\n",
      "text to token id: 2879\n",
      "token id to text:  Sever\n",
      "text to token id: 2880\n",
      "token id to text:  Several\n",
      "text to token id: 2881\n",
      "token id to text:  influential\n",
      "text to token id: 2882\n",
      "token id to text:  overthr\n",
      "text to token id: 2883\n",
      "token id to text: aving\n",
      "text to token id: 2884\n",
      "token id to text:  Zong\n",
      "text to token id: 2885\n",
      "token id to text:  king\n",
      "text to token id: 2886\n",
      "token id to text:  Shand\n",
      "text to token id: 2887\n",
      "token id to text:  Shandong\n",
      "text to token id: 2888\n",
      "token id to text:  southeast\n",
      "text to token id: 2889\n",
      "token id to text: 476\n",
      "text to token id: 2890\n",
      "token id to text:  You\n",
      "text to token id: 2891\n",
      "token id to text:  Quan\n",
      "text to token id: 2892\n",
      "token id to text:  barb\n",
      "text to token id: 2893\n",
      "token id to text:  barbar\n",
      "text to token id: 2894\n",
      "token id to text:  aristocr\n",
      "text to token id: 2895\n",
      "token id to text:  aristocrat\n",
      "text to token id: 2896\n",
      "token id to text:  aristocrats\n",
      "text to token id: 2897\n",
      "token id to text:  ph\n",
      "text to token id: 2898\n",
      "token id to text:  nam\n",
      "text to token id: 2899\n",
      "token id to text:  shar\n",
      "text to token id: 2900\n",
      "token id to text:  sharp\n",
      "text to token id: 2901\n",
      "token id to text:  sharply\n",
      "text to token id: 2902\n",
      "token id to text:  reduced\n",
      "text to token id: 2903\n",
      "token id to text:  vacu\n",
      "text to token id: 2904\n",
      "token id to text:  vacuum\n",
      "text to token id: 2905\n",
      "token id to text:  wall\n",
      "text to token id: 2906\n",
      "token id to text:  hege\n",
      "text to token id: 2907\n",
      "token id to text:  hegem\n",
      "text to token id: 2908\n",
      "token id to text:  hegemony\n",
      "text to token id: 2909\n",
      "token id to text:  disappear\n",
      "text to token id: 2910\n",
      "token id to text: alities\n",
      "text to token id: 2911\n",
      "token id to text:  claimed\n",
      "text to token id: 2912\n",
      "token id to text:  undert\n",
      "text to token id: 2913\n",
      "token id to text:  commercial\n",
      "text to token id: 2914\n",
      "token id to text:  individuals\n",
      "text to token id: 2915\n",
      "token id to text: aoz\n",
      "text to token id: 2916\n",
      "token id to text:  administrations\n",
      "text to token id: 2917\n",
      "token id to text:  mob\n",
      "text to token id: 2918\n",
      "token id to text: ying\n",
      "text to token id: 2919\n",
      "token id to text:  overthrew\n",
      "text to token id: 2920\n",
      "token id to text:  Hundred\n",
      "text to token id: 2921\n",
      "token id to text:  Sch\n",
      "text to token id: 2922\n",
      "token id to text: ools\n",
      "text to token id: 2923\n",
      "token id to text: oming\n",
      "text to token id: 2924\n",
      "token id to text:  changing\n",
      "text to token id: 2925\n",
      "token id to text:  nominally\n",
      "text to token id: 2926\n",
      "token id to text:  largely\n",
      "text to token id: 2927\n",
      "token id to text:  mat\n",
      "text to token id: 2928\n",
      "token id to text:  mathem\n",
      "text to token id: 2929\n",
      "token id to text: inc\n",
      "text to token id: 2930\n",
      "token id to text: includ\n",
      "text to token id: 2931\n",
      "token id to text: including\n",
      "text to token id: 2932\n",
      "token id to text:  Zuo\n",
      "text to token id: 2933\n",
      "token id to text:  work\n",
      "text to token id: 2934\n",
      "token id to text:  sum\n",
      "text to token id: 2935\n",
      "token id to text: izing\n",
      "text to token id: 2936\n",
      "token id to text:  preceding\n",
      "text to token id: 2937\n",
      "token id to text:  Ts\n",
      "text to token id: 2938\n",
      "token id to text:  Tsing\n",
      "text to token id: 2939\n",
      "token id to text:  Tsinghu\n",
      "text to token id: 2940\n",
      "token id to text:  Tsinghua\n",
      "text to token id: 2941\n",
      "token id to text:  collection\n",
      "text to token id: 2942\n",
      "token id to text:  soph\n",
      "text to token id: 2943\n",
      "token id to text:  commander\n",
      "text to token id: 2944\n",
      "token id to text:  commanderies\n",
      "text to token id: 2945\n",
      "token id to text:  prefectures\n",
      "text to token id: 2946\n",
      "token id to text: ili\n",
      "text to token id: 2947\n",
      "token id to text:  xian\n",
      "text to token id: 2948\n",
      "token id to text:  (\"\n",
      "text to token id: 2949\n",
      "token id to text: \")\n",
      "text to token id: 2950\n",
      "token id to text:  wan\n",
      "text to token id: 2951\n",
      "token id to text:  Chengdu\n",
      "text to token id: 2952\n",
      "token id to text:  Plain\n",
      "text to token id: 2953\n",
      "token id to text: by\n",
      "text to token id: 2954\n",
      "token id to text:  Its\n",
      "text to token id: 2955\n",
      "token id to text:  expans\n",
      "text to token id: 2956\n",
      "token id to text:  expansion\n",
      "text to token id: 2957\n",
      "token id to text: 206\n",
      "text to token id: 2958\n",
      "token id to text: �\n",
      "text to token id: 2959\n",
      "token id to text: 秦\n",
      "text to token id: 2960\n",
      "token id to text:  formal\n",
      "text to token id: 2961\n",
      "token id to text:  piv\n",
      "text to token id: 2962\n",
      "token id to text:  pivot\n",
      "text to token id: 2963\n",
      "token id to text:  pivotal\n",
      "text to token id: 2964\n",
      "token id to text: ving\n",
      "text to token id: 2965\n",
      "token id to text: \".\n",
      "text to token id: 2966\n",
      "token id to text:  Huangdi\n",
      "text to token id: 2967\n",
      "token id to text:  tit\n",
      "text to token id: 2968\n",
      "token id to text:  title\n",
      "text to token id: 2969\n",
      "token id to text:  der\n",
      "text to token id: 2970\n",
      "token id to text:  derived\n",
      "text to token id: 2971\n",
      "token id to text:  bureaucr\n",
      "text to token id: 2972\n",
      "token id to text:  bureaucratic\n",
      "text to token id: 2973\n",
      "token id to text:  dominated\n",
      "text to token id: 2974\n",
      "token id to text:  effort\n",
      "text to token id: 2975\n",
      "token id to text:  prog\n",
      "text to token id: 2976\n",
      "token id to text:  progress\n",
      "text to token id: 2977\n",
      "token id to text:  smaller\n",
      "text to token id: 2978\n",
      "token id to text:  asp\n",
      "text to token id: 2979\n",
      "token id to text:  aspects\n",
      "text to token id: 2980\n",
      "token id to text:  chance\n",
      "text to token id: 2981\n",
      "token id to text:  chancell\n",
      "text to token id: 2982\n",
      "token id to text:  legal\n",
      "text to token id: 2983\n",
      "token id to text:  matt\n",
      "text to token id: 2984\n",
      "token id to text:  matters\n",
      "text to token id: 2985\n",
      "token id to text:  severe\n",
      "text to token id: 2986\n",
      "token id to text:  pun\n",
      "text to token id: 2987\n",
      "token id to text: agement\n",
      "text to token id: 2988\n",
      "token id to text:  Reform\n",
      "text to token id: 2989\n",
      "token id to text:  boo\n",
      "text to token id: 2990\n",
      "token id to text:  books\n",
      "text to token id: 2991\n",
      "token id to text:  live\n",
      "text to token id: 2992\n",
      "token id to text:  considerable\n",
      "text to token id: 2993\n",
      "token id to text:  dou\n",
      "text to token id: 2994\n",
      "token id to text:  historic\n",
      "text to token id: 2995\n",
      "token id to text:  Despite\n",
      "text to token id: 2996\n",
      "token id to text:  supplement\n",
      "text to token id: 2997\n",
      "token id to text: olitical\n",
      "text to token id: 2998\n",
      "token id to text:  mor\n",
      "text to token id: 2999\n",
      "token id to text:  moral\n",
      "text to token id: 3000\n",
      "token id to text:  belief\n",
      "text to token id: 3001\n",
      "token id to text:  beliefs\n",
      "text to token id: 3002\n",
      "token id to text:  five\n",
      "text to token id: 3003\n",
      "token id to text:  kept\n",
      "text to token id: 3004\n",
      "token id to text:  collect\n",
      "text to token id: 3005\n",
      "token id to text:  sex\n",
      "text to token id: 3006\n",
      "token id to text: ff\n",
      "text to token id: 3007\n",
      "token id to text: ffered\n",
      "text to token id: 3008\n",
      "token id to text:  harsh\n",
      "text to token id: 3009\n",
      "token id to text:  Pat\n",
      "text to token id: 3010\n",
      "token id to text:  Patric\n",
      "text to token id: 3011\n",
      "token id to text:  Patricia\n",
      "text to token id: 3012\n",
      "token id to text:  Eb\n",
      "text to token id: 3013\n",
      "token id to text:  Ebre\n",
      "text to token id: 3014\n",
      "token id to text:  Ebrey\n",
      "text to token id: 3015\n",
      "token id to text:  conscripted\n",
      "text to token id: 3016\n",
      "token id to text:  highway\n",
      "text to token id: 3017\n",
      "token id to text:  miles\n",
      "text to token id: 3018\n",
      "token id to text:  km\n",
      "text to token id: 3019\n",
      "token id to text:  alt\n",
      "text to token id: 3020\n",
      "token id to text:  altog\n",
      "text to token id: 3021\n",
      "token id to text:  altogether\n",
      "text to token id: 3022\n",
      "token id to text:  Meng\n",
      "text to token id: 3023\n",
      "token id to text:  successful\n",
      "text to token id: 3024\n",
      "token id to text:  peop\n",
      "text to token id: 3025\n",
      "token id to text:  peoples\n",
      "text to token id: 3026\n",
      "token id to text:  Under\n",
      "text to token id: 3027\n",
      "token id to text:  ord\n",
      "text to token id: 3028\n",
      "token id to text: ining\n",
      "text to token id: 3029\n",
      "token id to text:  build\n",
      "text to token id: 3030\n",
      "token id to text: erior\n",
      "text to token id: 3031\n",
      "token id to text:  sacked\n",
      "text to token id: 3032\n",
      "token id to text:  rebels\n",
      "text to token id: 3033\n",
      "token id to text:  Liu\n",
      "text to token id: 3034\n",
      "token id to text:  consolidated\n",
      "text to token id: 3035\n",
      "token id to text: mit\n",
      "text to token id: 3036\n",
      "token id to text:  elev\n",
      "text to token id: 3037\n",
      "token id to text:  elevated\n",
      "text to token id: 3038\n",
      "token id to text:  shap\n",
      "text to token id: 3039\n",
      "token id to text:  unp\n",
      "text to token id: 3040\n",
      "token id to text:  unpre\n",
      "text to token id: 3041\n",
      "token id to text:  unpreced\n",
      "text to token id: 3042\n",
      "token id to text:  unprecedent\n",
      "text to token id: 3043\n",
      "token id to text:  unprecedented\n",
      "text to token id: 3044\n",
      "token id to text:  lasting\n",
      "text to token id: 3045\n",
      "token id to text:  tak\n",
      "text to token id: 3046\n",
      "token id to text:  taken\n",
      "text to token id: 3047\n",
      "token id to text:  Emperors\n",
      "text to token id: 3048\n",
      "token id to text:  Jing\n",
      "text to token id: 3049\n",
      "token id to text: izes\n",
      "text to token id: 3050\n",
      "token id to text:  strengthe\n",
      "text to token id: 3051\n",
      "token id to text: Major\n",
      "text to token id: 3052\n",
      "token id to text:  weaken\n",
      "text to token id: 3053\n",
      "token id to text: iting\n",
      "text to token id: 3054\n",
      "token id to text:  Along\n",
      "text to token id: 3055\n",
      "token id to text:  connected\n",
      "text to token id: 3056\n",
      "token id to text:  stimul\n",
      "text to token id: 3057\n",
      "token id to text:  kingdoms\n",
      "text to token id: 3058\n",
      "token id to text:  bey\n",
      "text to token id: 3059\n",
      "token id to text:  beyond\n",
      "text to token id: 3060\n",
      "token id to text: Emperor\n",
      "text to token id: 3061\n",
      "token id to text: atched\n",
      "text to token id: 3062\n",
      "token id to text:  Bai\n",
      "text to token id: 3063\n",
      "token id to text: yue\n",
      "text to token id: 3064\n",
      "token id to text: 109\n",
      "text to token id: 3065\n",
      "token id to text:  exped\n",
      "text to token id: 3066\n",
      "token id to text:  assimil\n",
      "text to token id: 3067\n",
      "token id to text:  assimilation\n",
      "text to token id: 3068\n",
      "token id to text:  contact\n",
      "text to token id: 3069\n",
      "token id to text:  gradual\n",
      "text to token id: 3070\n",
      "token id to text:  excessive\n",
      "text to token id: 3071\n",
      "token id to text:  acqu\n",
      "text to token id: 3072\n",
      "token id to text:  acquis\n",
      "text to token id: 3073\n",
      "token id to text:  acquisitions\n",
      "text to token id: 3074\n",
      "token id to text:  consort\n",
      "text to token id: 3075\n",
      "token id to text:  clans\n",
      "text to token id: 3076\n",
      "token id to text:  strings\n",
      "text to token id: 3077\n",
      "token id to text:  incompet\n",
      "text to token id: 3078\n",
      "token id to text:  incompetent\n",
      "text to token id: 3079\n",
      "token id to text:  usurp\n",
      "text to token id: 3080\n",
      "token id to text:  usurpation\n",
      "text to token id: 3081\n",
      "token id to text:  progr\n",
      "text to token id: 3082\n",
      "token id to text:  program\n",
      "text to token id: 3083\n",
      "token id to text:  slavery\n",
      "text to token id: 3084\n",
      "token id to text:  supported\n",
      "text to token id: 3085\n",
      "token id to text:  inst\n",
      "text to token id: 3086\n",
      "token id to text:  chaos\n",
      "text to token id: 3087\n",
      "token id to text:  displaced\n",
      "text to token id: 3088\n",
      "token id to text:  farm\n",
      "text to token id: 3089\n",
      "token id to text:  farmers\n",
      "text to token id: 3090\n",
      "token id to text:  enr\n",
      "text to token id: 3091\n",
      "token id to text:  merchant\n",
      "text to token id: 3092\n",
      "token id to text:  termed\n",
      "text to token id: 3093\n",
      "token id to text:  decis\n",
      "text to token id: 3094\n",
      "token id to text:  decisively\n",
      "text to token id: 3095\n",
      "token id to text:  Chao\n",
      "text to token id: 3096\n",
      "token id to text:  thus\n",
      "text to token id: 3097\n",
      "token id to text:  emb\n",
      "text to token id: 3098\n",
      "token id to text:  sea\n",
      "text to token id: 3099\n",
      "token id to text:  route\n",
      "text to token id: 3100\n",
      "token id to text: 280\n",
      "text to token id: 3101\n",
      "token id to text: By\n",
      "text to token id: 3102\n",
      "token id to text:  amidst\n",
      "text to token id: 3103\n",
      "token id to text:  feud\n",
      "text to token id: 3104\n",
      "token id to text:  eun\n",
      "text to token id: 3105\n",
      "token id to text:  eunuch\n",
      "text to token id: 3106\n",
      "token id to text:  eunuchs\n",
      "text to token id: 3107\n",
      "token id to text:  broke\n",
      "text to token id: 3108\n",
      "token id to text:  ushe\n",
      "text to token id: 3109\n",
      "token id to text:  ushering\n",
      "text to token id: 3110\n",
      "token id to text:  ensu\n",
      "text to token id: 3111\n",
      "token id to text:  ensuing\n",
      "text to token id: 3112\n",
      "token id to text:  reunify\n",
      "text to token id: 3113\n",
      "token id to text:  giving\n",
      "text to token id: 3114\n",
      "token id to text:  novel\n",
      "text to token id: 3115\n",
      "token id to text:  events\n",
      "text to token id: 3116\n",
      "token id to text:  Cao\n",
      "text to token id: 3117\n",
      "token id to text: 266\n",
      "text to token id: 3118\n",
      "token id to text: 420\n",
      "text to token id: 3119\n",
      "token id to text: -Han\n",
      "text to token id: 3120\n",
      "token id to text:  rebell\n",
      "text to token id: 3121\n",
      "token id to text: -day\n",
      "text to token id: 3122\n",
      "token id to text: 439\n",
      "text to token id: 3123\n",
      "token id to text:  Qiang\n",
      "text to token id: 3124\n",
      "token id to text:  before\n",
      "text to token id: 3125\n",
      "token id to text:  fron\n",
      "text to token id: 3126\n",
      "token id to text:  front\n",
      "text to token id: 3127\n",
      "token id to text:  frontier\n",
      "text to token id: 3128\n",
      "token id to text:  rav\n",
      "text to token id: 3129\n",
      "token id to text:  ravaged\n",
      "text to token id: 3130\n",
      "token id to text: -scal\n",
      "text to token id: 3131\n",
      "token id to text: -scale\n",
      "text to token id: 3132\n",
      "token id to text: 589\n",
      "text to token id: 3133\n",
      "token id to text: ves\n",
      "text to token id: 3134\n",
      "token id to text:  Chen\n",
      "text to token id: 3135\n",
      "token id to text: kang\n",
      "text to token id: 3136\n",
      "token id to text:  off\n",
      "text to token id: 3137\n",
      "token id to text:  attac\n",
      "text to token id: 3138\n",
      "token id to text:  tol\n",
      "text to token id: 3139\n",
      "token id to text:  toler\n",
      "text to token id: 3140\n",
      "token id to text:  Founded\n",
      "text to token id: 3141\n",
      "token id to text:  succession\n",
      "text to token id: 3142\n",
      "token id to text:  went\n",
      "text to token id: 3143\n",
      "token id to text:  institutions\n",
      "text to token id: 3144\n",
      "token id to text:  Dep\n",
      "text to token id: 3145\n",
      "token id to text:  Departments\n",
      "text to token id: 3146\n",
      "token id to text:  Ministr\n",
      "text to token id: 3147\n",
      "token id to text:  Ministries\n",
      "text to token id: 3148\n",
      "token id to text:  examinations\n",
      "text to token id: 3149\n",
      "token id to text:  sel\n",
      "text to token id: 3150\n",
      "token id to text:  systems\n",
      "text to token id: 3151\n",
      "token id to text:  fub\n",
      "text to token id: 3152\n",
      "token id to text:  fubing\n",
      "text to token id: 3153\n",
      "token id to text: -field\n",
      "text to token id: 3154\n",
      "token id to text:  amassed\n",
      "text to token id: 3155\n",
      "token id to text:  coinage\n",
      "text to token id: 3156\n",
      "token id to text:  enfor\n",
      "text to token id: 3157\n",
      "token id to text:  enforced\n",
      "text to token id: 3158\n",
      "token id to text: construc\n",
      "text to token id: 3159\n",
      "token id to text:  ship\n",
      "text to token id: 3160\n",
      "token id to text:  maneu\n",
      "text to token id: 3161\n",
      "token id to text:  maneuvers\n",
      "text to token id: 3162\n",
      "token id to text:  Pen\n",
      "text to token id: 3163\n",
      "token id to text:  failed\n",
      "text to token id: 3164\n",
      "token id to text:  trig\n",
      "text to token id: 3165\n",
      "token id to text:  trigg\n",
      "text to token id: 3166\n",
      "token id to text:  revolts\n",
      "text to token id: 3167\n",
      "token id to text:  prosperous\n",
      "text to token id: 3168\n",
      "token id to text:  stable\n",
      "text to token id: 3169\n",
      "token id to text:  particularly\n",
      "text to token id: 3170\n",
      "token id to text:  predominant\n",
      "text to token id: 3171\n",
      "token id to text:  placed\n",
      "text to token id: 3172\n",
      "token id to text:  Taiz\n",
      "text to token id: 3173\n",
      "token id to text: ucrative\n",
      "text to token id: 3174\n",
      "token id to text:  routes\n",
      "text to token id: 3175\n",
      "token id to text:  countries\n",
      "text to token id: 3176\n",
      "token id to text:  settled\n",
      "text to token id: 3177\n",
      "token id to text:  adap\n",
      "text to token id: 3178\n",
      "token id to text:  Xuan\n",
      "text to token id: 3179\n",
      "token id to text:  Xuanz\n",
      "text to token id: 3180\n",
      "token id to text:  Buddhist\n",
      "text to token id: 3181\n",
      "token id to text:  travell\n",
      "text to token id: 3182\n",
      "token id to text:  retur\n",
      "text to token id: 3183\n",
      "token id to text: ayana\n",
      "text to token id: 3184\n",
      "token id to text: Th\n",
      "text to token id: 3185\n",
      "token id to text:  rev\n",
      "text to token id: 3186\n",
      "token id to text:  implement\n",
      "text to token id: 3187\n",
      "token id to text:  dep\n",
      "text to token id: 3188\n",
      "token id to text:  joined\n",
      "text to token id: 3189\n",
      "token id to text:  replaced\n",
      "text to token id: 3190\n",
      "token id to text:  setting\n",
      "text to token id: 3191\n",
      "token id to text: Un\n",
      "text to token id: 3192\n",
      "token id to text:  stimulated\n",
      "text to token id: 3193\n",
      "token id to text:  product\n",
      "text to token id: 3194\n",
      "token id to text:  mid\n",
      "text to token id: 3195\n",
      "token id to text:  hands\n",
      "text to token id: 3196\n",
      "token id to text:  vibr\n",
      "text to token id: 3197\n",
      "token id to text:  vibrant\n",
      "text to token id: 3198\n",
      "token id to text: At\n",
      "text to token id: 3199\n",
      "token id to text:  wat\n",
      "text to token id: 3200\n",
      "token id to text:  dise\n",
      "text to token id: 3201\n",
      "token id to text:  disease\n",
      "text to token id: 3202\n",
      "token id to text: ruption\n",
      "text to token id: 3203\n",
      "token id to text:  devastated\n",
      "text to token id: 3204\n",
      "token id to text:  Upon\n",
      "text to token id: 3205\n",
      "token id to text:  autonom\n",
      "text to token id: 3206\n",
      "token id to text:  autonomous\n",
      "text to token id: 3207\n",
      "token id to text: oly\n",
      "text to token id: 3208\n",
      "token id to text:  Ext\n",
      "text to token id: 3209\n",
      "token id to text:  subm\n",
      "text to token id: 3210\n",
      "token id to text:  ra\n",
      "text to token id: 3211\n",
      "token id to text: -of\n",
      "text to token id: 3212\n",
      "token id to text: -officials\n",
      "text to token id: 3213\n",
      "token id to text:  engaged\n",
      "text to token id: 3214\n",
      "token id to text: ional\n",
      "text to token id: 3215\n",
      "token id to text: atast\n",
      "text to token id: 3216\n",
      "token id to text: atastrop\n",
      "text to token id: 3217\n",
      "token id to text:  massac\n",
      "text to token id: 3218\n",
      "token id to text:  inh\n",
      "text to token id: 3219\n",
      "token id to text:  inhab\n",
      "text to token id: 3220\n",
      "token id to text:  inhabit\n",
      "text to token id: 3221\n",
      "token id to text:  inhabitants\n",
      "text to token id: 3222\n",
      "token id to text:  Turk\n",
      "text to token id: 3223\n",
      "token id to text:  Turkic\n",
      "text to token id: 3224\n",
      "token id to text:  Consequent\n",
      "text to token id: 3225\n",
      "token id to text:  Consequently\n",
      "text to token id: 3226\n",
      "token id to text:  Jinzh\n",
      "text to token id: 3227\n",
      "token id to text:  Jinzhong\n",
      "text to token id: 3228\n",
      "token id to text:  chas\n",
      "text to token id: 3229\n",
      "token id to text:  Uyghurs\n",
      "text to token id: 3230\n",
      "token id to text:  served\n",
      "text to token id: 3231\n",
      "token id to text:  fighting\n",
      "text to token id: 3232\n",
      "token id to text:  kh\n",
      "text to token id: 3233\n",
      "token id to text:  khaganate\n",
      "text to token id: 3234\n",
      "token id to text:  Zhangx\n",
      "text to token id: 3235\n",
      "token id to text:  Zhangxin\n",
      "text to token id: 3236\n",
      "token id to text:  suic\n",
      "text to token id: 3237\n",
      "token id to text:  suicide\n",
      "text to token id: 3238\n",
      "token id to text:  precip\n",
      "text to token id: 3239\n",
      "token id to text:  precipit\n",
      "text to token id: 3240\n",
      "token id to text:  tried\n",
      "text to token id: 3241\n",
      "token id to text:  particip\n",
      "text to token id: 3242\n",
      "token id to text:  participated\n",
      "text to token id: 3243\n",
      "token id to text:  offic\n",
      "text to token id: 3244\n",
      "token id to text:  Tu\n",
      "text to token id: 3245\n",
      "token id to text:  Tangut\n",
      "text to token id: 3246\n",
      "token id to text:  mount\n",
      "text to token id: 3247\n",
      "token id to text:  mountain\n",
      "text to token id: 3248\n",
      "token id to text:  Ten\n",
      "text to token id: 3249\n",
      "token id to text:  lasted\n",
      "text to token id: 3250\n",
      "token id to text: -cent\n",
      "text to token id: 3251\n",
      "token id to text: -century\n",
      "text to token id: 3252\n",
      "token id to text: -st\n",
      "text to token id: 3253\n",
      "token id to text:  namely\n",
      "text to token id: 3254\n",
      "token id to text: Later\n",
      "text to token id: 3255\n",
      "token id to text:  rapidly\n",
      "text to token id: 3256\n",
      "token id to text:  Am\n",
      "text to token id: 3257\n",
      "token id to text:  sinicized\n",
      "text to token id: 3258\n",
      "token id to text: Ten\n",
      "text to token id: 3259\n",
      "token id to text:  strate\n",
      "text to token id: 3260\n",
      "token id to text:  strateg\n",
      "text to token id: 3261\n",
      "token id to text:  strategic\n",
      "text to token id: 3262\n",
      "token id to text:  ceded\n",
      "text to token id: 3263\n",
      "token id to text:  Khitan\n",
      "text to token id: 3264\n",
      "token id to text:  defense\n",
      "text to token id: 3265\n",
      "token id to text:  shif\n",
      "text to token id: 3266\n",
      "token id to text:  Later\n",
      "text to token id: 3267\n",
      "token id to text:  annihilated\n",
      "text to token id: 3268\n",
      "token id to text:  occupied\n",
      "text to token id: 3269\n",
      "token id to text:  Manchur\n",
      "text to token id: 3270\n",
      "token id to text:  Manchuria\n",
      "text to token id: 3271\n",
      "token id to text:  provinces\n",
      "text to token id: 3272\n",
      "token id to text: 103\n",
      "text to token id: 3273\n",
      "token id to text: 122\n",
      "text to token id: 3274\n",
      "token id to text:  caval\n",
      "text to token id: 3275\n",
      "token id to text:  cavalry\n",
      "text to token id: 3276\n",
      "token id to text:  swept\n",
      "text to token id: 3277\n",
      "token id to text:  outs\n",
      "text to token id: 3278\n",
      "token id to text:  outsk\n",
      "text to token id: 3279\n",
      "token id to text:  outskir\n",
      "text to token id: 3280\n",
      "token id to text:  forcing\n",
      "text to token id: 3281\n",
      "token id to text:  imposed\n",
      "text to token id: 3282\n",
      "token id to text:  Yet\n",
      "text to token id: 3283\n",
      "token id to text:  silver\n",
      "text to token id: 3284\n",
      "token id to text:  back\n",
      "text to token id: 3285\n",
      "token id to text:  goods\n",
      "text to token id: 3286\n",
      "token id to text:  incent\n",
      "text to token id: 3287\n",
      "token id to text:  sinicization\n",
      "text to token id: 3288\n",
      "token id to text:  expense\n",
      "text to token id: 3289\n",
      "token id to text:  might\n",
      "text to token id: 3290\n",
      "token id to text:  lif\n",
      "text to token id: 3291\n",
      "token id to text: onomical\n",
      "text to token id: 3292\n",
      "token id to text: ences\n",
      "text to token id: 3293\n",
      "token id to text:  relations\n",
      "text to token id: 3294\n",
      "token id to text:  devastating\n",
      "text to token id: 3295\n",
      "token id to text: cident\n",
      "text to token id: 3296\n",
      "token id to text:  living\n",
      "text to token id: 3297\n",
      "token id to text:  standards\n",
      "text to token id: 3298\n",
      "token id to text:  tremend\n",
      "text to token id: 3299\n",
      "token id to text:  due\n",
      "text to token id: 3300\n",
      "token id to text:  Although\n",
      "text to token id: 3301\n",
      "token id to text:  South\n",
      "text to token id: 3302\n",
      "token id to text:  equipped\n",
      "text to token id: 3303\n",
      "token id to text: -h\n",
      "text to token id: 3304\n",
      "token id to text:  act\n",
      "text to token id: 3305\n",
      "token id to text:  che\n",
      "text to token id: 3306\n",
      "token id to text:  innovative\n",
      "text to token id: 3307\n",
      "token id to text:  Shen\n",
      "text to token id: 3308\n",
      "token id to text:  invented\n",
      "text to token id: 3309\n",
      "token id to text:  reformers\n",
      "text to token id: 3310\n",
      "token id to text:  compiled\n",
      "text to token id: 3311\n",
      "token id to text:  Tong\n",
      "text to token id: 3312\n",
      "token id to text: jian\n",
      "text to token id: 3313\n",
      "token id to text:  movable\n",
      "text to token id: 3314\n",
      "token id to text: ledge\n",
      "text to token id: 3315\n",
      "token id to text:  Culture\n",
      "text to token id: 3316\n",
      "token id to text:  arts\n",
      "text to token id: 3317\n",
      "token id to text: ute\n",
      "text to token id: 3318\n",
      "token id to text: unp\n",
      "text to token id: 3319\n",
      "token id to text: unpow\n",
      "text to token id: 3320\n",
      "token id to text: unpowder\n",
      "text to token id: 3321\n",
      "token id to text: ms\n",
      "text to token id: 3322\n",
      "token id to text:  sie\n",
      "text to token id: 3323\n",
      "token id to text:  siege\n",
      "text to token id: 3324\n",
      "token id to text:  guard\n",
      "text to token id: 3325\n",
      "token id to text:  head\n",
      "text to token id: 3326\n",
      "token id to text:  could\n",
      "text to token id: 3327\n",
      "token id to text:  advances\n",
      "text to token id: 3328\n",
      "token id to text: isation\n",
      "text to token id: 3329\n",
      "token id to text: rupt\n",
      "text to token id: 3330\n",
      "token id to text:  marked\n",
      "text to token id: 3331\n",
      "token id to text:  additional\n",
      "text to token id: 3332\n",
      "token id to text:  inhe\n",
      "text to token id: 3333\n",
      "token id to text:  entirety\n",
      "text to token id: 3334\n",
      "token id to text:  minority\n",
      "text to token id: 3335\n",
      "token id to text:  Khanbali\n",
      "text to token id: 3336\n",
      "token id to text:  Khanbaliq\n",
      "text to token id: 3337\n",
      "token id to text: ote\n",
      "text to token id: 3338\n",
      "token id to text: 130\n",
      "text to token id: 3339\n",
      "token id to text:  uphe\n",
      "text to token id: 3340\n",
      "token id to text:  nominal\n",
      "text to token id: 3341\n",
      "token id to text:  post\n",
      "text to token id: 3342\n",
      "token id to text:  ports\n",
      "text to token id: 3343\n",
      "token id to text:  Pol\n",
      "text to token id: 3344\n",
      "token id to text:  inspired\n",
      "text to token id: 3345\n",
      "token id to text:  med\n",
      "text to token id: 3346\n",
      "token id to text:  spl\n",
      "text to token id: 3347\n",
      "token id to text:  splend\n",
      "text to token id: 3348\n",
      "token id to text: icted\n",
      "text to token id: 3349\n",
      "token id to text:  substantially\n",
      "text to token id: 3350\n",
      "token id to text:  less\n",
      "text to token id: 3351\n",
      "token id to text:  On\n",
      "text to token id: 3352\n",
      "token id to text: ibly\n",
      "text to token id: 3353\n",
      "token id to text:  variet\n",
      "text to token id: 3354\n",
      "token id to text:  variety\n",
      "text to token id: 3355\n",
      "token id to text:  underw\n",
      "text to token id: 3356\n",
      "token id to text:  underwent\n",
      "text to token id: 3357\n",
      "token id to text:  Lar\n",
      "text to token id: 3358\n",
      "token id to text:  Large\n",
      "text to token id: 3359\n",
      "token id to text:  elements\n",
      "text to token id: 3360\n",
      "token id to text:  intellectuals\n",
      "text to token id: 3361\n",
      "token id to text: ular\n",
      "text to token id: 3362\n",
      "token id to text:  popular\n",
      "text to token id: 3363\n",
      "token id to text:  cens\n",
      "text to token id: 3364\n",
      "token id to text:  census\n",
      "text to token id: 3365\n",
      "token id to text:  necessar\n",
      "text to token id: 3366\n",
      "token id to text:  necessarily\n",
      "text to token id: 3367\n",
      "token id to text:  arg\n",
      "text to token id: 3368\n",
      "token id to text:  argue\n",
      "text to token id: 3369\n",
      "token id to text:  among\n",
      "text to token id: 3370\n",
      "token id to text:  populace\n",
      "text to token id: 3371\n",
      "token id to text:  causing\n",
      "text to token id: 3372\n",
      "token id to text: organ\n",
      "text to token id: 3373\n",
      "token id to text:  plague\n",
      "text to token id: 3374\n",
      "token id to text:  ep\n",
      "text to token id: 3375\n",
      "token id to text:  epid\n",
      "text to token id: 3376\n",
      "token id to text:  epidem\n",
      "text to token id: 3377\n",
      "token id to text:  epidemics\n",
      "text to token id: 3378\n",
      "token id to text:  estim\n",
      "text to token id: 3379\n",
      "token id to text:  estimated\n",
      "text to token id: 3380\n",
      "token id to text:  quarter\n",
      "text to token id: 3381\n",
      "token id to text:  mainly\n",
      "text to token id: 3382\n",
      "token id to text:  Yuanzhang\n",
      "text to token id: 3383\n",
      "token id to text:  sust\n",
      "text to token id: 3384\n",
      "token id to text:  sustained\n",
      "text to token id: 3385\n",
      "token id to text:  indust\n",
      "text to token id: 3386\n",
      "token id to text:  industry\n",
      "text to token id: 3387\n",
      "token id to text:  markets\n",
      "text to token id: 3388\n",
      "token id to text:  man\n",
      "text to token id: 3389\n",
      "token id to text:  charac\n",
      "text to token id: 3390\n",
      "token id to text:  character\n",
      "text to token id: 3391\n",
      "token id to text:  characteristic\n",
      "text to token id: 3392\n",
      "token id to text:  isol\n",
      "text to token id: 3393\n",
      "token id to text:  outside\n",
      "text to token id: 3394\n",
      "token id to text:  voy\n",
      "text to token id: 3395\n",
      "token id to text:  voyages\n",
      "text to token id: 3396\n",
      "token id to text:  orig\n",
      "text to token id: 3397\n",
      "token id to text:  origin\n",
      "text to token id: 3398\n",
      "token id to text: bidd\n",
      "text to token id: 3399\n",
      "token id to text: bidden\n",
      "text to token id: 3400\n",
      "token id to text:  laws\n",
      "text to token id: 3401\n",
      "token id to text:  pover\n",
      "text to token id: 3402\n",
      "token id to text:  poverty\n",
      "text to token id: 3403\n",
      "token id to text: work\n",
      "text to token id: 3404\n",
      "token id to text: icts\n",
      "text to token id: 3405\n",
      "token id to text:  repor\n",
      "text to token id: 3406\n",
      "token id to text:  reports\n",
      "text to token id: 3407\n",
      "token id to text: acing\n",
      "text to token id: 3408\n",
      "token id to text:  tons\n",
      "text to token id: 3409\n",
      "token id to text: leet\n",
      "text to token id: 3410\n",
      "token id to text:  sailed\n",
      "text to token id: 3411\n",
      "token id to text:  seas\n",
      "text to token id: 3412\n",
      "token id to text:  Domest\n",
      "text to token id: 3413\n",
      "token id to text:  domestic\n",
      "text to token id: 3414\n",
      "token id to text:  Over\n",
      "text to token id: 3415\n",
      "token id to text:  current\n",
      "text to token id: 3416\n",
      "token id to text:  eit\n",
      "text to token id: 3417\n",
      "token id to text:  either\n",
      "text to token id: 3418\n",
      "token id to text: lar\n",
      "text to token id: 3419\n",
      "token id to text: ged\n",
      "text to token id: 3420\n",
      "token id to text: hib\n",
      "text to token id: 3421\n",
      "token id to text:  ban\n",
      "text to token id: 3422\n",
      "token id to text: iscover\n",
      "text to token id: 3423\n",
      "token id to text:  repe\n",
      "text to token id: 3424\n",
      "token id to text:  repeated\n",
      "text to token id: 3425\n",
      "token id to text:  repeatedly\n",
      "text to token id: 3426\n",
      "token id to text: 152\n",
      "text to token id: 3427\n",
      "token id to text:  wok\n",
      "text to token id: 3428\n",
      "token id to text:  wokou\n",
      "text to token id: 3429\n",
      "token id to text: line\n",
      "text to token id: 3430\n",
      "token id to text:  Jiajing\n",
      "text to token id: 3431\n",
      "token id to text:  raids\n",
      "text to token id: 3432\n",
      "token id to text:  Phil\n",
      "text to token id: 3433\n",
      "token id to text:  Philip\n",
      "text to token id: 3434\n",
      "token id to text:  Philipp\n",
      "text to token id: 3435\n",
      "token id to text:  Philippines\n",
      "text to token id: 3436\n",
      "token id to text: 155\n",
      "text to token id: 3437\n",
      "token id to text:  imported\n",
      "text to token id: 3438\n",
      "token id to text: ican\n",
      "text to token id: 3439\n",
      "token id to text:  Amer\n",
      "text to token id: 3440\n",
      "token id to text:  resistance\n",
      "text to token id: 3441\n",
      "token id to text:  island\n",
      "text to token id: 3442\n",
      "token id to text:  islands\n",
      "text to token id: 3443\n",
      "token id to text: 162\n",
      "text to token id: 3444\n",
      "token id to text: 163\n",
      "text to token id: 3445\n",
      "token id to text:  surrendered\n",
      "text to token id: 3446\n",
      "token id to text:  loyalist\n",
      "text to token id: 3447\n",
      "token id to text:  Kox\n",
      "text to token id: 3448\n",
      "token id to text:  Koxing\n",
      "text to token id: 3449\n",
      "token id to text:  Koxinga\n",
      "text to token id: 3450\n",
      "token id to text:  earth\n",
      "text to token id: 3451\n",
      "token id to text:  earthqu\n",
      "text to token id: 3452\n",
      "token id to text:  earthquake\n",
      "text to token id: 3453\n",
      "token id to text:  dead\n",
      "text to token id: 3454\n",
      "token id to text: 159\n",
      "text to token id: 3455\n",
      "token id to text:  toll\n",
      "text to token id: 3456\n",
      "token id to text:  Nur\n",
      "text to token id: 3457\n",
      "token id to text:  Nurh\n",
      "text to token id: 3458\n",
      "token id to text:  Nurhac\n",
      "text to token id: 3459\n",
      "token id to text:  Nurhaci\n",
      "text to token id: 3460\n",
      "token id to text:  subd\n",
      "text to token id: 3461\n",
      "token id to text:  subdue\n",
      "text to token id: 3462\n",
      "token id to text: zhen\n",
      "text to token id: 3463\n",
      "token id to text:  proce\n",
      "text to token id: 3464\n",
      "token id to text:  proceeded\n",
      "text to token id: 3465\n",
      "token id to text:  transition\n",
      "text to token id: 3466\n",
      "token id to text:  leaders\n",
      "text to token id: 3467\n",
      "token id to text:  appeared\n",
      "text to token id: 3468\n",
      "token id to text:  que\n",
      "text to token id: 3469\n",
      "token id to text:  queue\n",
      "text to token id: 3470\n",
      "token id to text:  wear\n",
      "text to token id: 3471\n",
      "token id to text:  clothing\n",
      "text to token id: 3472\n",
      "token id to text: nermen\n",
      "text to token id: 3473\n",
      "token id to text:  given\n",
      "text to token id: 3474\n",
      "token id to text:  ordered\n",
      "text to token id: 3475\n",
      "token id to text:  creation\n",
      "text to token id: 3476\n",
      "token id to text: iction\n",
      "text to token id: 3477\n",
      "token id to text: ictionary\n",
      "text to token id: 3478\n",
      "token id to text: 168\n",
      "text to token id: 3479\n",
      "token id to text:  suppressed\n",
      "text to token id: 3480\n",
      "token id to text:  Revol\n",
      "text to token id: 3481\n",
      "token id to text:  Revolt\n",
      "text to token id: 3482\n",
      "token id to text:  den\n",
      "text to token id: 3483\n",
      "token id to text:  denied\n",
      "text to token id: 3484\n",
      "token id to text:  Kingdom\n",
      "text to token id: 3485\n",
      "token id to text:  Rus\n",
      "text to token id: 3486\n",
      "token id to text:  Russ\n",
      "text to token id: 3487\n",
      "token id to text:  First\n",
      "text to token id: 3488\n",
      "token id to text:  Nanking\n",
      "text to token id: 3489\n",
      "token id to text:  Taiping\n",
      "text to token id: 3490\n",
      "token id to text:  movement\n",
      "text to token id: 3491\n",
      "token id to text:  Guofan\n",
      "text to token id: 3492\n",
      "token id to text:  effective\n",
      "text to token id: 3493\n",
      "token id to text: stitutional\n",
      "text to token id: 3494\n",
      "token id to text:  Shik\n",
      "text to token id: 3495\n",
      "token id to text:  Shikai\n",
      "text to token id: 3496\n",
      "token id to text: ays\n",
      "text to token id: 3497\n",
      "token id to text:  Dow\n",
      "text to token id: 3498\n",
      "token id to text:  Dowag\n",
      "text to token id: 3499\n",
      "token id to text:  Dowager\n",
      "text to token id: 3500\n",
      "token id to text:  fear\n",
      "text to token id: 3501\n",
      "token id to text:  quick\n",
      "text to token id: 3502\n",
      "token id to text:  quickly\n",
      "text to token id: 3503\n",
      "token id to text:  opposed\n",
      "text to token id: 3504\n",
      "token id to text:  Christians\n",
      "text to token id: 3505\n",
      "token id to text:  Boxers\n",
      "text to token id: 3506\n",
      "token id to text:  Ger\n",
      "text to token id: 3507\n",
      "token id to text:  German\n",
      "text to token id: 3508\n",
      "token id to text:  rou\n",
      "text to token id: 3509\n",
      "token id to text:  routed\n",
      "text to token id: 3510\n",
      "token id to text:  exact\n",
      "text to token id: 3511\n",
      "token id to text: emn\n",
      "text to token id: 3512\n",
      "token id to text:  instituted\n",
      "text to token id: 3513\n",
      "token id to text:  abol\n",
      "text to token id: 3514\n",
      "token id to text:  student\n",
      "text to token id: 3515\n",
      "token id to text:  students\n",
      "text to token id: 3516\n",
      "token id to text:  republic\n",
      "text to token id: 3517\n",
      "token id to text:  revolution\n",
      "text to token id: 3518\n",
      "token id to text:  revolutionary\n",
      "text to token id: 3519\n",
      "token id to text:  Wuchang\n",
      "text to token id: 3520\n",
      "token id to text:  Oct\n",
      "text to token id: 3521\n",
      "token id to text:  Octob\n",
      "text to token id: 3522\n",
      "token id to text:  October\n",
      "text to token id: 3523\n",
      "token id to text:  Wuhan\n",
      "text to token id: 3524\n",
      "token id to text: since\n",
      "text to token id: 3525\n",
      "token id to text:  Pres\n",
      "text to token id: 3526\n",
      "token id to text:  President\n",
      "text to token id: 3527\n",
      "token id to text:  turned\n",
      "text to token id: 3528\n",
      "token id to text:  provin\n",
      "text to token id: 3529\n",
      "token id to text:  provincial\n",
      "text to token id: 3530\n",
      "token id to text:  violent\n",
      "text to token id: 3531\n",
      "token id to text:  causes\n",
      "text to token id: 3532\n",
      "token id to text: ees\n",
      "text to token id: 3533\n",
      "token id to text:  compet\n",
      "text to token id: 3534\n",
      "token id to text:  competing\n",
      "text to token id: 3535\n",
      "token id to text:  Intellect\n",
      "text to token id: 3536\n",
      "token id to text:  Intellectuals\n",
      "text to token id: 3537\n",
      "token id to text:  terms\n",
      "text to token id: 3538\n",
      "token id to text: wide\n",
      "text to token id: 3539\n",
      "token id to text:  protests\n",
      "text to token id: 3540\n",
      "token id to text:  ref\n",
      "text to token id: 3541\n",
      "token id to text:  refus\n",
      "text to token id: 3542\n",
      "token id to text:  mist\n",
      "text to token id: 3543\n",
      "token id to text:  Acc\n",
      "text to token id: 3544\n",
      "token id to text:  According\n",
      "text to token id: 3545\n",
      "token id to text:  patr\n",
      "text to token id: 3546\n",
      "token id to text:  patri\n",
      "text to token id: 3547\n",
      "token id to text:  go\n",
      "text to token id: 3548\n",
      "token id to text: com\n",
      "text to token id: 3549\n",
      "token id to text: ling\n",
      "text to token id: 3550\n",
      "token id to text: CCP\n",
      "text to token id: 3551\n",
      "token id to text: é\n",
      "text to token id: 3552\n",
      "token id to text: -y\n",
      "text to token id: 3553\n",
      "token id to text: -year\n",
      "text to token id: 3554\n",
      "token id to text:  II\n",
      "text to token id: 3555\n",
      "token id to text:  ten\n",
      "text to token id: 3556\n",
      "token id to text: oot\n",
      "text to token id: 3557\n",
      "token id to text:  Dec\n",
      "text to token id: 3558\n",
      "token id to text:  struggle\n",
      "text to token id: 3559\n",
      "token id to text: Following\n",
      "text to token id: 3560\n",
      "token id to text:  attemp\n",
      "text to token id: 3561\n",
      "token id to text:  West\n",
      "text to token id: 3562\n",
      "token id to text:  carried\n",
      "text to token id: 3563\n",
      "token id to text:  recognised\n",
      "text to token id: 3564\n",
      "token id to text:  legitimate\n",
      "text to token id: 3565\n",
      "token id to text:  communist\n",
      "text to token id: 3566\n",
      "token id to text: tr\n",
      "text to token id: 3567\n",
      "token id to text:  diss\n",
      "text to token id: 3568\n",
      "token id to text:  crac\n",
      "text to token id: 3569\n",
      "token id to text:  crackdown\n",
      "text to token id: 3570\n",
      "token id to text:  democratic\n",
      "text to token id: 3571\n",
      "token id to text:  elected\n",
      "text to token id: 3572\n",
      "token id to text:  election\n",
      "text to token id: 3573\n",
      "token id to text:  See\n",
      "text to token id: 3574\n",
      "token id to text:  pul\n",
      "text to token id: 3575\n",
      "token id to text:  resulted\n",
      "text to token id: 3576\n",
      "token id to text:  mot\n",
      "text to token id: 3577\n",
      "token id to text:  motivated\n",
      "text to token id: 3578\n",
      "token id to text: -Soviet\n",
      "text to token id: 3579\n",
      "token id to text:  distribution\n",
      "text to token id: 3580\n",
      "token id to text:  cond\n",
      "text to token id: 3581\n",
      "token id to text:  enter\n",
      "text to token id: 3582\n",
      "token id to text: anmen\n",
      "text to token id: 3583\n",
      "token id to text: quare\n",
      "text to token id: 3584\n",
      "token id to text:  Jiang\n",
      "text to token id: 3585\n",
      "token id to text: mier\n",
      "text to token id: 3586\n",
      "token id to text:  rural\n",
      "text to token id: 3587\n",
      "token id to text:  detained\n",
      "text to token id: 3588\n",
      "token id to text:  camps\n",
      "text to token id: 3589\n",
      "token id to text:  detain\n",
      "text to token id: 3590\n",
      "token id to text: ys\n",
      "text to token id: 3591\n",
      "token id to text:  abuse\n",
      "text to token id: 3592\n",
      "token id to text: emic\n",
      "text to token id: 3593\n",
      "token id to text:  detention\n",
      "text to token id: 3594\n",
      "token id to text:  Refer\n",
      "text to token id: 3595\n",
      "token id to text:  spans\n",
      "text to token id: 3596\n",
      "token id to text:  experi\n",
      "text to token id: 3597\n",
      "token id to text:  experien\n",
      "text to token id: 3598\n",
      "token id to text:  experienced\n",
      "text to token id: 3599\n",
      "token id to text:  fracture\n",
      "text to token id: 3600\n",
      "token id to text:  basin\n",
      "text to token id: 3601\n",
      "token id to text:  constitutes\n",
      "text to token id: 3602\n",
      "token id to text:  geographic\n",
      "text to token id: 3603\n",
      "token id to text:  maint\n",
      "text to token id: 3604\n",
      "token id to text:  maintains\n",
      "text to token id: 3605\n",
      "token id to text:  rich\n",
      "text to token id: 3606\n",
      "token id to text:  divers\n",
      "text to token id: 3607\n",
      "token id to text:  diversity\n",
      "text to token id: 3608\n",
      "token id to text:  lingu\n",
      "text to token id: 3609\n",
      "token id to text:  linguistic\n",
      "text to token id: 3610\n",
      "token id to text:  viewing\n",
      "text to token id: 3611\n",
      "token id to text:  cy\n",
      "text to token id: 3612\n",
      "token id to text:  cyc\n",
      "text to token id: 3613\n",
      "token id to text:  cycle\n",
      "text to token id: 3614\n",
      "token id to text:  ascribed\n",
      "text to token id: 3615\n",
      "token id to text:  tend\n",
      "text to token id: 3616\n",
      "token id to text:  tends\n",
      "text to token id: 3617\n",
      "token id to text:  assume\n",
      "text to token id: 3618\n",
      "token id to text:  traced\n",
      "text to token id: 3619\n",
      "token id to text:  unb\n",
      "text to token id: 3620\n",
      "token id to text:  unbro\n",
      "text to token id: 3621\n",
      "token id to text:  unbrok\n",
      "text to token id: 3622\n",
      "token id to text:  unbroken\n",
      "text to token id: 3623\n",
      "token id to text:  thread\n",
      "text to token id: 3624\n",
      "token id to text:  thous\n",
      "text to token id: 3625\n",
      "token id to text:  thousands\n",
      "text to token id: 3626\n",
      "token id to text:  past\n",
      "text to token id: 3627\n",
      "token id to text:  making\n",
      "text to token id: 3628\n",
      "token id to text:  crad\n",
      "text to token id: 3629\n",
      "token id to text:  cradles\n",
      "text to token id: 3630\n",
      "token id to text:  representative\n",
      "text to token id: 3631\n",
      "token id to text:  stretch\n",
      "text to token id: 3632\n",
      "token id to text:  stretching\n",
      "text to token id: 3633\n",
      "token id to text:  Himal\n",
      "text to token id: 3634\n",
      "token id to text:  Himalay\n",
      "text to token id: 3635\n",
      "token id to text:  Himalayas\n",
      "text to token id: 3636\n",
      "token id to text:  Sayan\n",
      "text to token id: 3637\n",
      "token id to text:  Mountains\n",
      "text to token id: 3638\n",
      "token id to text:  polit\n",
      "text to token id: 3639\n",
      "token id to text:  politics\n",
      "text to token id: 3640\n",
      "token id to text:  emerge\n",
      "text to token id: 3641\n",
      "token id to text:  rivers\n",
      "text to token id: 3642\n",
      "token id to text:  plains\n",
      "text to token id: 3643\n",
      "token id to text: rd\n",
      "text to token id: 3644\n",
      "token id to text:  consist\n",
      "text to token id: 3645\n",
      "token id to text:  consisting\n",
      "text to token id: 3646\n",
      "token id to text:  divinations\n",
      "text to token id: 3647\n",
      "token id to text:  inscribed\n",
      "text to token id: 3648\n",
      "token id to text:  ritual\n",
      "text to token id: 3649\n",
      "token id to text:  ded\n",
      "text to token id: 3650\n",
      "token id to text:  dedicated\n",
      "text to token id: 3651\n",
      "token id to text:  corp\n",
      "text to token id: 3652\n",
      "token id to text:  corpus\n",
      "text to token id: 3653\n",
      "token id to text:  strat\n",
      "text to token id: 3654\n",
      "token id to text:  strata\n",
      "text to token id: 3655\n",
      "token id to text:  speec\n",
      "text to token id: 3656\n",
      "token id to text:  speeches\n",
      "text to token id: 3657\n",
      "token id to text:  loci\n",
      "text to token id: 3658\n",
      "token id to text:  display\n",
      "text to token id: 3659\n",
      "token id to text: -mature\n",
      "text to token id: 3660\n",
      "token id to text:  rememb\n",
      "text to token id: 3661\n",
      "token id to text:  remembered\n",
      "text to token id: 3662\n",
      "token id to text:  Ax\n",
      "text to token id: 3663\n",
      "token id to text:  Axial\n",
      "text to token id: 3664\n",
      "token id to text:  foundations\n",
      "text to token id: 3665\n",
      "token id to text:  philosophies\n",
      "text to token id: 3666\n",
      "token id to text:  Orth\n",
      "text to token id: 3667\n",
      "token id to text:  Orthography\n",
      "text to token id: 3668\n",
      "token id to text:  Short\n",
      "text to token id: 3669\n",
      "token id to text:  Shortly\n",
      "text to token id: 3670\n",
      "token id to text:  therea\n",
      "text to token id: 3671\n",
      "token id to text:  thereafter\n",
      "text to token id: 3672\n",
      "token id to text:  crit\n",
      "text to token id: 3673\n",
      "token id to text:  critical\n",
      "text to token id: 3674\n",
      "token id to text:  farthe\n",
      "text to token id: 3675\n",
      "token id to text:  farthest\n",
      "text to token id: 3676\n",
      "token id to text:  extents\n",
      "text to token id: 3677\n",
      "token id to text:  sanc\n",
      "text to token id: 3678\n",
      "token id to text:  sanction\n",
      "text to token id: 3679\n",
      "token id to text:  sanctioned\n",
      "text to token id: 3680\n",
      "token id to text:  edited\n",
      "text to token id: 3681\n",
      "token id to text:  forms\n",
      "text to token id: 3682\n",
      "token id to text:  wield\n",
      "text to token id: 3683\n",
      "token id to text:  aided\n",
      "text to token id: 3684\n",
      "token id to text:  proliferation\n",
      "text to token id: 3685\n",
      "token id to text:  doc\n",
      "text to token id: 3686\n",
      "token id to text:  docu\n",
      "text to token id: 3687\n",
      "token id to text:  documents\n",
      "text to token id: 3688\n",
      "token id to text:  empl\n",
      "text to token id: 3689\n",
      "token id to text:  employed\n",
      "text to token id: 3690\n",
      "token id to text:  afterwards\n",
      "text to token id: 3691\n",
      "token id to text:  internation\n",
      "text to token id: 3692\n",
      "token id to text:  internationally\n",
      "text to token id: 3693\n",
      "token id to text:  seric\n",
      "text to token id: 3694\n",
      "token id to text:  sericulture\n",
      "text to token id: 3695\n",
      "token id to text:  collapsed\n",
      "text to token id: 3696\n",
      "token id to text:  equally\n",
      "text to token id: 3697\n",
      "token id to text:  impact\n",
      "text to token id: 3698\n",
      "token id to text:  calligraphy\n",
      "text to token id: 3699\n",
      "token id to text:  story\n",
      "text to token id: 3700\n",
      "token id to text:  storyt\n",
      "text to token id: 3701\n",
      "token id to text:  storytell\n",
      "text to token id: 3702\n",
      "token id to text:  storytelling\n",
      "text to token id: 3703\n",
      "token id to text:  cases\n",
      "text to token id: 3704\n",
      "token id to text: 608\n",
      "text to token id: 3705\n",
      "token id to text:  flourishing\n",
      "text to token id: 3706\n",
      "token id to text:  economics\n",
      "text to token id: 3707\n",
      "token id to text: Tang\n",
      "text to token id: 3708\n",
      "token id to text:  demony\n",
      "text to token id: 3709\n",
      "token id to text:  demonym\n",
      "text to token id: 3710\n",
      "token id to text:  fractur\n",
      "text to token id: 3711\n",
      "token id to text:  fractured\n",
      "text to token id: 3712\n",
      "token id to text:  max\n",
      "text to token id: 3713\n",
      "token id to text:  maximal\n",
      "text to token id: 3714\n",
      "token id to text:  Mechanical\n",
      "text to token id: 3715\n",
      "token id to text:  witness\n",
      "text to token id: 3716\n",
      "token id to text:  witnesses\n",
      "text to token id: 3717\n",
      "token id to text: -block\n",
      "text to token id: 3718\n",
      "token id to text:  prints\n",
      "text to token id: 3719\n",
      "token id to text:  ideological\n",
      "text to token id: 3720\n",
      "token id to text:  knit\n",
      "text to token id: 3721\n",
      "token id to text: Eventually\n",
      "text to token id: 3722\n",
      "token id to text:  establishing\n",
      "text to token id: 3723\n",
      "token id to text:  Contact\n",
      "text to token id: 3724\n",
      "token id to text:  Achievements\n",
      "text to token id: 3725\n",
      "token id to text:  exploration\n",
      "text to token id: 3726\n",
      "token id to text:  fine\n",
      "text to token id: 3727\n",
      "token id to text:  restoring\n",
      "text to token id: 3728\n",
      "token id to text:  Class\n",
      "text to token id: 3729\n",
      "token id to text:  Classic\n",
      "text to token id: 3730\n",
      "token id to text: 173\n",
      "text to token id: 3731\n",
      "token id to text:  commission\n",
      "text to token id: 3732\n",
      "token id to text:  commissioned\n",
      "text to token id: 3733\n",
      "token id to text:  encyclopa\n",
      "text to token id: 3734\n",
      "token id to text:  encyclopaedia\n",
      "text to token id: 3735\n",
      "token id to text:  libr\n",
      "text to token id: 3736\n",
      "token id to text:  libraries\n",
      "text to token id: 3737\n",
      "token id to text:  totaling\n",
      "text to token id: 3738\n",
      "token id to text:  bill\n",
      "text to token id: 3739\n",
      "token id to text:  billion\n",
      "text to token id: 3740\n",
      "token id to text:  word\n",
      "text to token id: 3741\n",
      "token id to text:  words\n",
      "text to token id: 3742\n",
      "token id to text:  conflict\n",
      "text to token id: 3743\n",
      "token id to text:  culminating\n",
      "text to token id: 3744\n",
      "token id to text:  Xinhai\n",
      "text to token id: 3745\n",
      "token id to text:  costly\n",
      "text to token id: 3746\n",
      "token id to text:  roiled\n",
      "text to token id: 3747\n",
      "token id to text:  Republican\n",
      "text to token id: 3748\n",
      "token id to text: -al\n",
      "text to token id: 3749\n",
      "token id to text: -aligned\n",
      "text to token id: 3750\n",
      "token id to text:  industrialized\n",
      "text to token id: 3751\n",
      "token id to text: PRC\n",
      "text to token id: 3752\n",
      "token id to text:  retreating\n",
      "text to token id: 3753\n",
      "token id to text:  Both\n",
      "text to token id: 3754\n",
      "token id to text:  governments\n",
      "text to token id: 3755\n",
      "token id to text:  legitimacy\n",
      "text to token id: 3756\n",
      "token id to text:  accum\n",
      "text to token id: 3757\n",
      "token id to text:  accumulated\n",
      "text to token id: 3758\n",
      "token id to text:  recognition\n",
      "text to token id: 3759\n",
      "token id to text:  disputed\n",
      "text to token id: 3760\n",
      "token id to text:  day\n",
      "text to token id: 3761\n",
      "token id to text:  fast\n",
      "text to token id: 3762\n",
      "token id to text:  fastest\n",
      "text to token id: 3763\n",
      "token id to text: -gr\n",
      "text to token id: 3764\n",
      "token id to text: -grow\n",
      "text to token id: 3765\n",
      "token id to text: -growing\n",
      "text to token id: 3766\n",
      "token id to text:  unific\n",
      "text to token id: 3767\n",
      "token id to text:  unification\n",
      "text to token id: 3768\n",
      "token id to text:  surp\n",
      "text to token id: 3769\n",
      "token id to text:  surpassed\n",
      "text to token id: 3770\n",
      "token id to text:  Preh\n",
      "text to token id: 3771\n",
      "token id to text:  Prehistory\n",
      "text to token id: 3772\n",
      "token id to text:  ka\n",
      "text to token id: 3773\n",
      "token id to text:  archaic\n",
      "text to token id: 3774\n",
      "token id to text:  species\n",
      "text to token id: 3775\n",
      "token id to text:  Euras\n",
      "text to token id: 3776\n",
      "token id to text:  Eurasia\n",
      "text to token id: 3777\n",
      "token id to text:  sometime\n",
      "text to token id: 3778\n",
      "token id to text: Ma\n",
      "text to token id: 3779\n",
      "token id to text:  subsp\n",
      "text to token id: 3780\n",
      "token id to text:  subspec\n",
      "text to token id: 3781\n",
      "token id to text:  subspecies\n",
      "text to token id: 3782\n",
      "token id to text:  old\n",
      "text to token id: 3783\n",
      "token id to text:  oldest\n",
      "text to token id: 3784\n",
      "token id to text:  southwestern\n",
      "text to token id: 3785\n",
      "token id to text:  Yuanm\n",
      "text to token id: 3786\n",
      "token id to text:  Yuanmou\n",
      "text to token id: 3787\n",
      "token id to text: �\n",
      "text to token id: 3788\n",
      "token id to text: 元\n",
      "text to token id: 3789\n",
      "token id to text: 元�\n",
      "text to token id: 3790\n",
      "token id to text: 元�\n",
      "text to token id: 3791\n",
      "token id to text: 元谋\n",
      "text to token id: 3792\n",
      "token id to text: 元谋人\n",
      "text to token id: 3793\n",
      "token id to text:  Yun\n",
      "text to token id: 3794\n",
      "token id to text:  Yunn\n",
      "text to token id: 3795\n",
      "token id to text:  Yunnan\n",
      "text to token id: 3796\n",
      "token id to text:  bus\n",
      "text to token id: 3797\n",
      "token id to text:  bush\n",
      "text to token id: 3798\n",
      "token id to text:  bushland\n",
      "text to token id: 3799\n",
      "token id to text: -fore\n",
      "text to token id: 3800\n",
      "token id to text: -forest\n",
      "text to token id: 3801\n",
      "token id to text:  chal\n",
      "text to token id: 3802\n",
      "token id to text:  chalic\n",
      "text to token id: 3803\n",
      "token id to text:  chalico\n",
      "text to token id: 3804\n",
      "token id to text:  chalicothe\n",
      "text to token id: 3805\n",
      "token id to text:  chalicotheres\n",
      "text to token id: 3806\n",
      "token id to text:  deer\n",
      "text to token id: 3807\n",
      "token id to text:  elep\n",
      "text to token id: 3808\n",
      "token id to text:  eleph\n",
      "text to token id: 3809\n",
      "token id to text:  elephant\n",
      "text to token id: 3810\n",
      "token id to text:  rhin\n",
      "text to token id: 3811\n",
      "token id to text:  rhinos\n",
      "text to token id: 3812\n",
      "token id to text:  pigs\n",
      "text to token id: 3813\n",
      "token id to text: -faced\n",
      "text to token id: 3814\n",
      "token id to text: -known\n",
      "text to token id: 3815\n",
      "token id to text:  Peking\n",
      "text to token id: 3816\n",
      "token id to text: �\n",
      "text to token id: 3817\n",
      "token id to text: 北\n",
      "text to token id: 3818\n",
      "token id to text: 北�\n",
      "text to token id: 3819\n",
      "token id to text: 北京\n",
      "text to token id: 3820\n",
      "token id to text: 北京�\n",
      "text to token id: 3821\n",
      "token id to text: 北京�\n",
      "text to token id: 3822\n",
      "token id to text: 北京猿\n",
      "text to token id: 3823\n",
      "token id to text: 北京猿人\n",
      "text to token id: 3824\n",
      "token id to text: 400\n",
      "text to token id: 3825\n",
      "token id to text:  Zhouk\n",
      "text to token id: 3826\n",
      "token id to text:  Zhoukou\n",
      "text to token id: 3827\n",
      "token id to text:  Zhoukoud\n",
      "text to token id: 3828\n",
      "token id to text:  Zhoukoudian\n",
      "text to token id: 3829\n",
      "token id to text:  cave\n",
      "text to token id: 3830\n",
      "token id to text:  scr\n",
      "text to token id: 3831\n",
      "token id to text:  scrap\n",
      "text to token id: 3832\n",
      "token id to text:  scrapers\n",
      "text to token id: 3833\n",
      "token id to text:  chop\n",
      "text to token id: 3834\n",
      "token id to text:  chopp\n",
      "text to token id: 3835\n",
      "token id to text:  choppers\n",
      "text to token id: 3836\n",
      "token id to text:  slight\n",
      "text to token id: 3837\n",
      "token id to text:  slightly\n",
      "text to token id: 3838\n",
      "token id to text:  points\n",
      "text to token id: 3839\n",
      "token id to text:  burins\n",
      "text to token id: 3840\n",
      "token id to text:  aw\n",
      "text to token id: 3841\n",
      "token id to text:  awls\n",
      "text to token id: 3842\n",
      "token id to text:  fossils\n",
      "text to token id: 3843\n",
      "token id to text:  northwestern\n",
      "text to token id: 3844\n",
      "token id to text:  Lant\n",
      "text to token id: 3845\n",
      "token id to text:  Lantian\n",
      "text to token id: 3846\n",
      "token id to text:  specim\n",
      "text to token id: 3847\n",
      "token id to text:  specimens\n",
      "text to token id: 3848\n",
      "token id to text:  magn\n",
      "text to token id: 3849\n",
      "token id to text:  magnet\n",
      "text to token id: 3850\n",
      "token id to text:  magneto\n",
      "text to token id: 3851\n",
      "token id to text:  magnetostr\n",
      "text to token id: 3852\n",
      "token id to text:  magnetostrat\n",
      "text to token id: 3853\n",
      "token id to text:  magnetostratigraphy\n",
      "text to token id: 3854\n",
      "token id to text:  Majuang\n",
      "text to token id: 3855\n",
      "token id to text:  Majuangou\n",
      "text to token id: 3856\n",
      "token id to text:  Lan\n",
      "text to token id: 3857\n",
      "token id to text:  Lanpo\n",
      "text to token id: 3858\n",
      "token id to text:  Xiao\n",
      "text to token id: 3859\n",
      "token id to text:  Xiaochang\n",
      "text to token id: 3860\n",
      "token id to text:  Xiaochangli\n",
      "text to token id: 3861\n",
      "token id to text:  Xiaochangliang\n",
      "text to token id: 3862\n",
      "token id to text:  Xiant\n",
      "text to token id: 3863\n",
      "token id to text:  Xiantai\n",
      "text to token id: 3864\n",
      "token id to text:  Bans\n",
      "text to token id: 3865\n",
      "token id to text:  Banshan\n",
      "text to token id: 3866\n",
      "token id to text: 32\n",
      "text to token id: 3867\n",
      "token id to text:  Feil\n",
      "text to token id: 3868\n",
      "token id to text:  Feiliang\n",
      "text to token id: 3869\n",
      "token id to text:  Dong\n",
      "text to token id: 3870\n",
      "token id to text:  Dongg\n",
      "text to token id: 3871\n",
      "token id to text:  Donggut\n",
      "text to token id: 3872\n",
      "token id to text:  Donggutuo\n",
      "text to token id: 3873\n",
      "token id to text:  Xih\n",
      "text to token id: 3874\n",
      "token id to text:  Xihou\n",
      "text to token id: 3875\n",
      "token id to text:  Xihoudu\n",
      "text to token id: 3876\n",
      "token id to text:  Shanxi\n",
      "text to token id: 3877\n",
      "token id to text:  cir\n",
      "text to token id: 3878\n",
      "token id to text:  circ\n",
      "text to token id: 3879\n",
      "token id to text:  circum\n",
      "text to token id: 3880\n",
      "token id to text:  circumst\n",
      "text to token id: 3881\n",
      "token id to text:  circumstan\n",
      "text to token id: 3882\n",
      "token id to text:  circumstances\n",
      "text to token id: 3883\n",
      "token id to text:  evolution\n",
      "text to token id: 3884\n",
      "token id to text:  sap\n",
      "text to token id: 3885\n",
      "token id to text:  sapi\n",
      "text to token id: 3886\n",
      "token id to text:  sapiens\n",
      "text to token id: 3887\n",
      "token id to text: Out\n",
      "text to token id: 3888\n",
      "token id to text:  theory\n",
      "text to token id: 3889\n",
      "token id to text: OOA\n",
      "text to token id: 3890\n",
      "token id to text:  continuity\n",
      "text to token id: 3891\n",
      "token id to text:  mod\n",
      "text to token id: 3892\n",
      "token id to text:  model\n",
      "text to token id: 3893\n",
      "token id to text:  admix\n",
      "text to token id: 3894\n",
      "token id to text:  admixture\n",
      "text to token id: 3895\n",
      "token id to text:  variant\n",
      "text to token id: 3896\n",
      "token id to text:  OOA\n",
      "text to token id: 3897\n",
      "token id to text:  Reg\n",
      "text to token id: 3898\n",
      "token id to text:  Regard\n",
      "text to token id: 3899\n",
      "token id to text:  Regardless\n",
      "text to token id: 3900\n",
      "token id to text:  fossilized\n",
      "text to token id: 3901\n",
      "token id to text:  te\n",
      "text to token id: 3902\n",
      "token id to text:  teet\n",
      "text to token id: 3903\n",
      "token id to text:  teeth\n",
      "text to token id: 3904\n",
      "token id to text:  Fuy\n",
      "text to token id: 3905\n",
      "token id to text:  Fuyan\n",
      "text to token id: 3906\n",
      "token id to text:  Dao\n",
      "text to token id: 3907\n",
      "token id to text:  Count\n",
      "text to token id: 3908\n",
      "token id to text:  County\n",
      "text to token id: 3909\n",
      "token id to text:  Hun\n",
      "text to token id: 3910\n",
      "token id to text:  Hunan\n",
      "text to token id: 3911\n",
      "token id to text:  extinct\n",
      "text to token id: 3912\n",
      "token id to text:  Ail\n",
      "text to token id: 3913\n",
      "token id to text:  Ailur\n",
      "text to token id: 3914\n",
      "token id to text:  Ailurop\n",
      "text to token id: 3915\n",
      "token id to text:  Ailuropod\n",
      "text to token id: 3916\n",
      "token id to text:  Ailuropoda\n",
      "text to token id: 3917\n",
      "token id to text:  bac\n",
      "text to token id: 3918\n",
      "token id to text:  bacon\n",
      "text to token id: 3919\n",
      "token id to text:  baconi\n",
      "text to token id: 3920\n",
      "token id to text:  panda\n",
      "text to token id: 3921\n",
      "token id to text:  Croc\n",
      "text to token id: 3922\n",
      "token id to text:  Crocut\n",
      "text to token id: 3923\n",
      "token id to text:  Crocuta\n",
      "text to token id: 3924\n",
      "token id to text:  ultima\n",
      "text to token id: 3925\n",
      "token id to text:  tap\n",
      "text to token id: 3926\n",
      "token id to text:  tapir\n",
      "text to token id: 3927\n",
      "token id to text:  Middle\n",
      "text to token id: 3928\n",
      "token id to text:  Pala\n",
      "text to token id: 3929\n",
      "token id to text:  Palaeolithic\n",
      "text to token id: 3930\n",
      "token id to text:  Lev\n",
      "text to token id: 3931\n",
      "token id to text:  Levall\n",
      "text to token id: 3932\n",
      "token id to text:  Levallo\n",
      "text to token id: 3933\n",
      "token id to text:  Levallois\n",
      "text to token id: 3934\n",
      "token id to text:  lithic\n",
      "text to token id: 3935\n",
      "token id to text:  assemblage\n",
      "text to token id: 3936\n",
      "token id to text:  Guan\n",
      "text to token id: 3937\n",
      "token id to text:  Guany\n",
      "text to token id: 3938\n",
      "token id to text:  Guanyind\n",
      "text to token id: 3939\n",
      "token id to text:  Guanyindong\n",
      "text to token id: 3940\n",
      "token id to text:  southwest\n",
      "text to token id: 3941\n",
      "token id to text: 170\n",
      "text to token id: 3942\n",
      "token id to text:  begun\n",
      "text to token id: 3943\n",
      "token id to text:  Bec\n",
      "text to token id: 3944\n",
      "token id to text:  Because\n",
      "text to token id: 3945\n",
      "token id to text:  convention\n",
      "text to token id: 3946\n",
      "token id to text:  conventionally\n",
      "text to token id: 3947\n",
      "token id to text:  defined\n",
      "text to token id: 3948\n",
      "token id to text:  presence\n",
      "text to token id: 3949\n",
      "token id to text:  follows\n",
      "text to token id: 3950\n",
      "token id to text:  Ag\n",
      "text to token id: 3951\n",
      "token id to text:  Agric\n",
      "text to token id: 3952\n",
      "token id to text:  Agriculture\n",
      "text to token id: 3953\n",
      "token id to text:  domestication\n",
      "text to token id: 3954\n",
      "token id to text:  expanding\n",
      "text to token id: 3955\n",
      "token id to text:  carb\n",
      "text to token id: 3956\n",
      "token id to text:  carbon\n",
      "text to token id: 3957\n",
      "token id to text:  millet\n",
      "text to token id: 3958\n",
      "token id to text:  radi\n",
      "text to token id: 3959\n",
      "token id to text:  radioc\n",
      "text to token id: 3960\n",
      "token id to text:  radiocarb\n",
      "text to token id: 3961\n",
      "token id to text:  radiocarbon\n",
      "text to token id: 3962\n",
      "token id to text:  vill\n",
      "text to token id: 3963\n",
      "token id to text:  villages\n",
      "text to token id: 3964\n",
      "token id to text: 172\n",
      "text to token id: 3965\n",
      "token id to text:  clif\n",
      "text to token id: 3966\n",
      "token id to text:  cliff\n",
      "text to token id: 3967\n",
      "token id to text:  carv\n",
      "text to token id: 3968\n",
      "token id to text:  carvings\n",
      "text to token id: 3969\n",
      "token id to text: feat\n",
      "text to token id: 3970\n",
      "token id to text: featuring\n",
      "text to token id: 3971\n",
      "token id to text: 45\n",
      "text to token id: 3972\n",
      "token id to text: 453\n",
      "text to token id: 3973\n",
      "token id to text:  individual\n",
      "text to token id: 3974\n",
      "token id to text:  sun\n",
      "text to token id: 3975\n",
      "token id to text:  moon\n",
      "text to token id: 3976\n",
      "token id to text:  stars\n",
      "text to token id: 3977\n",
      "token id to text:  scen\n",
      "text to token id: 3978\n",
      "token id to text:  scenes\n",
      "text to token id: 3979\n",
      "token id to text:  hun\n",
      "text to token id: 3980\n",
      "token id to text:  hunting\n",
      "text to token id: 3981\n",
      "token id to text:  graz\n",
      "text to token id: 3982\n",
      "token id to text:  grazing\n",
      "text to token id: 3983\n",
      "token id to text:  rese\n",
      "text to token id: 3984\n",
      "token id to text:  researc\n",
      "text to token id: 3985\n",
      "token id to text:  researcher\n",
      "text to token id: 3986\n",
      "token id to text:  Xiang\n",
      "text to token id: 3987\n",
      "token id to text:  Xiangshi\n",
      "text to token id: 3988\n",
      "token id to text:  Writ\n",
      "text to token id: 3989\n",
      "token id to text:  Written\n",
      "text to token id: 3990\n",
      "token id to text:  symb\n",
      "text to token id: 3991\n",
      "token id to text:  symbols\n",
      "text to token id: 3992\n",
      "token id to text:  proto\n",
      "text to token id: 3993\n",
      "token id to text: -writing\n",
      "text to token id: 3994\n",
      "token id to text:  Dadi\n",
      "text to token id: 3995\n",
      "token id to text:  Dadiwan\n",
      "text to token id: 3996\n",
      "token id to text: 540\n",
      "text to token id: 3997\n",
      "token id to text:  Banpo\n",
      "text to token id: 3998\n",
      "token id to text:  store\n",
      "text to token id: 3999\n",
      "token id to text:  redistribut\n",
      "text to token id: 4000\n",
      "token id to text:  redistribute\n",
      "text to token id: 4001\n",
      "token id to text:  specialist\n",
      "text to token id: 4002\n",
      "token id to text:  cra\n",
      "text to token id: 4003\n",
      "token id to text:  craf\n",
      "text to token id: 4004\n",
      "token id to text:  crafts\n",
      "text to token id: 4005\n",
      "token id to text:  craftsmen\n",
      "text to token id: 4006\n",
      "token id to text:  administrat\n",
      "text to token id: 4007\n",
      "token id to text:  administrators\n",
      "text to token id: 4008\n",
      "token id to text:  Taos\n",
      "text to token id: 4009\n",
      "token id to text:  Taosi\n",
      "text to token id: 4010\n",
      "token id to text:  Liangzh\n",
      "text to token id: 4011\n",
      "token id to text:  Liangzhu\n",
      "text to token id: 4012\n",
      "token id to text:  middle\n",
      "text to token id: 4013\n",
      "token id to text:  Yangsh\n",
      "text to token id: 4014\n",
      "token id to text:  Yangshao\n",
      "text to token id: 4015\n",
      "token id to text:  Longshan\n",
      "text to token id: 4016\n",
      "token id to text:  Pigs\n",
      "text to token id: 4017\n",
      "token id to text:  dogs\n",
      "text to token id: 4018\n",
      "token id to text: -domest\n",
      "text to token id: 4019\n",
      "token id to text: -domesticated\n",
      "text to token id: 4020\n",
      "token id to text:  sheep\n",
      "text to token id: 4021\n",
      "token id to text:  Whe\n",
      "text to token id: 4022\n",
      "token id to text:  Wheat\n",
      "text to token id: 4023\n",
      "token id to text:  Fru\n",
      "text to token id: 4024\n",
      "token id to text:  Fruit\n",
      "text to token id: 4025\n",
      "token id to text:  peac\n",
      "text to token id: 4026\n",
      "token id to text:  peaches\n",
      "text to token id: 4027\n",
      "token id to text:  cher\n",
      "text to token id: 4028\n",
      "token id to text:  cherries\n",
      "text to token id: 4029\n",
      "token id to text:  orang\n",
      "text to token id: 4030\n",
      "token id to text:  oranges\n",
      "text to token id: 4031\n",
      "token id to text:  chick\n",
      "text to token id: 4032\n",
      "token id to text:  chickens\n",
      "text to token id: 4033\n",
      "token id to text:  veg\n",
      "text to token id: 4034\n",
      "token id to text:  veget\n",
      "text to token id: 4035\n",
      "token id to text:  vegetabl\n",
      "text to token id: 4036\n",
      "token id to text:  vegetables\n",
      "text to token id: 4037\n",
      "token id to text: Bronze\n",
      "text to token id: 4038\n",
      "token id to text:  Majia\n",
      "text to token id: 4039\n",
      "token id to text:  Majiay\n",
      "text to token id: 4040\n",
      "token id to text:  Majiayao\n",
      "text to token id: 4041\n",
      "token id to text: 310\n",
      "text to token id: 4042\n",
      "token id to text: 27\n",
      "text to token id: 4043\n",
      "token id to text: 270\n",
      "text to token id: 4044\n",
      "token id to text:  represented\n",
      "text to token id: 4045\n",
      "token id to text:  Lower\n",
      "text to token id: 4046\n",
      "token id to text:  Xiaji\n",
      "text to token id: 4047\n",
      "token id to text:  Xiajiad\n",
      "text to token id: 4048\n",
      "token id to text:  Xiajiadian\n",
      "text to token id: 4049\n",
      "token id to text:  unknown\n",
      "text to token id: 4050\n",
      "token id to text: -dis\n",
      "text to token id: 4051\n",
      "token id to text: -discovered\n",
      "text to token id: 4052\n",
      "token id to text:  graves\n",
      "text to token id: 4053\n",
      "token id to text:  Mog\n",
      "text to token id: 4054\n",
      "token id to text:  Mogou\n",
      "text to token id: 4055\n",
      "token id to text:  reve\n",
      "text to token id: 4056\n",
      "token id to text:  reveal\n",
      "text to token id: 4057\n",
      "token id to text:  revealed\n",
      "text to token id: 4058\n",
      "token id to text:  violence\n",
      "text to token id: 4059\n",
      "token id to text:  Qijia\n",
      "text to token id: 4060\n",
      "token id to text: Ferr\n",
      "text to token id: 4061\n",
      "token id to text: Ferrous\n",
      "text to token id: 4062\n",
      "token id to text:  metall\n",
      "text to token id: 4063\n",
      "token id to text:  metallurg\n",
      "text to token id: 4064\n",
      "token id to text:  metallurgy\n",
      "text to token id: 4065\n",
      "token id to text:  begins\n",
      "text to token id: 4066\n",
      "token id to text:  hat\n",
      "text to token id: 4067\n",
      "token id to text:  hatc\n",
      "text to token id: 4068\n",
      "token id to text:  hatche\n",
      "text to token id: 4069\n",
      "token id to text:  hatchet\n",
      "text to token id: 4070\n",
      "token id to text:  blade\n",
      "text to token id: 4071\n",
      "token id to text:  mete\n",
      "text to token id: 4072\n",
      "token id to text:  meteor\n",
      "text to token id: 4073\n",
      "token id to text:  meteoric\n",
      "text to token id: 4074\n",
      "token id to text:  Ga\n",
      "text to token id: 4075\n",
      "token id to text:  Gaoc\n",
      "text to token id: 4076\n",
      "token id to text:  Gaocheng\n",
      "text to token id: 4077\n",
      "token id to text:  Shijia\n",
      "text to token id: 4078\n",
      "token id to text:  Shijiazhuang\n",
      "text to token id: 4079\n",
      "token id to text:  Hebei\n",
      "text to token id: 4080\n",
      "token id to text:  Iron\n",
      "text to token id: 4081\n",
      "token id to text:  Plate\n",
      "text to token id: 4082\n",
      "token id to text:  Plateau\n",
      "text to token id: 4083\n",
      "token id to text:  tent\n",
      "text to token id: 4084\n",
      "token id to text:  tentatively\n",
      "text to token id: 4085\n",
      "token id to text:  Zhung\n",
      "text to token id: 4086\n",
      "token id to text:  writings\n",
      "text to token id: 4087\n",
      "token id to text:  Ancient\n",
      "text to token id: 4088\n",
      "token id to text: Chinese\n",
      "text to token id: 4089\n",
      "token id to text:  accustom\n",
      "text to token id: 4090\n",
      "token id to text:  accustomed\n",
      "text to token id: 4091\n",
      "token id to text:  notion\n",
      "text to token id: 4092\n",
      "token id to text:  situ\n",
      "text to token id: 4093\n",
      "token id to text:  situation\n",
      "text to token id: 4094\n",
      "token id to text:  complicated\n",
      "text to token id: 4095\n",
      "token id to text:  Hence\n",
      "text to token id: 4096\n",
      "token id to text:  entities\n",
      "text to token id: 4097\n",
      "token id to text:  bears\n",
      "text to token id: 4098\n",
      "token id to text:  similar\n",
      "text to token id: 4099\n",
      "token id to text:  similarities\n",
      "text to token id: 4100\n",
      "token id to text:  contemporaneously\n",
      "text to token id: 4101\n",
      "token id to text:  legally\n",
      "text to token id: 4102\n",
      "token id to text:  once\n",
      "text to token id: 4103\n",
      "token id to text:  sage\n",
      "text to token id: 4104\n",
      "token id to text: -emperor\n",
      "text to token id: 4105\n",
      "token id to text: -emperors\n",
      "text to token id: 4106\n",
      "token id to text:  yield\n",
      "text to token id: 4107\n",
      "token id to text:  yielding\n",
      "text to token id: 4108\n",
      "token id to text:  Bamboo\n",
      "text to token id: 4109\n",
      "token id to text: 91\n",
      "text to token id: 4110\n",
      "token id to text:  generally\n",
      "text to token id: 4111\n",
      "token id to text:  mythical\n",
      "text to token id: 4112\n",
      "token id to text: 195\n",
      "text to token id: 4113\n",
      "token id to text:  enough\n",
      "text to token id: 4114\n",
      "token id to text:  case\n",
      "text to token id: 4115\n",
      "token id to text:  organization\n",
      "text to token id: 4116\n",
      "token id to text:  incompat\n",
      "text to token id: 4117\n",
      "token id to text:  incompatib\n",
      "text to token id: 4118\n",
      "token id to text:  incompatible\n",
      "text to token id: 4119\n",
      "token id to text:  legends\n",
      "text to token id: 4120\n",
      "token id to text:  importantly\n",
      "text to token id: 4121\n",
      "token id to text:  conduc\n",
      "text to token id: 4122\n",
      "token id to text:  conducted\n",
      "text to token id: 4123\n",
      "token id to text:  rituals\n",
      "text to token id: 4124\n",
      "token id to text:  cast\n",
      "text to token id: 4125\n",
      "token id to text: Both\n",
      "text to token id: 4126\n",
      "token id to text:  bronz\n",
      "text to token id: 4127\n",
      "token id to text:  bronzes\n",
      "text to token id: 4128\n",
      "token id to text:  transm\n",
      "text to token id: 4129\n",
      "token id to text:  transmitted\n",
      "text to token id: 4130\n",
      "token id to text:  attest\n",
      "text to token id: 4131\n",
      "token id to text:  come\n",
      "text to token id: 4132\n",
      "token id to text:  excavations\n",
      "text to token id: 4133\n",
      "token id to text:  Erl\n",
      "text to token id: 4134\n",
      "token id to text:  Erlig\n",
      "text to token id: 4135\n",
      "token id to text:  Erligang\n",
      "text to token id: 4136\n",
      "token id to text:  Zhengzhou\n",
      "text to token id: 4137\n",
      "token id to text:  Yinxu\n",
      "text to token id: 4138\n",
      "token id to text: 105\n",
      "text to token id: 4139\n",
      "token id to text:  shell\n",
      "text to token id: 4140\n",
      "token id to text:  shells\n",
      "text to token id: 4141\n",
      "token id to text: —the\n",
      "text to token id: 4142\n",
      "token id to text:  twent\n",
      "text to token id: 4143\n",
      "token id to text:  twenty\n",
      "text to token id: 4144\n",
      "token id to text: -n\n",
      "text to token id: 4145\n",
      "token id to text: -nine\n",
      "text to token id: 4146\n",
      "token id to text:  Throughout\n",
      "text to token id: 4147\n",
      "token id to text:  reigns\n",
      "text to token id: 4148\n",
      "token id to text:  syn\n",
      "text to token id: 4149\n",
      "token id to text:  synony\n",
      "text to token id: 4150\n",
      "token id to text:  synonymous\n",
      "text to token id: 4151\n",
      "token id to text:  lately\n",
      "text to token id: 4152\n",
      "token id to text:  specif\n",
      "text to token id: 4153\n",
      "token id to text:  specifically\n",
      "text to token id: 4154\n",
      "token id to text:  latter\n",
      "text to token id: 4155\n",
      "token id to text:  confir\n",
      "text to token id: 4156\n",
      "token id to text:  confirm\n",
      "text to token id: 4157\n",
      "token id to text:  hes\n",
      "text to token id: 4158\n",
      "token id to text:  hesit\n",
      "text to token id: 4159\n",
      "token id to text:  hesitant\n",
      "text to token id: 4160\n",
      "token id to text:  associ\n",
      "text to token id: 4161\n",
      "token id to text:  associate\n",
      "text to token id: 4162\n",
      "token id to text:  technolog\n",
      "text to token id: 4163\n",
      "token id to text:  technologically\n",
      "text to token id: 4164\n",
      "token id to text:  unli\n",
      "text to token id: 4165\n",
      "token id to text:  unlike\n",
      "text to token id: 4166\n",
      "token id to text:  incon\n",
      "text to token id: 4167\n",
      "token id to text:  inconcl\n",
      "text to token id: 4168\n",
      "token id to text:  inconclus\n",
      "text to token id: 4169\n",
      "token id to text:  inconclusive\n",
      "text to token id: 4170\n",
      "token id to text:  proving\n",
      "text to token id: 4171\n",
      "token id to text:  realm\n",
      "text to token id: 4172\n",
      "token id to text:  diver\n",
      "text to token id: 4173\n",
      "token id to text:  diverse\n",
      "text to token id: 4174\n",
      "token id to text:  referred\n",
      "text to token id: 4175\n",
      "token id to text:  longest\n",
      "text to token id: 4176\n",
      "token id to text: -last\n",
      "text to token id: 4177\n",
      "token id to text: -lasting\n",
      "text to token id: 4178\n",
      "token id to text:  stead\n",
      "text to token id: 4179\n",
      "token id to text:  steadily\n",
      "text to token id: 4180\n",
      "token id to text:  aro\n",
      "text to token id: 4181\n",
      "token id to text:  arose\n",
      "text to token id: 4182\n",
      "token id to text:  appointed\n",
      "text to token id: 4183\n",
      "token id to text:  Protectors\n",
      "text to token id: 4184\n",
      "token id to text:  coalition\n",
      "text to token id: 4185\n",
      "token id to text:  Mu\n",
      "text to token id: 4186\n",
      "token id to text:  Muye\n",
      "text to token id: 4187\n",
      "token id to text:  lower\n",
      "text to token id: 4188\n",
      "token id to text:  enfe\n",
      "text to token id: 4189\n",
      "token id to text:  enfeof\n",
      "text to token id: 4190\n",
      "token id to text:  enfeoff\n",
      "text to token id: 4191\n",
      "token id to text:  enfeoffed\n",
      "text to token id: 4192\n",
      "token id to text:  sem\n",
      "text to token id: 4193\n",
      "token id to text:  semi\n",
      "text to token id: 4194\n",
      "token id to text: -ind\n",
      "text to token id: 4195\n",
      "token id to text: -independ\n",
      "text to token id: 4196\n",
      "token id to text: -independent\n",
      "text to token id: 4197\n",
      "token id to text:  invok\n",
      "text to token id: 4198\n",
      "token id to text:  invoked\n",
      "text to token id: 4199\n",
      "token id to text:  legitimize\n",
      "text to token id: 4200\n",
      "token id to text:  every\n",
      "text to token id: 4201\n",
      "token id to text:  Like\n",
      "text to token id: 4202\n",
      "token id to text:  Shangdi\n",
      "text to token id: 4203\n",
      "token id to text: tian\n",
      "text to token id: 4204\n",
      "token id to text:  decided\n",
      "text to token id: 4205\n",
      "token id to text:  realist\n",
      "text to token id: 4206\n",
      "token id to text:  realistically\n",
      "text to token id: 4207\n",
      "token id to text:  sover\n",
      "text to token id: 4208\n",
      "token id to text:  sovere\n",
      "text to token id: 4209\n",
      "token id to text:  sovereign\n",
      "text to token id: 4210\n",
      "token id to text:  appa\n",
      "text to token id: 4211\n",
      "token id to text:  apparen\n",
      "text to token id: 4212\n",
      "token id to text:  apparently\n",
      "text to token id: 4213\n",
      "token id to text:  overthrown\n",
      "text to token id: 4214\n",
      "token id to text:  having\n",
      "text to token id: 4215\n",
      "token id to text:  Zongzhou\n",
      "text to token id: 4216\n",
      "token id to text:  Chengzhou\n",
      "text to token id: 4217\n",
      "token id to text: Luoyang\n",
      "text to token id: 4218\n",
      "token id to text:  moving\n",
      "text to token id: 4219\n",
      "token id to text:  regularly\n",
      "text to token id: 4220\n",
      "token id to text:  eastward\n",
      "text to token id: 4221\n",
      "token id to text:  southeastward\n",
      "text to token id: 4222\n",
      "token id to text: 72\n",
      "text to token id: 4223\n",
      "token id to text: 722\n",
      "text to token id: 4224\n",
      "token id to text:  \n",
      "\n",
      "text to token id: 4225\n",
      "token id to text: 77\n",
      "text to token id: 4226\n",
      "token id to text: 771\n",
      "text to token id: 4227\n",
      "token id to text:  Quanr\n",
      "text to token id: 4228\n",
      "token id to text:  Quanrong\n",
      "text to token id: 4229\n",
      "token id to text:  barbarians\n",
      "text to token id: 4230\n",
      "token id to text:  Ping\n",
      "text to token id: 4231\n",
      "token id to text:  phase\n",
      "text to token id: 4232\n",
      "token id to text:  named\n",
      "text to token id: 4233\n",
      "token id to text:  center\n",
      "text to token id: 4234\n",
      "token id to text:  deleg\n",
      "text to token id: 4235\n",
      "token id to text:  delegated\n",
      "text to token id: 4236\n",
      "token id to text:  hundreds\n",
      "text to token id: 4237\n",
      "token id to text:  walled\n",
      "text to token id: 4238\n",
      "token id to text:  town\n",
      "text to token id: 4239\n",
      "token id to text:  tended\n",
      "text to token id: 4240\n",
      "token id to text:  incorporate\n",
      "text to token id: 4241\n",
      "token id to text:  weaker\n",
      "text to token id: 4242\n",
      "token id to text:  ones\n",
      "text to token id: 4243\n",
      "token id to text:  disappeared\n",
      "text to token id: 4244\n",
      "token id to text:  princip\n",
      "text to token id: 4245\n",
      "token id to text:  principalities\n",
      "text to token id: 4246\n",
      "token id to text:  underto\n",
      "text to token id: 4247\n",
      "token id to text:  undertook\n",
      "text to token id: 4248\n",
      "token id to text: Wu\n",
      "text to token id: 4249\n",
      "token id to text:  Yue\n",
      "text to token id: 4250\n",
      "token id to text:  urbanized\n",
      "text to token id: 4251\n",
      "token id to text:  commercialized\n",
      "text to token id: 4252\n",
      "token id to text:  Laoz\n",
      "text to token id: 4253\n",
      "token id to text:  Laozi\n",
      "text to token id: 4254\n",
      "token id to text:  Confuc\n",
      "text to token id: 4255\n",
      "token id to text:  Confuci\n",
      "text to token id: 4256\n",
      "token id to text:  Confucius\n",
      "text to token id: 4257\n",
      "token id to text:  Tz\n",
      "text to token id: 4258\n",
      "token id to text:  Tzu\n",
      "text to token id: 4259\n",
      "token id to text:  chaot\n",
      "text to token id: 4260\n",
      "token id to text:  chaotic\n",
      "text to token id: 4261\n",
      "token id to text: Con\n",
      "text to token id: 4262\n",
      "token id to text: Confl\n",
      "text to token id: 4263\n",
      "token id to text: Conflict\n",
      "text to token id: 4264\n",
      "token id to text:  Warfare\n",
      "text to token id: 4265\n",
      "token id to text:  mobil\n",
      "text to token id: 4266\n",
      "token id to text:  mobilize\n",
      "text to token id: 4267\n",
      "token id to text:  sold\n",
      "text to token id: 4268\n",
      "token id to text:  soldi\n",
      "text to token id: 4269\n",
      "token id to text:  soldiers\n",
      "text to token id: 4270\n",
      "token id to text:  Within\n",
      "text to token id: 4271\n",
      "token id to text:  constant\n",
      "text to token id: 4272\n",
      "token id to text:  joc\n",
      "text to token id: 4273\n",
      "token id to text:  jocke\n",
      "text to token id: 4274\n",
      "token id to text:  jockeying\n",
      "text to token id: 4275\n",
      "token id to text: —Z\n",
      "text to token id: 4276\n",
      "token id to text: —Zh\n",
      "text to token id: 4277\n",
      "token id to text: —Zhao\n",
      "text to token id: 4278\n",
      "token id to text: —e\n",
      "text to token id: 4279\n",
      "token id to text: —eventually\n",
      "text to token id: 4280\n",
      "token id to text:  partition\n",
      "text to token id: 4281\n",
      "token id to text:  partitioned\n",
      "text to token id: 4282\n",
      "token id to text:  Schools\n",
      "text to token id: 4283\n",
      "token id to text:  Thought\n",
      "text to token id: 4284\n",
      "token id to text:  bloss\n",
      "text to token id: 4285\n",
      "token id to text:  blossoming\n",
      "text to token id: 4286\n",
      "token id to text:  Such\n",
      "text to token id: 4287\n",
      "token id to text:  movements\n",
      "text to token id: 4288\n",
      "token id to text:  Moh\n",
      "text to token id: 4289\n",
      "token id to text:  Mohism\n",
      "text to token id: 4290\n",
      "token id to text:  partly\n",
      "text to token id: 4291\n",
      "token id to text:  philosophical\n",
      "text to token id: 4292\n",
      "token id to text:  thoughts\n",
      "text to token id: 4293\n",
      "token id to text:  consolidations\n",
      "text to token id: 4294\n",
      "token id to text:  batt\n",
      "text to token id: 4295\n",
      "token id to text:  battled\n",
      "text to token id: 4296\n",
      "token id to text:  Though\n",
      "text to token id: 4297\n",
      "token id to text:  fig\n",
      "text to token id: 4298\n",
      "token id to text:  figure\n",
      "text to token id: 4299\n",
      "token id to text:  figurehe\n",
      "text to token id: 4300\n",
      "token id to text:  figurehead\n",
      "text to token id: 4301\n",
      "token id to text:  little\n",
      "text to token id: 4302\n",
      "token id to text: Num\n",
      "text to token id: 4303\n",
      "token id to text: Numerous\n",
      "text to token id: 4304\n",
      "token id to text:  mathematic\n",
      "text to token id: 4305\n",
      "token id to text:  mathematics\n",
      "text to token id: 4306\n",
      "token id to text: —including\n",
      "text to token id: 4307\n",
      "token id to text:  Zhuan\n",
      "text to token id: 4308\n",
      "token id to text:  summ\n",
      "text to token id: 4309\n",
      "token id to text:  summar\n",
      "text to token id: 4310\n",
      "token id to text:  summarizing\n",
      "text to token id: 4311\n",
      "token id to text:  bund\n",
      "text to token id: 4312\n",
      "token id to text:  bundle\n",
      "text to token id: 4313\n",
      "token id to text:  bamboo\n",
      "text to token id: 4314\n",
      "token id to text:  slips\n",
      "text to token id: 4315\n",
      "token id to text: 305\n",
      "text to token id: 4316\n",
      "token id to text: —b\n",
      "text to token id: 4317\n",
      "token id to text: —be\n",
      "text to token id: 4318\n",
      "token id to text: —being\n",
      "text to token id: 4319\n",
      "token id to text: -dig\n",
      "text to token id: 4320\n",
      "token id to text: -digit\n",
      "text to token id: 4321\n",
      "token id to text:  multipl\n",
      "text to token id: 4322\n",
      "token id to text:  multiplication\n",
      "text to token id: 4323\n",
      "token id to text:  table\n",
      "text to token id: 4324\n",
      "token id to text:  indic\n",
      "text to token id: 4325\n",
      "token id to text:  indicates\n",
      "text to token id: 4326\n",
      "token id to text:  sophist\n",
      "text to token id: 4327\n",
      "token id to text:  sophisticated\n",
      "text to token id: 4328\n",
      "token id to text:  arith\n",
      "text to token id: 4329\n",
      "token id to text:  arithm\n",
      "text to token id: 4330\n",
      "token id to text:  arithmet\n",
      "text to token id: 4331\n",
      "token id to text:  arithmetic\n",
      "text to token id: 4332\n",
      "token id to text: As\n",
      "text to token id: 4333\n",
      "token id to text:  governed\n",
      "text to token id: 4334\n",
      "token id to text:  else\n",
      "text to token id: 4335\n",
      "token id to text:  elsew\n",
      "text to token id: 4336\n",
      "token id to text:  elsewhere\n",
      "text to token id: 4337\n",
      "token id to text:  resili\n",
      "text to token id: 4338\n",
      "token id to text:  resilient\n",
      "text to token id: 4339\n",
      "token id to text: —it\n",
      "text to token id: 4340\n",
      "token id to text: —its\n",
      "text to token id: 4341\n",
      "token id to text:  termin\n",
      "text to token id: 4342\n",
      "token id to text:  terminology\n",
      "text to token id: 4343\n",
      "token id to text:  seen\n",
      "text to token id: 4344\n",
      "token id to text:  sheng\n",
      "text to token id: 4345\n",
      "token id to text: pro\n",
      "text to token id: 4346\n",
      "token id to text: prov\n",
      "text to token id: 4347\n",
      "token id to text: provinces\n",
      "text to token id: 4348\n",
      "token id to text: count\n",
      "text to token id: 4349\n",
      "token id to text: counties\n",
      "text to token id: 4350\n",
      "token id to text:  waning\n",
      "text to token id: 4351\n",
      "token id to text:  conquering\n",
      "text to token id: 4352\n",
      "token id to text:  Jinsh\n",
      "text to token id: 4353\n",
      "token id to text:  Jinsha\n",
      "text to token id: 4354\n",
      "token id to text:  driving\n",
      "text to token id: 4355\n",
      "token id to text:  imitated\n",
      "text to token id: 4356\n",
      "token id to text:  thereby\n",
      "text to token id: 4357\n",
      "token id to text:  becoming\n",
      "text to token id: 4358\n",
      "token id to text:  powerh\n",
      "text to token id: 4359\n",
      "token id to text:  powerhouse\n",
      "text to token id: 4360\n",
      "token id to text:  unify\n",
      "text to token id: 4361\n",
      "token id to text:  unifying\n",
      "text to token id: 4362\n",
      "token id to text:  enabl\n",
      "text to token id: 4363\n",
      "token id to text:  enabling\n",
      "text to token id: 4364\n",
      "token id to text:  proclaim\n",
      "text to token id: 4365\n",
      "token id to text: —known\n",
      "text to token id: 4366\n",
      "token id to text: Ying\n",
      "text to token id: 4367\n",
      "token id to text: 秦�\n",
      "text to token id: 4368\n",
      "token id to text: 秦�\n",
      "text to token id: 4369\n",
      "token id to text: 秦朝\n",
      "text to token id: 4370\n",
      "token id to text:  formalised\n",
      "text to token id: 4371\n",
      "token id to text:  true\n",
      "text to token id: 4372\n",
      "token id to text: Qin\n",
      "text to token id: 4373\n",
      "token id to text:  evol\n",
      "text to token id: 4374\n",
      "token id to text:  evolving\n",
      "text to token id: 4375\n",
      "token id to text:  emphasise\n",
      "text to token id: 4376\n",
      "token id to text: �\n",
      "text to token id: 4377\n",
      "token id to text: 始\n",
      "text to token id: 4378\n",
      "token id to text: 始�\n",
      "text to token id: 4379\n",
      "token id to text: 始�\n",
      "text to token id: 4380\n",
      "token id to text: 始皇\n",
      "text to token id: 4381\n",
      "token id to text: 始皇�\n",
      "text to token id: 4382\n",
      "token id to text: 始皇�\n",
      "text to token id: 4383\n",
      "token id to text: 始皇帝\n",
      "text to token id: 4384\n",
      "token id to text: First\n",
      "text to token id: 4385\n",
      "token id to text: \");\n",
      "text to token id: 4386\n",
      "token id to text:  mythology\n",
      "text to token id: 4387\n",
      "token id to text:  Based\n",
      "text to token id: 4388\n",
      "token id to text:  Xianyang\n",
      "text to token id: 4389\n",
      "token id to text:  governing\n",
      "text to token id: 4390\n",
      "token id to text:  schem\n",
      "text to token id: 4391\n",
      "token id to text:  scheme\n",
      "text to token id: 4392\n",
      "token id to text:  fut\n",
      "text to token id: 4393\n",
      "token id to text:  future\n",
      "text to token id: 4394\n",
      "token id to text:  improve\n",
      "text to token id: 4395\n",
      "token id to text:  perce\n",
      "text to token id: 4396\n",
      "token id to text:  perceived\n",
      "text to token id: 4397\n",
      "token id to text:  failures\n",
      "text to token id: 4398\n",
      "token id to text:  consisted\n",
      "text to token id: 4399\n",
      "token id to text: �\n",
      "text to token id: 4400\n",
      "token id to text: 郡\n",
      "text to token id: 4401\n",
      "token id to text:  jun\n",
      "text to token id: 4402\n",
      "token id to text:  counties\n",
      "text to token id: 4403\n",
      "token id to text: �\n",
      "text to token id: 4404\n",
      "token id to text: 县\n",
      "text to token id: 4405\n",
      "token id to text:  progressively\n",
      "text to token id: 4406\n",
      "token id to text:  divisions\n",
      "text to token id: 4407\n",
      "token id to text: Many\n",
      "text to token id: 4408\n",
      "token id to text:  informed\n",
      "text to token id: 4409\n",
      "token id to text:  ideology\n",
      "text to token id: 4410\n",
      "token id to text:  promo\n",
      "text to token id: 4411\n",
      "token id to text:  promoted\n",
      "text to token id: 4412\n",
      "token id to text:  chancellor\n",
      "text to token id: 4413\n",
      "token id to text:  Si\n",
      "text to token id: 4414\n",
      "token id to text:  emphasised\n",
      "text to token id: 4415\n",
      "token id to text:  mut\n",
      "text to token id: 4416\n",
      "token id to text:  mutual\n",
      "text to token id: 4417\n",
      "token id to text:  respons\n",
      "text to token id: 4418\n",
      "token id to text:  responsib\n",
      "text to token id: 4419\n",
      "token id to text:  responsibility\n",
      "text to token id: 4420\n",
      "token id to text:  disputes\n",
      "text to token id: 4421\n",
      "token id to text:  punish\n",
      "text to token id: 4422\n",
      "token id to text:  punishments\n",
      "text to token id: 4423\n",
      "token id to text:  crime\n",
      "text to token id: 4424\n",
      "token id to text:  practic\n",
      "text to token id: 4425\n",
      "token id to text:  practices\n",
      "text to token id: 4426\n",
      "token id to text:  encouragement\n",
      "text to token id: 4427\n",
      "token id to text:  repress\n",
      "text to token id: 4428\n",
      "token id to text:  repression\n",
      "text to token id: 4429\n",
      "token id to text:  Reforms\n",
      "text to token id: 4430\n",
      "token id to text:  sty\n",
      "text to token id: 4431\n",
      "token id to text:  styles\n",
      "text to token id: 4432\n",
      "token id to text: seal\n",
      "text to token id: 4433\n",
      "token id to text:  script\n",
      "text to token id: 4434\n",
      "token id to text:  metal\n",
      "text to token id: 4435\n",
      "token id to text: Ban\n",
      "text to token id: 4436\n",
      "token id to text:  ordering\n",
      "text to token id: 4437\n",
      "token id to text:  burning\n",
      "text to token id: 4438\n",
      "token id to text:  burial\n",
      "text to token id: 4439\n",
      "token id to text:  guise\n",
      "text to token id: 4440\n",
      "token id to text:  express\n",
      "text to token id: 4441\n",
      "token id to text:  doub\n",
      "text to token id: 4442\n",
      "token id to text:  doubt\n",
      "text to token id: 4443\n",
      "token id to text:  historicity\n",
      "text to token id: 4444\n",
      "token id to text:  importance\n",
      "text to token id: 4445\n",
      "token id to text:  supplemented\n",
      "text to token id: 4446\n",
      "token id to text: -p\n",
      "text to token id: 4447\n",
      "token id to text: -political\n",
      "text to token id: 4448\n",
      "token id to text: -element\n",
      "text to token id: 4449\n",
      "token id to text: 五\n",
      "text to token id: 4450\n",
      "token id to text: 五�\n",
      "text to token id: 4451\n",
      "token id to text: 五�\n",
      "text to token id: 4452\n",
      "token id to text: 五行\n",
      "text to token id: 4453\n",
      "token id to text:  cosmological\n",
      "text to token id: 4454\n",
      "token id to text:  thought\n",
      "text to token id: 4455\n",
      "token id to text:  exh\n",
      "text to token id: 4456\n",
      "token id to text:  exhau\n",
      "text to token id: 4457\n",
      "token id to text:  exhaust\n",
      "text to token id: 4458\n",
      "token id to text:  exhaustive\n",
      "text to token id: 4459\n",
      "token id to text:  collecting\n",
      "text to token id: 4460\n",
      "token id to text:  inform\n",
      "text to token id: 4461\n",
      "token id to text:  information\n",
      "text to token id: 4462\n",
      "token id to text:  residence\n",
      "text to token id: 4463\n",
      "token id to text:  Common\n",
      "text to token id: 4464\n",
      "token id to text:  Commoners\n",
      "text to token id: 4465\n",
      "token id to text: suffered\n",
      "text to token id: 4466\n",
      "token id to text:  treatment\n",
      "text to token id: 4467\n",
      "token id to text:  historian\n",
      "text to token id: 4468\n",
      "token id to text:  Buc\n",
      "text to token id: 4469\n",
      "token id to text:  Buck\n",
      "text to token id: 4470\n",
      "token id to text:  Buckle\n",
      "text to token id: 4471\n",
      "token id to text:  Buckley\n",
      "text to token id: 4472\n",
      "token id to text:  highways\n",
      "text to token id: 4473\n",
      "token id to text:  rang\n",
      "text to token id: 4474\n",
      "token id to text:  ranged\n",
      "text to token id: 4475\n",
      "token id to text: 250\n",
      "text to token id: 4476\n",
      "token id to text: 840\n",
      "text to token id: 4477\n",
      "token id to text:  assigned\n",
      "text to token id: 4478\n",
      "token id to text: 210\n",
      "text to token id: 4479\n",
      "token id to text:  reportedly\n",
      "text to token id: 4480\n",
      "token id to text:  orders\n",
      "text to token id: 4481\n",
      "token id to text:  super\n",
      "text to token id: 4482\n",
      "token id to text:  superv\n",
      "text to token id: 4483\n",
      "token id to text:  supervised\n",
      "text to token id: 4484\n",
      "token id to text:  combining\n",
      "text to token id: 4485\n",
      "token id to text:  walls\n",
      "text to token id: 4486\n",
      "token id to text:  building\n",
      "text to token id: 4487\n",
      "token id to text: 800\n",
      "text to token id: 4488\n",
      "token id to text:  stra\n",
      "text to token id: 4489\n",
      "token id to text:  straight\n",
      "text to token id: 4490\n",
      "token id to text:  monu\n",
      "text to token id: 4491\n",
      "token id to text:  monument\n",
      "text to token id: 4492\n",
      "token id to text:  monumental\n",
      "text to token id: 4493\n",
      "token id to text:  ma\n",
      "text to token id: 4494\n",
      "token id to text:  maus\n",
      "text to token id: 4495\n",
      "token id to text:  mausole\n",
      "text to token id: 4496\n",
      "token id to text:  mausoleum\n",
      "text to token id: 4497\n",
      "token id to text:  Ter\n",
      "text to token id: 4498\n",
      "token id to text:  Terrac\n",
      "text to token id: 4499\n",
      "token id to text:  Terracot\n",
      "text to token id: 4500\n",
      "token id to text:  Terracotta\n",
      "text to token id: 4501\n",
      "token id to text:  deterior\n",
      "text to token id: 4502\n",
      "token id to text:  deteriorated\n",
      "text to token id: 4503\n",
      "token id to text:  capitulated\n",
      "text to token id: 4504\n",
      "token id to text:  ====\n",
      "\n",
      "\n",
      "\n",
      "text to token id: 4505\n",
      "token id to text: =====\n",
      "text to token id: 4506\n",
      "token id to text:  =====\n",
      "\n",
      "\n",
      "text to token id: 4507\n",
      "token id to text:  Bang\n",
      "text to token id: 4508\n",
      "token id to text:  victor\n",
      "text to token id: 4509\n",
      "token id to text:  victorious\n",
      "text to token id: 4510\n",
      "token id to text: –Han\n",
      "text to token id: 4511\n",
      "token id to text:  Contention\n",
      "text to token id: 4512\n",
      "token id to text:  intermit\n",
      "text to token id: 4513\n",
      "token id to text:  intermitt\n",
      "text to token id: 4514\n",
      "token id to text:  intermittently\n",
      "text to token id: 4515\n",
      "token id to text:  orth\n",
      "text to token id: 4516\n",
      "token id to text:  orthod\n",
      "text to token id: 4517\n",
      "token id to text:  orthodox\n",
      "text to token id: 4518\n",
      "token id to text:  shape\n",
      "text to token id: 4519\n",
      "token id to text:  Art\n",
      "text to token id: 4520\n",
      "token id to text:  heights\n",
      "text to token id: 4521\n",
      "token id to text:  prof\n",
      "text to token id: 4522\n",
      "token id to text:  profound\n",
      "text to token id: 4523\n",
      "token id to text:  impacts\n",
      "text to token id: 4524\n",
      "token id to text:  commonly\n",
      "text to token id: 4525\n",
      "token id to text:  lais\n",
      "text to token id: 4526\n",
      "token id to text:  laisse\n",
      "text to token id: 4527\n",
      "token id to text:  laissez\n",
      "text to token id: 4528\n",
      "token id to text: -fa\n",
      "text to token id: 4529\n",
      "token id to text: -faire\n",
      "text to token id: 4530\n",
      "token id to text:  ambit\n",
      "text to token id: 4531\n",
      "token id to text:  ambitious\n",
      "text to token id: 4532\n",
      "token id to text:  disen\n",
      "text to token id: 4533\n",
      "token id to text:  disenfr\n",
      "text to token id: 4534\n",
      "token id to text:  disenfran\n",
      "text to token id: 4535\n",
      "token id to text:  disenfranch\n",
      "text to token id: 4536\n",
      "token id to text:  disenfranchised\n",
      "text to token id: 4537\n",
      "token id to text:  appoin\n",
      "text to token id: 4538\n",
      "token id to text:  appointing\n",
      "text to token id: 4539\n",
      "token id to text:  lands\n",
      "text to token id: 4540\n",
      "token id to text:  step\n",
      "text to token id: 4541\n",
      "token id to text:  patron\n",
      "text to token id: 4542\n",
      "token id to text:  patronage\n",
      "text to token id: 4543\n",
      "token id to text:  emphasizes\n",
      "text to token id: 4544\n",
      "token id to text: -struc\n",
      "text to token id: 4545\n",
      "token id to text: -structured\n",
      "text to token id: 4546\n",
      "token id to text:  Univ\n",
      "text to token id: 4547\n",
      "token id to text:  Univers\n",
      "text to token id: 4548\n",
      "token id to text:  Universities\n",
      "text to token id: 4549\n",
      "token id to text:  study\n",
      "text to token id: 4550\n",
      "token id to text:  urg\n",
      "text to token id: 4551\n",
      "token id to text:  urging\n",
      "text to token id: 4552\n",
      "token id to text:  Legalist\n",
      "text to token id: 4553\n",
      "token id to text:  advis\n",
      "text to token id: 4554\n",
      "token id to text:  advisors\n",
      "text to token id: 4555\n",
      "token id to text:  strengthened\n",
      "text to token id: 4556\n",
      "token id to text:  fis\n",
      "text to token id: 4557\n",
      "token id to text:  fiscal\n",
      "text to token id: 4558\n",
      "token id to text:  monopol\n",
      "text to token id: 4559\n",
      "token id to text:  monopolies\n",
      "text to token id: 4560\n",
      "token id to text:  lim\n",
      "text to token id: 4561\n",
      "token id to text:  limiting\n",
      "text to token id: 4562\n",
      "token id to text:  efforts\n",
      "text to token id: 4563\n",
      "token id to text:  stimulating\n",
      "text to token id: 4564\n",
      "token id to text:  bil\n",
      "text to token id: 4565\n",
      "token id to text:  bilater\n",
      "text to token id: 4566\n",
      "token id to text:  bilateral\n",
      "text to token id: 4567\n",
      "token id to text:  Valley\n",
      "text to token id: 4568\n",
      "token id to text:  dispatched\n",
      "text to token id: 4569\n",
      "token id to text:  Baiyue\n",
      "text to token id: 4570\n",
      "token id to text:  Minyue\n",
      "text to token id: 4571\n",
      "token id to text: 135\n",
      "text to token id: 4572\n",
      "token id to text:  Nany\n",
      "text to token id: 4573\n",
      "token id to text:  Nanyue\n",
      "text to token id: 4574\n",
      "token id to text:  Dian\n",
      "text to token id: 4575\n",
      "token id to text:  Migr\n",
      "text to token id: 4576\n",
      "token id to text:  Migration\n",
      "text to token id: 4577\n",
      "token id to text:  expeditions\n",
      "text to token id: 4578\n",
      "token id to text:  Southeast\n",
      "text to token id: 4579\n",
      "token id to text:  introducing\n",
      "text to token id: 4580\n",
      "token id to text:  diplomacy\n",
      "text to token id: 4581\n",
      "token id to text:  slipped\n",
      "text to token id: 4582\n",
      "token id to text:  stagn\n",
      "text to token id: 4583\n",
      "token id to text:  stagnation\n",
      "text to token id: 4584\n",
      "token id to text:  Econom\n",
      "text to token id: 4585\n",
      "token id to text:  Economically\n",
      "text to token id: 4586\n",
      "token id to text:  strained\n",
      "text to token id: 4587\n",
      "token id to text:  drained\n",
      "text to token id: 4588\n",
      "token id to text:  Var\n",
      "text to token id: 4589\n",
      "token id to text:  Various\n",
      "text to token id: 4590\n",
      "token id to text:  exer\n",
      "text to token id: 4591\n",
      "token id to text:  exerted\n",
      "text to token id: 4592\n",
      "token id to text:  brief\n",
      "text to token id: 4593\n",
      "token id to text:  briefly\n",
      "text to token id: 4594\n",
      "token id to text:  usurper\n",
      "text to token id: 4595\n",
      "token id to text:  started\n",
      "text to token id: 4596\n",
      "token id to text:  outla\n",
      "text to token id: 4597\n",
      "token id to text:  outlawing\n",
      "text to token id: 4598\n",
      "token id to text:  nationalization\n",
      "text to token id: 4599\n",
      "token id to text:  redistribution\n",
      "text to token id: 4600\n",
      "token id to text:  programs\n",
      "text to token id: 4601\n",
      "token id to text:  favored\n",
      "text to token id: 4602\n",
      "token id to text:  instability\n",
      "text to token id: 4603\n",
      "token id to text:  compounded\n",
      "text to token id: 4604\n",
      "token id to text:  flood\n",
      "text to token id: 4605\n",
      "token id to text:  flooding\n",
      "text to token id: 4606\n",
      "token id to text:  silt\n",
      "text to token id: 4607\n",
      "token id to text:  buildup\n",
      "text to token id: 4608\n",
      "token id to text:  chan\n",
      "text to token id: 4609\n",
      "token id to text:  chann\n",
      "text to token id: 4610\n",
      "token id to text:  channels\n",
      "text to token id: 4611\n",
      "token id to text:  Weiyang\n",
      "text to token id: 4612\n",
      "token id to text:  Palace\n",
      "text to token id: 4613\n",
      "token id to text:  enraged\n",
      "text to token id: 4614\n",
      "token id to text: 23\n",
      "text to token id: 4615\n",
      "token id to text:  ====\n",
      "\n",
      "text to token id: 4616\n",
      "token id to text:  Guangwu\n",
      "text to token id: 4617\n",
      "token id to text:  rein\n",
      "text to token id: 4618\n",
      "token id to text:  reinst\n",
      "text to token id: 4619\n",
      "token id to text:  reinstated\n",
      "text to token id: 4620\n",
      "token id to text:  Thus\n",
      "text to token id: 4621\n",
      "token id to text:  capable\n",
      "text to token id: 4622\n",
      "token id to text:  glories\n",
      "text to token id: 4623\n",
      "token id to text:  reclaimed\n",
      "text to token id: 4624\n",
      "token id to text:  brill\n",
      "text to token id: 4625\n",
      "token id to text:  brilliant\n",
      "text to token id: 4626\n",
      "token id to text:  diplomat\n",
      "text to token id: 4627\n",
      "token id to text:  Pam\n",
      "text to token id: 4628\n",
      "token id to text:  Pamir\n",
      "text to token id: 4629\n",
      "token id to text:  Pamirs\n",
      "text to token id: 4630\n",
      "token id to text:  sho\n",
      "text to token id: 4631\n",
      "token id to text:  shores\n",
      "text to token id: 4632\n",
      "token id to text:  Cas\n",
      "text to token id: 4633\n",
      "token id to text:  Casp\n",
      "text to token id: 4634\n",
      "token id to text:  Caspian\n",
      "text to token id: 4635\n",
      "token id to text:  reop\n",
      "text to token id: 4636\n",
      "token id to text:  reopen\n",
      "text to token id: 4637\n",
      "token id to text:  reopening\n",
      "text to token id: 4638\n",
      "token id to text:  arrival\n",
      "text to token id: 4639\n",
      "token id to text:  connections\n",
      "text to token id: 4640\n",
      "token id to text:  embass\n",
      "text to token id: 4641\n",
      "token id to text:  embassies\n",
      "text to token id: 4642\n",
      "token id to text:  sources\n",
      "text to token id: 4643\n",
      "token id to text:  coming\n",
      "text to token id: 4644\n",
      "token id to text: 284\n",
      "text to token id: 4645\n",
      "token id to text:  eras\n",
      "text to token id: 4646\n",
      "token id to text:  paperm\n",
      "text to token id: 4647\n",
      "token id to text:  papermaking\n",
      "text to token id: 4648\n",
      "token id to text:  Cai\n",
      "text to token id: 4649\n",
      "token id to text:  Lun\n",
      "text to token id: 4650\n",
      "token id to text:  mathemat\n",
      "text to token id: 4651\n",
      "token id to text:  mathematical\n",
      "text to token id: 4652\n",
      "token id to text:  contributions\n",
      "text to token id: 4653\n",
      "token id to text:  poly\n",
      "text to token id: 4654\n",
      "token id to text:  polym\n",
      "text to token id: 4655\n",
      "token id to text:  polymath\n",
      "text to token id: 4656\n",
      "token id to text:  Heng\n",
      "text to token id: 4657\n",
      "token id to text:  feuding\n",
      "text to token id: 4658\n",
      "token id to text:  Turban\n",
      "text to token id: 4659\n",
      "token id to text:  turm\n",
      "text to token id: 4660\n",
      "token id to text:  turmo\n",
      "text to token id: 4661\n",
      "token id to text:  turmoil\n",
      "text to token id: 4662\n",
      "token id to text:  trying\n",
      "text to token id: 4663\n",
      "token id to text:  gain\n",
      "text to token id: 4664\n",
      "token id to text:  predominance\n",
      "text to token id: 4665\n",
      "token id to text:  classic\n",
      "text to token id: 4666\n",
      "token id to text:  Romance\n",
      "text to token id: 4667\n",
      "token id to text:  dram\n",
      "text to token id: 4668\n",
      "token id to text:  dramat\n",
      "text to token id: 4669\n",
      "token id to text:  dramatizes\n",
      "text to token id: 4670\n",
      "token id to text: 208\n",
      "text to token id: 4671\n",
      "token id to text:  accep\n",
      "text to token id: 4672\n",
      "token id to text:  accepted\n",
      "text to token id: 4673\n",
      "token id to text:  initi\n",
      "text to token id: 4674\n",
      "token id to text:  initiating\n",
      "text to token id: 4675\n",
      "token id to text:  So\n",
      "text to token id: 4676\n",
      "token id to text:  Soon\n",
      "text to token id: 4677\n",
      "token id to text:  rivals\n",
      "text to token id: 4678\n",
      "token id to text:  characteri\n",
      "text to token id: 4679\n",
      "token id to text:  characteriz\n",
      "text to token id: 4680\n",
      "token id to text:  characterized\n",
      "text to token id: 4681\n",
      "token id to text:  decentral\n",
      "text to token id: 4682\n",
      "token id to text:  decentralization\n",
      "text to token id: 4683\n",
      "token id to text:  union\n",
      "text to token id: 4684\n",
      "token id to text:  reunited\n",
      "text to token id: 4685\n",
      "token id to text:  severely\n",
      "text to token id: 4686\n",
      "token id to text:  Princes\n",
      "text to token id: 4687\n",
      "token id to text:  settl\n",
      "text to token id: 4688\n",
      "token id to text:  settlers\n",
      "text to token id: 4689\n",
      "token id to text:  rebelled\n",
      "text to token id: 4690\n",
      "token id to text: 317\n",
      "text to token id: 4691\n",
      "token id to text:  prince\n",
      "text to token id: 4692\n",
      "token id to text:  Rui\n",
      "text to token id: 4693\n",
      "token id to text:  Pri\n",
      "text to token id: 4694\n",
      "token id to text:  Prior\n",
      "text to token id: 4695\n",
      "token id to text: 304\n",
      "text to token id: 4696\n",
      "token id to text: Nor\n",
      "text to token id: 4697\n",
      "token id to text: Northern\n",
      "text to token id: 4698\n",
      "token id to text:  Jie\n",
      "text to token id: 4699\n",
      "token id to text:  Di\n",
      "text to token id: 4700\n",
      "token id to text: sinic\n",
      "text to token id: 4701\n",
      "token id to text: sinicized\n",
      "text to token id: 4702\n",
      "token id to text:  ascent\n",
      "text to token id: 4703\n",
      "token id to text:  promp\n",
      "text to token id: 4704\n",
      "token id to text:  prompted\n",
      "text to token id: 4705\n",
      "token id to text:  migration\n",
      "text to token id: 4706\n",
      "token id to text:  Delta\n",
      "text to token id: 4707\n",
      "token id to text:  paralle\n",
      "text to token id: 4708\n",
      "token id to text:  parallel\n",
      "text to token id: 4709\n",
      "token id to text:  halves\n",
      "text to token id: 4710\n",
      "token id to text:  Jian\n",
      "text to token id: 4711\n",
      "token id to text:  Jiankang\n",
      "text to token id: 4712\n",
      "token id to text:  attacks\n",
      "text to token id: 4713\n",
      "token id to text:  barbarian\n",
      "text to token id: 4714\n",
      "token id to text:  sin\n",
      "text to token id: 4715\n",
      "token id to text:  sinify\n",
      "text to token id: 4716\n",
      "token id to text:  extingu\n",
      "text to token id: 4717\n",
      "token id to text:  extinguished\n",
      "text to token id: 4718\n",
      "token id to text:  kingdom\n",
      "text to token id: 4719\n",
      "token id to text:  married\n",
      "text to token id: 4720\n",
      "token id to text:  surnam\n",
      "text to token id: 4721\n",
      "token id to text:  surnames\n",
      "text to token id: 4722\n",
      "token id to text:  debates\n",
      "text to token id: 4723\n",
      "token id to text:  should\n",
      "text to token id: 4724\n",
      "token id to text:  frequ\n",
      "text to token id: 4725\n",
      "token id to text:  frequently\n",
      "text to token id: 4726\n",
      "token id to text:  nobl\n",
      "text to token id: 4727\n",
      "token id to text:  nobles\n",
      "text to token id: 4728\n",
      "token id to text:  Buddhists\n",
      "text to token id: 4729\n",
      "token id to text:  Taoists\n",
      "text to token id: 4730\n",
      "token id to text:  become\n",
      "text to token id: 4731\n",
      "token id to text:  tolerant\n",
      "text to token id: 4732\n",
      "token id to text:  Mid\n",
      "text to token id: 4733\n",
      "token id to text: -i\n",
      "text to token id: 4734\n",
      "token id to text: -imperial\n",
      "text to token id: 4735\n",
      "token id to text:  pion\n",
      "text to token id: 4736\n",
      "token id to text:  pione\n",
      "text to token id: 4737\n",
      "token id to text:  pioneered\n",
      "text to token id: 4738\n",
      "token id to text:  select\n",
      "text to token id: 4739\n",
      "token id to text:  selecting\n",
      "text to token id: 4740\n",
      "token id to text:  commoners\n",
      "text to token id: 4741\n",
      "token id to text:  equal\n",
      "text to token id: 4742\n",
      "token id to text:  distribut\n",
      "text to token id: 4743\n",
      "token id to text:  distributions\n",
      "text to token id: 4744\n",
      "token id to text:  weal\n",
      "text to token id: 4745\n",
      "token id to text:  wealth\n",
      "text to token id: 4746\n",
      "token id to text:  Stand\n",
      "text to token id: 4747\n",
      "token id to text:  Standard\n",
      "text to token id: 4748\n",
      "token id to text:  Standardized\n",
      "text to token id: 4749\n",
      "token id to text:  root\n",
      "text to token id: 4750\n",
      "token id to text:  meg\n",
      "text to token id: 4751\n",
      "token id to text:  mega\n",
      "text to token id: 4752\n",
      "token id to text: -construc\n",
      "text to token id: 4753\n",
      "token id to text: -construction\n",
      "text to token id: 4754\n",
      "token id to text:  Intended\n",
      "text to token id: 4755\n",
      "token id to text:  shipment\n",
      "text to token id: 4756\n",
      "token id to text:  transp\n",
      "text to token id: 4757\n",
      "token id to text:  transport\n",
      "text to token id: 4758\n",
      "token id to text:  transporting\n",
      "text to token id: 4759\n",
      "token id to text:  constructed\n",
      "text to token id: 4760\n",
      "token id to text:  Dax\n",
      "text to token id: 4761\n",
      "token id to text:  Daxing\n",
      "text to token id: 4762\n",
      "token id to text: Ch\n",
      "text to token id: 4763\n",
      "token id to text: Chang\n",
      "text to token id: 4764\n",
      "token id to text:  wealthy\n",
      "text to token id: 4765\n",
      "token id to text:  pac\n",
      "text to token id: 4766\n",
      "token id to text:  pacified\n",
      "text to token id: 4767\n",
      "token id to text:  Korean\n",
      "text to token id: 4768\n",
      "token id to text:  Penins\n",
      "text to token id: 4769\n",
      "token id to text:  Peninsul\n",
      "text to token id: 4770\n",
      "token id to text:  Peninsula\n",
      "text to token id: 4771\n",
      "token id to text:  Gog\n",
      "text to token id: 4772\n",
      "token id to text:  Gogury\n",
      "text to token id: 4773\n",
      "token id to text:  Gogurye\n",
      "text to token id: 4774\n",
      "token id to text:  Goguryeo\n",
      "text to token id: 4775\n",
      "token id to text: –S\n",
      "text to token id: 4776\n",
      "token id to text: –Sui\n",
      "text to token id: 4777\n",
      "token id to text:  disastr\n",
      "text to token id: 4778\n",
      "token id to text:  disastrously\n",
      "text to token id: 4779\n",
      "token id to text:  trigger\n",
      "text to token id: 4780\n",
      "token id to text:  triggering\n",
      "text to token id: 4781\n",
      "token id to text:  creat\n",
      "text to token id: 4782\n",
      "token id to text:  creative\n",
      "text to token id: 4783\n",
      "token id to text:  Gaoz\n",
      "text to token id: 4784\n",
      "token id to text:  Gaozu\n",
      "text to token id: 4785\n",
      "token id to text:  Shim\n",
      "text to token id: 4786\n",
      "token id to text:  Shimin\n",
      "text to token id: 4787\n",
      "token id to text:  Taizong\n",
      "text to token id: 4788\n",
      "token id to text:  Comb\n",
      "text to token id: 4789\n",
      "token id to text:  Combined\n",
      "text to token id: 4790\n",
      "token id to text:  threats\n",
      "text to token id: 4791\n",
      "token id to text:  Mil\n",
      "text to token id: 4792\n",
      "token id to text:  Military\n",
      "text to token id: 4793\n",
      "token id to text:  victories\n",
      "text to token id: 4794\n",
      "token id to text:  connecting\n",
      "text to token id: 4795\n",
      "token id to text:  lucrative\n",
      "text to token id: 4796\n",
      "token id to text:  distant\n",
      "text to token id: 4797\n",
      "token id to text:  encourag\n",
      "text to token id: 4798\n",
      "token id to text:  encouraging\n",
      "text to token id: 4799\n",
      "token id to text:  obs\n",
      "text to token id: 4800\n",
      "token id to text:  obser\n",
      "text to token id: 4801\n",
      "token id to text:  observed\n",
      "text to token id: 4802\n",
      "token id to text:  adapted\n",
      "text to token id: 4803\n",
      "token id to text:  Internally\n",
      "text to token id: 4804\n",
      "token id to text:  linked\n",
      "text to token id: 4805\n",
      "token id to text:  Xuanzang\n",
      "text to token id: 4806\n",
      "token id to text:  monk\n",
      "text to token id: 4807\n",
      "token id to text:  traveller\n",
      "text to token id: 4808\n",
      "token id to text:  transl\n",
      "text to token id: 4809\n",
      "token id to text:  translat\n",
      "text to token id: 4810\n",
      "token id to text:  translator\n",
      "text to token id: 4811\n",
      "token id to text:  travelled\n",
      "text to token id: 4812\n",
      "token id to text:  returned\n",
      "text to token id: 4813\n",
      "token id to text:  Mah\n",
      "text to token id: 4814\n",
      "token id to text:  Mahayana\n",
      "text to token id: 4815\n",
      "token id to text:  Hin\n",
      "text to token id: 4816\n",
      "token id to text:  Hinayana\n",
      "text to token id: 4817\n",
      "token id to text:  statu\n",
      "text to token id: 4818\n",
      "token id to text:  statues\n",
      "text to token id: 4819\n",
      "token id to text:  Buddha\n",
      "text to token id: 4820\n",
      "token id to text:  sar\n",
      "text to token id: 4821\n",
      "token id to text:  sarir\n",
      "text to token id: 4822\n",
      "token id to text:  sarira\n",
      "text to token id: 4823\n",
      "token id to text:  relics\n",
      "text to token id: 4824\n",
      "token id to text: .\"\n",
      "text to token id: 4825\n",
      "token id to text: .\"\n",
      "\n",
      "text to token id: 4826\n",
      "token id to text:  abet\n",
      "text to token id: 4827\n",
      "token id to text:  abetted\n",
      "text to token id: 4828\n",
      "token id to text:  organized\n",
      "text to token id: 4829\n",
      "token id to text: Three\n",
      "text to token id: 4830\n",
      "token id to text:  sep\n",
      "text to token id: 4831\n",
      "token id to text:  separ\n",
      "text to token id: 4832\n",
      "token id to text:  separate\n",
      "text to token id: 4833\n",
      "token id to text:  separately\n",
      "text to token id: 4834\n",
      "token id to text:  dra\n",
      "text to token id: 4835\n",
      "token id to text:  draft\n",
      "text to token id: 4836\n",
      "token id to text:  revie\n",
      "text to token id: 4837\n",
      "token id to text:  review\n",
      "text to token id: 4838\n",
      "token id to text:  departments\n",
      "text to token id: 4839\n",
      "token id to text:  run\n",
      "text to token id: 4840\n",
      "token id to text:  landed\n",
      "text to token id: 4841\n",
      "token id to text:  wore\n",
      "text to token id: 4842\n",
      "token id to text:  selected\n",
      "text to token id: 4843\n",
      "token id to text:  patt\n",
      "text to token id: 4844\n",
      "token id to text:  pattern\n",
      "text to token id: 4845\n",
      "token id to text:  patterns\n",
      "text to token id: 4846\n",
      "token id to text: Under\n",
      "text to token id: 4847\n",
      "token id to text:  owned\n",
      "text to token id: 4848\n",
      "token id to text:  household\n",
      "text to token id: 4849\n",
      "token id to text:  size\n",
      "text to token id: 4850\n",
      "token id to text:  Men\n",
      "text to token id: 4851\n",
      "token id to text:  serv\n",
      "text to token id: 4852\n",
      "token id to text:  service\n",
      "text to token id: 4853\n",
      "token id to text:  fixed\n",
      "text to token id: 4854\n",
      "token id to text:  policy\n",
      "text to token id: 4855\n",
      "token id to text:  productiv\n",
      "text to token id: 4856\n",
      "token id to text:  productivity\n",
      "text to token id: 4857\n",
      "token id to text:  without\n",
      "text to token id: 4858\n",
      "token id to text:  burd\n",
      "text to token id: 4859\n",
      "token id to text:  burden\n",
      "text to token id: 4860\n",
      "token id to text:  midp\n",
      "text to token id: 4861\n",
      "token id to text:  midpoin\n",
      "text to token id: 4862\n",
      "token id to text:  midpoint\n",
      "text to token id: 4863\n",
      "token id to text:  continuously\n",
      "text to token id: 4864\n",
      "token id to text:  falling\n",
      "text to token id: 4865\n",
      "token id to text:  owners\n",
      "text to token id: 4866\n",
      "token id to text:  exemp\n",
      "text to token id: 4867\n",
      "token id to text:  exempt\n",
      "text to token id: 4868\n",
      "token id to text:  exemptions\n",
      "text to token id: 4869\n",
      "token id to text:  regn\n",
      "text to token id: 4870\n",
      "token id to text:  regnant\n",
      "text to token id: 4871\n",
      "token id to text:  Xuanzong\n",
      "text to token id: 4872\n",
      "token id to text:  stretched\n",
      "text to token id: 4873\n",
      "token id to text:  Pac\n",
      "text to token id: 4874\n",
      "token id to text:  Pacific\n",
      "text to token id: 4875\n",
      "token id to text:  Aral\n",
      "text to token id: 4876\n",
      "token id to text: 50\n",
      "text to token id: 4877\n",
      "token id to text:  artistic\n",
      "text to token id: 4878\n",
      "token id to text:  creations\n",
      "text to token id: 4879\n",
      "token id to text:  poets\n",
      "text to token id: 4880\n",
      "token id to text:  Du\n",
      "text to token id: 4881\n",
      "token id to text:  Lus\n",
      "text to token id: 4882\n",
      "token id to text:  Lushan\n",
      "text to token id: 4883\n",
      "token id to text: 755\n",
      "text to token id: 4884\n",
      "token id to text: 763\n",
      "text to token id: 4885\n",
      "token id to text:  waters\n",
      "text to token id: 4886\n",
      "token id to text:  watershed\n",
      "text to token id: 4887\n",
      "token id to text:  disruption\n",
      "text to token id: 4888\n",
      "token id to text:  jied\n",
      "text to token id: 4889\n",
      "token id to text:  jiedus\n",
      "text to token id: 4890\n",
      "token id to text:  jiedushi\n",
      "text to token id: 4891\n",
      "token id to text:  reven\n",
      "text to token id: 4892\n",
      "token id to text:  revenue\n",
      "text to token id: 4893\n",
      "token id to text:  rely\n",
      "text to token id: 4894\n",
      "token id to text:  heav\n",
      "text to token id: 4895\n",
      "token id to text:  heavily\n",
      "text to token id: 4896\n",
      "token id to text:  sal\n",
      "text to token id: 4897\n",
      "token id to text:  salt\n",
      "text to token id: 4898\n",
      "token id to text:  monop\n",
      "text to token id: 4899\n",
      "token id to text:  monopoly\n",
      "text to token id: 4900\n",
      "token id to text:  Externally\n",
      "text to token id: 4901\n",
      "token id to text:  submis\n",
      "text to token id: 4902\n",
      "token id to text:  submissive\n",
      "text to token id: 4903\n",
      "token id to text:  raided\n",
      "text to token id: 4904\n",
      "token id to text:  Never\n",
      "text to token id: 4905\n",
      "token id to text:  Neverthe\n",
      "text to token id: 4906\n",
      "token id to text:  Nevertheless\n",
      "text to token id: 4907\n",
      "token id to text:  recovered\n",
      "text to token id: 4908\n",
      "token id to text:  thr\n",
      "text to token id: 4909\n",
      "token id to text:  thrived\n",
      "text to token id: 4910\n",
      "token id to text:  worn\n",
      "text to token id: 4911\n",
      "token id to text:  recur\n",
      "text to token id: 4912\n",
      "token id to text:  recurring\n",
      "text to token id: 4913\n",
      "token id to text:  factional\n",
      "text to token id: 4914\n",
      "token id to text:  corrupted\n",
      "text to token id: 4915\n",
      "token id to text:  Catastrop\n",
      "text to token id: 4916\n",
      "token id to text:  Catastroph\n",
      "text to token id: 4917\n",
      "token id to text:  Catastrophically\n",
      "text to token id: 4918\n",
      "token id to text: 874\n",
      "text to token id: 4919\n",
      "token id to text: 884\n",
      "text to token id: 4920\n",
      "token id to text: 879\n",
      "text to token id: 4921\n",
      "token id to text:  massacre\n",
      "text to token id: 4922\n",
      "token id to text:  esp\n",
      "text to token id: 4923\n",
      "token id to text:  espec\n",
      "text to token id: 4924\n",
      "token id to text:  especially\n",
      "text to token id: 4925\n",
      "token id to text:  encl\n",
      "text to token id: 4926\n",
      "token id to text:  enclaves\n",
      "text to token id: 4927\n",
      "token id to text: 88\n",
      "text to token id: 4928\n",
      "token id to text: 881\n",
      "text to token id: 4929\n",
      "token id to text:  successively\n",
      "text to token id: 4930\n",
      "token id to text:  reliance\n",
      "text to token id: 4931\n",
      "token id to text:  suppressing\n",
      "text to token id: 4932\n",
      "token id to text: 808\n",
      "text to token id: 4933\n",
      "token id to text:  defected\n",
      "text to token id: 4934\n",
      "token id to text:  punished\n",
      "text to token id: 4935\n",
      "token id to text:  killing\n",
      "text to token id: 4936\n",
      "token id to text:  chasing\n",
      "text to token id: 4937\n",
      "token id to text:  Bes\n",
      "text to token id: 4938\n",
      "token id to text:  Besh\n",
      "text to token id: 4939\n",
      "token id to text:  Beshbali\n",
      "text to token id: 4940\n",
      "token id to text:  Beshbalik\n",
      "text to token id: 4941\n",
      "token id to text: Li\n",
      "text to token id: 4942\n",
      "token id to text:  Guochang\n",
      "text to token id: 4943\n",
      "token id to text:  fellow\n",
      "text to token id: 4944\n",
      "token id to text: 839\n",
      "text to token id: 4945\n",
      "token id to text: Hu\n",
      "text to token id: 4946\n",
      "token id to text: Huig\n",
      "text to token id: 4947\n",
      "token id to text: Huigu\n",
      "text to token id: 4948\n",
      "token id to text:  Ju\n",
      "text to token id: 4949\n",
      "token id to text:  Juel\n",
      "text to token id: 4950\n",
      "token id to text:  Juelu\n",
      "text to token id: 4951\n",
      "token id to text:  Jueluow\n",
      "text to token id: 4952\n",
      "token id to text:  Jueluowu\n",
      "text to token id: 4953\n",
      "token id to text: �\n",
      "text to token id: 4954\n",
      "token id to text: 掘\n",
      "text to token id: 4955\n",
      "token id to text: 掘�\n",
      "text to token id: 4956\n",
      "token id to text: 掘�\n",
      "text to token id: 4957\n",
      "token id to text: 掘羅\n",
      "text to token id: 4958\n",
      "token id to text: 掘羅�\n",
      "text to token id: 4959\n",
      "token id to text: 掘羅�\n",
      "text to token id: 4960\n",
      "token id to text: 掘羅勿\n",
      "text to token id: 4961\n",
      "token id to text:  rose\n",
      "text to token id: 4962\n",
      "token id to text: -re\n",
      "text to token id: 4963\n",
      "token id to text: -reign\n",
      "text to token id: 4964\n",
      "token id to text: -reigning\n",
      "text to token id: 4965\n",
      "token id to text:  elic\n",
      "text to token id: 4966\n",
      "token id to text:  elicited\n",
      "text to token id: 4967\n",
      "token id to text:  help\n",
      "text to token id: 4968\n",
      "token id to text:  hors\n",
      "text to token id: 4969\n",
      "token id to text:  horses\n",
      "text to token id: 4970\n",
      "token id to text:  precipitating\n",
      "text to token id: 4971\n",
      "token id to text:  collapse\n",
      "text to token id: 4972\n",
      "token id to text:  extensively\n",
      "text to token id: 4973\n",
      "token id to text:  coun\n",
      "text to token id: 4974\n",
      "token id to text:  counter\n",
      "text to token id: 4975\n",
      "token id to text:  counteratt\n",
      "text to token id: 4976\n",
      "token id to text:  counterattac\n",
      "text to token id: 4977\n",
      "token id to text:  counterattacking\n",
      "text to token id: 4978\n",
      "token id to text: 843\n",
      "text to token id: 4979\n",
      "token id to text:  officer\n",
      "text to token id: 4980\n",
      "token id to text:  Tuy\n",
      "text to token id: 4981\n",
      "token id to text:  Tuyu\n",
      "text to token id: 4982\n",
      "token id to text:  Tuyuh\n",
      "text to token id: 4983\n",
      "token id to text:  Tuyuhun\n",
      "text to token id: 4984\n",
      "token id to text:  slau\n",
      "text to token id: 4985\n",
      "token id to text:  slaugh\n",
      "text to token id: 4986\n",
      "token id to text:  slaughter\n",
      "text to token id: 4987\n",
      "token id to text:  Shahu\n",
      "text to token id: 4988\n",
      "token id to text:  respects\n",
      "text to token id: 4989\n",
      "token id to text:  multi\n",
      "text to token id: 4990\n",
      "token id to text: -state\n",
      "text to token id: 4991\n",
      "token id to text:  Among\n",
      "text to token id: 4992\n",
      "token id to text:  mostly\n",
      "text to token id: 4993\n",
      "token id to text:  cum\n",
      "text to token id: 4994\n",
      "token id to text:  cumul\n",
      "text to token id: 4995\n",
      "token id to text:  cumulatively\n",
      "text to token id: 4996\n",
      "token id to text:  constituted\n",
      "text to token id: 4997\n",
      "token id to text: \".\n",
      "\n",
      "text to token id: 4998\n",
      "token id to text: Am\n",
      "text to token id: 4999\n",
      "token id to text: Amidst\n"
     ]
    }
   ],
   "source": [
    "new_vocab_range = range(256, len(tokenizer.vocab))\n",
    "reverse_vocab = {value: key for key, value in tokenizer.vocab.items()}\n",
    "\n",
    "for i in new_vocab_range:\n",
    "    text = tokenizer.vocab.get(i)\n",
    "    token_id = reverse_vocab.get(text)\n",
    "    print(f'text to token id: {tokenizer.encode_single(text)}')\n",
    "    print(f'token id to text: {tokenizer.decode_single(token_id)}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
